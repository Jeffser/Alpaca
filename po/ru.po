# Russian translations for Alpaca.
# Copyright (C) 2024 Jeffser
# This file is distributed under the same license as the Alpaca package.
# (YOUR NAME) <(EMAIL OPTIONAL)>
#
msgid ""
msgstr ""
"Project-Id-Version: 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-07-08 11:01+0800\n"
"PO-Revision-Date: 2024-07-08 17:18+0800\n"
"Last-Translator: (YOUR NAME) <(EMAIL OPTIONAL)>\n"
"Language-Team: Russian\n"
"Language: ru\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: Poedit 3.4.4\n"
"X-Poedit-Basepath: ../src\n"
"X-Poedit-SearchPath-0: .\n"

#: available_models_descriptions.py:2
msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
msgstr "Google Gemma 2 —Ç–µ–ø–µ—Ä—å –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –¥–≤—É—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö: 9B –∏ 27B."

#: available_models_descriptions.py:3
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: –°–∞–º—ã–π –º–æ—â–Ω—ã–π –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö LLM –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å"

#: available_models_descriptions.py:4
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 ‚Äî –Ω–æ–≤–∞—è —Å–µ—Ä–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç –≥—Ä—É–ø–ø—ã Alibaba"

#: available_models_descriptions.py:5
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"–ú–æ–¥–µ–ª—å —è–∑—ã–∫–∞ –∫–æ–¥–∞ Mixture-of-Experts —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, "
"–æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Å—Ä–∞–≤–Ω–∏–º—É—é —Å GPT4-Turbo, –≤ –∑–∞–¥–∞—á–∞—Ö, "
"—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –∫–æ–¥–∞."

#: available_models_descriptions.py:6
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –ª–µ–≥–∫–∏—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π 3B (Mini) –∏ 14B "
"(Medium) –æ—Ç Microsoft."

#: available_models_descriptions.py:7
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, –≤—ã–ø—É—â–µ–Ω–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏–µ–π Cohere, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–æ–≤–æ–µ —Å–µ–º–µ–π—Å—Ç–≤–æ "
"—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏—Ö 23 —è–∑—ã–∫–∞."

#: available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "–ú–æ–¥–µ–ª—å 7–ë, –≤—ã–ø—É—â–µ–Ω–Ω–∞—è Mistral AI, –æ–±–Ω–æ–≤–ª–µ–Ω–∞ ‚Äã‚Äã–¥–æ –≤–µ—Ä—Å–∏–∏ 0.3."

#: available_models_descriptions.py:9
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"–ù–∞–±–æ—Ä –º–æ–¥–µ–ª–∏ Mixture of Experts (MoE) —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –≤–µ—Å–∞–º–∏ –æ—Ç Mistral AI —Å "
"—Ä–∞–∑–º–µ—Ä–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ 8x7b –∏ 8x22b."

#: available_models_descriptions.py:10
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –º–æ—â–Ω—ã—Ö –∏ –ª–µ–≥–∫–∏—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å "
"—Ä–∞–∑–ª–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫–æ–¥–∞ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ–º "
"–ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞, –ø–æ–Ω–∏–º–∞–Ω–∏–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ "
"—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π."

#: available_models_descriptions.py:11
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R ‚Äî —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ "
"–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∏ –∑–∞–¥–∞—á —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º."

#: available_models_descriptions.py:12
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ ‚Äî —ç—Ç–æ –º–æ—â–Ω–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è –º–æ–¥–µ–ª—å –±–æ–ª—å—à–æ–≥–æ —è–∑—ã–∫–∞, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ "
"—Å–æ–∑–¥–∞–Ω–Ω–∞—è –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —É—Å–ø–µ—Ö–∞ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö "
"–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."

#: available_models_descriptions.py:13
msgid ""
"üåã LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"üåã LLaVA ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ–±—É—á–µ–Ω–Ω–∞—è –±–æ–ª—å—à–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, "
"–∫–æ—Ç–æ—Ä–∞—è —Å–æ—á–µ—Ç–∞–µ—Ç –≤ —Å–µ–±–µ –≤–∏–¥–µ–æ–∫–æ–¥–µ—Ä –∏ Vicuna –¥–ª—è –æ–±—â–µ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∏ "
"—è–∑—ã–∫–æ–≤–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ 1.6."

#: available_models_descriptions.py:14
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –ª–µ–≥–∫–∏—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö Google "
"DeepMind. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ 1.1"

#: available_models_descriptions.py:15
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5¬†‚Äî —ç—Ç–æ —Å–µ—Ä–∏—è –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç Alibaba Cloud —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ "
"–æ—Ç 0,5 –¥–æ 110¬†B"

#: available_models_descriptions.py:16
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –±–∞–∑–æ–≤—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ—Ç 7B –¥–æ 70B."

#: available_models_descriptions.py:17
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"–ë–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è "
"—Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∫–æ–¥–∞."

#: available_models_descriptions.py:18
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"–ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ 8x7b –∏ 8x22b, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ —Å–º–µ—Å–∏ "
"—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Mixtral, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –∑–∞–¥–∞—á–∞–º–∏ "
"–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –°–æ–∑–¥–∞–Ω –≠—Ä–∏–∫–æ–º –•–∞—Ä—Ç—Ñ–æ—Ä–¥–æ–º."

#: available_models_descriptions.py:19
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "–ú–æ–¥–µ–ª—å Llama 2 –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã –æ—Ç –î–∂–æ—Ä–¥–∂–∞ –°–∞–Ω–≥–∞ –∏ –î–∂–∞—Ä—Ä–∞–¥–∞ –•–æ—É–ø–∞."

#: available_models_descriptions.py:20
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder ‚Äî —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –¥–≤—É—Ö "
"—Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö –∫–æ–¥–∞ –∏ —Ç–æ–∫–µ–Ω–∞—Ö –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞."

#: available_models_descriptions.py:21
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Å –±–æ–ª—å—à–∏–º –æ–∫–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ "
"—Ç–æ–∫–µ–Ω–∞."

#: available_models_descriptions.py:22
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å 2,7B –æ—Ç Microsoft Research, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∞—è "
"–≤—ã–¥–∞—é—â–∏–µ—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—é —è–∑—ã–∫–∞."

#: available_models_descriptions.py:23
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"–ú–æ–¥–µ–ª—å Dolphin –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Mistral, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ "
"—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–∞–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ 2.8."

#: available_models_descriptions.py:24
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å 7 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –Ω–∞ "
"–æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏ Mistral 7B —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö OpenOrca."

#: available_models_descriptions.py:25
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"–ú–æ–¥–µ–ª—å –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å —á–∏—Å–ª–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç 3 –¥–æ 70 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤, "
"–ø–æ–¥—Ö–æ–¥—è—â–∞—è –¥–ª—è –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è."

#: available_models_descriptions.py:26
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è –æ—Ç mixbread.ai"

#: available_models_descriptions.py:27
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ä–∞–∑–º–µ—Ä–æ–≤ 8B –∏ 70B, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –≠—Ä–∏–∫–æ–º "
"–•–∞—Ä—Ç—Ñ–æ—Ä–¥–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 3, –∫–æ—Ç–æ—Ä–∞—è –æ–±–ª–∞–¥–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –Ω–∞–≤—ã–∫–∞–º–∏ "
"–æ–±—É—á–µ–Ω–∏—è, –æ–±—â–µ–Ω–∏—è –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."

#: available_models_descriptions.py:28
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 ‚Äî —ç—Ç–æ —Å–ª–µ–¥—É—é—â–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ LLM —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –æ–±—É—á–µ–Ω–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç—ã–º "
"–∫–æ–¥–æ–º, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤ —Ç—Ä–µ—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã 3B, 7B –∏ 15B."

#: available_models_descriptions.py:29
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 2 –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤ –¥–∏–∞–ª–æ–≥–∞ –Ω–∞ "
"–∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ."

#: available_models_descriptions.py:30
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr ‚Äî —ç—Ç–æ —Å–µ—Ä–∏—è –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–µ–π Mistral –∏ Mixtral, –∫–æ—Ç–æ—Ä—ã–µ "
"–æ–±—É—á–µ–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å —Ä–æ–ª—å –ø–æ–ª–µ–∑–Ω—ã—Ö –ø–æ–º–æ—â–Ω–∏–∫–æ–≤."

#: available_models_descriptions.py:31
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 ‚Äî —ç—Ç–æ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –¥–≤—É—è–∑—ã—á–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å."

#: available_models_descriptions.py:32
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"–ú–æ—â–Ω–æ–µ —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –æ—Ç Nous Research, –∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å "
"–∑–∞–¥–∞—á–∞–º–∏ –Ω–∞—É—á–Ω–æ–≥–æ –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è."

#: available_models_descriptions.py:33
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"–ú–æ–¥–µ–ª—å —á–∞—Ç–∞ –æ–±—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama –∏ Llama 2 —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ "
"–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç 2 –¥–æ 16 –ö–ë."

#: available_models_descriptions.py:34
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 7B, 13B –∏ 30B, "
"–æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Llama 2 –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã –≠—Ä–∏–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞."

#: available_models_descriptions.py:35
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"–ü—Ä–æ–µ–∫—Ç TinyLlama ‚Äî —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–∏—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –º–æ–¥–µ–ª—å Llama "
"—Ä–∞–∑–º–µ—Ä–æ–º 1,1B –Ω–∞ 3 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤."

#: available_models_descriptions.py:36
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –±–æ–ª—å—à–æ–≥–æ —è–∑—ã–∫–∞ –æ—Ç Microsoft AI —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π "
"–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –≤ —Å–ª–æ–∂–Ω—ã—Ö —á–∞—Ç–∞—Ö, –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö, —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏ "
"—Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤."

#: available_models_descriptions.py:37
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –±–æ–ª–µ–µ —á–µ–º 80 —è–∑—ã–∫–∞—Ö "
"–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."

#: available_models_descriptions.py:38
msgid ""
"Codestral is Mistral AI‚Äôs first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral ‚Äî —ç—Ç–æ –ø–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å –∫–æ–¥–∞ Mistral AI, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∑–∞–¥–∞—á "
"–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞."

#: available_models_descriptions.py:39
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"–°–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –æ–±—É—á–µ–Ω–Ω—ã—Ö –Ω–∞ —à–∏—Ä–æ–∫–æ–º —Å–ø–µ–∫—Ç—Ä–µ "
"–¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏—Ö ChatGPT –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ "
"3.5-0106."

#: available_models_descriptions.py:40
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 1.1B, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –Ω–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ "
"–¥–∞–Ω–Ω—ã—Ö Dolphin 2.8 –≠—Ä–∏–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞ –∏ –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ TinyLlama."

#: available_models_descriptions.py:41
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å 7B, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è Teknium –Ω–∞ Mistral —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é "
"–æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö."

#: available_models_descriptions.py:42
msgid "State-of-the-art code generation model"
msgstr "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞"

#: available_models_descriptions.py:43
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"–°—Ç–∞–±–∏–ª—å–Ω—ã–π –∫–æ–¥ 3B ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ "
"–∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–¥–∞ –Ω–∞—Ä–∞–≤–Ω–µ —Å —Ç–∞–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏, –∫–∞–∫ Code Llama 7B, –∫–æ—Ç–æ—Ä—ã–µ –≤ 2,5 "
"—Ä–∞–∑–∞ –±–æ–ª—å—à–µ."

#: available_models_descriptions.py:44
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"–î–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ Mistral —Å —Ö–æ—Ä–æ—à–∏–º –æ—Ö–≤–∞—Ç–æ–º –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏ "
"—è–∑—ã–∫–∞."

#: available_models_descriptions.py:45
msgid "Model focused on math and logic problems"
msgstr "–ú–æ–¥–µ–ª—å –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏"

#: available_models_descriptions.py:46
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 ‚Äî —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ "
"–±–æ–ª—å—à–æ–º –æ–±—ä–µ–º–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–¥–∞."

#: available_models_descriptions.py:47
msgid "Code generation model based on Code Llama."
msgstr "–ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Code Llama."

#: available_models_descriptions.py:48
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 ‚Äî —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 1,6B –∏ 12B, "
"–æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –∏—Å–ø–∞–Ω—Å–∫–æ–º, –Ω–µ–º–µ—Ü–∫–æ–º, "
"–∏—Ç–∞–ª—å—è–Ω—Å–∫–æ–º, —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º, –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–æ–º –∏ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–º —è–∑—ã–∫–∞—Ö."

#: available_models_descriptions.py:49
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"–í–∞—Ä–∏–∞–Ω—Ç —Å–µ–º–µ–π—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π Dolphin 7B –∏ 15B –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π –≤ "
"–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏, –Ω–∞ –æ—Å–Ω–æ–≤–µ StarCoder2."

#: available_models_descriptions.py:50
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"–í—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π."

#: available_models_descriptions.py:51
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "–ú–æ–¥–µ–ª–∏ –æ–±—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ –±–∞–∑–µ Llama –∏ Llama 2 –æ—Ç Nous Research."

#: available_models_descriptions.py:52
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling ‚Äî —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å "
"–ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∑—ã–≤–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –Ω–∞ "
"–ø–æ–≤—ã—à–µ–Ω–∏–µ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ —á–∞—Ç-–±–æ—Ç–∞."

#: available_models_descriptions.py:53
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–¥–∞, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤ StarCoder –¥–ª—è –∑–∞–¥–∞—á "
"–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL"

#: available_models_descriptions.py:54
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 —Å–æ–∑–¥–∞–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π Microsoft –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π "
"–¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–µ–π Meta 2 Llama 2. –ú–æ–¥–µ–ª—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞, —á—Ç–æ–±—ã "
"–ø—Ä–µ—É—Å–ø–µ—Ç—å, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö."

#: available_models_descriptions.py:55
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"–≠—Ç–∞ –º–æ–¥–µ–ª—å —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ LLama-3 8B —Å 8 —Ç—ã—Å. –¥–æ –±–æ–ª–µ–µ —á–µ–º 1 "
"–º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤."

#: available_models_descriptions.py:56
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"–£—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ 2 —Ç—Ä–∏–ª–ª–∏–æ–Ω–æ–≤ "
"–¥–≤—É—è–∑—ã—á–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤."

#: available_models_descriptions.py:57
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Llama 2, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ 128 —Ç—ã—Å. —Ç–æ–∫–µ–Ω–æ–≤."

#: available_models_descriptions.py:58
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"–ú–æ–¥–µ–ª—å –æ—Ç NVIDIA –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 3, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å "
"–¥–∏–∞–ª–æ–≥–æ–≤—ã–º –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã (QA) –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (RAG)."

#: available_models_descriptions.py:59
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è, –Ω–æ –º–æ—â–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 10,7 –ë–ë, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è "
"–¥–ª—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."

#: available_models_descriptions.py:60
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"–î–∏–∞–ª–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ Llama 2, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–∞—è –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º "
"–ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º."

#: available_models_descriptions.py:61
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "–°–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Ñ–æ–Ω–¥–∞ –æ—Ç IBM –¥–ª—è Code Intelligence"

#: available_models_descriptions.py:62
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"2.7B –º–æ–¥–µ–ª—å Dolphin –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã –≠—Ä–∏–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –º–æ–¥–µ–ª–∏ —è–∑—ã–∫–∞ "
"Phi, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–π Microsoft Research."

#: available_models_descriptions.py:63
msgid "General use model based on Llama 2."
msgstr "–ú–æ–¥–µ–ª—å –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –±–∞–∑–µ Llama 2."

#: available_models_descriptions.py:64
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"–ü–æ–º–æ—â–Ω–∏–∫-–∫–æ–º–ø–∞–Ω—å–æ–Ω, –ø—Ä–æ—à–µ–¥—à–∏–π –æ–±—É—á–µ–Ω–∏–µ –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏, –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏ –∏ "
"–ª–∏—á–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. –ù–∞ –±–∞–∑–µ –ú–∏—Å—Ç—Ä–∞–ª—è."

#: available_models_descriptions.py:65
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 2 —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–∏–ª–µ Orca. "
"–ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ –Ω–∞–∑—ã–≤–∞–ª—Å—è –°–≤–æ–±–æ–¥–Ω—ã–π –í–∏–ª–ª–∏."

#: available_models_descriptions.py:66
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA ‚Äî –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, —Å–æ—Å—Ç–æ—è—â–∞—è –∏–∑ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ Mistral 7B, "
"–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π LLaVA."

#: available_models_descriptions.py:67
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"–ú–æ–¥–µ–ª—å LLaVA, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 3 Instruct, —Å –ª—É—á—à–∏–º–∏ "
"–ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ—Å—Ç–∞—Ö."

#: available_models_descriptions.py:68
msgid "Uncensored version of Wizard LM model"
msgstr "–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ Wizard LM –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã"

#: available_models_descriptions.py:69
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"–¢–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ Llama 2 –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ "
"–Ω–∞–±–æ—Ä–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º."

#: available_models_descriptions.py:70
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"–ú–æ–¥–µ–ª—å Nous Hermes 2 –æ—Ç Nous Research, –∫–æ—Ç–æ—Ä–∞—è —Ç–µ–ø–µ—Ä—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ Mixtral."

#: available_models_descriptions.py:71
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Mistral –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –æ–∫–æ–Ω —Ä–∞–∑–º–µ—Ä–æ–º 64 –ö–ë –∏–ª–∏ 128 –ö–ë."

#: available_models_descriptions.py:72
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"–ù–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ—Ç Snowflake, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è "
"–ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."

#: available_models_descriptions.py:73
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Llama 2, –∫–æ—Ç–æ—Ä–æ–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–∞–∫ –æ–±—â–µ–≥–æ "
"–ø–æ–Ω–∏–º–∞–Ω–∏—è —è–∑—ã–∫–∞, —Ç–∞–∫ –∏ –∑–Ω–∞–Ω–∏–π –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ "
"–æ–±–ª–∞—Å—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏."

#: available_models_descriptions.py:74
msgid "Great code generation model based on Llama2."
msgstr "–û—Ç–ª–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama2."

#: available_models_descriptions.py:75
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"–ë–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å  —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–∑ Llama "
"2 –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Å—Ñ–µ—Ä—ã."

#: available_models_descriptions.py:76
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 ‚Äî —ç—Ç–æ –Ω–µ–±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –≤–∏–¥–µ–Ω–∏—è, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è "
"—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö."

#: available_models_descriptions.py:77
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama2 –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ 16 –ö–ë."

#: available_models_descriptions.py:78
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 13B –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è –∑–∞–¥–∞—á –≤—ã–∑–æ–≤–∞ "
"—Ñ—É–Ω–∫—Ü–∏–π."

#: available_models_descriptions.py:79
msgid ""
"üé© Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"üé© Magicoder ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –æ–±—É—á–µ–Ω–Ω—ã—Ö –Ω–∞ 75 000 "
"—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OSS-Instruct, –Ω–æ–≤–æ–≥–æ "
"–ø–æ–¥—Ö–æ–¥–∞ –∫ –æ–±—É—á–µ–Ω–∏—é LLM —Å –ø–æ–º–æ—â—å—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∫–æ–¥–∞ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º."

#: available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "–°–∏–ª—å–Ω–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å ¬´–°–º–µ—Å—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤¬ª."

#: available_models_descriptions.py:81
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"–û–±–ª–µ–≥—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —á–∞—Ç–∞, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∞—è —Ç–æ—á–Ω—ã–π –∏ –±—ã—Å—Ç—Ä—ã–π –≤—ã–≤–æ–¥ –±–µ–∑ "
"–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è."

#: available_models_descriptions.py:82
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∫–æ–¥–∞, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –ø—É—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è "
"–¥–≤—É—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π –∫–æ–¥–∞."

#: available_models_descriptions.py:83
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "–ù–æ–≤–∞—è –º–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å LLaVA, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Phi 3 Mini."

#: available_models_descriptions.py:84
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite ‚Äî –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ Mistral —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ "
"–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤."

#: available_models_descriptions.py:85
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å 13B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Llama 2, "
"–æ–±—É—á–µ–Ω–Ω–∞—è MelodysDreamj."

#: available_models_descriptions.py:86
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"–ú–æ–¥–µ–ª—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ SQL —Å 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, —Å–æ–∑–¥–∞–Ω–Ω–∞—è MotherDuck –∏ "
"Numbers Station."

#: available_models_descriptions.py:87
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –ø—É—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–≤—É—Ö —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π "
"Llama 2 70B –≤ –æ–¥–Ω—É."

#: available_models_descriptions.py:88
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b ‚Äî —ç—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è Dolphin-2.2-70b, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –ø—É—Ç–µ–º "
"—á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–∞–º–æ–π —Å —Å–æ–±–æ–π."

#: available_models_descriptions.py:89
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"–°–ª–∏—è–Ω–∏–µ –º–æ–¥–µ–ª–∏ Open Orca OpenChat –∏ –º–æ–¥–µ–ª–∏ Garage-bAInd Platypus 2. "
"–ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è —á–∞—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞."

#: available_models_descriptions.py:90
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"–í—ã—Å–æ–∫–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏, —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ "
"–≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."

#: available_models_descriptions.py:91
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"–ú–æ–¥–µ–ª—å —á–∞—Ç–∞ 7B, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è "
"–Ω–∞ Zephyr."

#: available_models_descriptions.py:92
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX ‚Äî —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è LLM –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è, —Å–æ–∑–¥–∞–Ω–Ω–∞—è Databricks."

#: available_models_descriptions.py:93
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –ø—Ä–∏—á–∏–Ω–Ω–æ–≥–æ –¥–µ–∫–æ–¥–µ—Ä–∞ —Å 11B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω–∞—è TII –∏ "
"–æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ —Ç–æ–∫–µ–Ω–∞—Ö 5T."

#: available_models_descriptions.py:94
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"–ù–∞–¥–µ–∂–Ω–∞—è –¥–∏–∞–ª–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∫ –≤ —á–∞—Ç–µ, "
"—Ç–∞–∫ –∏ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π."

#: dialogs.py:17
msgid "Chat cannot be cleared while receiving a message"
msgstr "–ß–∞—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"

#: dialogs.py:20
msgid "Clear Chat?"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç?"

#: dialogs.py:21
msgid "Are you sure you want to clear the chat?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –æ—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç?"

#: dialogs.py:24 dialogs.py:45 dialogs.py:72 dialogs.py:99 dialogs.py:121
#: dialogs.py:142 dialogs.py:163 dialogs.py:223 dialogs.py:308 dialogs.py:346
msgid "Cancel"
msgstr "–û—Ç–º–µ–Ω–∞"

#: dialogs.py:25
msgid "Clear"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å"

#: dialogs.py:41
msgid "Delete Chat?"
msgstr "–£–¥–∞–ª–∏—Ç—å —á–∞—Ç?"

#: dialogs.py:42 dialogs.py:139
msgid "Are you sure you want to delete '{}'?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å '{}'?"

#: dialogs.py:46 dialogs.py:143
msgid "Delete"
msgstr "–£–¥–∞–ª–∏—Ç—å"

#: dialogs.py:66
msgid "Rename Chat?"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —á–∞—Ç?"

#: dialogs.py:67
msgid "Renaming '{}'"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ '{}'"

#: dialogs.py:73
msgid "Rename"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å"

#: dialogs.py:84 window.py:58 window.py:1042 window.py:1104 window.ui:41
msgid "New Chat"
msgstr "–ù–æ–≤—ã–π –ß–∞—Ç"

#: dialogs.py:93
msgid "Create Chat?"
msgstr "–°–æ–∑–¥–∞—Ç—å —á–∞—Ç?"

#: dialogs.py:94
msgid "Enter name for new chat"
msgstr "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞"

#: dialogs.py:100 window.ui:469
msgid "Create"
msgstr "–°–æ–∑–¥–∞—Ç—å"

#: dialogs.py:117
msgid "Stop Download?"
msgstr "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É?"

#: dialogs.py:118
msgid "Are you sure you want to stop pulling '{} ({})'?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ '{} ({})'?"

#: dialogs.py:122
msgid "Stop"
msgstr "–°—Ç–æ–ø"

#: dialogs.py:138
msgid "Delete Model?"
msgstr "–£–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å?"

#: dialogs.py:159
msgid "Remove Attachment?"
msgstr "–£–¥–∞–ª–∏—Ç—å –≤–ª–æ–∂–µ–Ω–∏–µ?"

#: dialogs.py:160
msgid "Are you sure you want to remove attachment?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å –≤–ª–æ–∂–µ–Ω–∏–µ?"

#: dialogs.py:164
msgid "Remove"
msgstr "–£–¥–∞–ª–∏—Ç—å"

#: dialogs.py:189
msgid "Connection Error"
msgstr "–û—à–∏–±–∫–∞ –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è"

#: dialogs.py:190
msgid "The remote instance has disconnected"
msgstr "–£–¥–∞–ª–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ—Ç–∫–ª—é—á–∏–ª—Å—è"

#: dialogs.py:194
msgid "Close Alpaca"
msgstr "–ó–∞–∫—Ä—ã—Ç—å –ü—Ä–æ–≥—Ä–∞–º–º—É"

#: dialogs.py:195
msgid "Use local instance"
msgstr "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä"

#: dialogs.py:196
msgid "Connect"
msgstr "–ü–æ–¥–∫–ª—é—á–∏—Ç—å"

#: dialogs.py:219
msgid "Select Model"
msgstr "–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏"

#: dialogs.py:220
msgid "This model will be used as the base for the new model"
msgstr "–≠—Ç–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –±–∞–∑–æ–≤–æ–π –¥–ª—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏"

#: dialogs.py:224 dialogs.py:309 dialogs.py:347
msgid "Accept"
msgstr "–ü—Ä–∏–Ω—è—Ç—å"

#: dialogs.py:238
msgid "An error occurred while creating the model"
msgstr "–ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"

#: dialogs.py:258 window.py:1403
msgid "Image recognition is only available on specific models"
msgstr "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"

#: dialogs.py:294
msgid "This video does not have any transcriptions"
msgstr "–í —ç—Ç–æ–º –≤–∏–¥–µ–æ –Ω–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–æ–∫"

#: dialogs.py:303
msgid "Attach YouTube Video?"
msgstr "–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –≤–∏–¥–µ–æ —Å YouTube?"

#: dialogs.py:304
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è"

#: dialogs.py:337
msgid "An error occurred while extracting text from the website"
msgstr "–ü—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –≤–µ–±-—Å–∞–π—Ç–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"

#: dialogs.py:342
msgid "Attach Website? (Experimental)"
msgstr "–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –≤–µ–±-—Å–∞–π—Ç? (–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π)"

#: dialogs.py:343
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å\n"
"\"{}\"?"

#: gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "–û–±—â–∏–µ"

#: gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∫–ª–∞–≤–∏—à"

#: gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Quit"
msgstr "–í—ã–π—Ç–∏"

#: window.py:167
msgid "Message edited successfully"
msgstr "–°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–æ"

#: window.py:182
msgid "Please select a model before chatting"
msgstr "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—â–µ–Ω–∏—è"

#: window.py:249
msgid "Close"
msgstr "–ó–∞–∫—Ä—ã—Ç—å"

#: window.py:250 window.ui:813
msgid "Next"
msgstr "–°–ª–µ–¥—É—é—â–∏–π"

#: window.py:283 window.py:294
msgid "Failed to connect to server"
msgstr "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É"

#: window.py:301
msgid "Pulling in the background..."
msgstr "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ..."

#: window.py:353
msgid "Stop Creating '{}'"
msgstr "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ '{}'"

#: window.py:390
msgid "image"
msgstr "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"

#: window.py:458
msgid "Message copied to the clipboard"
msgstr "–°–æ–æ–±—â–µ–Ω–∏–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞"

#: window.py:559
msgid "Remove Message"
msgstr "–£–¥–∞–ª–∏—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: window.py:564 window.py:835
msgid "Copy Message"
msgstr "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: window.py:569
msgid "Edit Message"
msgstr "–ò–∑–º–µ–Ω–∏—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: window.py:627
msgid "Missing Image"
msgstr "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

#: window.py:643
msgid "Missing image"
msgstr "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

#: window.py:723
msgid "Remove '{} ({})'"
msgstr "–£–¥–∞–ª–∏—Ç—å '{} ({})'"

#: window.py:861
msgid "Code copied to the clipboard"
msgstr "–ö–æ–¥ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞"

#: window.py:934
msgid "Task Complete"
msgstr "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"

#: window.py:934
msgid "Model '{}' pulled successfully."
msgstr "–ú–æ–¥–µ–ª—å '{}' —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∞."

#: window.py:939
msgid "Pull Model Error"
msgstr "–û—à–∏–±–∫–∞ –ò–∑–≤–ª–µ—á–µ–Ω–∏—è –ú–æ–¥–µ–ª–∏"

#: window.py:939
msgid "Failed to pull model '{}' due to network error."
msgstr "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–æ–¥–µ–ª—å '{}' –∏–∑-–∑–∞ —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–∏."

#: window.py:970
msgid "Stop Pulling '{} ({})'"
msgstr "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ '{} ({})'"

#: window.py:1010
msgid "Image Recognition"
msgstr "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

#: window.py:1118
msgid "Model deleted successfully"
msgstr "–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞"

#: window.py:1192
msgid "There was an error with the local Ollama instance, so it has been reset"
msgstr ""
"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º Ollama, –ø–æ—ç—Ç–æ–º—É –æ–Ω –±—ã–ª —Å–±—Ä–æ—à–µ–Ω"

#: window.py:1211
msgid "Chat exported successfully"
msgstr "–ß–∞—Ç —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"

#: window.py:1279
msgid "Chat imported successfully"
msgstr "–ß–∞—Ç —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"

#: window.py:1309
msgid "Cannot open image"
msgstr "–ù–µ —É–¥–∞–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"

#: window.py:1386
msgid "This video is not available"
msgstr "–≠—Ç–æ –≤–∏–¥–µ–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"

#: window.ui:52
msgid "Menu"
msgstr "–ú–µ–Ω—é"

#: window.ui:82
msgid "Toggle Sidebar"
msgstr "–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏"

#: window.ui:107 window.ui:587
msgid "Manage Models"
msgstr "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ú–æ–¥–µ–ª—è–º–∏"

#: window.ui:121
msgid "Chat Menu"
msgstr "–ú–µ–Ω—é —á–∞—Ç–∞"

#: window.ui:197
msgid "Attach File"
msgstr "–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–∞–π–ª"

#: window.ui:242 window.ui:1127
msgid "Send Message"
msgstr "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: window.ui:290 window.ui:972 window.ui:1086
msgid "Preferences"
msgstr "–ù–∞—Å—Ç—Ä–æ–π–∫–∏"

#: window.ui:293 window.ui:1064
msgid "General"
msgstr "–û–±—â–∏–µ"

#: window.ui:299
msgid "Use Remote Connection to Ollama"
msgstr "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–¥–∞–ª–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama"

#: window.ui:305
msgid "URL of Remote Instance"
msgstr "URL —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞"

#: window.ui:312
msgid "Bearer Token (Optional)"
msgstr "–¢–æ–∫–µ–Ω –Ω–∞ –ø—Ä–µ–¥—ä—è–≤–∏—Ç–µ–ª—è (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)"

#: window.ui:322
msgid "Run Alpaca In Background"
msgstr "–ó–∞–ø—É—Å–∫ Alpaca –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"

#: window.ui:333
msgid "Temperature"
msgstr "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞"

#: window.ui:334
msgid ""
"The temperature of the model. Increasing the temperature will make the model "
"answer more creatively. (Default: 0.8)"
msgstr ""
"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏. –ü—Ä–∏ –ø–æ–≤—ã—à–µ–Ω–∏–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–µ "
"—Ç–≤–æ—Ä—á–µ—Å–∫–∏. (–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0,8)"

#: window.ui:349
msgid "Seed"
msgstr "–ó–µ—Ä–Ω–æ"

#: window.ui:350
msgid ""
"Sets the random number seed to use for generation. Setting this to a "
"specific number will make the model generate the same text for the same "
"prompt. (Default: 0 (random))"
msgstr ""
"–ó–∞–¥–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è "
"–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –∑–∞—Å—Ç–∞–≤–∏—Ç –º–æ–¥–µ–ª—å "
"–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –∑–∞–ø—Ä–æ—Å–∞. (–ü–æ "
"—É–º–æ–ª—á–∞–Ω–∏—é: 0 (—Å–ª—É—á–∞–π–Ω—ã–π))"

#: window.ui:364
msgid "Keep Alive Time"
msgstr "–í—Ä–µ–º—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∂–∏–∑–Ω–∏"

#: window.ui:365
msgid ""
"Controls how long the model will stay loaded into memory following the "
"request in minutes (Default: 5)"
msgstr ""
"–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫ –¥–æ–ª–≥–æ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –≤ –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ "
"–º–∏–Ω—É—Ç–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)."

#: window.ui:381
msgid "Ollama Instance"
msgstr "–≠–∫–∑–µ–º–ø–ª—è—Ä Ollama"

#: window.ui:385
msgid "Ollama Overrides"
msgstr "–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è Ollama"

#: window.ui:386
msgid ""
"Manage the arguments used on Ollama, any changes on this page only applies "
"to the integrated instance, the instance will restart if you make changes."
msgstr ""
"–£–ø—Ä–∞–≤–ª—è–π—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º–∏ –≤ Ollama, –ª—é–±—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞ —ç—Ç–æ–π "
"—Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º—ã —Ç–æ–ª—å–∫–æ –∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —ç–∫–∑–µ–º–ø–ª—è—Ä—É, —ç–∫–∑–µ–º–ø–ª—è—Ä –±—É–¥–µ—Ç "
"–ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω, –µ—Å–ª–∏ –≤—ã –≤–Ω–µ—Å–µ—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è."

#: window.ui:482 window.ui:597
msgid "Create Model"
msgstr "–°–æ–∑–¥–∞—Ç—å –ú–æ–¥–µ–ª—å"

#: window.ui:508
msgid "Base"
msgstr "–û—Å–Ω–æ–≤–∞"

#: window.ui:526
msgid "Name"
msgstr "–ò–º—è"

#: window.ui:532
msgid "Context"
msgstr "–ö–æ–Ω—Ç–µ–∫—Å—Ç"

#: window.ui:547
msgid "Template"
msgstr "–®–∞–±–ª–æ–Ω"

#: window.ui:553
msgid ""
"Some models require a specific template. Please visit the model's website "
"for more information if you're unsure."
msgstr ""
"–î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —à–∞–±–ª–æ–Ω. –ï—Å–ª–∏ –≤—ã –Ω–µ —É–≤–µ—Ä–µ–Ω—ã, "
"–ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ—Å–µ—Ç–∏—Ç–µ –≤–µ–±-—Å–∞–π—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

#: window.ui:604
msgid "Search Model"
msgstr "–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏"

#: window.ui:617
msgid "Search models"
msgstr "–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π"

#: window.ui:664
msgid "No Models Found"
msgstr "–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

#: window.ui:665
msgid "Try a different search"
msgstr "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –ø–æ–∏—Å–∫"

#: window.ui:708
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website."
msgstr ""
"–ó–∞–≥—Ä—É–∂–∞—è —ç—Ç—É –º–æ–¥–µ–ª—å, –≤—ã –ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ, –¥–æ—Å—Ç—É–ø–Ω–æ–µ –Ω–∞ –≤–µ–±-"
"—Å–∞–π—Ç–µ –º–æ–¥–µ–ª–∏."

#: window.ui:745
msgid "Open with Default App"
msgstr "–û—Ç–∫—Ä—ã—Ç—å —Å –ø–æ–º–æ—â—å—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"

#: window.ui:797
msgid "Previous"
msgstr "–ü—Ä–µ–¥—ã–¥—É—â–∏–π"

#: window.ui:840
msgid "Welcome to Alpaca"
msgstr "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Alpaca"

#: window.ui:841
msgid "Powered by Ollama"
msgstr "–ü—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ Ollama"

#: window.ui:844
msgid "Ollama Website"
msgstr "–í–µ–±-—Å–∞–π—Ç Ollama"

#: window.ui:860
msgid "Disclaimer"
msgstr "–û—Ç–∫–∞–∑ –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"

#: window.ui:861
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it."
msgstr ""
"Alpaca –∏ –µ–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –Ω–µ –Ω–µ—Å—É—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –ª—é–±–æ–π —É—â–µ—Ä–±, "
"–ø—Ä–∏—á–∏–Ω–µ–Ω–Ω—ã–π —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º –∏–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º—É –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è "
"–∫–æ–¥–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. "
"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã –∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –æ–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –∫–æ–¥–æ–º –ø–µ—Ä–µ–¥ –µ–≥–æ "
"–∑–∞–ø—É—Å–∫–æ–º."

#: window.ui:872
msgid "Featured Models"
msgstr "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏"

#: window.ui:873
msgid ""
"Alpaca works locally on your device, to start chatting you'll need an AI "
"model, you can either pull models from this list or the 'Manage Models' menu "
"later."
msgstr ""
"Alpaca —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ –≤–∞—à–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ, "
"–≤–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –º–æ–¥–µ–ª—å —Å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º, –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏ "
"–∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –∏–∑ –º–µ–Ω—é \"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏\" –ø–æ–∑–∂–µ."

#: window.ui:883
msgid "Built by Meta"
msgstr "–ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å –ø–æ–º–æ—â—å—é Meta"

#: window.ui:901
msgid "Built by Google DeepMind"
msgstr "–°–æ–∑–¥–∞–Ω Google DeepMind"

#: window.ui:919
msgid "Built by Microsoft"
msgstr "–°–æ–∑–¥–∞–Ω –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–µ–π –ú–∞–π–∫—Ä–æ—Å–æ—Ñ—Ç"

#: window.ui:937
msgid "Multimodal AI with image recognition"
msgstr "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

#: window.ui:966
msgid "Import Chat"
msgstr "–ò–º–ø–æ—Ä—Ç –ß–∞—Ç–∞"

#: window.ui:976
msgid "Keyboard Shortcuts"
msgstr "–ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ö–ª–∞–≤–∏—à"

#: window.ui:980
msgid "About Alpaca"
msgstr "–û –ü—Ä–æ–≥—Ä–∞–º–º–µ"

#: window.ui:987 window.ui:1006
msgid "Rename Chat"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –ß–∞—Ç"

#: window.ui:991 window.ui:1010
msgid "Export Chat"
msgstr "–≠–∫—Å–ø–æ—Ä—Ç –ß–∞—Ç–∞"

#: window.ui:995
msgid "Clear Chat"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å –ß–∞—Ç"

#: window.ui:1002
msgid "Delete Chat"
msgstr "–£–¥–∞–ª–∏—Ç—å –ß–∞—Ç"

#: window.ui:1018
msgid "From Existing Model"
msgstr "–ò–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏"

#: window.ui:1022
msgid "From GGUF File (Experimental)"
msgstr "–ò–∑ —Ñ–∞–π–ª–∞ GGUF (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π)"

#: window.ui:1068
msgid "Close application"
msgstr "–ó–∞–∫—Ä—ã—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"

#: window.ui:1074
msgid "Import chat"
msgstr "–ò–º–ø–æ—Ä—Ç —á–∞—Ç–∞"

#: window.ui:1080
msgid "Clear chat"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç"

#: window.ui:1092
msgid "New chat"
msgstr "–ù–æ–≤—ã–π —á–∞—Ç"

#: window.ui:1098
msgid "Show shortcuts window"
msgstr "–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –∫–ª–∞–≤–∏—à"

#: window.ui:1105
msgid "Editor"
msgstr "–†–µ–¥–∞–∫—Ç–æ—Ä"

#: window.ui:1109
msgid "Copy"
msgstr "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å"

#: window.ui:1115
msgid "Paste"
msgstr "–í—Å—Ç–∞–≤–∏—Ç—å"

#: window.ui:1121
msgid "Insert new line"
msgstr "–í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É"
