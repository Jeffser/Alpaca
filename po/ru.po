# Russian translations for Alpaca package.
# Copyright (C) 2024 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# (YOUR NAME) <(EMAIL OPTIONAL)>
#
msgid ""
msgstr ""
"Project-Id-Version: 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-12-17 01:04-0600\n"
"PO-Revision-Date: 2024-07-08 17:18+0800\n"
"Last-Translator: (YOUR NAME) <(EMAIL OPTIONAL)>\n"
"Language-Team: Russian\n"
"Language: ru\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: Poedit 3.4.4\n"
"X-Poedit-Basepath: ../src\n"
"X-Poedit-SearchPath-0: .\n"

#: data/com.jeffser.Alpaca.desktop.in:3
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.desktop.in:9
msgid "ai;ollama;llm"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with local AI models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "An Ollama client"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
msgid "Built in Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Talk to multiple models in the same conversation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "Pull and delete models from the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Have multiple conversations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Image recognition (Only available with compatible models)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Plain text documents recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Import and export chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append YouTube transcripts to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "Append text from a website to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:22
msgid "PDF recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:24 src/window.ui:1038
msgid "Disclaimer"
msgstr "–û—Ç–∫–∞–∑ –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"

#: data/com.jeffser.Alpaca.metainfo.xml.in:25
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:54
msgid "A normal conversation with an AI Model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:58
msgid "A conversation involving image recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:62
msgid "A conversation showing code highlighting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:66
msgid "A Python script running inside integrated terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:70
msgid "A conversation involving a YouTube video transcript"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:74
msgid "Multiple models being downloaded"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:88
#: data/com.jeffser.Alpaca.metainfo.xml.in:98
#: data/com.jeffser.Alpaca.metainfo.xml.in:109
#: data/com.jeffser.Alpaca.metainfo.xml.in:123
#: data/com.jeffser.Alpaca.metainfo.xml.in:135
#: data/com.jeffser.Alpaca.metainfo.xml.in:151
#: data/com.jeffser.Alpaca.metainfo.xml.in:166
#: data/com.jeffser.Alpaca.metainfo.xml.in:201
#: data/com.jeffser.Alpaca.metainfo.xml.in:226
#: data/com.jeffser.Alpaca.metainfo.xml.in:257
#: data/com.jeffser.Alpaca.metainfo.xml.in:283
#: data/com.jeffser.Alpaca.metainfo.xml.in:305
#: data/com.jeffser.Alpaca.metainfo.xml.in:336
#: data/com.jeffser.Alpaca.metainfo.xml.in:358
#: data/com.jeffser.Alpaca.metainfo.xml.in:379
#: data/com.jeffser.Alpaca.metainfo.xml.in:394
#: data/com.jeffser.Alpaca.metainfo.xml.in:419
msgid "New"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:90
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:91
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:100
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "Added integration as Gnome Search Provider"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:102
msgid "Updated Ollama to v0.4.2 with new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "User messages are now compacted into bubbles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:113
#: data/com.jeffser.Alpaca.metainfo.xml.in:141
#: data/com.jeffser.Alpaca.metainfo.xml.in:155
#: data/com.jeffser.Alpaca.metainfo.xml.in:172
#: data/com.jeffser.Alpaca.metainfo.xml.in:183
#: data/com.jeffser.Alpaca.metainfo.xml.in:192
#: data/com.jeffser.Alpaca.metainfo.xml.in:209
#: data/com.jeffser.Alpaca.metainfo.xml.in:219
#: data/com.jeffser.Alpaca.metainfo.xml.in:236
#: data/com.jeffser.Alpaca.metainfo.xml.in:246
#: data/com.jeffser.Alpaca.metainfo.xml.in:293
#: data/com.jeffser.Alpaca.metainfo.xml.in:318
#: data/com.jeffser.Alpaca.metainfo.xml.in:343
#: data/com.jeffser.Alpaca.metainfo.xml.in:365
#: data/com.jeffser.Alpaca.metainfo.xml.in:383
#: data/com.jeffser.Alpaca.metainfo.xml.in:401
#: data/com.jeffser.Alpaca.metainfo.xml.in:413
#: data/com.jeffser.Alpaca.metainfo.xml.in:429
msgid "Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:115
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Details page for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:127
msgid "Added warning when model is too big for the device"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
msgid "Added AMD GPU indicator in preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:137
msgid "Better system for handling dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:138
msgid "Better system for handling instance switching"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:139
msgid "Remote connection dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:143
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:144
msgid "Better internal instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:153
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:157
msgid "Better handling of image recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:158
msgid "Remove unused files when canceling a model download"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:159
msgid "Better message blocks rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:168
msgid "Run bash and python scripts straight from chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:169
msgid "Updated Ollama to 0.3.12"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:170
msgid "New models!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:174
msgid "Fixed and made faster the launch sequence"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:175
msgid "Better detection of code blocks in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:176
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:185
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:194
msgid "Fixed message generation sometimes failing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Sidebar resizes with the window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "New welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:205
msgid "Message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:206
msgid "Updated Ollama to v0.3.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:207
msgid "A lot of new models provided by Ollama repository"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:211
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:212
msgid "Fixed image recognition on unsupported models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:221
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:222
msgid "Fixed image recognition with local images"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:223
msgid "Changed appearance of delete / stop model buttons"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:224
msgid "Fixed stop button crashing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:228
msgid "Made sidebar resize a little when the window is smaller"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "Instant launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:238
msgid "Fixed error on first run (welcome dialog)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:248
msgid "Fixed 'clear chat' option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:249
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:250
msgid "Fixed support for AMD GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:259
msgid "Model, message and chat systems have been rewritten"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "New models are available"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Ollama updated to v0.3.9"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Added support for multiple chat generations simultaneously"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid "Added experimental AMD GPU support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:264
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:265
msgid "Added animations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:266
msgid "Changed model manager / model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:267
msgid "Changed message appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:268
msgid "Added markdown and code blocks to user messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:269
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:270
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:271
msgid "Added inactivity timer to integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:274
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid "Better handling of focus on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Better general performance on the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:285
msgid "New duplicate chat option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Changed model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:287
msgid "Message entry is focused on launch and chat change"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:288
msgid "Message is focused when it's being edited"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:289
msgid "Added loading spinner when regenerating a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:290
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:291
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:295
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:296
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Fixed message generation not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:298
msgid "Fixed message edition not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Model manager opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid "Delete chat option in secondary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:309
msgid "New model selector popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:310
msgid "Standard shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:311
msgid "Model manager is navigable with keyboard"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Changed sidebar collapsing behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid "Focus indicators on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:315
msgid "Give message entry focus at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:316
msgid "Generally better code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:320
msgid "Better width for dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:321
msgid "Better compatibility with screen readers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:322
msgid "Fixed message regenerator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Removed 'Featured models' from welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:324
msgid "Added default buttons to dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:325
msgid "Fixed import / export of chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:326
msgid "Changed Python2 title to Python on code blocks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:327
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:328
msgid "Show date on stopped messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:329
msgid "Fix clear chat error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:338
msgid "Changed shortcuts to standards"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:339
msgid "Moved 'Manage Models' button to primary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
#: data/com.jeffser.Alpaca.metainfo.xml.in:362
msgid "Stable support for GGUF model files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
#: data/com.jeffser.Alpaca.metainfo.xml.in:616
msgid "General optimizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:345
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:346
msgid "Removed sponsor dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:347
msgid "Added sponsor link in about dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:348
msgid "Changed window and elements dimensions"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:349
msgid "Selected model changes when entering model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:350
msgid "Better image tooltips"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:351
msgid "GGUF Support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:360
msgid "Regenerate any response, even if they are incomplete"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid "Support for pulling models by name:tag"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:363
msgid "Restored sidebar toggle button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:367
msgid "Reverted back to standard styles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:368
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:369
msgid "Changed min width for model dropdown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:370
msgid "Changed message entry shadow"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:371
msgid "The last model used is now restored when the user changes chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:372
msgid "Better check for message finishing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:381
msgid "Added table rendering (Thanks Nokse)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:385
msgid "Made support dialog more common"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:386
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:387
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:396
msgid "Bearer Token entry on connection error dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:397
msgid "Small appearance changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:398
msgid "Compatibility with code blocks without explicit language"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:399
msgid "Rare, optional and dismissible support dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:403
msgid "Date format for Simplified Chinese translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:404
msgid "Bug with unsupported localizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:405
msgid "Min height being too large to be used on mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:406
msgid "Remote connection checker bug"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:415
msgid "Models with capital letters on their tag don't work"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:416
msgid "Ollama fails to launch on some systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:417
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:421
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:422
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:431
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:432
msgid "Better connection check for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:439
msgid "Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:440
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:441
msgid "Features and fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:443
msgid "Updated Ollama instance to 0.2.8"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:444
msgid "Better model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:445
msgid "Model manager redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:446
msgid "Better tag selector when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:447
msgid "Model search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:448
msgid "Added support for bearer tokens on remote instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:449
msgid "Preferences dialog redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:450
msgid "Added context menus to interact with a chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:451
msgid "Redesigned primary and secondary menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:452
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:453
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:454
msgid "Chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:455
msgid "Auto resizing of message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:456
msgid "Chat notifications"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid "Added indicator when an image is missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Redesigned file preview dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid "Credited new contributors"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:461
msgid "Better stability and optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:462
msgid "Edit messages to change the context of a conversation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:463
msgid "Added disclaimers when pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:464
msgid "Preview files before sending a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:465
msgid "Better format for date and time on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:466
msgid "Error and debug logging on terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:467
msgid "Auto-hiding sidebar button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:468
msgid "Various UI tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:470
msgid "New Models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid "Gemma2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:473
msgid "GLM4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:474
msgid "Codegeex4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:475
msgid "InternLM2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:476
msgid "Llama3-groq-tool-use"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:477
msgid "Mathstral"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Mistral-nemo"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:479
msgid "Firefunction-v2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:480
msgid "Nuextract"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:482
msgid "Translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:483
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:485
msgid "Russian: Alex K"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:486
msgid "Spanish: Jeffser"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:487
msgid "Brazilian Portuguese: Daimar Stein"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:488
msgid "French: Louis Chauvet-Villaret"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:489
msgid "Norwegian: CounterFlow64"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:490
msgid "Bengali: Aritra Saha"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:491
msgid "Simplified Chinese: Yuehao Sui"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:498
#: data/com.jeffser.Alpaca.metainfo.xml.in:547
msgid "Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:499
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:505
#: data/com.jeffser.Alpaca.metainfo.xml.in:535
#: data/com.jeffser.Alpaca.metainfo.xml.in:556
#: data/com.jeffser.Alpaca.metainfo.xml.in:761
#: data/com.jeffser.Alpaca.metainfo.xml.in:818
msgid "Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:507
msgid "Added compatibility for PDF"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:508
msgid "Added compatibility for DOCX"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:509
msgid "Merged 'file attachment' menu into one button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:516
#: data/com.jeffser.Alpaca.metainfo.xml.in:709
msgid "Quick Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:517
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:523
#: data/com.jeffser.Alpaca.metainfo.xml.in:675
msgid "Huge Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:525
msgid "Added: Support for plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:526
msgid "Added: New backend system for storing messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:527
msgid "Added: Support for changing Ollama's overrides"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:528
msgid "General Optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:537
msgid "Added: Support for GGUF models (experimental)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:538
msgid "Added: Support for customization and creation of models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:539
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:540
msgid "Update Ollama to v0.1.39"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:558
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:559
msgid "Combined export / import chat buttons into a menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:561
msgid "Fixed send / stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:562
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:569
msgid "Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:571
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:572
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:573
msgid "New message entry design"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:574
msgid "Fixed: Can't rename the same chat multiple times"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "The fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:583
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:584
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:591
msgid "Quick tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:593
msgid "Added progress bar to models that are being pulled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:594
msgid "Added size to tags when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "General optimizations on the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:602
msgid "Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Fixed: Scroll when message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Added 'Featured Models' page on welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Nice Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:615
msgid "UI tweaks (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:617
msgid "Metadata fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "Quick fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Updated Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:627
msgid "Added compatibility for PNG"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:634
msgid "New Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:636
msgid "Updated model list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:637
msgid "Added image recognition to more models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:638
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:639
msgid "Refined the general UI (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:640
msgid "Added 'delete message' feature"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:641
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:649
msgid "Bug Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:651
msgid "Fixed: Minor spelling mistake"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:652
msgid "Added 'mobile' as a supported form factor"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:653
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Fixed: App might freeze randomly on startup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:662
msgid "Cool Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:664
msgid "Better design for chat window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
msgid "Better design for chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:666
msgid "Fixed remote connections"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:667
msgid "Fixed Ollama restarting in loop"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:668
msgid "Other cool backend stuff"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:677
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid "Added option to import and export chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Added option to run Alpaca with Ollama in the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Added preferences dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:682
msgid "Changed the welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:684
#: data/com.jeffser.Alpaca.metainfo.xml.in:701
#: data/com.jeffser.Alpaca.metainfo.xml.in:713
#: data/com.jeffser.Alpaca.metainfo.xml.in:732
#: data/com.jeffser.Alpaca.metainfo.xml.in:753
#: data/com.jeffser.Alpaca.metainfo.xml.in:769
#: data/com.jeffser.Alpaca.metainfo.xml.in:785
#: data/com.jeffser.Alpaca.metainfo.xml.in:799
#: data/com.jeffser.Alpaca.metainfo.xml.in:809
#: data/com.jeffser.Alpaca.metainfo.xml.in:827
#: data/com.jeffser.Alpaca.metainfo.xml.in:849
msgid "Please report any errors to the issues page, thank you."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:692
msgid "Yet Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:694
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:695
msgid "Added better UI for the chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
msgid "Added myself to the credits as the spanish translator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:698
msgid "Using XDG properly to get config folder"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:699
msgid "Update for translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:711
msgid "The last update had some mistakes in the description of the update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Added full Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid "Added support for background pulling of multiple models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Added interrupt button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:726
msgid "Added basic shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid "Better translation support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Better scalling for different window sizes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:730
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Really Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Added multiple chats support!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:745
msgid "Added support for multiple tags on a single model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:746
msgid "Added better model management dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "Added loading spinner when sending message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:748
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:749
msgid "Added new symbolic icon"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:750
msgid "Added frame to message textview widget"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "Added code highlighting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "Added image recognition (llava model)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:765
msgid "Added multiline prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Fixed some small bugs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:767
msgid "General optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:777
msgid "Fixes and features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:779
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:780
msgid "Fixed: Cannot close app on first setup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:781
msgid "Fixed: Brand colors for Flathub"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:782
msgid "Fixed: App description"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:793
msgid "0.2.2 Bug fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:795
msgid "Toast messages appearing behind dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:796
msgid "Local model list not updating when changing servers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:797
msgid "Closing the setup dialog closes the whole app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:807
msgid "0.2.1 Data saving fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:808
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:817
msgid "0.2.0"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:819
msgid "New Features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Restore chat after closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "A button to clear the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Fixed multiple bugs involving how messages are shown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Added welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:825
msgid "More stability"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "0.1.2 Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "0.1.1 Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "This is the first public version of Alpaca"
msgstr ""

#: src/window.py:157 src/window.py:922
msgid "Please select a model before chatting"
msgstr "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—â–µ–Ω–∏—è"

#: src/window.py:215 src/window.py:216
msgid "Close"
msgstr "–ó–∞–∫—Ä—ã—Ç—å"

#: src/window.py:218 src/window.py:219 src/window.ui:991
msgid "Next"
msgstr "–°–ª–µ–¥—É—é—â–∏–π"

#: src/window.py:324
msgid "image"
msgstr "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"

#: src/window.py:433
msgid "Missing file"
msgstr ""

#: src/window.py:565 src/window.py:622 src/window.py:642 src/window.py:644
#: src/window.ui:31 src/custom_widgets/chat_widget.py:361
msgid "New Chat"
msgstr "–ù–æ–≤—ã–π –ß–∞—Ç"

#: src/window.py:668
msgid "Close Alpaca"
msgstr "–ó–∞–∫—Ä—ã—Ç—å –ü—Ä–æ–≥—Ä–∞–º–º—É"

#: src/window.py:669
msgid "Use Local Instance"
msgstr ""

#: src/window.py:670 src/window.py:892
msgid "Connect"
msgstr "–ü–æ–¥–∫–ª—é—á–∏—Ç—å"

#: src/window.py:673 src/window.py:895
msgid "Server URL"
msgstr ""

#: src/window.py:674 src/window.py:896
msgid "Bearer Token (Optional)"
msgstr "–¢–æ–∫–µ–Ω –Ω–∞ –ø—Ä–µ–¥—ä—è–≤–∏—Ç–µ–ª—è (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)"

#: src/window.py:676
msgid "Connection Error"
msgstr "–û—à–∏–±–∫–∞ –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è"

#: src/window.py:676
msgid "The remote instance has disconnected"
msgstr "–£–¥–∞–ª–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ—Ç–∫–ª—é—á–∏–ª—Å—è"

#: src/window.py:679
msgid "There was an error with the local Ollama instance, so it has been reset"
msgstr ""
"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º Ollama, –ø–æ—ç—Ç–æ–º—É –æ–Ω –±—ã–ª —Å–±—Ä–æ—à–µ–Ω"

#: src/window.py:701
msgid "Cannot open image"
msgstr "–ù–µ —É–¥–∞–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"

#: src/window.py:759
msgid "Delete Chat?"
msgstr "–£–¥–∞–ª–∏—Ç—å —á–∞—Ç?"

#: src/window.py:760 src/custom_widgets/model_widget.py:330
msgid "Are you sure you want to delete '{}'?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å '{}'?"

#: src/window.py:762 src/custom_widgets/model_widget.py:332
msgid "Delete"
msgstr "–£–¥–∞–ª–∏—Ç—å"

#: src/window.py:769
msgid "Rename Chat?"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —á–∞—Ç?"

#: src/window.py:770
msgid "Renaming '{}'"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ '{}'"

#: src/window.py:772
msgid "Chat name"
msgstr ""

#: src/window.py:773
msgid "Rename"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å"

#: src/window.py:796
msgid "This video does not have any transcriptions"
msgstr "–í —ç—Ç–æ–º –≤–∏–¥–µ–æ –Ω–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–æ–∫"

#: src/window.py:803
msgid "Attach YouTube Video?"
msgstr "–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –≤–∏–¥–µ–æ —Å YouTube?"

#: src/window.py:804
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è"

#: src/window.py:810
msgid "Error attaching video, please try again"
msgstr ""

#: src/window.py:830
msgid "Attach Website? (Experimental)"
msgstr "–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –≤–µ–±-—Å–∞–π—Ç? (–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π)"

#: src/window.py:831
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å\n"
"\"{}\"?"

#: src/window.py:849 src/generic_actions.py:84
msgid "Image recognition is only available on specific models"
msgstr "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"

#: src/window.py:891 src/custom_widgets/message_widget.py:44
#: src/custom_widgets/dialog_widget.py:136
#: src/custom_widgets/dialog_widget.py:148
#: src/custom_widgets/dialog_widget.py:160
msgid "Cancel"
msgstr "–û—Ç–º–µ–Ω–∞"

#: src/window.py:899
msgid "Connect Remote Instance"
msgstr ""

#: src/window.py:900
msgid "Enter instance information to continue"
msgstr ""

#: src/window.py:915
msgid "An error occurred: {}"
msgstr ""

#: src/window.py:924 src/window.ui:512
msgid "Quick Ask"
msgstr ""

#: src/window.py:1054
msgid "Clear Chat?"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç?"

#: src/window.py:1054
msgid "Are you sure you want to clear the chat?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –æ—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç?"

#: src/window.py:1054
msgid "Clear"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å"

#: src/window.py:1056
msgid "Select Model"
msgstr "–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏"

#: src/window.py:1056
msgid "This model will be used as the base for the new model"
msgstr "–≠—Ç–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –±–∞–∑–æ–≤–æ–π –¥–ª—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏"

#: src/window.py:1058
msgid "Pull Model"
msgstr ""

#: src/window.py:1058
msgid ""
"Input the name of the model in this format\n"
"name:tag"
msgstr ""

#: src/window.py:1082
msgid "Remove Attachment?"
msgstr "–£–¥–∞–ª–∏—Ç—å –≤–ª–æ–∂–µ–Ω–∏–µ?"

#: src/window.py:1082
msgid "Are you sure you want to remove attachment?"
msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å –≤–ª–æ–∂–µ–Ω–∏–µ?"

#: src/window.py:1082
msgid "Remove"
msgstr "–£–¥–∞–ª–∏—Ç—å"

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to Llama 3.1 405B model."
msgstr ""

#: src/available_models_descriptions.py:3
msgid ""
"QwQ is an experimental research model focused on advancing AI reasoning "
"capabilities."
msgstr ""

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr ""

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: –°–∞–º—ã–π –º–æ—â–Ω—ã–π –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö LLM –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å"

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "–ú–æ–¥–µ–ª—å 7–ë, –≤—ã–ø—É—â–µ–Ω–Ω–∞—è Mistral AI, –æ–±–Ω–æ–≤–ª–µ–Ω–∞ ‚Äã‚Äã–¥–æ –≤–µ—Ä—Å–∏–∏ 0.3."

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Å –±–æ–ª—å—à–∏–º –æ–∫–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ "
"—Ç–æ–∫–µ–Ω–∞."

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –ª–µ–≥–∫–∏—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö Google "
"DeepMind. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ 1.1"

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5¬†‚Äî —ç—Ç–æ —Å–µ—Ä–∏—è –∫—Ä—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç Alibaba Cloud —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ "
"–æ—Ç 0,5 –¥–æ 110¬†B"

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 ‚Äî –Ω–æ–≤–∞—è —Å–µ—Ä–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç –≥—Ä—É–ø–ø—ã Alibaba"

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –ª–µ–≥–∫–∏—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π 3B (Mini) –∏ 14B "
"(Medium) –æ—Ç Microsoft."

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –±–∞–∑–æ–≤—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ—Ç 7B –¥–æ 70B."

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""

#: src/available_models_descriptions.py:17
msgid ""
"üåã LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"üåã LLaVA ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ–±—É—á–µ–Ω–Ω–∞—è –±–æ–ª—å—à–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, "
"–∫–æ—Ç–æ—Ä–∞—è —Å–æ—á–µ—Ç–∞–µ—Ç –≤ —Å–µ–±–µ –≤–∏–¥–µ–æ–∫–æ–¥–µ—Ä –∏ Vicuna –¥–ª—è –æ–±—â–µ–≥–æ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∏ "
"—è–∑—ã–∫–æ–≤–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ 1.6."

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"–ë–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è "
"—Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∫–æ–¥–∞."

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"–ü—Ä–æ–µ–∫—Ç TinyLlama ‚Äî —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–∏—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –º–æ–¥–µ–ª—å Llama "
"—Ä–∞–∑–º–µ—Ä–æ–º 1,1B –Ω–∞ 3 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤."

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è –æ—Ç mixbread.ai"

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 ‚Äî —ç—Ç–æ —Å–ª–µ–¥—É—é—â–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ LLM —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –æ–±—É—á–µ–Ω–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç—ã–º "
"–∫–æ–¥–æ–º, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤ —Ç—Ä–µ—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã 3B, 7B –∏ 15B."

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"–ù–∞–±–æ—Ä –º–æ–¥–µ–ª–∏ Mixture of Experts (MoE) —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –≤–µ—Å–∞–º–∏ –æ—Ç Mistral AI —Å "
"—Ä–∞–∑–º–µ—Ä–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ 8x7b –∏ 8x22b."

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"–ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ 8x7b –∏ 8x22b, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ —Å–º–µ—Å–∏ "
"—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Mixtral, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –∑–∞–¥–∞—á–∞–º–∏ "
"–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –°–æ–∑–¥–∞–Ω –≠—Ä–∏–∫–æ–º –•–∞—Ä—Ç—Ñ–æ—Ä–¥–æ–º."

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –º–æ—â–Ω—ã—Ö –∏ –ª–µ–≥–∫–∏—Ö –º–æ–¥–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å "
"—Ä–∞–∑–ª–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∫–æ–¥–∞ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ–º "
"–ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞, –ø–æ–Ω–∏–º–∞–Ω–∏–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ "
"—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π."

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"–ú–æ–¥–µ–ª—å —è–∑—ã–∫–∞ –∫–æ–¥–∞ Mixture-of-Experts —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, "
"–æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Å—Ä–∞–≤–Ω–∏–º—É—é —Å GPT4-Turbo, –≤ –∑–∞–¥–∞—á–∞—Ö, "
"—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –∫–æ–¥–∞."

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å 2,7B –æ—Ç Microsoft Research, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∞—è "
"–≤—ã–¥–∞—é—â–∏–µ—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—é —è–∑—ã–∫–∞."

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "–ú–æ–¥–µ–ª—å Llama 2 –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã –æ—Ç –î–∂–æ—Ä–¥–∂–∞ –°–∞–Ω–≥–∞ –∏ –î–∂–∞—Ä—Ä–∞–¥–∞ –•–æ—É–ø–∞."

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder ‚Äî —ç—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –¥–≤—É—Ö "
"—Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö –∫–æ–¥–∞ –∏ —Ç–æ–∫–µ–Ω–∞—Ö –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞."

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"–ù–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ—Ç Snowflake, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è "
"–ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –±–æ–ª—å—à–æ–≥–æ —è–∑—ã–∫–∞ –æ—Ç Microsoft AI —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π "
"–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –≤ —Å–ª–æ–∂–Ω—ã—Ö —á–∞—Ç–∞—Ö, –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö, —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö –∏ "
"—Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤."

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"–ú–æ–¥–µ–ª—å Dolphin –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Mistral, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ "
"—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–∞–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ 2.8."

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 ‚Äî —ç—Ç–æ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ä–∞–∑–º–µ—Ä–æ–≤ 8B –∏ 70B, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –≠—Ä–∏–∫–æ–º "
"–•–∞—Ä—Ç—Ñ–æ—Ä–¥–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 3, –∫–æ—Ç–æ—Ä–∞—è –æ–±–ª–∞–¥–∞–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –Ω–∞–≤—ã–∫–∞–º–∏ "
"–æ–±—É—á–µ–Ω–∏—è, –æ–±—â–µ–Ω–∏—è –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 ‚Äî —ç—Ç–æ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –¥–≤—É—è–∑—ã—á–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å."

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R ‚Äî —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤–æ–≥–æ "
"–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∏ –∑–∞–¥–∞—á —Å –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º."

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"–ú–æ–¥–µ–ª—å –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å —á–∏—Å–ª–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç 3 –¥–æ 70 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤, "
"–ø–æ–¥—Ö–æ–¥—è—â–∞—è –¥–ª—è –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è."

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"–ú–æ–¥–µ–ª—å LLaVA, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 3 Instruct, —Å –ª—É—á—à–∏–º–∏ "
"–ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ—Å—Ç–∞—Ö."

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr ‚Äî —ç—Ç–æ —Å–µ—Ä–∏—è –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–µ–π Mistral –∏ Mixtral, –∫–æ—Ç–æ—Ä—ã–µ "
"–æ–±—É—á–µ–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å —Ä–æ–ª—å –ø–æ–ª–µ–∑–Ω—ã—Ö –ø–æ–º–æ—â–Ω–∏–∫–æ–≤."

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"–í—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –≤ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π."

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI‚Äôs first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral ‚Äî —ç—Ç–æ –ø–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å –∫–æ–¥–∞ Mistral AI, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∑–∞–¥–∞—á "
"–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞."

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –±–æ–ª–µ–µ —á–µ–º 80 —è–∑—ã–∫–∞—Ö "
"–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"–ú–æ–¥–µ–ª—å —á–∞—Ç–∞ –æ–±—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama –∏ Llama 2 —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ "
"–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç 2 –¥–æ 16 –ö–ë."

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "–°–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Ñ–æ–Ω–¥–∞ –æ—Ç IBM –¥–ª—è Code Intelligence"

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å 7 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –Ω–∞ "
"–æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏ Mistral 7B —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö OpenOrca."

#: src/available_models_descriptions.py:47
msgid ""
"ü™ê A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 7B, 13B –∏ 30B, "
"–æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Llama 2 –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã –≠—Ä–∏–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞."

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 2 –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤ –¥–∏–∞–ª–æ–≥–∞ –Ω–∞ "
"–∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–µ."

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"–°–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –æ–±—É—á–µ–Ω–Ω—ã—Ö –Ω–∞ —à–∏—Ä–æ–∫–æ–º —Å–ø–µ–∫—Ç—Ä–µ "
"–¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏—Ö ChatGPT –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º. –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –≤–µ—Ä—Å–∏–∏ "
"3.5-0106."

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, –≤—ã–ø—É—â–µ–Ω–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏–µ–π Cohere, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–æ–≤–æ–µ —Å–µ–º–µ–π—Å—Ç–≤–æ "
"—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏—Ö 23 —è–∑—ã–∫–∞."

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 ‚Äî —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ "
"–±–æ–ª—å—à–æ–º –æ–±—ä–µ–º–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–¥–∞."

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"–ú–æ—â–Ω–æ–µ —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –æ—Ç Nous Research, –∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å "
"–∑–∞–¥–∞—á–∞–º–∏ –Ω–∞—É—á–Ω–æ–≥–æ –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è."

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ ‚Äî —ç—Ç–æ –º–æ—â–Ω–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è –º–æ–¥–µ–ª—å –±–æ–ª—å—à–æ–≥–æ —è–∑—ã–∫–∞, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ "
"—Å–æ–∑–¥–∞–Ω–Ω–∞—è –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —É—Å–ø–µ—Ö–∞ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö "
"–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞"

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"–°—Ç–∞–±–∏–ª—å–Ω—ã–π –∫–æ–¥ 3B ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ "
"–∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–¥–∞ –Ω–∞—Ä–∞–≤–Ω–µ —Å —Ç–∞–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏, –∫–∞–∫ Code Llama 7B, –∫–æ—Ç–æ—Ä—ã–µ –≤ 2,5 "
"—Ä–∞–∑–∞ –±–æ–ª—å—à–µ."

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 1.1B, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –Ω–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ "
"–¥–∞–Ω–Ω—ã—Ö Dolphin 2.8 –≠—Ä–∏–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞ –∏ –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ TinyLlama."

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å 7B, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è Teknium –Ω–∞ Mistral —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é "
"–æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö."

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 ‚Äî —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ 1,6B –∏ 12B, "
"–æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –∏—Å–ø–∞–Ω—Å–∫–æ–º, –Ω–µ–º–µ—Ü–∫–æ–º, "
"–∏—Ç–∞–ª—å—è–Ω—Å–∫–æ–º, —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º, –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–æ–º –∏ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–æ–º —è–∑—ã–∫–∞—Ö."

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA ‚Äî –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, —Å–æ—Å—Ç–æ—è—â–∞—è –∏–∑ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ Mistral 7B, "
"–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π LLaVA."

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"–£—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ 2 —Ç—Ä–∏–ª–ª–∏–æ–Ω–æ–≤ "
"–¥–≤—É—è–∑—ã—á–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤."

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"–≠—Ç–∞ –º–æ–¥–µ–ª—å —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ LLama-3 8B —Å 8 —Ç—ã—Å. –¥–æ –±–æ–ª–µ–µ —á–µ–º 1 "
"–º–ª–Ω —Ç–æ–∫–µ–Ω–æ–≤."

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "–ú–æ–¥–µ–ª—å –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏"

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 ‚Äî —ç—Ç–æ –Ω–µ–±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –≤–∏–¥–µ–Ω–∏—è, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è "
"—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö."

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"–î–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ Mistral —Å —Ö–æ—Ä–æ—à–∏–º –æ—Ö–≤–∞—Ç–æ–º –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏ "
"—è–∑—ã–∫–∞."

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"–ú–æ–¥–µ–ª—å –æ—Ç NVIDIA –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 3, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å "
"–¥–∏–∞–ª–æ–≥–æ–≤—ã–º –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã (QA) –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º (RAG)."

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"–î–∏–∞–ª–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ Llama 2, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–∞—è –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º "
"–ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º."

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–¥–∞, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –≤ StarCoder –¥–ª—è –∑–∞–¥–∞—á "
"–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL"

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "–ú–æ–¥–µ–ª–∏ –æ–±—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ –±–∞–∑–µ Llama –∏ Llama 2 –æ—Ç Nous Research."

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "–ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Code Llama."

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Llama 2, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ 128 —Ç—ã—Å. —Ç–æ–∫–µ–Ω–æ–≤."

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"–í–∞—Ä–∏–∞–Ω—Ç —Å–µ–º–µ–π—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π Dolphin 7B –∏ 15B –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π –≤ "
"–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏, –Ω–∞ –æ—Å–Ω–æ–≤–µ StarCoder2."

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "–ú–æ–¥–µ–ª—å –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –±–∞–∑–µ Llama 2."

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "–°–∏–ª—å–Ω–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å ¬´–°–º–µ—Å—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤¬ª."

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling ‚Äî —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–∏—è —Å "
"–ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∑—ã–≤–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –Ω–∞ "
"–ø–æ–≤—ã—à–µ–Ω–∏–µ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ —á–∞—Ç-–±–æ—Ç–∞."

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"–ü–æ–º–æ—â–Ω–∏–∫-–∫–æ–º–ø–∞–Ω—å–æ–Ω, –ø—Ä–æ—à–µ–¥—à–∏–π –æ–±—É—á–µ–Ω–∏–µ –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏, –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏ –∏ "
"–ª–∏—á–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. –ù–∞ –±–∞–∑–µ –ú–∏—Å—Ç—Ä–∞–ª—è."

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è, –Ω–æ –º–æ—â–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 10,7 –ë–ë, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è "
"–¥–ª—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "–ù–æ–≤–∞—è –º–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å LLaVA, –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Phi 3 Mini."

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 —Å–æ–∑–¥–∞–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π Microsoft –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π "
"–¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–µ–π Meta 2 Llama 2. –ú–æ–¥–µ–ª—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞, —á—Ç–æ–±—ã "
"–ø—Ä–µ—É—Å–ø–µ—Ç—å, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è—Ö."

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 2 —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–∏–ª–µ Orca. "
"–ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ –Ω–∞–∑—ã–≤–∞–ª—Å—è –°–≤–æ–±–æ–¥–Ω—ã–π –í–∏–ª–ª–∏."

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small is a lightweight model designed for cost-effective use in "
"tasks like translation and summarization."
msgstr ""

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"2.7B –º–æ–¥–µ–ª—å Dolphin –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã –≠—Ä–∏–∫–∞ –•–∞—Ä—Ç—Ñ–æ—Ä–¥–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –º–æ–¥–µ–ª–∏ —è–∑—ã–∫–∞ "
"Phi, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–π Microsoft Research."

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "–í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ Wizard LM –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã"

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Mistral –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –æ–∫–æ–Ω —Ä–∞–∑–º–µ—Ä–æ–º 64 –ö–ë –∏–ª–∏ 128 –ö–ë."

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ Llama 2, –∫–æ—Ç–æ—Ä–æ–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–∞–∫ –æ–±—â–µ–≥–æ "
"–ø–æ–Ω–∏–º–∞–Ω–∏—è —è–∑—ã–∫–∞, —Ç–∞–∫ –∏ –∑–Ω–∞–Ω–∏–π –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ "
"–æ–±–ª–∞—Å—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏."

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"–¢–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ Llama 2 –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ "
"–Ω–∞–±–æ—Ä–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º."

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"–ë–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å  —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–∑ Llama "
"2 –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Å—Ñ–µ—Ä—ã."

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 13B –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è –∑–∞–¥–∞—á –≤—ã–∑–æ–≤–∞ "
"—Ñ—É–Ω–∫—Ü–∏–π."

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"–ú–æ–¥–µ–ª—å Nous Hermes 2 –æ—Ç Nous Research, –∫–æ—Ç–æ—Ä–∞—è —Ç–µ–ø–µ—Ä—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ Mixtral."

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "–û—Ç–ª–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama2."

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"–ú–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama2 –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ 16 –ö–ë."

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""

#: src/available_models_descriptions.py:109
msgid ""
"üé© Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"üé© Magicoder ‚Äî —ç—Ç–æ —Å–µ–º–µ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —Å 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –æ–±—É—á–µ–Ω–Ω—ã—Ö –Ω–∞ 75 000 "
"—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OSS-Instruct, –Ω–æ–≤–æ–≥–æ "
"–ø–æ–¥—Ö–æ–¥–∞ –∫ –æ–±—É—á–µ–Ω–∏—é LLM —Å –ø–æ–º–æ—â—å—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∫–æ–¥–∞ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º."

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"–û–±–ª–µ–≥—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —á–∞—Ç–∞, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∞—è —Ç–æ—á–Ω—ã–π –∏ –±—ã—Å—Ç—Ä—ã–π –≤—ã–≤–æ–¥ –±–µ–∑ "
"–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è."

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∫–æ–¥–∞, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –ø—É—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è "
"–¥–≤—É—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π –∫–æ–¥–∞."

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –ø—Ä–∏—á–∏–Ω–Ω–æ–≥–æ –¥–µ–∫–æ–¥–µ—Ä–∞ —Å 11B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω–∞—è TII –∏ "
"–æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ —Ç–æ–∫–µ–Ω–∞—Ö 5T."

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å —Å 13B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Llama 2, "
"–æ–±—É—á–µ–Ω–Ω–∞—è MelodysDreamj."

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite ‚Äî –¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ Mistral —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ "
"–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤."

#: src/available_models_descriptions.py:115
msgid ""
"MathŒ£tral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"–ú–æ–¥–µ–ª—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ SQL —Å 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, —Å–æ–∑–¥–∞–Ω–Ω–∞—è MotherDuck –∏ "
"Numbers Station."

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b ‚Äî —ç—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è Dolphin-2.2-70b, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –ø—É—Ç–µ–º "
"—á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–∞–º–æ–π —Å —Å–æ–±–æ–π."

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"–í—ã—Å–æ–∫–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏, —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ "
"–≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"–ú–æ–¥–µ–ª—å —á–∞—Ç–∞ 7B, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è "
"–Ω–∞ Zephyr."

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"–°–ª–∏—è–Ω–∏–µ –º–æ–¥–µ–ª–∏ Open Orca OpenChat –∏ –º–æ–¥–µ–ª–∏ Garage-bAInd Platypus 2. "
"–ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è —á–∞—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞."

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, —Å–æ–∑–¥–∞–Ω–Ω–∞—è –ø—É—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–≤—É—Ö —Ç–æ—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π "
"Llama 2 70B –≤ –æ–¥–Ω—É."

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX ‚Äî —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç–∞—è LLM –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è, —Å–æ–∑–¥–∞–Ω–Ω–∞—è Databricks."

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr ""

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"–ù–∞–¥–µ–∂–Ω–∞—è –¥–∏–∞–ª–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–∞—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∫ –≤ —á–∞—Ç–µ, "
"—Ç–∞–∫ –∏ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π."

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""

#: src/available_models_descriptions.py:138
msgid ""
"T√ºlu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""

#: src/connection_handler.py:14
msgid "Alpaca Support"
msgstr ""

#: src/connection_handler.py:25
msgid "Model request too large for system"
msgstr ""

#: src/connection_handler.py:28
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""

#: src/connection_handler.py:30
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr ""

#: src/connection_handler.py:33
msgid "Using AMD GPU type '{}'"
msgstr ""

#: src/connection_handler.py:94
msgid "Ollama instance was shut down due to inactivity"
msgstr ""

#: src/connection_handler.py:132
msgid "Integrated Ollama instance is running"
msgstr ""

#: src/connection_handler.py:148 src/window.ui:494
msgid "Integrated Ollama instance is not running"
msgstr ""

#: src/window.ui:42
msgid "Menu"
msgstr "–ú–µ–Ω—é"

#: src/window.ui:64
msgid "Toggle Sidebar"
msgstr "–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏"

#: src/window.ui:71
msgid "Search Messages"
msgstr ""

#: src/window.ui:93
msgid "Loading Instance"
msgstr ""

#: src/window.ui:105 src/window.ui:106 src/window.ui:571 src/window.ui:1056
#: src/custom_widgets/model_widget.py:24 src/custom_widgets/model_widget.py:25
msgid "Manage Models"
msgstr "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ú–æ–¥–µ–ª—è–º–∏"

#: src/window.ui:118
msgid "Chat Menu"
msgstr "–ú–µ–Ω—é —á–∞—Ç–∞"

#: src/window.ui:127
msgid "Message search bar"
msgstr ""

#: src/window.ui:134 src/window.ui:136
msgid "Search messages"
msgstr ""

#: src/window.ui:150
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""

#: src/window.ui:197
msgid "Attach File"
msgstr "–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–∞–π–ª"

#: src/window.ui:235
msgid "Message text box"
msgstr ""

#: src/window.ui:248 src/window.ui:1299
msgid "Send Message"
msgstr "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: src/window.ui:298 src/window.ui:1062 src/window.ui:1240
msgid "Preferences"
msgstr "–ù–∞—Å—Ç—Ä–æ–π–∫–∏"

#: src/window.ui:301 src/window.ui:1218
msgid "General"
msgstr "–û–±—â–∏–µ"

#: src/window.ui:307
msgid "Use Remote Connection to Ollama"
msgstr "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–¥–∞–ª–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama"

#: src/window.ui:317
msgid "Run Alpaca In Background"
msgstr "–ó–∞–ø—É—Å–∫ Alpaca –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"

#: src/window.ui:323
msgid "Show Power Saver Warning"
msgstr ""

#: src/window.ui:330
msgid "Default Model"
msgstr ""

#: src/window.ui:331
msgid ""
"The default model to use on new chats and when Alpaca is launched with the "
"option --ask \"message\""
msgstr ""

#: src/window.ui:349
msgid "Temperature"
msgstr "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞"

#: src/window.ui:350
msgid ""
"The temperature of the model. Increasing the temperature will make the model "
"answer more creatively. (Default: 0.8)"
msgstr ""
"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏. –ü—Ä–∏ –ø–æ–≤—ã—à–µ–Ω–∏–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–µ "
"—Ç–≤–æ—Ä—á–µ—Å–∫–∏. (–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0,8)"

#: src/window.ui:365
msgid "Seed"
msgstr "–ó–µ—Ä–Ω–æ"

#: src/window.ui:366
msgid ""
"Sets the random number seed to use for generation. Setting this to a "
"specific number will make the model generate the same text for the same "
"prompt. (Default: 0 (random))"
msgstr ""
"–ó–∞–¥–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è "
"–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –∑–∞—Å—Ç–∞–≤–∏—Ç –º–æ–¥–µ–ª—å "
"–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –∑–∞–ø—Ä–æ—Å–∞. (–ü–æ "
"—É–º–æ–ª—á–∞–Ω–∏—é: 0 (—Å–ª—É—á–∞–π–Ω—ã–π))"

#: src/window.ui:380
msgid "Keep Alive Time"
msgstr "–í—Ä–µ–º—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∂–∏–∑–Ω–∏"

#: src/window.ui:381
msgid ""
"Controls how long the model will stay loaded into memory following the "
"request in minutes (Default: 5)"
msgstr ""
"–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫ –¥–æ–ª–≥–æ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –≤ –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ "
"–º–∏–Ω—É—Ç–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)."

#: src/window.ui:397
msgid "Ollama Instance"
msgstr "–≠–∫–∑–µ–º–ø–ª—è—Ä Ollama"

#: src/window.ui:401
msgid "Ollama Overrides"
msgstr "–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è Ollama"

#: src/window.ui:402
msgid ""
"Manage the arguments used on Ollama, any changes on this page only applies "
"to the integrated instance, the instance will restart if you make changes."
msgstr ""
"–£–ø—Ä–∞–≤–ª—è–π—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º–∏ –≤ Ollama, –ª—é–±—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞ —ç—Ç–æ–π "
"—Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–∏–º–µ–Ω–∏–º—ã —Ç–æ–ª—å–∫–æ –∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —ç–∫–∑–µ–º–ø–ª—è—Ä—É, —ç–∫–∑–µ–º–ø–ª—è—Ä –±—É–¥–µ—Ç "
"–ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω, –µ—Å–ª–∏ –≤—ã –≤–Ω–µ—Å–µ—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è."

#: src/window.ui:474
msgid "Idle Timer"
msgstr ""

#: src/window.ui:475
msgid ""
"Number of minutes the instance should remain idle before it is shut down (0 "
"means it won't be shut down)"
msgstr ""

#: src/window.ui:510
msgid "Quick ask dialog"
msgstr ""

#: src/window.ui:522
msgid "Save Conversation to Alpaca"
msgstr ""

#: src/window.ui:537 src/window.ui:560
msgid "Manage models dialog"
msgstr ""

#: src/window.ui:539
msgid "Terminal"
msgstr ""

#: src/window.ui:581 src/window.ui:756
msgid "Create Model"
msgstr "–°–æ–∑–¥–∞—Ç—å –ú–æ–¥–µ–ª—å"

#: src/window.ui:588
msgid "Search Model"
msgstr "–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏"

#: src/window.ui:595
msgid "Refresh Local Models"
msgstr ""

#: src/window.ui:605
msgid "Model search bar"
msgstr ""

#: src/window.ui:612 src/window.ui:614
msgid "Search models"
msgstr "–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π"

#: src/window.ui:637
msgid "No Models Found"
msgstr "–ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"

#: src/window.ui:638
msgid "Try a different search or pull an unlisted model from it's name"
msgstr ""

#: src/window.ui:646
msgid "Pull Model From Name"
msgstr ""

#: src/window.ui:696
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website."
msgstr ""
"–ó–∞–≥—Ä—É–∂–∞—è —ç—Ç—É –º–æ–¥–µ–ª—å, –≤—ã –ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ, –¥–æ—Å—Ç—É–ø–Ω–æ–µ –Ω–∞ –≤–µ–±-"
"—Å–∞–π—Ç–µ –º–æ–¥–µ–ª–∏."

#: src/window.ui:721
msgid "Model Details"
msgstr ""

#: src/window.ui:784
msgid "Base"
msgstr "–û—Å–Ω–æ–≤–∞"

#: src/window.ui:803
msgid "Name"
msgstr "–ò–º—è"

#: src/window.ui:809
msgid "Context"
msgstr "–ö–æ–Ω—Ç–µ–∫—Å—Ç"

#: src/window.ui:856
msgid ""
"Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
"instructions automatically. Please visit the model's website or Ollama "
"documentation for more information if you're unsure."
msgstr ""

#: src/window.ui:872
msgid "Create"
msgstr "–°–æ–∑–¥–∞—Ç—å"

#: src/window.ui:895
msgid "File preview dialog"
msgstr ""

#: src/window.ui:907
msgid "Open With Default App"
msgstr ""

#: src/window.ui:915
msgid "Remove Attachment"
msgstr ""

#: src/window.ui:975
msgid "Previous"
msgstr "–ü—Ä–µ–¥—ã–¥—É—â–∏–π"

#: src/window.ui:1018
msgid "Welcome to Alpaca"
msgstr "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Alpaca"

#: src/window.ui:1019
msgid "Powered by Ollama"
msgstr "–ü—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ Ollama"

#: src/window.ui:1022
msgid "Ollama Website"
msgstr "–í–µ–±-—Å–∞–π—Ç Ollama"

#: src/window.ui:1039
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it."
msgstr ""
"Alpaca –∏ –µ–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –Ω–µ –Ω–µ—Å—É—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –ª—é–±–æ–π —É—â–µ—Ä–±, "
"–ø—Ä–∏—á–∏–Ω–µ–Ω–Ω—ã–π —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º –∏–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–º—É –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è "
"–∫–æ–¥–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. "
"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã –∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –æ–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –∫–æ–¥–æ–º –ø–µ—Ä–µ–¥ –µ–≥–æ "
"–∑–∞–ø—É—Å–∫–æ–º."

#: src/window.ui:1052
msgid "Import Chat"
msgstr "–ò–º–ø–æ—Ä—Ç –ß–∞—Ç–∞"

#: src/window.ui:1066
msgid "Keyboard Shortcuts"
msgstr "–ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ö–ª–∞–≤–∏—à"

#: src/window.ui:1070
msgid "About Alpaca"
msgstr "–û –ü—Ä–æ–≥—Ä–∞–º–º–µ"

#: src/window.ui:1078 src/window.ui:1104
msgid "Rename Chat"
msgstr "–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –ß–∞—Ç"

#: src/window.ui:1082 src/window.ui:1108
msgid "Duplicate Chat"
msgstr ""

#: src/window.ui:1086 src/window.ui:1112
msgid "Export Chat"
msgstr "–≠–∫—Å–ø–æ—Ä—Ç –ß–∞—Ç–∞"

#: src/window.ui:1090
msgid "Clear Chat"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å –ß–∞—Ç"

#: src/window.ui:1096 src/window.ui:1118
msgid "Delete Chat"
msgstr "–£–¥–∞–ª–∏—Ç—å –ß–∞—Ç"

#: src/window.ui:1126
msgid "Send as User"
msgstr ""

#: src/window.ui:1130
msgid "Send as System"
msgstr ""

#: src/window.ui:1138
msgid "From Existing Model"
msgstr "–ò–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏"

#: src/window.ui:1142
msgid "From GGUF File"
msgstr ""

#: src/window.ui:1146
msgid "From Name"
msgstr ""

#: src/window.ui:1222
msgid "Close application"
msgstr "–ó–∞–∫—Ä—ã—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"

#: src/window.ui:1228
msgid "Import chat"
msgstr "–ò–º–ø–æ—Ä—Ç —á–∞—Ç–∞"

#: src/window.ui:1234
msgid "Clear chat"
msgstr "–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç"

#: src/window.ui:1246
msgid "New chat"
msgstr "–ù–æ–≤—ã–π —á–∞—Ç"

#: src/window.ui:1252
msgid "Show shortcuts window"
msgstr "–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –∫–ª–∞–≤–∏—à"

#: src/window.ui:1258
msgid "Manage models"
msgstr ""

#: src/window.ui:1264
msgid "Toggle sidebar"
msgstr ""

#: src/window.ui:1270
msgid "Rename chat"
msgstr ""

#: src/window.ui:1277
msgid "Editor"
msgstr "–†–µ–¥–∞–∫—Ç–æ—Ä"

#: src/window.ui:1281
msgid "Copy"
msgstr "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å"

#: src/window.ui:1287
msgid "Paste"
msgstr "–í—Å—Ç–∞–≤–∏—Ç—å"

#: src/window.ui:1293
msgid "Insert new line"
msgstr "–í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É"

#: src/alpaca_search_provider.py.in:40
msgid "Open chat"
msgstr ""

#: src/alpaca_search_provider.py.in:41
msgid "Quick ask"
msgstr ""

#: src/generic_actions.py:68
msgid "An error occurred while extracting text from the website"
msgstr "–ü—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –≤–µ–±-—Å–∞–π—Ç–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"

#: src/custom_widgets/chat_widget.py:121
msgid "Send prompt: '{}'"
msgstr ""

#: src/custom_widgets/chat_widget.py:127 src/custom_widgets/chat_widget.py:128
msgid "Open Model Manager"
msgstr ""

#: src/custom_widgets/chat_widget.py:137
msgid "Try one of these prompts"
msgstr ""

#: src/custom_widgets/chat_widget.py:137
msgid ""
"It looks like you don't have any models downloaded yet. Download models to "
"get started!"
msgstr ""

#: src/custom_widgets/chat_widget.py:172
msgid "User"
msgstr ""

#: src/custom_widgets/chat_widget.py:176
#: src/custom_widgets/message_widget.py:467
msgid "System"
msgstr ""

#: src/custom_widgets/chat_widget.py:232
msgid "Regenerate Response"
msgstr ""

#: src/custom_widgets/chat_widget.py:399
msgid "Copy of {}"
msgstr ""

#: src/custom_widgets/chat_widget.py:411
msgid "Chat exported successfully"
msgstr "–ß–∞—Ç —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"

#: src/custom_widgets/chat_widget.py:487
msgid "Chat imported successfully"
msgstr "–ß–∞—Ç —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"

#: src/custom_widgets/message_widget.py:53
msgid "Save Message"
msgstr ""

#: src/custom_widgets/message_widget.py:86
msgid "Message edited successfully"
msgstr "–°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–æ"

#: src/custom_widgets/message_widget.py:113
msgid "Response message"
msgstr ""

#: src/custom_widgets/message_widget.py:115
msgid "System message"
msgstr ""

#: src/custom_widgets/message_widget.py:117
msgid "User message"
msgstr ""

#: src/custom_widgets/message_widget.py:159
msgid "{}Code Block"
msgstr ""

#: src/custom_widgets/message_widget.py:162
msgid "Code Block"
msgstr ""

#: src/custom_widgets/message_widget.py:163
#: src/custom_widgets/message_widget.py:361
msgid "Copy Message"
msgstr "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: src/custom_widgets/message_widget.py:167
#: src/custom_widgets/message_widget.py:189
msgid "Run Script"
msgstr ""

#: src/custom_widgets/message_widget.py:182
msgid "Code copied to the clipboard"
msgstr "–ö–æ–¥ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞"

#: src/custom_widgets/message_widget.py:190
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""

#: src/custom_widgets/message_widget.py:192
msgid "Execute"
msgstr ""

#: src/custom_widgets/message_widget.py:276
#: src/custom_widgets/message_widget.py:278
msgid "Image"
msgstr ""

#: src/custom_widgets/message_widget.py:286
#: src/custom_widgets/message_widget.py:302
msgid "Missing Image"
msgstr "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

#: src/custom_widgets/message_widget.py:304
msgid "Missing image"
msgstr "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

#: src/custom_widgets/message_widget.py:351
msgid "Remove Message"
msgstr "–£–¥–∞–ª–∏—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: src/custom_widgets/message_widget.py:371
msgid "Edit Message"
msgstr "–ò–∑–º–µ–Ω–∏—Ç—å –°–æ–æ–±—â–µ–Ω–∏–µ"

#: src/custom_widgets/message_widget.py:382
msgid "Regenerate Message"
msgstr ""

#: src/custom_widgets/message_widget.py:403
msgid "Message copied to the clipboard"
msgstr "–°–æ–æ–±—â–µ–Ω–∏–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞"

#: src/custom_widgets/message_widget.py:438
msgid "Message cannot be regenerated while receiving a response"
msgstr ""

#: src/custom_widgets/model_widget.py:181
msgid "Stop Pulling '{}'"
msgstr ""

#: src/custom_widgets/model_widget.py:184
msgid "Stop Download?"
msgstr "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É?"

#: src/custom_widgets/model_widget.py:185
msgid "Are you sure you want to stop pulling '{}'?"
msgstr ""

#: src/custom_widgets/model_widget.py:187
msgid "Stop"
msgstr "–°—Ç–æ–ø"

#: src/custom_widgets/model_widget.py:315
msgid "Details"
msgstr ""

#: src/custom_widgets/model_widget.py:325
msgid "Remove '{}'"
msgstr ""

#: src/custom_widgets/model_widget.py:329
msgid "Delete Model?"
msgstr "–£–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å?"

#: src/custom_widgets/model_widget.py:362
msgid "Create Model Based on '{}'"
msgstr ""

#: src/custom_widgets/model_widget.py:378
msgid "Modified At"
msgstr ""

#: src/custom_widgets/model_widget.py:379
msgid "Parent Model"
msgstr ""

#: src/custom_widgets/model_widget.py:380
msgid "Format"
msgstr ""

#: src/custom_widgets/model_widget.py:381
msgid "Family"
msgstr ""

#: src/custom_widgets/model_widget.py:382
msgid "Parameter Size"
msgstr ""

#: src/custom_widgets/model_widget.py:383
msgid "Quantization Level"
msgstr ""

#: src/custom_widgets/model_widget.py:449
msgid "Image Recognition"
msgstr "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

#: src/custom_widgets/model_widget.py:475
msgid "Enter download menu for {}"
msgstr ""

#: src/custom_widgets/model_widget.py:514
msgid "Large Model"
msgstr ""

#: src/custom_widgets/model_widget.py:515
msgid ""
"Your system's available RAM suggests that this model might be too large to "
"run optimally. Are you sure you want to download it anyway?"
msgstr ""

#: src/custom_widgets/model_widget.py:517
msgid "Download"
msgstr ""

#: src/custom_widgets/model_widget.py:540
msgid "Download {}:{}"
msgstr ""

#: src/custom_widgets/model_widget.py:612
msgid "Model deleted successfully"
msgstr "–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞"

#: src/custom_widgets/model_widget.py:692
msgid "Task Complete"
msgstr "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"

#: src/custom_widgets/model_widget.py:692
#: src/custom_widgets/model_widget.py:693
msgid "Model '{}' pulled successfully."
msgstr "–ú–æ–¥–µ–ª—å '{}' —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–∞."

#: src/custom_widgets/model_widget.py:696
#: src/custom_widgets/model_widget.py:699
msgid "Pull Model Error"
msgstr "–û—à–∏–±–∫–∞ –ò–∑–≤–ª–µ—á–µ–Ω–∏—è –ú–æ–¥–µ–ª–∏"

#: src/custom_widgets/model_widget.py:696
msgid "Failed to pull model '{}': {}"
msgstr ""

#: src/custom_widgets/model_widget.py:697
msgid "Error pulling '{}': {}"
msgstr ""

#: src/custom_widgets/model_widget.py:699
msgid "Failed to pull model '{}' due to network error."
msgstr "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–æ–¥–µ–ª—å '{}' –∏–∑-–∑–∞ —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–∏."

#: src/custom_widgets/model_widget.py:700
msgid "Error pulling '{}'"
msgstr ""

#: src/custom_widgets/dialog_widget.py:134
#: src/custom_widgets/dialog_widget.py:146
#: src/custom_widgets/dialog_widget.py:158
msgid "Accept"
msgstr "–ü—Ä–∏–Ω—è—Ç—å"

#: src/custom_widgets/terminal_widget.py:64
msgid "Setting up Python environment..."
msgstr ""

#: src/custom_widgets/terminal_widget.py:75
msgid "Script exited"
msgstr ""

#: src/custom_widgets/terminal_widget.py:86
msgid "The script is contained inside Flatpak"
msgstr ""

#~ msgid "This video is not available"
#~ msgstr "–≠—Ç–æ –≤–∏–¥–µ–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr "–ß–∞—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"

#~ msgid "Create Chat?"
#~ msgstr "–°–æ–∑–¥–∞—Ç—å —á–∞—Ç?"

#~ msgid "Enter name for new chat"
#~ msgstr "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞"

#~ msgid "Use local instance"
#~ msgstr "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä"

#~ msgid "An error occurred while creating the model"
#~ msgstr "–ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞"

#~ msgid "Failed to connect to server"
#~ msgstr "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É"

#~ msgid "Stop Creating '{}'"
#~ msgstr "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ '{}'"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 —Ç–µ–ø–µ—Ä—å –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –¥–≤—É—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö: 9B –∏ 27B."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ '{} ({})'?"

#~ msgid "Try a different search"
#~ msgstr "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –ø–æ–∏—Å–∫"

#~ msgid "Pulling in the background..."
#~ msgstr "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ..."

#~ msgid "Featured Models"
#~ msgstr "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏"

#~ msgid "Built by Meta"
#~ msgstr "–ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å –ø–æ–º–æ—â—å—é Meta"

#~ msgid "Built by Google DeepMind"
#~ msgstr "–°–æ–∑–¥–∞–Ω Google DeepMind"

#~ msgid "Built by Microsoft"
#~ msgstr "–°–æ–∑–¥–∞–Ω –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–µ–π –ú–∞–π–∫—Ä–æ—Å–æ—Ñ—Ç"

#~ msgid "Multimodal AI with image recognition"
#~ msgstr ""
#~ "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

#~ msgid "Remove '{} ({})'"
#~ msgstr "–£–¥–∞–ª–∏—Ç—å '{} ({})'"

#~ msgid "Stop Pulling '{} ({})'"
#~ msgstr "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ '{} ({})'"

#~ msgid "Template"
#~ msgstr "–®–∞–±–ª–æ–Ω"

#~ msgid ""
#~ "Some models require a specific template. Please visit the model's website "
#~ "for more information if you're unsure."
#~ msgstr ""
#~ "–î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —à–∞–±–ª–æ–Ω. –ï—Å–ª–∏ –≤—ã –Ω–µ —É–≤–µ—Ä–µ–Ω—ã, "
#~ "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ—Å–µ—Ç–∏—Ç–µ –≤–µ–±-—Å–∞–π—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π "
#~ "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

#~ msgid "From GGUF File (Experimental)"
#~ msgstr "–ò–∑ —Ñ–∞–π–ª–∞ GGUF (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π)"

#~ msgctxt "shortcut window"
#~ msgid "General"
#~ msgstr "–û–±—â–∏–µ"

#~ msgctxt "shortcut window"
#~ msgid "Show Shortcuts"
#~ msgstr "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∫–ª–∞–≤–∏—à"

#~ msgctxt "shortcut window"
#~ msgid "Quit"
#~ msgstr "–í—ã–π—Ç–∏"

#~ msgid "Open with Default App"
#~ msgstr "–û—Ç–∫—Ä—ã—Ç—å —Å –ø–æ–º–æ—â—å—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later."
#~ msgstr ""
#~ "Alpaca —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ –≤–∞—à–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ–±—â–µ–Ω–∏–µ –≤ "
#~ "—á–∞—Ç–µ, –≤–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –º–æ–¥–µ–ª—å —Å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º, –≤—ã –º–æ–∂–µ—Ç–µ "
#~ "–≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –∏–∑ –º–µ–Ω—é \"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏\" –ø–æ–∑–∂–µ."
