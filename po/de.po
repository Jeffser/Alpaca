# German translations for Alpaca package.
# Copyright (C) 2024-2025 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# Marcel Margenberg <dev.margenberg@gmail.com>, 2024.
# Magnus Schlinsog <magnusschlinsog@gmail.com>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: 5.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-24 16:45-0600\n"
"PO-Revision-Date: 2025-05-04 01:36+0200\n"
"Last-Translator: Magnus Schlinsog <magnusschlinsog@gmail.com>\n"
"Language-Team: German\n"
"Language: de\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Generator: Gtranslator 48.0\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ki;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "Mit KI-Modellen chatten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "Ein privater KI-Client"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1317
msgid "Features"
msgstr "Funktionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1319
msgid "Talk to multiple models in the same conversation"
msgstr "Sprechen Sie mit mehreren Modellen in derselben Konversation"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1320
msgid "Pull and delete models from the app"
msgstr "Modelle aus der App abrufen und löschen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "Mehrere Konversationen führen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "Bilderkennung (Nur mit kompatiblen Modellen verfügbar)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "Erkennung von Plaintext-Dokumenten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "Chats importieren und exportieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "YouTube-Transkripte zur Eingabeaufforderung hinzufügen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "Text von einer Website zur Eingabeaufforderung hinzufügen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "PDF-Erkennung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23
msgid "Disclaimer"
msgstr "Haftungsausschluss"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"Dieses Projekt ist in keiner Weise mit Ollama verbunden, ich bin nicht "
"verantwortlich für jegliche Schäden an Ihrem Gerät oder Ihrer Software, die "
"durch die Ausführung von Code entstehen, der von Modellen geliefert wird."

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "Eine normale Konversation mit einem KI-Modell"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "Eine Konversation mit Bilderkennung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "Eine Unterhaltung mit einem benutzerdefinierten Modell"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "Eine Konversation mit Code-Hervorhebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "Ein Python-Skript, das im integrierten Terminal läuft"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation with web search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "Mehrere Modelle werden heruntergeladen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "A Live Chat conversation with a character"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:117
#: data/com.jeffser.Alpaca.metainfo.xml.in:131
#: data/com.jeffser.Alpaca.metainfo.xml.in:159
#: data/com.jeffser.Alpaca.metainfo.xml.in:211
#: data/com.jeffser.Alpaca.metainfo.xml.in:225
#: data/com.jeffser.Alpaca.metainfo.xml.in:258
#: data/com.jeffser.Alpaca.metainfo.xml.in:305
#: data/com.jeffser.Alpaca.metainfo.xml.in:352
#: data/com.jeffser.Alpaca.metainfo.xml.in:369
#: data/com.jeffser.Alpaca.metainfo.xml.in:399
#: data/com.jeffser.Alpaca.metainfo.xml.in:409
#: data/com.jeffser.Alpaca.metainfo.xml.in:420
#: data/com.jeffser.Alpaca.metainfo.xml.in:447
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:493
#: data/com.jeffser.Alpaca.metainfo.xml.in:508
#: data/com.jeffser.Alpaca.metainfo.xml.in:533
#: data/com.jeffser.Alpaca.metainfo.xml.in:561
#: data/com.jeffser.Alpaca.metainfo.xml.in:571
#: data/com.jeffser.Alpaca.metainfo.xml.in:582
#: data/com.jeffser.Alpaca.metainfo.xml.in:596
#: data/com.jeffser.Alpaca.metainfo.xml.in:608
#: data/com.jeffser.Alpaca.metainfo.xml.in:624
#: data/com.jeffser.Alpaca.metainfo.xml.in:639
#: data/com.jeffser.Alpaca.metainfo.xml.in:674
#: data/com.jeffser.Alpaca.metainfo.xml.in:699
#: data/com.jeffser.Alpaca.metainfo.xml.in:730
#: data/com.jeffser.Alpaca.metainfo.xml.in:756
#: data/com.jeffser.Alpaca.metainfo.xml.in:778
#: data/com.jeffser.Alpaca.metainfo.xml.in:809
#: data/com.jeffser.Alpaca.metainfo.xml.in:831
#: data/com.jeffser.Alpaca.metainfo.xml.in:852
#: data/com.jeffser.Alpaca.metainfo.xml.in:867
#: data/com.jeffser.Alpaca.metainfo.xml.in:892
msgid "New"
msgstr "Neu"

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Added option to regenerate responses when messages are edited"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
#: data/com.jeffser.Alpaca.metainfo.xml.in:108
#: data/com.jeffser.Alpaca.metainfo.xml.in:121
#: data/com.jeffser.Alpaca.metainfo.xml.in:138
#: data/com.jeffser.Alpaca.metainfo.xml.in:147
#: data/com.jeffser.Alpaca.metainfo.xml.in:174
#: data/com.jeffser.Alpaca.metainfo.xml.in:190
#: data/com.jeffser.Alpaca.metainfo.xml.in:199
#: data/com.jeffser.Alpaca.metainfo.xml.in:215
#: data/com.jeffser.Alpaca.metainfo.xml.in:236
#: data/com.jeffser.Alpaca.metainfo.xml.in:249
#: data/com.jeffser.Alpaca.metainfo.xml.in:264
#: data/com.jeffser.Alpaca.metainfo.xml.in:273
#: data/com.jeffser.Alpaca.metainfo.xml.in:284
#: data/com.jeffser.Alpaca.metainfo.xml.in:293
#: data/com.jeffser.Alpaca.metainfo.xml.in:341
#: data/com.jeffser.Alpaca.metainfo.xml.in:359
#: data/com.jeffser.Alpaca.metainfo.xml.in:375
#: data/com.jeffser.Alpaca.metainfo.xml.in:387
#: data/com.jeffser.Alpaca.metainfo.xml.in:437
#: data/com.jeffser.Alpaca.metainfo.xml.in:483
#: data/com.jeffser.Alpaca.metainfo.xml.in:514
#: data/com.jeffser.Alpaca.metainfo.xml.in:523
#: data/com.jeffser.Alpaca.metainfo.xml.in:586
#: data/com.jeffser.Alpaca.metainfo.xml.in:614
#: data/com.jeffser.Alpaca.metainfo.xml.in:628
#: data/com.jeffser.Alpaca.metainfo.xml.in:645
#: data/com.jeffser.Alpaca.metainfo.xml.in:656
#: data/com.jeffser.Alpaca.metainfo.xml.in:665
#: data/com.jeffser.Alpaca.metainfo.xml.in:682
#: data/com.jeffser.Alpaca.metainfo.xml.in:692
#: data/com.jeffser.Alpaca.metainfo.xml.in:709
#: data/com.jeffser.Alpaca.metainfo.xml.in:719
#: data/com.jeffser.Alpaca.metainfo.xml.in:766
#: data/com.jeffser.Alpaca.metainfo.xml.in:791
#: data/com.jeffser.Alpaca.metainfo.xml.in:816
#: data/com.jeffser.Alpaca.metainfo.xml.in:838
#: data/com.jeffser.Alpaca.metainfo.xml.in:856
#: data/com.jeffser.Alpaca.metainfo.xml.in:874
#: data/com.jeffser.Alpaca.metainfo.xml.in:886
#: data/com.jeffser.Alpaca.metainfo.xml.in:902
msgid "Fixes"
msgstr "Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "Fixed message rendering problems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:110
msgid "Fixed inconsistent message generation rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:119
msgid "Save message edit with ctrl+enter"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Fixed Live Chat and Quick Ask not working sometimes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Fixed model creation and GGUF import"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:133
msgid "Added option to use tools by default"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "Redesign model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:135
msgid "Added option to attach audio and video files (audio transcription)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:136
msgid "Added Spotify controller tool"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:140
msgid "Fixed thinking mode being on bugs out normal models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:149
msgid "Fixed Alpaca crashing when chats database has incorrect metadata (type)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:150
msgid ""
"Fixed Quick Ask and Live Chat not running when opened from terminal whilst "
"Alpaca is running"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:151
msgid ""
"Fixed stop button not working when pressed before text generation beggins"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:152
msgid "Fixed instances sometimes not appearing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:161
msgid "Live Chat (Talk to models as if you were on a call)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:162
msgid "Live message rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:163
msgid "Faster dictation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:164
msgid "Dictation whilst message is being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:165
msgid "Camera picture attachment"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:166
msgid "Quick Ask now supports attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:167
msgid "Separator element for message and attachment rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:168
msgid "Redesigned popups"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:169
msgid "Thought switch for Ollama instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:170
msgid "Username sharing for Ollama instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:171
msgid "Redesign for instance manager and tool manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:172
msgid "Better web searching tool with options"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:176
msgid "Fixed duplication of thought attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:177
msgid "Fixed weird behavior with model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:178
msgid "Ollama (Managed) instances behave better"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:179
msgid "Better optimizations for RAM (~2GB difference)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:180
msgid "Instant chat rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Models profile pictures are now saved at a higher resolution"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Quick Ask messages can now be sent by using the enter key"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:183
msgid "Alpaca is less prone to crashes now"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:192
msgid "Fixed new chat not being created when the chat list is empty"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:201
msgid "Chat exporting now works as expected"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:202
msgid "Fixed automatic creation of Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Added Hebrew and Telugu credits"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "Fixed STT model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Multiple QuickAsk window rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:217
msgid "Better stability for QuickAsk"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:218
msgid "Creating a new chat now selects it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:227
msgid "Chat Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:228
msgid "Hide \"latest\" and \"custom\" tags from model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "Hide model's languages behind popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:230
msgid "New models listed for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:231
msgid "Added option to autodictate new mesages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:232
msgid "Added Meta Llama API to list of instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:233
msgid ""
"Added new env variables options (\"24H hour formatting\" and \"only Ollama "
"mode\")"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:234
msgid "Made Mermaid scripts executable using Python HTTP server"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:238
msgid "Better stability when switching instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "Better performance when navigating menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:240
msgid "Fixed some dialogs not appearing in Quick Ask window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
msgid "Faster message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:242
msgid "Faster message rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "Fixed whisper directory not existing causing error"
msgstr "Fehler durch fehlendes \"whisper\"-Verzeichnis behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
#: data/com.jeffser.Alpaca.metainfo.xml.in:1109
msgid "Updated model list"
msgstr "Modellliste aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Alpaca now remembers it's size"
msgstr "Alpaca merkt sich nun die Fenstergröße"

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Added reasoning category for Ollama models"
msgstr "Reasoning-Kategorie für Ollama-Modelle hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:266
msgid "Improvements in sample prompts"
msgstr "Verbesserungen in Beispielprompts"

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid "Fixed auto creation of Ollama (Managed) instance"
msgstr "Automatische Erstellung einer Ollama (verwaltet)-Instanz behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Removed legacy JSON to SQLite3 migration code"
msgstr "Alten JSON-zu-SQLite3-Migrationscode entfernt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:277
msgid "Fixed power saving mode appearing whilst using online instances"
msgstr "Warnung vor Energiesparmodus bei Nutzung von Online-Instanzen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Fixed Ollama (Manged) instance not being able to be created"
msgstr "Fehler bei der Erstellung der integrierten Ollama-Instanz behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:295
msgid "Instance manager now follows default model"
msgstr "Instanz-Manager befolgt nun das Standardmodell"

#: data/com.jeffser.Alpaca.metainfo.xml.in:296
msgid "English text-to-speech voices not working"
msgstr "Englische Text-zu-Sprache-Stimmen funktionieren nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Instance manager sometimes not saving instances"
msgstr "Instanz-Manager speichert manchmal Instanzen nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:298
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""
"Fehler behoben, durch den Groq- und Deepseek-Instanzen keinen Text "
"generierten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Smart tools for models"
msgstr "Intelligente Werkzeuge für Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid "Speech recognition (message dictation)"
msgstr "Spracherkennung (Diktieren der Eingabe)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:309 src/widgets/models/speech.py:94
msgid "Text to Speech"
msgstr "Text-zu-Sprache"

#: data/com.jeffser.Alpaca.metainfo.xml.in:310
msgid "New Quick Chat system"
msgstr "Neues \"Flinke Frage\"-System"

#: data/com.jeffser.Alpaca.metainfo.xml.in:311
msgid "Filter Ollama models by categories"
msgstr "Filtern von Ollama-Modellen nach Kategorien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Better math Latex rendering in messages"
msgstr "Verbessertes Mathematik-LaTeX-Rendering in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid "Rich text rendering in attachment preview"
msgstr "Rich-Text-Rendering in Anhangsvorschau"

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Matplotlib is now included in Python code runner"
msgstr ""
"Matplotlib ist nun in der integrierten Python-Codeausführung mitgeliefert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:315
msgid "Styling for messages being generated"
msgstr "Verschönerung von Nachrichten, die gerade noch generiert werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:317
#: data/com.jeffser.Alpaca.metainfo.xml.in:425
msgid "New Instances"
msgstr "Neue Instanzen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:319
msgid "Deepseek"
msgstr "Deepseek"

#: data/com.jeffser.Alpaca.metainfo.xml.in:320
msgid "OpenRouter AI"
msgstr "OpenRouter AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:321
msgid "Anthropic"
msgstr "Anthropic"

#: data/com.jeffser.Alpaca.metainfo.xml.in:322
msgid "Groq Cloud"
msgstr "Groq Cloud"

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Fireworks AI"
msgstr "Fireworks AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:324
msgid "Lambda Labs"
msgstr "Lambda Labs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:326
msgid "New Attachment Types"
msgstr "Neue Anhangstypen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:328
msgid "Microsoft Word Document (docx)"
msgstr "Microsoft Word-Dokument (docx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:329
msgid "Microsoft PowerPoint Document (pptx)"
msgstr "Microsoft PowerPoint-Dokument (pptx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:330
msgid "Microsoft Excel Document (xlsx)"
msgstr "Microsoft Excel-Dokument (xlsx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:332
msgid "New Tools"
msgstr "Neue Werkzeuge"

#: data/com.jeffser.Alpaca.metainfo.xml.in:334 src/widgets/tools/tools.py:491
msgid "Run Command (Testing)"
msgstr "Befehl ausführen (Testing)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:335 src/widgets/tools/tools.py:407
msgid "Online Search"
msgstr "Online-Suche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:336 src/widgets/tools/tools.py:366
msgid "Extract Wikipedia Article"
msgstr "Wikipedia-Artikel extrahieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:337 src/widgets/tools/tools.py:250
msgid "Get Recipe by Name"
msgstr "Rezept durch Namen finden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:338 src/widgets/tools/tools.py:310
msgid "Get Recipes by Category"
msgstr "Rezept durch Kategorie finden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:339 src/widgets/tools/tools.py:218
msgid "Get Current Datetime"
msgstr "Derzeitiges Datum samt Uhrzeit abrufen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:343
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""
"Fehler behoben, durch den der Startbildschirm nach dem Löschen einer "
"Nachricht manchmal nicht erschien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:344
msgid "Fixed bold text not rendering correctly in tables"
msgstr "Fehlerhaftes Rendering von fettem Text in Tabellen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:345
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr "Überlaufen von Beispielprompt-Buttons auf kleinen Bildschirmen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "Updated runtime to Gnome 48"
msgstr "Laufzeit auf GNOME 48 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "Added back 'category pills' to model manager"
msgstr "Kategorie-Indikatoren zurück zum Modell-Manager gebracht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Better appearance for model manager sidebar"
msgstr "Besseres Erscheinungsbild der Seitenleiste im Modell-Manager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
#: data/com.jeffser.Alpaca.metainfo.xml.in:373
msgid "New models"
msgstr "Neue Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid "Fixed bad title generation with chain-of-thought models"
msgstr "Schlechte Titelgenerierung von Chain-of-Thought-Modellen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:362
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""
"Seitenwechsler im Modell-Manager versteckt, wenn nur eine Seite vorhanden "
"ist (Online-Instanzen)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:371
msgid "Option to delete all chats"
msgstr "Option, alle Chats zu löschen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:372
msgid "Button to refresh sample prompts"
msgstr "Knopf, um Beispielprompts neu zu laden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:377
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr "Behoben, dass integrierte Ollama-Instanz beim Speichern absürzt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:378
msgid "Fixed stop button"
msgstr "Stopp-Knopf behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:379
msgid "Fixed model search not working if there are only pulling models"
msgstr ""
"Nicht funktionierenden Modellsuche behoben, wenn es nur zu ladende Modelle "
"gibt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:380
msgid "Fixed sample prompts sometimes not appearing"
msgstr "Nicht erscheinende Beispielprompts behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:389
msgid "Don't clear the building output of C++ scripts"
msgstr "Build-Ausgabe von C++-Skripten wird nicht mehr geleert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:390
msgid "Better handling of attachments"
msgstr "Bessere Handhabung von Anhängen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:391
msgid "Handle remote Ollama instance's API Key better"
msgstr "Bessere Handhabung des API-Schlüssels einer Ollama-Remoteinstanz"

#: data/com.jeffser.Alpaca.metainfo.xml.in:392
msgid "Remove '\\n' characters in instance edit page"
msgstr "Entferne '\\n'-Buchstaben in Instanzbearbeitungsseite"

#: data/com.jeffser.Alpaca.metainfo.xml.in:401
msgid "Dynamic chat loading"
msgstr "Dynamisches Laden von Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:402
msgid "Updated Ollama instance"
msgstr "Ollama-Instanz aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:411
msgid "Tweaked appearance of models in model manager"
msgstr "Aussehen der Modelle im Modell-Manager angepasst"

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "Updated Ollama instance to 0.5.11"
msgstr "Ollama-Instanz auf 0.5.11 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:413
msgid "Added new models"
msgstr "Neue Modelle hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:422
msgid "New instance manager"
msgstr "Neuer Instanz-Manager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "New welcome screen"
msgstr "Neuer Willkommensbildschirm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:427
msgid "OpenAI ChatGPT"
msgstr "Open AI ChatGPT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "Google Gemini"
msgstr "Google Gemini"

#: data/com.jeffser.Alpaca.metainfo.xml.in:429
msgid "Together AI"
msgstr "Together AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:430
msgid "Venice"
msgstr "Venice"

#: data/com.jeffser.Alpaca.metainfo.xml.in:439
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr "Das Exportieren von Chats mit 'Gedanken'-Anhängen ist behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:440
msgid "Fixed attachment filters"
msgstr "Anhangs-Filter behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:449
msgid "New model manager"
msgstr "Neuer KI-Modell-Manager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:450
msgid "Changed GtkSpinner to AdwSpinner"
msgstr "Von GtkSpinner auf AdwSpinner gewechselt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:451
msgid "Better handling of launch process"
msgstr "Besserer Ablauf des Startprozesses"

#: data/com.jeffser.Alpaca.metainfo.xml.in:452
msgid "New loading screen at launch"
msgstr "Neuer Ladebildschirm beim Start"

#: data/com.jeffser.Alpaca.metainfo.xml.in:453
msgid "Better handling of file types"
msgstr "Bessere Handhabung von Dateitypen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:454
msgid "Better regex expression for LaTeX equations"
msgstr "Bessere RegEx-Ausdrücke für LaTeX-Gleichungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:455
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""
"Bestätigungsdialog, sollte Alpaca während des Downloads eines Modells "
"geschlossen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:456
msgid "Better handling of think tags in messages"
msgstr "Bessere Handhabung von Reasoning-Tags in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid "Default model is now in charge of generating titles"
msgstr "Das Standard-Modell generiert nun Titel"

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Message header is now shown whilst the message is being generated"
msgstr "Die Nachrichtenkopfzeile wird nun während der Generierung angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Better handling of model profile pictures"
msgstr "Bessere Handhabung von Profilbildern der Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid "New models in 'available models' list"
msgstr "Neue Modelle in der 'Verfügbare Modelle'-Liste"

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid "Added option for attaching screenshots"
msgstr "Option zum Anfügen von Screenshots hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:470
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""
"Grundlegende LaTeX-Mathematikgleichungen werden nun in Nachrichten gerendert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:471
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""
"HTML sowie C++-Skripte können nun innerhalb von Alpaca ausgeführt werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid "Added option to open the environment directory from the terminal"
msgstr "Option hinzugefügt, den Umgebungsordner vom Terminal aus zu öffnen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:473
msgid "Added option to edit code blocks directly"
msgstr "Option hinzugefügt, um Codeblöcke direkt bearbeiten zu können"

#: data/com.jeffser.Alpaca.metainfo.xml.in:474
msgid "Complete keyboard shortcut list"
msgstr "Tastenkürzelliste vervollständigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:475
msgid "Images are now attached in 640p resolution"
msgstr "Bilder werden nun in 640p-Auflösung angehangen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:476
msgid "Website attachments now use extracted titles"
msgstr "Website-Anhänge nutzen nun auch extrahierte Titel"

#: data/com.jeffser.Alpaca.metainfo.xml.in:477
msgid "Better chat title generation"
msgstr "Bessere Generierung der Chat-Titel"

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Added option to attach any plain text files"
msgstr "Option hinzugefügt, um Klartextdateien anzuhängen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:479
msgid "Added spellchecker to message entry"
msgstr "Rechtschreiberkennung zum Nachrichtenfeld hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:480
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr "Alpaca's Einstellungen werden nun mittels SQLite3 gespeichert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:481
msgid "Small appearance changes in text entries"
msgstr "Geringfügige Aussehensanpassungen in Textfeldern"

#: data/com.jeffser.Alpaca.metainfo.xml.in:485
msgid "Alpaca's launch process is more reliable"
msgstr "Alpaca's Startprozess ist zuverlässiger"

#: data/com.jeffser.Alpaca.metainfo.xml.in:486
msgid "Closing the terminal now kills the script subprocess"
msgstr ""
"Das Terminal zu schließen führt nun zum Beenden des Skript-Subprozesses"

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr "Chat-Backend von JSON zu SQLite migriert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Changed appearance of messages"
msgstr "Erscheinungsbild der Nachrichten geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:497
msgid "Added the option to add profile pictures to models"
msgstr "Option hinzugefügt, um Profilbilder zu Modellen hinzuzufügen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:499
#: data/com.jeffser.Alpaca.metainfo.xml.in:971
#: data/com.jeffser.Alpaca.metainfo.xml.in:1020
msgid "Fix"
msgstr "Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:501
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr "Override HIP_VISIBLE_DEVICES zu ROCR_VISIBLE_DEVICES gewechselt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:510
msgid "Added categories to models"
msgstr "Kategorien zu Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:511
msgid "Specified model's languages"
msgstr "Sprachen der Modelle spezifiziert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:512
msgid "Added warning when downloading embedding models"
msgstr "Warnung beim Download von Embedding-Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:516
msgid "Replaced low ram warning with big model warning"
msgstr ""
"Warnung über geringen Arbeitsspeicher mit Warnung zu großem Modell ersetzt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:525
msgid "Correctly escape markup before rendering message"
msgstr "Markup richtig escapen, bevor es in der Nachricht gerendert wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:526
msgid "Fixed about dialog not working if log file was missing"
msgstr ""
"Nicht funktionierenden 'Über Alpaca'-Dialog behoben, sollte die Log-Datei "
"fehlen."

#: data/com.jeffser.Alpaca.metainfo.xml.in:535
msgid "System messages can now be sent directly from Alpaca"
msgstr "Systemnachrichten können nun direkt mit Alpaca gesendet werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:536
msgid "New redesign for messages and smaller minimum size"
msgstr "Neues Design für Nachrichten und kleinere Minimalgröße"

#: data/com.jeffser.Alpaca.metainfo.xml.in:537
msgid "New models included in 'available models list'"
msgstr "Neue Modelle in 'Verfügbare Modelle'-Liste aufgenommen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:538
msgid "Added symbolic icon when attaching code files"
msgstr "Symbolische Icons beim Anhang von Codedateien hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:539
msgid "When exporting a chat it now includes a markdown file"
msgstr "Der Export eines Chats beinhaltet nun eine Markdown-Datei"

#: data/com.jeffser.Alpaca.metainfo.xml.in:540
msgid "Refresh button in model manager when using a remote instance"
msgstr "'Neu laden'-Knopf im Modellmanager bei Nutzung einer Remoteinstanz"

#: data/com.jeffser.Alpaca.metainfo.xml.in:541
msgid "Assistant messages are now editable"
msgstr "Assistentnachrichten können nun bearbeitet werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:542
msgid "Updated Ollama to v0.5.2"
msgstr "Ollama auf v0.5.2 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:543
msgid "New option to change model directory"
msgstr "Neue Option zum Wechseln des Modellordners"

#: data/com.jeffser.Alpaca.metainfo.xml.in:544
msgid "File previewer now resizes dynamically to content"
msgstr "Größe der Dateivorschau wird nun dynamisch zum Inhalt angepasst"

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr "Alpaca angepasst, sodass es ohne integrierte Instanz arbeiten kann"

#: data/com.jeffser.Alpaca.metainfo.xml.in:546
msgid "Compatibility added with ODT files"
msgstr "Kompatibilität mit ODT-Dateien hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "Restored ROCm compatibility"
msgstr "ROCm-Kompatibilität wiederhergestellt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Langes Drücken-Geste zu Chatzeilen hinzugefügt, sodass Aktionen auch auf "
"Touchscreens durchgeführt werden können."

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Fixed edit button not saving changes"
msgstr ""
"Fehler des Bearbeiten-Knopfes behoben, der die Änderungen nicht speicherte"

#: data/com.jeffser.Alpaca.metainfo.xml.in:552
msgid "Changed max temperature value to 2"
msgstr "Maximal-Modelltemperaturwert auf 2 geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:553
msgid "Made seed 0 actually random"
msgstr "Seed '0' tatsächlich zufällig gemacht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:554
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""
"Nicht funktionierenden GNOME-Search-Provider außerhalb von Flatpak-"
"Installationen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:563
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""
"Neue Option '--ask MESSAGE', um ein neues 'Quick Ask'-Fenster zu öffnen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:564
msgid "Gnome Search integration now works whilst the app is opened"
msgstr "GNOME-Suche-Integration funktioniert nun, wenn die App geöffnet ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:573
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""
"Startparameter '--ask MESSAGE', '--new-chat CHAT', '--select-chat CHAT', '--"
"list-chats', '--version' hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:574
msgid "Added integration as Gnome Search Provider"
msgstr "Integration als GNOME-Suche-Provider hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:575
msgid "Updated Ollama to v0.4.2 with new models"
msgstr "Ollama auf Version v0.4.2 mit neuen Modellen aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:584
msgid "User messages are now compacted into bubbles"
msgstr "Nutzernachrichten sind nun kleiner in Sprechblasen komprimiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:588
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""
"Bei Auswahl von 'Nutzung lokaler Instanz' nicht funktionierenden re-"
"Verbindungsdialog behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:589
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""
"Nicht mit zu großen Systemschriftgrößen funktionierenden Modellmanager "
"behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Details page for models"
msgstr "Detailseite für Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""
"Die Modellauswahl wird durch die Schaltfläche Modelle verwalten ersetzt, "
"wenn keine Modelle heruntergeladen wurden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:600
msgid "Added warning when model is too big for the device"
msgstr "Warnung hinzugefügt, wenn das Modell zu groß für das Gerät ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:601
msgid "Added AMD GPU indicator in preferences"
msgstr "AMD-GPU-Anzeige in den Einstellungen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:610
msgid "Better system for handling dialogs"
msgstr "Besseres System zur Handhabung von Dialogen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:611
msgid "Better system for handling instance switching"
msgstr "Besseres System für die Handhabung des Instanzenwechsels"

#: data/com.jeffser.Alpaca.metainfo.xml.in:612
msgid "Remote connection dialog"
msgstr "Dialog zur Remoteverbindung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""
"Behoben: Modelle werden beim Wechsel zwischen lokaler und entfernter Instanz "
"dupliziert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:617
msgid "Better internal instance manager"
msgstr "Besserer interner Instanzmanager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""
"Schaltflächen Abbrechen und Speichern beim Bearbeiten einer Nachricht "
"hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:630
msgid "Better handling of image recognition"
msgstr "Bessere Handhabung der Bilderkennung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "Remove unused files when canceling a model download"
msgstr "Entfernen unbenutzter Dateien beim Abbrechen eines Modell-Downloads"

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Better message blocks rendering"
msgstr "Bessere Darstellung von Nachrichtenblöcken"

#: data/com.jeffser.Alpaca.metainfo.xml.in:641
msgid "Run bash and python scripts straight from chat"
msgstr "Bash- und Python-Skripte direkt aus dem Chat ausführen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid "Updated Ollama to 0.3.12"
msgstr "Ollama auf 0.3.12 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "New models!"
msgstr "Neue Modelle!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Fixed and made faster the launch sequence"
msgstr "Startsequenz behoben und beschleunigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:648
msgid "Better detection of code blocks in messages"
msgstr "Verbesserte Erkennung von Codeblöcken in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:649
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""
"Behoben, dass die App in bestimmten Setups mit Nvidia-GPUs nicht geladen wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:658
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""
"Behoben, dass die Nachrichtenbenachrichtigung manchmal die Textrendering "
"abstürzen lässt, da sie auf unterschiedlichen Threads ausgeführt wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:667
msgid "Fixed message generation sometimes failing"
msgstr "Behoben, dass die Nachrichtenerstellung manchmal fehlschlägt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:676
msgid "Sidebar resizes with the window"
msgstr "Seitenleiste passt sich der Fenstergröße an"

#: data/com.jeffser.Alpaca.metainfo.xml.in:677
msgid "New welcome dialog"
msgstr "Neuer Begrüßungsdialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Message search"
msgstr "Nachrichtensuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid "Updated Ollama to v0.3.11"
msgstr "Ollama auf v0.3.11 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "A lot of new models provided by Ollama repository"
msgstr "Viele neue Modelle aus dem Ollama-Repository"

#: data/com.jeffser.Alpaca.metainfo.xml.in:684
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""
"Behoben, dass der Text im Modell-Manager bei aktivierter "
"Barrierefreiheitseinstellung 'Großer Text' angezeigt wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:685
msgid "Fixed image recognition on unsupported models"
msgstr "Bild-Erkennung bei nicht unterstützten Modellen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:694
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""
"Behoben, dass der Ladeindikator nicht ausgeblendet wird, wenn das Backend "
"fehlschlägt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:695
msgid "Fixed image recognition with local images"
msgstr "Bild-Erkennung bei lokalen Bildern behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Changed appearance of delete / stop model buttons"
msgstr "Aussehen der Löschen-/Stopp-Modell-Buttons geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
msgid "Fixed stop button crashing the app"
msgstr "Behoben, dass der Stopp-Button die App abstürzen lässt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:701
msgid "Made sidebar resize a little when the window is smaller"
msgstr "Seitenleiste passt sich etwas an, wenn das Fenster kleiner ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:702
msgid "Instant launch"
msgstr "Sofortiger Start"

#: data/com.jeffser.Alpaca.metainfo.xml.in:711
msgid "Fixed error on first run (welcome dialog)"
msgstr "Fehler beim ersten Start (Begrüßungsdialog) behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:712
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr "Prüfer für Ollama-Instanz (verwendet in Systempaketen) behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "Fixed 'clear chat' option"
msgstr "'Chat leeren'-Option behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:722
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr "Behoben, dass der Begrüßungsdialog die lokale Instanz am Start hindert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Fixed support for AMD GPUs"
msgstr "Unterstützung für AMD-GPUs behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:732
msgid "Model, message and chat systems have been rewritten"
msgstr "Modell-, Nachrichten und Chatsysteme wurden neugeschrieben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:733
msgid "New models are available"
msgstr "Neue Modelle verfügbar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:734
msgid "Ollama updated to v0.3.9"
msgstr "Ollama zu Version v0.3.9 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:735
msgid "Added support for multiple chat generations simultaneously"
msgstr "Support für simultane Multi-Chat-Generationen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:736
msgid "Added experimental AMD GPU support"
msgstr "Experimenteller AMD GPU Support hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:737
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""
"Statusladebalken als Indikator für Nachrichten zum Chat-Tab hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Added animations"
msgstr "Animationen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:739
msgid "Changed model manager / model selector appearance"
msgstr "Die Gestaltung des Modell Manager / Modellauswähler geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Changed message appearance"
msgstr "Die Gestaltung der Nachrichten geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:741
msgid "Added markdown and code blocks to user messages"
msgstr "Markdown und Codeblöcke für Benutzernachrichten hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Added loading dialog at launch so the app opens faster"
msgstr "Ladedialog beim Start hinzugefügt, damit sich die App schneller öffnet"

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""
"Warnung hinzugefügt, wenn sich das Gerät im 'Batteriesparmodus' befindet"

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Added inactivity timer to integrated instance"
msgstr "Inaktivitäts-Timer zur integrierten Instanz hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr "Der Chat wird jetzt nach unten gescrollt, wenn er geändert wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:748
msgid "Better handling of focus on messages"
msgstr "Bessere Handhabung von Nachrichten, die im Fokus stehen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:749
msgid "Better general performance on the app"
msgstr "Bessere Grundperformance der App"

#: data/com.jeffser.Alpaca.metainfo.xml.in:758
msgid "New duplicate chat option"
msgstr "Option zum Duplizieren von Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:759
msgid "Changed model selector appearance"
msgstr "Erscheinungsbild des Modellselektors geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Message entry is focused on launch and chat change"
msgstr "Nachrichteneingabe wird beim Start und Chatwechsel fokussiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Message is focused when it's being edited"
msgstr "Nachricht wird beim Bearbeiten fokussiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Added loading spinner when regenerating a message"
msgstr "Ladeanimation beim erneuten Generieren einer Nachricht hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr "Ollama-Debugging zum 'Über Alpaca'-Dialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""
"Erscheinungsbild und Verhalten des YouTube-Transkriptionsdialogs geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:768
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr "STRG+W und STRG+Q stoppen die lokale Instanz vor dem Schließen der App"

#: data/com.jeffser.Alpaca.metainfo.xml.in:769
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""
"Erscheinungsbild der Schaltfläche 'Modell-Manager öffnen' auf dem "
"Begrüßungsbildschirm geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:770
msgid "Fixed message generation not working consistently"
msgstr "Nachrichtengenerierung funktioniert nicht konsistent - behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:771
msgid "Fixed message edition not working consistently"
msgstr "Nachrichtenbearbeitung funktioniert nicht konsistent - behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:780
msgid "Model manager opens faster"
msgstr "Modell-Manager öffnet sich schneller"

#: data/com.jeffser.Alpaca.metainfo.xml.in:781
msgid "Delete chat option in secondary menu"
msgstr "Option 'Chat löschen' im sekundären Menü"

#: data/com.jeffser.Alpaca.metainfo.xml.in:782
msgid "New model selector popup"
msgstr "Neues Popup für die Modellauswahl"

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid "Standard shortcuts"
msgstr "Standard-Tastenkombinationen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:784
msgid "Model manager is navigable with keyboard"
msgstr "Modell-Manager ist mit der Tastatur navigierbar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:785
msgid "Changed sidebar collapsing behavior"
msgstr "Verhalten beim Ausblenden der Seitenleiste geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:786
msgid "Focus indicators on messages"
msgstr "Fokus-Indikatoren auf Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:787
msgid "Welcome screen"
msgstr "Begrüßungsbildschirm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:788
msgid "Give message entry focus at launch"
msgstr "Nachrichteneingabe beim Start fokussieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:789
msgid "Generally better code"
msgstr "Allgemein besserer Code"

#: data/com.jeffser.Alpaca.metainfo.xml.in:793
msgid "Better width for dialogs"
msgstr "Bessere Breite für Dialoge"

#: data/com.jeffser.Alpaca.metainfo.xml.in:794
msgid "Better compatibility with screen readers"
msgstr "Bessere Kompatibilität mit Bildschirmlesern"

#: data/com.jeffser.Alpaca.metainfo.xml.in:795
msgid "Fixed message regenerator"
msgstr "Nachrichtengenerator repariert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:796
msgid "Removed 'Featured models' from welcome dialog"
msgstr "'Empfohlene Modelle' aus dem Begrüßungsdialog entfernt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:797
msgid "Added default buttons to dialogs"
msgstr "Standard-Schaltflächen zu Dialogen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:798
msgid "Fixed import / export of chats"
msgstr "Import/Export von Chats behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:799
msgid "Changed Python2 title to Python on code blocks"
msgstr "Titel 'Python2' in Codeblöcken zu 'Python' geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""
"Verhindern Sie die erneute Generierung des Titels, wenn der Benutzer ihn in "
"einen benutzerdefinierten Titel geändert hat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Show date on stopped messages"
msgstr "Datum bei gestoppten Nachrichten anzeigen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Fix clear chat error"
msgstr "Fehler beim Leeren des Chats behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:811
msgid "Changed shortcuts to standards"
msgstr "Tastenkombinationen auf Standards geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "Moved 'Manage Models' button to primary menu"
msgstr "Schaltfläche 'Modelle verwalten' in das Hauptmenü verschoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "Stable support for GGUF model files"
msgstr "Stabile Unterstützung für GGUF-Modelldateien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
#: data/com.jeffser.Alpaca.metainfo.xml.in:1089
msgid "General optimizations"
msgstr "Allgemeine Optimierungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:818
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""
"Bessere Behandlung der Eingabetaste (wichtig für die japanische Eingabe)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:819
msgid "Removed sponsor dialog"
msgstr "Sponsorendialog entfernt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:820
msgid "Added sponsor link in about dialog"
msgstr "Sponsorenlink im Info-Dialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Changed window and elements dimensions"
msgstr "Fenster- und Elementabmessungen geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Selected model changes when entering model manager"
msgstr "Ausgewähltes Modell ändert sich beim Aufrufen des Modell-Managers"

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Better image tooltips"
msgstr "Bessere Bild-Tooltips"

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "GGUF Support"
msgstr "GGUF-Unterstützung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid "Regenerate any response, even if they are incomplete"
msgstr "Jede Antwort neu generieren, auch wenn sie unvollständig sind"

#: data/com.jeffser.Alpaca.metainfo.xml.in:834
msgid "Support for pulling models by name:tag"
msgstr "Unterstützung für das Abrufen von Modellen nach Name:Tag"

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid "Restored sidebar toggle button"
msgstr "Seitenleisten-Umschalttaste wiederhergestellt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:840
msgid "Reverted back to standard styles"
msgstr "Zu Standardstilen zurückgekehrt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:841
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""
"Es wurde behoben, dass generierte Titel aus irgendeinem Grund \"'S\" "
"enthalten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "Changed min width for model dropdown"
msgstr "Minimale Breite für Modell-Dropdown geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Changed message entry shadow"
msgstr "Schatten der Nachrichteneingabe geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "The last model used is now restored when the user changes chat"
msgstr ""
"Das zuletzt verwendete Modell wird nun wiederhergestellt, wenn der Benutzer "
"den Chat wechselt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:845
msgid "Better check for message finishing"
msgstr "Bessere Prüfung auf Nachrichtenende"

#: data/com.jeffser.Alpaca.metainfo.xml.in:854
msgid "Added table rendering (Thanks Nokse)"
msgstr "Tabellen-Rendering hinzugefügt (Danke Nokse)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:858
msgid "Made support dialog more common"
msgstr "Support-Dialog gängiger gemacht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:859
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""
"Dialog-Titel auf Tag-Auswahl beim Herunterladen von Modellen wurde nicht "
"richtig angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:860
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""
"Verhindern, dass bei der Chat-Generierung ein mehrzeiliger Titel generiert "
"wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:869
msgid "Bearer Token entry on connection error dialog"
msgstr "Eingabe des Bearer-Tokens im Verbindungsfehler-Dialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:870
msgid "Small appearance changes"
msgstr "Kleine Änderungen am Erscheinungsbild"

#: data/com.jeffser.Alpaca.metainfo.xml.in:871
msgid "Compatibility with code blocks without explicit language"
msgstr "Kompatibilität mit Codeblöcken ohne explizite Sprache"

#: data/com.jeffser.Alpaca.metainfo.xml.in:872
msgid "Rare, optional and dismissible support dialog"
msgstr "Seltener, optionaler und entfernbarer Support-Dialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:876
msgid "Date format for Simplified Chinese translation"
msgstr "Datumsformat für vereinfachte chinesische Übersetzung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Bug with unsupported localizations"
msgstr "Fehler bei nicht unterstützten Lokalisierungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:878
msgid "Min height being too large to be used on mobile"
msgstr "Mindesthöhe zu groß für die Verwendung auf Mobilgeräten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "Remote connection checker bug"
msgstr "Fehler beim Prüfen der Remoteverbindung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:888
msgid "Models with capital letters on their tag don't work"
msgstr "Modelle mit Großbuchstaben in ihrem Tag funktionieren nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:889
msgid "Ollama fails to launch on some systems"
msgstr "Ollama startet auf einigen Systemen nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:890
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""
"YouTube-Transkripte werden nicht im richtigen TMP-Verzeichnis gespeichert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:894
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr "Debug-Meldungen werden jetzt im 'Über Alpaca'-Dialog angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:895
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr "Ollama auf v0.3.0 aktualisiert (neue Modelle)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:904
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""
"Modelle mit '-' in ihren Namen funktionierten nicht richtig, dies ist jetzt "
"behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:905
msgid "Better connection check for Ollama"
msgstr "Bessere Verbindungsprüfung für Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:912
msgid "Stable Release"
msgstr "Stabiles Release"

#: data/com.jeffser.Alpaca.metainfo.xml.in:913
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""
"Das neue Icon wurde von Tobias Bernard über Gnome Gitlab erstellt, vielen "
"Dank für das tolle Icon!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:914
msgid "Features and fixes"
msgstr "Funktionen und Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid "Updated Ollama instance to 0.2.8"
msgstr "Ollama-Instanz auf 0.2.8 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:917
msgid "Better model selector"
msgstr "Besserer Modellselektor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:918
msgid "Model manager redesign"
msgstr "Überarbeitung des Modell-Managers"

#: data/com.jeffser.Alpaca.metainfo.xml.in:919
msgid "Better tag selector when pulling a model"
msgstr "Besserer Tag-Selektor beim Abrufen eines Modells"

#: data/com.jeffser.Alpaca.metainfo.xml.in:920
msgid "Model search"
msgstr "Modellsuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:921
msgid "Added support for bearer tokens on remote instances"
msgstr "Unterstützung für Bearer-Token auf Remote-Instanzen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:922
msgid "Preferences dialog redesign"
msgstr "Überarbeitung des Einstellungsdialogs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:923
msgid "Added context menus to interact with a chat"
msgstr "Kontextmenüs zur Interaktion mit einem Chat hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "Redesigned primary and secondary menus"
msgstr "Überarbeitete primäre und sekundäre Menüs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:925
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""
"YouTube-Integration: Fügen Sie die URL eines Videos mit Transkript ein und "
"es wird zur Eingabeaufforderung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""
"Website-Integration (experimentell): Extrahieren Sie den Text aus dem Body "
"einer Website durch Hinzufügen der URL zur Eingabeaufforderung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:927
msgid "Chat title generation"
msgstr "Generierung von Chat-Titeln"

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Auto resizing of message entry"
msgstr "Automatische Größenänderung der Nachrichteneingabe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "Chat notifications"
msgstr "Chat-Benachrichtigungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "Added indicator when an image is missing"
msgstr "Indikator hinzugefügt, wenn ein Bild fehlt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:931
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""
"Automatisches Neuanordnen der Reihenfolge der Chats beim Empfang einer "
"Nachricht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:932
msgid "Redesigned file preview dialog"
msgstr "Überarbeiteter Dateivorschau-Dialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:933
msgid "Credited new contributors"
msgstr "Neue Mitwirkende aufgeführt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:934
msgid "Better stability and optimization"
msgstr "Bessere Stabilität und Optimierung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:935
msgid "Edit messages to change the context of a conversation"
msgstr "Nachrichten bearbeiten, um den Kontext einer Unterhaltung zu ändern"

#: data/com.jeffser.Alpaca.metainfo.xml.in:936
msgid "Added disclaimers when pulling models"
msgstr "Haftungsausschlüsse beim Abrufen von Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:937
msgid "Preview files before sending a message"
msgstr "Vorschau von Dateien vor dem Senden einer Nachricht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:938
msgid "Better format for date and time on messages"
msgstr "Besseres Format für Datum und Uhrzeit in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:939
msgid "Error and debug logging on terminal"
msgstr "Fehler- und Debug-Protokollierung im Terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:940
msgid "Auto-hiding sidebar button"
msgstr "Automatisch ausblendbare Seitenleisten-Schaltfläche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:941
msgid "Various UI tweaks"
msgstr "Verschiedene Verbesserungen der Benutzeroberfläche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:943
msgid "New Models"
msgstr "Neue Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:945
msgid "Gemma2"
msgstr "Gemma2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:946
msgid "GLM4"
msgstr "GLM4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:947
msgid "Codegeex4"
msgstr "Codegeex4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:948
msgid "InternLM2"
msgstr "InternLM2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:949
msgid "Llama3-groq-tool-use"
msgstr "Llama3-groq-tool-use"

#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Mathstral"
msgstr "Mathstral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:951
msgid "Mistral-nemo"
msgstr "Mistral-nemo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "Firefunction-v2"
msgstr "Firefunction-v2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:953
msgid "Nuextract"
msgstr "Nuextract"

#: data/com.jeffser.Alpaca.metainfo.xml.in:955
msgid "Translations"
msgstr "Übersetzungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:956
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""
"Das sind alle verfügbaren Übersetzungen in Version 1.0.0, vielen Dank an "
"alle Mitwirkenden!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:958
msgid "Russian: Alex K"
msgstr "Russisch: Alex K"

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
msgid "Spanish: Jeffser"
msgstr "Spanisch: Jeffser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:960
msgid "Brazilian Portuguese: Daimar Stein"
msgstr "Brasilianisches Portugiesisch: Daimar Stein"

#: data/com.jeffser.Alpaca.metainfo.xml.in:961
msgid "French: Louis Chauvet-Villaret"
msgstr "Französisch: Louis Chauvet-Villaret"

#: data/com.jeffser.Alpaca.metainfo.xml.in:962
msgid "Norwegian: CounterFlow64"
msgstr "Norwegisch: CounterFlow64"

#: data/com.jeffser.Alpaca.metainfo.xml.in:963
msgid "Bengali: Aritra Saha"
msgstr "Bengalisch: Aritra Saha"

#: data/com.jeffser.Alpaca.metainfo.xml.in:964
msgid "Simplified Chinese: Yuehao Sui"
msgstr "Vereinfachtes Chinesisch: Yuehao Sui"

#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""
"DOCX-Kompatibilität vorübergehend entfernt aufgrund eines Fehlers mit der "
"python-lxml-Abhängigkeit"

#: data/com.jeffser.Alpaca.metainfo.xml.in:978
#: data/com.jeffser.Alpaca.metainfo.xml.in:1008
#: data/com.jeffser.Alpaca.metainfo.xml.in:1029
#: data/com.jeffser.Alpaca.metainfo.xml.in:1234
#: data/com.jeffser.Alpaca.metainfo.xml.in:1291
msgid "Big Update"
msgstr "Großes Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:980
msgid "Added compatibility for PDF"
msgstr "Kompatibilität für PDF hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:981
msgid "Added compatibility for DOCX"
msgstr "Kompatibilität für DOCX hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:982
msgid "Merged 'file attachment' menu into one button"
msgstr "Menü 'Dateianhang' in eine Schaltfläche zusammengeführt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:989
#: data/com.jeffser.Alpaca.metainfo.xml.in:1182
msgid "Quick Fix"
msgstr "Schnelle Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:990
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""
"Es gab einige Fehler beim Übergang von der alten Version der Chats zur neuen "
"Version. Ich entschuldige mich, wenn dies zu einer Beschädigung Ihres Chat-"
"Verlaufs geführt hat. Dies sollte das einzige Mal sein, dass ein solcher "
"Übergang erforderlich ist."

#: data/com.jeffser.Alpaca.metainfo.xml.in:996
#: data/com.jeffser.Alpaca.metainfo.xml.in:1148
msgid "Huge Update"
msgstr "Riesiges Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid "Added: Support for plain text files"
msgstr "Hinzugefügt: Unterstützung für reine Textdateien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid "Added: New backend system for storing messages"
msgstr "Hinzugefügt: Neues Backend-System zum Speichern von Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1000
msgid "Added: Support for changing Ollama's overrides"
msgstr "Hinzugefügt: Unterstützung zum Ändern der Überschreibungen von Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1001
msgid "General Optimization"
msgstr "Allgemeine Optimierung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1010
msgid "Added: Support for GGUF models (experimental)"
msgstr "Hinzugefügt: Unterstützung für GGUF-Modelle (experimentell)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1011
msgid "Added: Support for customization and creation of models"
msgstr ""
"Hinzugefügt: Unterstützung für die Anpassung und Erstellung von Modellen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1012
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr "Behoben: Symbole werden auf Nicht-Gnome-Systemen nicht angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1013
msgid "Update Ollama to v0.1.39"
msgstr "Ollama auf v0.1.39 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1022
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""
"Behoben: App öffnete sich nicht, wenn Modellanpassungen nicht in den "
"Konfigurationsdateien vorhanden waren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1031
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr "Mehrere Symbole geändert (Papierflugzeug für die Senden-Schaltfläche)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1032
msgid "Combined export / import chat buttons into a menu"
msgstr "Export-/Import-Chat-Schaltflächen in ein Menü zusammengefasst"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1033
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr "'Modellanpassungen' (Temperatur, Seed, Keep_Alive) hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1034
msgid "Fixed send / stop button"
msgstr "Senden-/Stopp-Schaltfläche behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1035
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""
"Behoben, dass die App beim Start nicht prüft, ob die Remoteverbindung "
"funktioniert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1042
msgid "Daily Update"
msgstr "Tägliches Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1044
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""
"Text-Ellipse zum Chatnamen hinzugefügt, damit sich die Schaltflächenbreite "
"nicht ändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1045
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr "Neue Verknüpfung zum Erstellen eines Chats (STRG+N)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1046
msgid "New message entry design"
msgstr "Neues Design für die Nachrichteneingabe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1047
msgid "Fixed: Can't rename the same chat multiple times"
msgstr "Behoben: Derselbe Chat kann nicht mehrmals umbenannt werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1054
msgid "The fix"
msgstr "Die Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1056
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""
"Behoben: Ollama-Instanz läuft weiter im Hintergrund, auch wenn sie "
"deaktiviert ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1057
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""
"Behoben: Modelle können nicht in die integrierte Instanz gezogen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1064
msgid "Quick tweaks"
msgstr "Schnelle Anpassungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1066
msgid "Added progress bar to models that are being pulled"
msgstr "Fortschrittsbalken für Modelle hinzugefügt, die abgerufen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1067
msgid "Added size to tags when pulling a model"
msgstr "Größe zu Tags hinzugefügt, wenn ein Modell abgerufen wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1068
msgid "General optimizations on the background"
msgstr "Allgemeine Optimierungen im Hintergrund"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1075
msgid "Quick fixes"
msgstr "Schnelle Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1077
msgid "Fixed: Scroll when message is received"
msgstr "Behoben: Scrollen, wenn eine Nachricht empfangen wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1078
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr "Behoben: Inhalt ändert sich nicht beim Erstellen eines neuen Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1079
msgid "Added 'Featured Models' page on welcome dialog"
msgstr "Seite 'Empfohlene Modelle' im Begrüßungsdialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1086
msgid "Nice Update"
msgstr "Schönes Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1088
msgid "UI tweaks (Thanks Nokse22)"
msgstr "UI-Anpassungen (Danke Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1090
msgid "Metadata fixes"
msgstr "Fehlerbehebungen bei den Metadaten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1097
msgid "Quick fix"
msgstr "Schnelle Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1099
msgid "Updated Spanish translation"
msgstr "Spanische Übersetzung aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1100
msgid "Added compatibility for PNG"
msgstr "Kompatibilität für PNG hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1107
msgid "New Update"
msgstr "Neues Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1110
msgid "Added image recognition to more models"
msgstr "Bilderkennung zu weiteren Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1111
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""
"Brasilianische portugiesische Übersetzung hinzugefügt (Danke Daimaar Stein)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1112
msgid "Refined the general UI (Thanks Nokse22)"
msgstr "Allgemeine Benutzeroberfläche verfeinert (Danke Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1113
msgid "Added 'delete message' feature"
msgstr "Funktion 'Nachricht löschen' hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1114
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""
"Metadaten hinzugefügt, damit Softwareanbieter wissen, dass die App mit "
"Mobilgeräten kompatibel ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1115
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""
"'Senden'-Verknüpfung auf die Eingabetaste geändert (für einen Zeilenumbruch "
"Umschalttaste+Eingabetaste verwenden)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1122
msgid "Bug Fixes"
msgstr "Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1124
msgid "Fixed: Minor spelling mistake"
msgstr "Behoben: Kleiner Rechtschreibfehler"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1125
msgid "Added 'mobile' as a supported form factor"
msgstr "'Mobil' als unterstützten Formfaktor hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1126
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr "Behoben: Dialog 'Verbindungsfehler' funktioniert nicht richtig"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1127
msgid "Fixed: App might freeze randomly on startup"
msgstr "Behoben: App kann beim Start zufällig einfrieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1128
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr "Bezeichnung 'Chats' in der Seitenleiste in 'Alpaca' geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1135
msgid "Cool Update"
msgstr "Cooles Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1137
msgid "Better design for chat window"
msgstr "Besseres Design für das Chatfenster"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1138
msgid "Better design for chat sidebar"
msgstr "Besseres Design für die Chat-Seitenleiste"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1139
msgid "Fixed remote connections"
msgstr "Remote-Verbindungen repariert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1140
msgid "Fixed Ollama restarting in loop"
msgstr "Ollama-Neustart in Schleife behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1141
msgid "Other cool backend stuff"
msgstr "Andere coole Backend-Sachen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1150
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""
"Ollama als Teil von Alpaca hinzugefügt, Ollama wird in einer Sandbox "
"ausgeführt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1151
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""
"Option zum Verbinden mit Remote-Instanzen hinzugefügt (wie es vorher "
"funktionierte)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1152
msgid "Added option to import and export chats"
msgstr "Option zum Importieren und Exportieren von Chats hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1153
msgid "Added option to run Alpaca with Ollama in the background"
msgstr "Option hinzugefügt, Alpaca mit Ollama im Hintergrund auszuführen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1154
msgid "Added preferences dialog"
msgstr "Einstellungsdialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1155
msgid "Changed the welcome dialog"
msgstr "Begrüßungsdialog geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1157
#: data/com.jeffser.Alpaca.metainfo.xml.in:1174
#: data/com.jeffser.Alpaca.metainfo.xml.in:1186
#: data/com.jeffser.Alpaca.metainfo.xml.in:1205
#: data/com.jeffser.Alpaca.metainfo.xml.in:1226
#: data/com.jeffser.Alpaca.metainfo.xml.in:1242
#: data/com.jeffser.Alpaca.metainfo.xml.in:1258
#: data/com.jeffser.Alpaca.metainfo.xml.in:1272
#: data/com.jeffser.Alpaca.metainfo.xml.in:1282
#: data/com.jeffser.Alpaca.metainfo.xml.in:1300
#: data/com.jeffser.Alpaca.metainfo.xml.in:1322
msgid "Please report any errors to the issues page, thank you."
msgstr "Bitte melden Sie alle Fehler auf der Problemseite, danke."

#: data/com.jeffser.Alpaca.metainfo.xml.in:1165
msgid "Yet Another Daily Update"
msgstr "Noch ein tägliches Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1167
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""
"Bessere Benutzeroberfläche für den Dialog 'Modelle verwalten' hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1168
msgid "Added better UI for the chat sidebar"
msgstr "Bessere Benutzeroberfläche für die Chat-Seitenleiste hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1169
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""
"Modellbeschreibung durch eine Schaltfläche zum Öffnen der Ollama-Website für "
"das Modell ersetzt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1170
msgid "Added myself to the credits as the spanish translator"
msgstr "Mich selbst als spanischen Übersetzer zu den Credits hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1171
msgid "Using XDG properly to get config folder"
msgstr "XDG korrekt verwenden, um den Konfigurationsordner zu erhalten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1172
msgid "Update for translations"
msgstr "Update für Übersetzungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1184
msgid "The last update had some mistakes in the description of the update"
msgstr ""
"Das letzte Update enthielt einige Fehler in der Beschreibung des Updates"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1194
msgid "Another Daily Update"
msgstr "Ein weiteres tägliches Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1196
msgid "Added full Spanish translation"
msgstr "Vollständige spanische Übersetzung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1197
msgid "Added support for background pulling of multiple models"
msgstr ""
"Unterstützung für das Abrufen mehrerer Modelle im Hintergrund hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1198
msgid "Added interrupt button"
msgstr "Schaltfläche zum Unterbrechen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1199
msgid "Added basic shortcuts"
msgstr "Grundlegende Tastenkürzel hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1200
msgid "Better translation support"
msgstr "Bessere Unterstützung für Übersetzungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1201
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""
"Benutzer können jetzt den Chatnamen beim Erstellen eines neuen Chats leer "
"lassen, es wird ein Platzhalter-Name hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1202
msgid "Better scalling for different window sizes"
msgstr "Bessere Skalierung für verschiedene Fenstergrößen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1203
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""
"Behoben: App kann nicht geschlossen werden, wenn die Ersteinrichtung "
"fehlschlägt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1213
msgid "Really Big Update"
msgstr "Wirklich großes Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1215
msgid "Added multiple chats support!"
msgstr "Unterstützung für mehrere Chats hinzugefügt!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1216
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""
"Unterstützung für Pango Markup hinzugefügt (fett, Liste, Titel, Untertitel, "
"Monospace)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1217
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""
"Automatisches Scrollen hinzugefügt, wenn der Benutzer am unteren Rand des "
"Chats ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1218
msgid "Added support for multiple tags on a single model"
msgstr "Unterstützung für mehrere Tags bei einem einzelnen Modell hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1219
msgid "Added better model management dialog"
msgstr "Besseren Dialog zur Modellverwaltung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1220
msgid "Added loading spinner when sending message"
msgstr "Ladespinner beim Senden einer Nachricht hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1221
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""
"Benachrichtigungen hinzugefügt, wenn die App nicht aktiv ist und ein Modell-"
"Pull abgeschlossen ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1222
msgid "Added new symbolic icon"
msgstr "Neues symbolisches Icon hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1223
msgid "Added frame to message textview widget"
msgstr "Rahmen zum Nachrichten-Textansichts-Widget hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1224
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr "Behoben: \"Code-Blöcke sollten nicht editierbar sein\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1236
msgid "Added code highlighting"
msgstr "Code-Highlighting hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1237
msgid "Added image recognition (llava model)"
msgstr "Bilderkennung hinzugefügt (LLaVA-Modell)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1238
msgid "Added multiline prompt"
msgstr "Mehrzeilige Eingabe hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1239
msgid "Fixed some small bugs"
msgstr "Einige kleine Fehler behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1240
msgid "General optimization"
msgstr "Allgemeine Optimierung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1250
msgid "Fixes and features"
msgstr "Fehlerbehebungen und Funktionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1252
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr "Russische Übersetzung (Danke github/alexkdeveloper)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1253
msgid "Fixed: Cannot close app on first setup"
msgstr "Behoben: App kann bei der Ersteinrichtung nicht geschlossen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1254
msgid "Fixed: Brand colors for Flathub"
msgstr "Behoben: Markenfarben für Flathub"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1255
msgid "Fixed: App description"
msgstr "Behoben: App-Beschreibung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1256
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""
"Behoben: Dialog 'Änderungen speichern' nur anzeigen, wenn die URL "
"tatsächlich geändert wurde"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1266
msgid "0.2.2 Bug fixes"
msgstr "0.2.2 Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1268
msgid "Toast messages appearing behind dialogs"
msgstr "Toast-Nachrichten erscheinen hinter Dialogen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1269
msgid "Local model list not updating when changing servers"
msgstr "Lokale Modellliste wird beim Wechseln der Server nicht aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1270
msgid "Closing the setup dialog closes the whole app"
msgstr "Das Schließen des Einrichtungsdialogs schließt die gesamte App"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1280
msgid "0.2.1 Data saving fix"
msgstr "0.2.1 Korrektur beim Speichern von Daten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1281
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""
"Die App hat die Konfigurationsdateien und den Chatverlauf nicht im richtigen "
"Verzeichnis gespeichert, dies ist jetzt behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1290
msgid "0.2.0"
msgstr "0.2.0"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1292
msgid "New Features"
msgstr "Neue Funktionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1294
msgid "Restore chat after closing the app"
msgstr "Chat nach dem Schließen der App wiederherstellen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1295
msgid "A button to clear the chat"
msgstr "Eine Schaltfläche zum Leeren des Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1296
msgid "Fixed multiple bugs involving how messages are shown"
msgstr "Mehrere Fehler behoben, die die Darstellung von Nachrichten betreffen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1297
msgid "Added welcome dialog"
msgstr "Begrüßungsdialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1298
msgid "More stability"
msgstr "Mehr Stabilität"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1308
msgid "0.1.2 Quick fixes"
msgstr "0.1.2 Schnelle Korrekturen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1309
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""
"Diese Version behebt einige Metadaten, die für eine ordnungsgemäße Flatpak-"
"Anwendung erforderlich sind"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1315
msgid "0.1.1 Stable Release"
msgstr "0.1.1 Stabiles Release"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1316
msgid "This is the first public version of Alpaca"
msgstr "Dies ist die erste öffentliche Version von Alpaca"

#: src/alpaca_search_provider.py.in:41
msgid "Open chat"
msgstr "Chat öffnen"

#: src/alpaca_search_provider.py.in:42
msgid "Quick ask"
msgstr "Flinke Frage"

#: src/live_chat.py:60 src/live_chat.py:152 src/quick_ask.py:76
msgid "Please select an instance in Alpaca before chatting"
msgstr ""

#: src/live_chat.py:156 src/quick_ask.py:80
msgid "Please select add a model for this instance in Alpaca before chatting"
msgstr ""

#: src/live_chat.py:159
msgid "Selected model is not available"
msgstr ""

#: src/live_chat.py:227
msgid "No Messages"
msgstr ""

#: src/live_chat.py:228
msgid "Begin by speaking to the model"
msgstr ""

#: src/main.py:220
msgid "Documentation"
msgstr "Dokumentation"

#: src/main.py:221
msgid "Become a Sponsor"
msgstr "Sponsor werden"

#: src/main.py:222
msgid "Discussions"
msgstr "Diskussionen"

#: src/ollama_models.py:33
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"70B-Modell auf dem neuesten Stand der Technik. Llama 3.3 70B liefert einemit "
"Llama 3.1 405B vergleichbare Leistung."

#: src/ollama_models.py:55
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ ist das Reasoning-Modell aus der Qwen-Serie."

#: src/ollama_models.py:83
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision ist eine Sammlung von besonders auf Anweisungen "
"abgestimmten, logisch denkenden generativen Modellen in Größen von11B und "
"90B Parametern."

#: src/ollama_models.py:119
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Metas Llama 3.2 wird kleiner mit 1B- und 3B-Modellen."

#: src/ollama_models.py:154
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 ist ein neues State-of-the-Art-Modell von Meta, das in den Größen "
"8B, 70B und 405B Parameter verfügbar ist."

#: src/ollama_models.py:181
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: Das derzeit leistungsfähigste offen verfügbare LLM"

#: src/ollama_models.py:204
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr ""
"Das von Mistral AI veröffentlichte 7B-Modell, aktualisiert auf Version 0.3."

#: src/ollama_models.py:228
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Ein leistungsstarkes offenes Einbettungsmodell mit einem großen Token-"
"Kontextfenster."

#: src/ollama_models.py:257
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma ist eine Familie leichtgewichtiger, hochmoderner offener Modelle, die "
"von Google DeepMind entwickelt wurden. Aktualisiert auf Version 1.1"

#: src/ollama_models.py:313
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 ist eine Reihe großer Sprachmodelle von Alibaba Cloud, die von 0,5 "
"Mrd. bis 110 Mrd. Parameter reichen"

#: src/ollama_models.py:377
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 ist eine neue Serie großer Sprachmodelle der Alibaba Group"

#: src/ollama_models.py:406
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 ist eine Familie leichtgewichtiger 3B (Mini) und 14B (Medium) State-of-"
"the-Art Open-Source-Modelle von Microsoft."

#: src/ollama_models.py:438
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 ist eine Sammlung von Grundlagensprachmodellen mit 7B bis 70B "
"Parametern."

#: src/ollama_models.py:500
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Die Qwen2.5-Modelle sind auf Alibabas neuesten groß angelegten Datensatz mit "
"bis zu 18 Billionen Tokens vortrainiert. Das Modell unterstützt bis zu 128K "
"Tokens und bietet mehrsprachige Unterstützung."

#: src/ollama_models.py:532
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 ist ein leistungsstarkes und effizientes Modell, das in drei "
"Größen verfügbar ist: 2B, 9B und 27B."

#: src/ollama_models.py:566
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA ist ein neuartiges End-to-End-trainiertes großes multimodales "
"Modell, das einen Vision-Encoder und Vicuna für das allgemeine Verständnis "
"von Bildern und Sprache kombiniert. Aktualisiert auf Version 1.6."

#: src/ollama_models.py:603
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Ein großes Sprachmodell, das Textaufforderungen verwenden kann, um Code zu "
"generieren und zu diskutieren."

#: src/ollama_models.py:649
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"Die neueste Serie von code-spezifischen Qwen-Modellen mit erheblichen "
"Verbesserungen in der Code-Generierung, dem Code-Verständnis und der Code-"
"Korrektur."

#: src/ollama_models.py:673
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Ein State-of-the-Art 12B-Modell mit 128k Kontextlänge, entwickelt von "
"Mistral AI in Zusammenarbeit mit NVIDIA."

#: src/ollama_models.py:695
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"Das TinyLlama-Projekt ist ein offenes Unterfangen, um ein kompaktes 1,1-"
"Milliarden-Llama-Modell mit 3 Billionen Token zu trainieren."

#: src/ollama_models.py:718
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "State-of-the-Art großes Einbettungsmodell von mixedbread.ai"

#: src/ollama_models.py:751
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 ist die nächste Generation transparent trainierter offener Code-"
"LLMs, die in drei Größen erhältlich ist: 3B, 7B und 15B Parameter."

#: src/ollama_models.py:777
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Eine Reihe von Mixture-of-Experts (MoE)-Modellen mit offenen Gewichten von "
"Mistral AI in den Parametergrößen 8x7b und 8x22b."

#: src/ollama_models.py:803
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Unzensierte, 8x7b und 8x22b feinabgestimmte Modelle basierend auf den "
"Mixtral-Mixture-of-Experts-Modellen, die sich bei Codierungsaufgaben "
"auszeichnen. Erstellt von Eric Hartford."

#: src/ollama_models.py:832
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma ist eine Sammlung leistungsstarker, leichtgewichtiger Modelle, die "
"eine Vielzahl von Codieraufgaben ausführen können, wie z. B. Fill-in-the-"
"Middle-Code-Vervollständigung, Code-Generierung, Verständnis natürlicher "
"Sprache, mathematisches Schlussfolgern und Anweisungsbefolgung."

#: src/ollama_models.py:860
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Ein Open-Source-Mixture-of-Experts-Codesprachmodell, das bei "
"codespezifischen Aufgaben eine Leistung vergleichbar mit GPT4-Turbo erreicht."

#: src/ollama_models.py:882
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: ein 2,7-Milliarden-Sprachmodell von Microsoft Research, das "
"herausragende Fähigkeiten beim Schlussfolgern und Sprachverständnis "
"demonstriert."

#: src/ollama_models.py:909
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Unzensiertes Llama 2-Modell von George Sung und Jarrad Hope."

#: src/ollama_models.py:944
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder ist ein leistungsfähiges Codiermodell, das mit zwei Billionen "
"Code- und natürlichen Sprach-Token trainiert wurde."

#: src/ollama_models.py:985
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Eine Sammlung von Text-Embedding-Modellen von Snowflake, optimiert für die "
"Leistung."

#: src/ollama_models.py:1013
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"State-of-the-Art-Großsprachenmodell von Microsoft AI mit verbesserter "
"Leistung bei komplexen Chat-, mehrsprachigen, Reasoning- und Agenten-"
"Anwendungsfällen."

#: src/ollama_models.py:1036
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"Das unzensierte Dolphin-Modell basierend auf Mistral, das sich bei "
"Codierungsaufgaben auszeichnet. Aktualisiert auf Version 2.8."

#: src/ollama_models.py:1064
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 ist ein neues Modell mit 8B und 70B Größen von Eric Hartford "
"basierend auf Llama 3, das eine Vielzahl von Anweisungs-, Konversations- und "
"Codierungsfähigkeiten besitzt."

#: src/ollama_models.py:1098
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 ist ein leistungsstarkes zweisprachiges Sprachmodell."

#: src/ollama_models.py:1121
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R ist ein großes Sprachmodell, das für die Konversationsinteraktion "
"und Aufgaben mit langem Kontext optimiert ist."

#: src/ollama_models.py:1158
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Ein universelles Modell mit 3 Milliarden bis 70 Milliarden Parametern, "
"geeignet für Einstiegshardware."

#: src/ollama_models.py:1181
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Ein LLaVA-Modell, das von Llama 3 Instruct mit besseren Ergebnissen in "
"mehreren Benchmarks feinabgestimmt wurde."

#: src/ollama_models.py:1208
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr ist eine Reihe von feinabgestimmten Versionen der Mistral- und "
"Mixtral-Modelle, die darauf trainiert sind, als hilfreiche Assistenten zu "
"fungieren."

#: src/ollama_models.py:1230
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Ein leichtgewichtiges KI-Modell mit 3,8 Milliarden Parametern, dessen "
"Leistung vergleichbare und größere Modelle übertrifft."

#: src/ollama_models.py:1258
msgid "Embedding models on very large sentence level datasets."
msgstr "Einbettungsmodelle auf sehr großen Datensätzen auf Satzebene."

#: src/ollama_models.py:1281
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral ist Mistral AIs initiales Code-Modell welches auf Code-"
"Generierungsaufgaben getrimmt ist"

#: src/ollama_models.py:1318
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder ist ein Codegenerierungsmodell, das auf über 80 "
"Programmiersprachen trainiert wurde."

#: src/ollama_models.py:1350
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Allgemeines Chat-Modell basierend auf Llama und Llama 2 mit Kontextgrößen "
"von 2K bis 16K."

#: src/ollama_models.py:1387
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "Eine Familie offener Grundlagenmodelle von IBM für Code Intelligence"

#: src/ollama_models.py:1409
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca ist ein Modell mit 7 Milliarden Parametern, das auf dem "
"Mistral 7B-Modell unter Verwendung des OpenOrca-Datensatzes feinabgestimmt "
"wurde."

#: src/ollama_models.py:1441
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 Eine Familie von kleinen Modellen mit 135M, 360M und 1.7B Parametern, "
"trainiert auf einem neuen hochwertigen Datensatz. "

#: src/ollama_models.py:1473
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored ist ein 7B-, 13B- und 30B-Parametermodell, das auf "
"Llama 2 Uncensored von Eric Hartford basiert."

#: src/ollama_models.py:1502
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Auf Llama 2 basierendes Modell, das zur Verbesserung der chinesischen "
"Dialogfähigkeit feinabgestimmt wurde."

#: src/ollama_models.py:1525
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 ist ein neues Modell von BAAI, das sich durch seine Vielseitigkeit in "
"Multi-Funktionalität, Mehrsprachigkeit und Multigranularität."

#: src/ollama_models.py:1550
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Ein vielseitiges Modell für KI-Softwareentwicklungsszenarien, einschließlich "
"Code-vervollständigung."

#: src/ollama_models.py:1573
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Eine Familie von Open-Source-Modellen, die auf einer Vielzahl von Daten "
"trainiert wurden und ChatGPT bei verschiedenen Benchmarks übertreffen. "
"Aktualisiert auf Version 3.5-0106."

#: src/ollama_models.py:1601
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, veröffentlicht von Cohere, ist eine neue Familie von State-of-the-"
"Art, mehrsprachigen Modellen, die 23 Sprachen unterstützen."

#: src/ollama_models.py:1624
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 ist ein großes Sprachmodell, das auf einer großen Menge von "
"Codedaten vortrainiert wurde."

#: src/ollama_models.py:1652
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"Die leistungsstarke Modellfamilie von Nous Research, die sich bei "
"wissenschaftlichen Diskussionen und Codierungsaufgaben. "

#: src/ollama_models.py:1674
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ ist ein leistungsstarkes, skalierbares großes Sprachmodell, das "
"speziell dafür entwickelt wurde, sich bei realen "
"Unternehmensanwendungsfällen zu bewähren."

#: src/ollama_models.py:1697
msgid "State-of-the-art code generation model"
msgstr "State-of-the-Art-Codegenerierungsmodell"

#: src/ollama_models.py:1721
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B ist ein Codierungsmodell mit Anweisungs- und "
"Codevervollständigungsvarianten, das Modellen wie Code Llama 7B, die 2,5-mal "
"größer sind, ebenbürtig ist."

#: src/ollama_models.py:1743
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Ein experimentelles 1,1-Milliarden-Parameter-Modell, das auf dem neuen "
"Dolphin-2.8-Datensatz von Eric Hartford trainiert und auf TinyLlama basiert "
"wurde."

#: src/ollama_models.py:1770
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 ist ein 7B-Modell, das von Teknium auf Mistral mit "
"vollständig offenen Datensätzen feinabgestimmt wurde."

#: src/ollama_models.py:1794
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 ist Mistrals neues Vorzeigemodell, das bei der "
"Codegenerierung, Mathematik und logischem Denken mit einem 128k-"
"Kontextfenster und Unterstützung für Dutzende von Sprachen deutlich "
"leistungsfähiger ist."

#: src/ollama_models.py:1827
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math  ist eine Reihe von spezialisierten mathematischen "
"Sprachmodellen, die auf den  Qwen2 LLMs aufbaut, die die mathematischen "
"Fähigkeiten von  Open-Source-Modellen und sogar Closed-Source-Modellen (z. "
"B. GPT4o) übertrifft."

#: src/ollama_models.py:1851
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Ein starkes mehrsprachiges allgemeines Sprachmodell mit wettbewerbsfähiger "
"Leistung gegenüber Llama 3."

#: src/ollama_models.py:1885
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 ist ein State-of-the-Art-Sprachmodell mit 1,6 Mrd. und 12 Mrd. "
"Parametern, das auf mehrsprachigen Daten in Englisch, Spanisch, Deutsch, "
"Italienisch, Französisch, Portugiesisch und Niederländisch trainiert wurde."

#: src/ollama_models.py:1908
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA ist ein multimodales Modell, das aus dem Mistral-7B-Basismodell "
"besteht, das um die LLaVA-Architektur erweitert wurde."

#: src/ollama_models.py:1929
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Ein leistungsstarkes Modell, das mit einer neuen Technik namens Reflection-"
"Tuning trainiert wurde, die einem LLM beibringt, Fehler in seinem "
"Denkprozess zu erkennen und zu korrigieren."

#: src/ollama_models.py:1960
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Ein fortschrittliches Sprachmodell, das mit 2 Billionen zweisprachigen Token "
"erstellt wurde."

#: src/ollama_models.py:1987
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Dieses Modell erweitert die Kontextlänge von LLama-3 8B von 8k auf über 1 "
"Million Token."

#: src/ollama_models.py:2020
msgid "Model focused on math and logic problems"
msgstr "Modell, das sich auf Mathematik- und Logikprobleme konzentriert"

#: src/ollama_models.py:2043
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 ist ein kleines Vision-Language-Modell, das für den effizienten "
"Betrieb auf Edge-Geräten entwickelt wurde."

#: src/ollama_models.py:2065
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Ein feinabgestimmtes Modell basierend auf Mistral mit guter Abdeckung von "
"Domäne und Sprache."

#: src/ollama_models.py:2092
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Ein Modell von NVIDIA, das auf Llama 3 basiert und sich bei "
"konversationeller Frage-beantwortung (QA) und abrufgestützter Generierung "
"(RAG) auszeichnet."

#: src/ollama_models.py:2119
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Konversationsmodell basierend auf Llama 2, das bei verschiedenen Benchmarks "
"konkurrenzfähig abschneidet."

#: src/ollama_models.py:2147
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder ist ein Codevervollständigungsmodell, das auf StarCoder für SQL-"
"Generierungsaufgaben feinabgestimmt wurde"

#: src/ollama_models.py:2174
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr ""
"Allgemeine Gebrauchsmodelle basierend auf Llama und Llama 2 von Nous "
"Research."

#: src/ollama_models.py:2197
msgid "Code generation model based on Code Llama."
msgstr "Codegenerierungsmodell basierend auf Code Llama."

#: src/ollama_models.py:2224
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr ""
"Eine Erweiterung von Llama 2, die einen Kontext von bis zu 128k Token "
"unterstützt."

#: src/ollama_models.py:2252
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Eine 7B- und 15B-unzensierte Variante der Dolphin-Modellfamilie, die sich "
"beim Codieren auszeichnet, basierend auf StarCoder2."

#: src/ollama_models.py:2279
msgid "General use model based on Llama 2."
msgstr "Allgemeines Gebrauchsmodell basierend auf Llama 2."

#: src/ollama_models.py:2308
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Ein starkes, wirtschaftliches und effizientes Mixture-of-Experts-"
"Sprachmodell."

#: src/ollama_models.py:2330
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling ist ein großes Sprachmodell, das durch Reinforcement Learning aus "
"KI-Feedback trainiert wurde, um die Nützlichkeit von Chatbots zu verbessern."

#: src/ollama_models.py:2352
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Ein Begleitassistent, der in Philosophie, Psychologie und persönlichen "
"Beziehungen geschult ist. Basierend auf Mistral."

#: src/ollama_models.py:2390
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 ist die neueste Version des Flaggschiffs der Hermes-Reihe von LLM "
"von Nous Research "

#: src/ollama_models.py:2418
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder ist eine Serie von Open-Source-Code-Sprachmodellen, die "
"Spitzenleistungen im Codieren mit weniger als 10 Milliarden Parametern "
"erbringt."

#: src/ollama_models.py:2449
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Ein vom Technology Innovation Institute (TII) entwickeltes LLM zur Nutzung "
"in Zusammenfassung, Textgenerierung und als Chatbot."

#: src/ollama_models.py:2486
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 ist ein 7B-Parametermodell, das auf praktische Szenarien mit "
"herausragender Schlussfolgerungsfähigkeit zugeschnitten ist."

#: src/ollama_models.py:2508
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Ein kompaktes, aber leistungsstarkes 10,7-Milliarden-Large-Language-Modell, "
"das für einmalige Konversation entwickelt wurde."

#: src/ollama_models.py:2532
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 ist ein 72B-Parameter-Modell welches besonders gut in "
"Codevervollständigung, Mathematik und Log-Extrahierungsaufgaben abschneidet."

#: src/ollama_models.py:2555
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr ""
"Ein neues kleines LLaVA-Modell, das von Phi 3 Mini feinabgestimmt wurde."

#: src/ollama_models.py:2583
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 wurde von Microsoft Research entwickelt und ist eine feinabgestimmte "
"Version von Metas Llama-2-Modellen. Das Modell ist speziell darauf "
"ausgelegt, sich besonders beim logischen Schlussfolgern auszuzeichnen."

#: src/ollama_models.py:2614
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Eine Serie multimodaler LLMs (MLLMs), die für das Verständnis von Vision und "
"Sprache entwickelt wurde."

#: src/ollama_models.py:2646
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Auf Llama 2 basierendes Modell, das auf einem Orca-ähnlichen Datensatz "
"feinabgestimmt wurde. Ursprünglich Free Willy genannt."

#: src/ollama_models.py:2675
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""
"Mistral Small 3 setzt neue Maße für die Kategorie an “kleinen” "
"Sprachmodellen unter 70B Parametern."

#: src/ollama_models.py:2697
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"2,7-Milliarden-unzensiertes Dolphin-Modell von Eric Hartford, basierend auf "
"dem Phi-Sprachmodell von Microsoft Research."

#: src/ollama_models.py:2730
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 ist eine Familie von kompakten Sprachmodellen - verfügbar in drei "
"Größen: 135M, 360M und 1.7B Parameter."

#: src/ollama_models.py:2752
msgid "Uncensored version of Wizard LM model"
msgstr "Unzensierte Version des Wizard-LM-Modells"

#: src/ollama_models.py:2775
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Ein kommerziell freundliches kleines Sprachmodell von NVIDIA, optimiert für "
"Rollenspiel, RAG-QA und Funktionsaufrufe."

#: src/ollama_models.py:2797
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Eine Erweiterung von Mistral zur Unterstützung von Kontextfenstern von 64K "
"oder 128K."

#: src/ollama_models.py:2825
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Eine Erweiterung von Llama 2, die sich darauf spezialisiert hat, sowohl "
"allgemeines Sprachverständnis als auch domänenspezifisches Wissen, "
"insbesondere im Bereich Programmierung und Mathematik, zu integrieren."

#: src/ollama_models.py:2847
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Feinabgestimmtes Llama-2-Modell zur Beantwortung medizinischer Fragen "
"basierend auf einem Open-Source-Medizindatensatz."

#: src/ollama_models.py:2874
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Open-Source-medizinisches Großsprachenmodell, das von Llama 2 auf den "
"medizinischen Bereich angepasst wurde."

#: src/ollama_models.py:2902
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Eine Reihe von Modellen von Groq, die einen bedeutenden Fortschritt in den "
"Open-Source-KI-Fähigkeiten für die Verwendung von Werkzeugen/"
"Funktionsaufrufen darstellen."

#: src/ollama_models.py:2924
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct ist ein LLM, welches von NVIDIA verfeinert "
"wurde, um dessen Antworten auf Nutzeranfragen hilfreicher zu machen."

#: src/ollama_models.py:2946
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven ist ein 13B-Anweisungsmodell, das für Funktionsaufrufaufgaben "
"optimiert wurde."

#: src/ollama_models.py:2967
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"Das Nous-Hermes-2-Modell von Nous Research, jetzt über Mixtral trainiert."

#: src/ollama_models.py:2990
msgid "Great code generation model based on Llama2."
msgstr "Großartiges Codegenerierungsmodell basierend auf Llama2."

#: src/ollama_models.py:3012
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Unzensiertes Llama2-basiertes Modell mit Unterstützung für ein 16K-"
"Kontextfenster."

#: src/ollama_models.py:3053
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Die IBM Granite 2B- und 8B-Modelle sind dazu entwickelt, toolbasierte "
"Anwendungsfälle und Unterstützung für abrufaugmentierte Generierung (RAG), "
"vereinfachte Codegenerierung, Übersetzung und das Beheben von Bugs zu "
"unterstützen."

#: src/ollama_models.py:3076
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder ist eine Familie von 7B-Parametermodellen, die mit 75K "
"synthetischen Anweisungsdaten unter Verwendung von OSS-Instruct trainiert "
"wurden, einem neuartigen Ansatz zur Aufklärung von LLMs mit Open-Source-"
"Codeschnipseln."

#: src/ollama_models.py:3098
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Ein leichtgewichtiges Chatmodell, das eine genaue und reaktionsschnelle "
"Ausgabe ermöglicht, ohne High-End-Hardware zu benötigen."

#: src/ollama_models.py:3121
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Ein leistungsstarkes Code-Anweisungsmodell, das durch Zusammenführen von "
"zwei bestehenden Code-Modellen erstellt wurde."

#: src/ollama_models.py:3144
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 ist ein kausales Decoder-only-Modell mit 11B Parametern, das von TII "
"entwickelt und über 5T Token trainiert wurde."

#: src/ollama_models.py:3166
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna ist ein 13B-Parametermodell basierend auf Llama 2, das von "
"MelodysDreamj trainiert wurde."

#: src/ollama_models.py:3188
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite ist ein feinabgestimmtes Modell basierend auf Mistral mit "
"verbesserten Fähigkeiten zur Verarbeitung langer Kontexte."

#: src/ollama_models.py:3211
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: ein 7B-Modell, das von Mistral AI für mathematisches "
"Schlussfolgern und wissenschaftliche Entdeckungen entwickelt wurde."

#: src/ollama_models.py:3233
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr "7B-Parameter-Text-zu-SQL-Modell von MotherDuck und Numbers Station."

#: src/ollama_models.py:3254
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b ist eine Transformation von Dolphin-2.2-70b, die durch "
"Verschachtelung des Modells mit sich selbst erstellt wurde."

#: src/ollama_models.py:3276
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro Preview: ein fortschrittliches großes Sprachmodell (LLM) mit 22 "
"Milliarden Parametern, das für den Einsatz auf einer einzelnen GPU ausgelegt "
"ist."

#: src/ollama_models.py:3303
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Eine Modellreihe, die HTML-Inhalte in Markdown-Inhalte umwandelt, was für "
"Aufgaben der Inhaltskonvertierung nützlich ist."

#: src/ollama_models.py:3324
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Ein leistungsstarkes Mixture-of-Experts-Modell, feinabgestimmt mit "
"hochwertigen Daten."

#: src/ollama_models.py:3346
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Ein 7B-Chatmodell, feinabgestimmt mit hochwertigen Daten und basierend auf "
"Zephyr."

#: src/ollama_models.py:3369
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Zusammenführung des Open-Orca-OpenChat-Modells und des Garage-bAInd-"
"Platypus-2-Modells. Entwickelt für Chat und Codegenerierung."

#: src/ollama_models.py:3386
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Ein Sprachmodell, das durch Kombination von zwei feinabgestimmten "
"Llama-2-70B-Modellen zu einem einzigen Modell erstellt wurde."

#: src/ollama_models.py:3427
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Die IBM Granite 1B- und 3B-Modelle sind die ersten Mixture of Experts (MoE)-"
"Granite-Modelle von IBM, entwickelt für Nutzung mit geringer Latenz."

#: src/ollama_models.py:3449
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Ein 3,8B-Modell, das auf einem privaten synthetischen Datensatz von hoher "
"Qualität für die Informationsextraktion feinabgestimmt wurde, basierend auf "
"Phi-3."

#: src/ollama_models.py:3500
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Cohere For AI's LLMs, trainiert darauf, gut in 23 Sprachen abzuschneiden."

#: src/ollama_models.py:3522
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr ""
"DBRX ist ein offenes, allgemeines LLM, das von Databricks erstellt wurde."

#: src/ollama_models.py:3544
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Ein offenes, großes Reasoning-Modell für Lösungen in der echten Welt von der "
"Alibaba International Digital Commerce Group (AIDC-AI)."

#: src/ollama_models.py:3567
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Einbettungsmodell von BAAI, das Texte auf Vektoren abbildet."

#: src/ollama_models.py:3589
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Ein offenes Funktionsaufrufmodell basierend auf Llama 3, das mit den "
"Funktionsaufruffähigkeiten von GPT-4o konkurrenzfähig ist."

#: src/ollama_models.py:3610
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Ein robustes Konversationsmodell, das sowohl für Chat- als auch für "
"Anweisungs-anwendungsfälle entwickelt wurde."

#: src/ollama_models.py:3632
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Eine verbesserte Version von DeepSeek-V2, welche die generischen sowie "
"Coding-Fähigkeiten von sowohl DeepSeek-V2-Chat als auch DeepSeek-Coder-V2-"
"Instruct vereint."

#: src/ollama_models.py:3665
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma ist eine Sammlung von Anweisungs-getuneten Modellen zur "
"Auswertung von der Sicherheit der Prompteingaben sowie -ausgaben aufgrund "
"einer Sammlung an definierten Sicherheitsregeln."

#: src/ollama_models.py:3687
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr "Ein hochmodernes Faktenprüfungsmodell, entwickelt von Bespoke Labs."

#: src/ollama_models.py:3715
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 ist eine Serie an Modellen, die auf Inhaltsicherheits-"
"Klassifizierung von LLM-Eingaben und -Ausgaben feinabgestimmt wurden."

#: src/ollama_models.py:3739
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Satztransformationsmodell, das für Aufgaben wie Clustering oder semantische "
"Suche verwendet werden kann."

#: src/ollama_models.py:3769
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder ist eine offene, reproduzierbare LLM-Familie, welche 1.5B und 8B-"
"Modelle beinhaltet und Konversationen in Englisch und Chinesisch unterstützt."

#: src/ollama_models.py:3798
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 ist eine Familie an führenden, Anweisungen folgenden Modellen mit "
"quelloffenen Daten, Code und Reproduktionsanweisungen vom The Allen "
"Institute for AI."

#: src/ollama_models.py:3826
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Snowflake's erstklassiges Einbettungsmodell. Arctic Embed 2.0 fügt "
"multilinguale Unterstützung hinzu, ohne die Leistung oder Skalierbarkeit in "
"Englisch zu beeinflussen."

#: src/ollama_models.py:3854
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Die IBM Granite Guardian 3.0 2B- und 8B-Modelle wurden entwickelt, um "
"Risiken in Ein- und Ausgaben zu erkennen."

#: src/ollama_models.py:3888
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 ist ein Sammlung an Anweisungs-feinabgestimmten, bilingualen "
"(Englisch und Koreanisch), generativen Modellen zwischen 2.4B und 32B "
"Parametern, entwickelt und veröffentlicht von LG AI Research."

#: src/ollama_models.py:3936
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 sind multilinguale Sprachmodelle für Südostasien. Verfügbar in 1B-, "
"8B- und 20B-Parametergrößen."

#: src/ollama_models.py:3974
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Eine Familie an effizienten KI-Modellen unter 10B Parametern, die "
"leistungsfähig in Wissenschaft, Mathematik und Programmierung durch "
"innovative Trainingstechniken sind."

#: src/ollama_models.py:4015
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"Die IBM Granite 2B- und 8B-Modelle sind ausschließlich textbasierte, dichte "
"LLMs, welche auf über 12 Billionen Tokens an Daten trainiert wurden und "
"umfangreiche Fortschritte gegenüber deren Vorgängern in Gebieten wie "
"Geschwindigkeit in IBM's initialien Tests zeigen."

#: src/ollama_models.py:4056
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Die IBM Granite 1B- und 3B-Modelle sind Mixture of Experts (MoE)-Modelle für "
"langen Kontext von IBM für die Nutzung mit geringer Latenz."

#: src/ollama_models.py:4097
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"Die IBM Granite Embedding 30M- und 278M-Modelle sind ausschließlich "
"textbasierte, dichte biencoder-embedding-Modelle mit 30M auf "
"Englischdedizierte und 278M auf multilinguale Zwecke dedizierte Parameter."

#: src/ollama_models.py:4119
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4 ist ein 14B-Parameter, modernes und offenes Modell von Microsoft."

#: src/ollama_models.py:4141
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Ein neues, kleines Reasoning-Modell, feinabgestimmt von dem Qwen 2.5 3B-"
"Instruct-Modell"

#: src/ollama_models.py:4165
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 ist die nächste Generation der Dolphin-Serie "
"vonAnweisungs-feinabgestimmten Modellen, die darauf ausgelegt sind, die "
"ultimativen, allgemeinen, lokalen Modelle für Coding, Mathematik, "
"Funktionsaufrufe und generelle Nutzung zu sein."

#: src/ollama_models.py:4215
msgid ""
"DeepSeek-R1 is a family of open reasoning models with performance "
"approaching that of leading models, such as O3 and Gemini 2.5 Pro."
msgstr ""

#: src/ollama_models.py:4236
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Ein starkes Mixture of Experts (MoE)-Sprachmodell mit 671B Parametern "
"insgesamt und 37B Parametern, die für jeden Token aktiviert werden."

#: src/ollama_models.py:4263
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 ist eine neue Familie von 7B- und 13B-Modellen, trainiert auf bis zu "
"5 Billionen Token. Diese Modelle haben eine ähnliche oder sogar bessere "
"Leistung als ähnliche, vollständig offene Modelle und sind mit anderen open-"
"weight-Modellen wie Llama 3.1 in englischen, akademischen Benchmarks "
"kompetetiv."

#: src/ollama_models.py:4311
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"Das kleinste Modell in Cohere's R-Serie liefert höchste Geschwindigkeit, "
"Effizienz und Qualität, um starke KI-Anwendungen auf handelsüblichen GPUs "
"und Edge-Geräten auszuführen."

#: src/ollama_models.py:4338
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"Eine vollständig quelloffenene Familie an Reasoning-Modellen, erstellt "
"mithilfe von Datensätzen, die von DeepSeek-R1 abgeleitet wurden."

#: src/ollama_models.py:4361
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"Eine feinabgestimmte Version von Deepseek-R1-Distilled-Qwen-1.5B, die die "
"Leistung von OpenAI's o1-preview mit nur 1.5B Parametern auf häufigen "
"Mathematikgleichungen übertrifft."

#: src/ollama_models.py:4390
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"Eine version vom DeepSeek-R1-Modell, welche durch Perplexity nachtrainiert "
"wurde, um unvoreingenommene, akkruate und faktenbasierte "
"Informationswiedergabe zu ermöglichen."

#: src/ollama_models.py:4427
msgid "The current, most capable model that runs on a single GPU."
msgstr "Das neue, leistungsstärkste Modell, das auf einer einzigen GPU läuft."

#: src/ollama_models.py:4474
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini bringt ausschlaggebende Verbesserungen in den multilingualen, "
"Reasoning- und mathematischen Fähigkeiten und unterstützt nun die "
"langerwarteten Funktionsaufruf-Fähigkeiten."

#: src/ollama_models.py:4498
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"Ein kompaktes und effizienties Vision-Sprachmodell, das besonders für das "
"visuelle Verstehen von Dokumenten, automatischer Extraktion von Inhalten aus "
"Tabellen, Diagrammen, Infografiken und mehr trainiert wurde."

#: src/ollama_models.py:4538
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 ist eine Familie von KI-Modellen mit langem Kontextfenster von "
"IBM, das für das Denken feinabgestimmt wurde."

#: src/ollama_models.py:4562
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"Eine hochmoderne Version des leichtgewichtigen Command R7B-Modells, das mit "
"seiner erweiterten arabischen Sprachfähigkeit für Unternehmen im mittleren "
"Osten und Nordafrika beeindruckt."

#: src/ollama_models.py:4608
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""
"111-Milliaren-Parameter-Modell optimiert für aufwändige Unternehmen, die "
"schnelle, sichere und hochqualitative KI benötigen."

#: src/ollama_models.py:4649
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""
"Qwen 3 ist die neueste Generation an großen Sprachmodellen der Qwen-Serie, "
"welche mit einer umfassenden Sammlung an Dense- und Mixture-of-Experts-"
"Modellen kommt."

#: src/ollama_models.py:4795
msgid "Devstral: the best open source model for coding agents"
msgstr ""

#: src/ollama_models.py:4823
msgid "Meta's latest collection of multimodal models."
msgstr "Meta's neueste Sammlung an multimodalen Modellen."

#: src/ollama_models.py:4871
msgid ""
"Flagship vision-language model of Qwen and also a significant leap from the "
"previous Qwen2-VL."
msgstr ""

#: src/ollama_models.py:4901
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"DeepCoder ist ein vollständig quelloffenes 14B-Coder-Modell auf dem Level "
"von o3-mini - eine 1.5B-Version ist ebenfalls erhältlich."

#: src/ollama_models.py:4925
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"Auf Mistral Small 3 aufbauend fügt Mistral Small 3.1 (2503) modernstes, "
"visuelles Verstehen und Fähigkeiten, mit längerem Kontext von bis zu 128.000 "
"Tokens umzugehen, ohne Kompromisse bei der Text-Leistungsfähigkeit "
"einzugehen, hinzu."

#: src/ollama_models.py:4965
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"Cogito v1 Preview ist eine Familie an hybriden Reasoning-Modellen von Deep "
"Cogito, die die besten verfügbaren, offenen Modelle derselben Größe "
"übertreffen - dazu gehören Gegenstücke von Llama, Deepseek und Qwen über die "
"Standard-Benchmarks hinweg."

#: src/ollama_models.py:4994
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""
"IBM Granite 2B und 8B sind Modelle mit 128K-Kontext-Länge, die auf das "
"Nachdenken und Befolgen von Anweisungen feinabgestimmt wurden."

#: src/ollama_models.py:5032
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""
"Phi 4 Reasoning und Reasoning Plus sind 14B-Parameter-Reasoning-Modelle mit "
"offenen Gewichten, die deutlich größeren Modelle bei komplexen Denkaufgaben "
"konkurrieren."

#: src/ollama_models.py:5064
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"EXAONE Deep zeigt überlegene Fähigkeiten in verschiedensten Denkaufgaben, "
"darunter Mathematik- und Coding-Benchmarks, mit Größen von 2.4 bis 32 "
"Milliaren Parametern - entwickelt und herausgegeben von LG AI Research."

#: src/ollama_models.py:5090
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""
"Phi 4 Mini Reasoning ist ein leichtgewichtiges Modell, das Effizienz mit "
"fortschrittlicher Denkfähigkeit balanciert."

#: src/ollama_models.py:5117
msgid ""
"Gemma 3n models are designed for efficient execution on everyday devices "
"such as laptops, tablets or phones."
msgstr ""

#: src/ollama_models.py:5140
msgid "Magistral is a small, efficient reasoning model with 24B parameters."
msgstr ""

#: src/ollama_models.py:5187
msgid ""
"An update to Mistral Small that improves on function calling, instruction "
"following, and less repetition errors."
msgstr ""

#: src/quick_ask.py:138 src/gtk/quick_ask.ui:11
msgid "Quick Ask"
msgstr "Flinke Frage"

#: src/window.py:94
msgid "Ollama Was Not Found"
msgstr "Ollama wurde nicht gefunden"

#: src/window.py:95
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""
"Um eine von Alpaca verwaltete, integrierte Ollama-Instanz zu nutzen, musst "
"du Ollama auf deinem Gerät installiert haben. Das ist aber ganz einfach und "
"sollte nicht länger als 5 Minuten dauern!"

#: src/window.py:97
msgid "Open Tutorial in Web Browser"
msgstr "Anleitung im Browser öffnen"

#: src/window.py:115 src/gtk/window.ui:309 src/gtk/window.ui:319
#: src/gtk/window.ui:341
msgid "Add Instance"
msgstr "Instanz hinzufügen"

#: src/window.py:116
msgid "Select a type of instance to add"
msgstr "Auswählen, welcher Typ von Instanz hinzugefügt werden soll"

#: src/window.py:169 src/window.py:522 src/widgets/dialog.py:197
#: src/widgets/dialog.py:210 src/widgets/dialog.py:223 src/widgets/voice.py:307
#: src/widgets/voice.py:310 src/widgets/models/added.py:409
#: src/widgets/models/creator.py:140 src/widgets/models/creator.py:141
#: src/widgets/instances/__init__.py:252 src/widgets/instances/__init__.py:253
#: src/widgets/blocks/code.py:138 src/widgets/blocks/text.py:148
#: src/widgets/tools/tools.py:98 src/widgets/tools/tools.py:99
msgid "Cancel"
msgstr "Abbrechen"

#: src/window.py:170
msgid "Hide"
msgstr "Verbergen"

#: src/window.py:171 src/gtk/window.ui:255 src/widgets/camera.py:119
msgid "Close"
msgstr "Schließen"

#: src/window.py:174
msgid "Close Alpaca?"
msgstr "Alpaca schließen?"

#: src/window.py:175
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr ""
"Eine Aufgabe wird derzeit bearbeitet. Sind Sie sicher, dass Sie Alpaca "
"schließen möchten?"

#: src/window.py:278
msgid "No tools enabled."
msgstr "Keine Werkzeuge aktiviert"

#: src/window.py:278
msgid "Open Tool Manager"
msgstr "Werkzeug-Manager öffnen"

#: src/window.py:281
msgid "Please select a model before chatting"
msgstr "Bitte wählen Sie ein Modell aus, bevor Sie chatten"

#: src/window.py:421 src/gtk/window.ui:51 src/gtk/window.ui:640
#: src/widgets/chat.py:229 src/widgets/instances/ollama_instances.py:38
#: src/widgets/instances/ollama_instances.py:54
#: src/widgets/instances/ollama_instances.py:91
#: src/widgets/instances/openai_instances.py:68
#: src/widgets/instances/openai_instances.py:79
#: src/widgets/instances/openai_instances.py:121
msgid "New Chat"
msgstr "Neuer Chat"

#: src/window.py:501
msgid "Chat imported successfully"
msgstr "Chatverlauf erfolgreich importiert"

#: src/window.py:524
msgid "Can't Run Live Chat"
msgstr ""

#: src/window.py:525
msgid "You are missing TTS libraries"
msgstr ""

#: src/window.py:575
msgid "Pull Model"
msgstr "Modell abrufen"

#: src/window.py:576
msgid "Please enter the model name following this template: name:tag"
msgstr "Bitte geben Sie den Modellnamen nach folgendem Schema an: name:tag"

#: src/window.py:583
msgid "Delete All Chats?"
msgstr "Alle Chats löschen?"

#: src/window.py:584
msgid "Are you sure you want to delete all chats?"
msgstr "Sind Sie sich sicher, dass Sie alle Chats löschen möchten?"

#: src/window.py:586 src/widgets/attachments.py:261
#: src/widgets/attachments.py:394 src/widgets/chat.py:519
msgid "Delete"
msgstr "Löschen"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "Allgemein"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "Tastenkürzel anzeigen"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "Einstellungen"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr "Flinke Frage"

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "Modellmanager"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "Instanz-Manager"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr "Werkzeug-Manager"

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "Seitenleiste auf-/zuklappen"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr "Beenden"

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "Chatverwaltung"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "Chat erstellen"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "Chat löschen"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "Chat leeren"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "Chat umbenennen"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr "Suchleisten ein-/ausklappen"

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "Nachricht-Eingabe"

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "Kopieren"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "Einfügen"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr "Emoji-Menü öffnen"

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "Neue Zeile einfügen"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr "Nachricht als System senden"

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr ""
"Systemnachrichten werden als tatsächliche Anweisung vom Modell interpretiert."

#: src/gtk/help-overlay.ui:133 src/widgets/message.py:628
msgid "Use Tools"
msgstr "Werkzeuge verwenden"

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr "Modell anweisen, Werkzeuge zur Generierung einer Nachricht zu nutzen"

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr "Nachricht als Nutzer senden"

#: src/gtk/window.ui:62
msgid "Menu"
msgstr "Menü"

#: src/gtk/window.ui:69
msgid "Search Chats"
msgstr ""

#: src/gtk/window.ui:78
msgid "Chat search bar"
msgstr ""

#: src/gtk/window.ui:86 src/gtk/window.ui:88
msgid "Search chats"
msgstr ""

#: src/gtk/window.ui:124
msgid "No Chats Found"
msgstr ""

#: src/gtk/window.ui:125
msgid "Oh no! It looks like there are no chats found for your search."
msgstr ""

#: src/gtk/window.ui:142
msgid "Toggle Sidebar"
msgstr "Seitenleiste ein-/ausblenden"

#: src/gtk/window.ui:149
msgid "Search Messages"
msgstr "Suche Nachrichten"

#: src/gtk/window.ui:176
msgid "Add Models"
msgstr "Modelle hinzufügen"

#: src/gtk/window.ui:180 src/gtk/window.ui:196 src/gtk/window.ui:660
msgid "Manage Models"
msgstr "Modelle verwalten"

#: src/gtk/window.ui:216
msgid "Chat Menu"
msgstr "Chat-Menü"

#: src/gtk/window.ui:229
msgid "Message search bar"
msgstr "Nachrichtensuchleiste"

#: src/gtk/window.ui:238 src/gtk/window.ui:240
msgid "Search messages"
msgstr "Nachrichten durchsuchen"

#: src/gtk/window.ui:256
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""
"Warnung: Der Energiesparmodus ist aktiviert, dies verlangsamt die "
"Nachrichtenerstellung"

#: src/gtk/window.ui:290
msgid "Instance Manager"
msgstr "Instanz-Manager"

#: src/gtk/window.ui:305
msgid "No Instances Found"
msgstr "Keine Instanzen gefunden"

#: src/gtk/window.ui:306
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr ""
"Hier sieht es ein wenig leer aus. Versuchen Sie, eine Instanz hinzuzufügen, "
"um loszulegen!"

#: src/gtk/window.ui:335
msgid "Added Instances"
msgstr "Hinzugefügte Instanzen"

#: src/gtk/window.ui:336
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""
"Verwalten Sie ihre KI-Instanzen - Chats und Nachrichten sind zwischen diesen "
"geteilt, wenn Antworten generiert werden."

#: src/gtk/window.ui:372
msgid "Tool Manager"
msgstr "Werkzeug-Manager"

#: src/gtk/window.ui:383
msgid "Available Tools"
msgstr "Verfügbare Werkzeuge"

#: src/gtk/window.ui:384
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""
"Funktionen, die Sprachmodelle nutzen können, wenn eine Nachricht durch die "
"\"Werkzeuge nutzen\"-Option im Kontextmenü des Senden-Buttons verschickt "
"wird."

#: src/gtk/window.ui:395
msgid "Help us build better AI tools! Submit your ideas here."
msgstr ""

#: src/gtk/window.ui:403
msgid "Request Form"
msgstr ""

#: src/gtk/window.ui:417
msgid "Model Manager"
msgstr "Modellmanager"

#: src/gtk/window.ui:427
msgid "Search Model"
msgstr "Modell suchen"

#: src/gtk/window.ui:441
msgid "Model Manager Menu"
msgstr "Modellmanager-Menü"

#: src/gtk/window.ui:454
msgid "Model search bar"
msgstr "Modell-Suchleiste"

#: src/gtk/window.ui:466 src/gtk/window.ui:468
msgid "Search models"
msgstr "Modelle suchen"

#: src/gtk/window.ui:475
msgid "Filter Models"
msgstr "Nach Modellen filtern"

#: src/gtk/window.ui:492 src/widgets/models/available.py:111
msgid "Added"
msgstr "Hinzugefügt"

#: src/gtk/window.ui:502 src/gtk/window.ui:561 src/gtk/window.ui:613
msgid "No Models Found"
msgstr "Keine Modelle gefunden"

#: src/gtk/window.ui:503
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""
"Hier sieht es ein wenig leer aus! Versuchen Sie, ein paar Modelle "
"herunterzuladen, oder ändern Sie die ausgewählte Instanz, um loszulegen!"

#: src/gtk/window.ui:506 src/gtk/window.ui:516 src/gtk/window.ui:656
msgid "Manage Instances"
msgstr "Instanzen verwalten"

#: src/gtk/window.ui:562 src/gtk/window.ui:614
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"Es scheint, als gäbe es für's Erste keine Modelle für diese Anfrage. "
"Probieren Sie, die Suche etwas abzuändern oder entdecken Sie etwas Neues!"

#: src/gtk/window.ui:574
msgid "Available"
msgstr "Verfügbar"

#: src/gtk/window.ui:644 src/widgets/chat.py:20
msgid "New Notebook"
msgstr ""

#: src/gtk/window.ui:652
msgid "Import Chat"
msgstr "Chat importieren"

#: src/gtk/window.ui:664
msgid "Manage Tools"
msgstr "Werkzeuge verwalten"

#: src/gtk/window.ui:670
msgid "Start Quick Ask"
msgstr "\"Flinke Frage\" starten"

#: src/gtk/window.ui:674
msgid "Start Live Chat"
msgstr ""

#: src/gtk/window.ui:678 src/gtk/live_chat.ui:56 src/gtk/live_chat.ui:127
msgid "Preferences"
msgstr "Einstellungen"

#: src/gtk/window.ui:682
msgid "Keyboard Shortcuts"
msgstr "Tastenkombinationen"

#: src/gtk/window.ui:686
msgid "About Alpaca"
msgstr "Über Alpaca"

#: src/gtk/window.ui:694 src/widgets/chat.py:451
msgid "Rename Chat"
msgstr "Chat umbenennen"

#: src/gtk/window.ui:698 src/widgets/chat.py:456
msgid "Duplicate Chat"
msgstr "Chat duplizieren"

#: src/gtk/window.ui:702 src/widgets/chat.py:461 src/widgets/chat.py:614
msgid "Export Chat"
msgstr "Chat exportieren"

#: src/gtk/window.ui:708 src/widgets/chat.py:468
msgid "Delete Chat"
msgstr "Chat löschen"

#: src/gtk/window.ui:716 src/gtk/live_chat.ui:146
msgid "Reload Added Models"
msgstr "Neu hinzugefügte Modelle neu laden"

#: src/gtk/window.ui:720
msgid "Add Model by Name"
msgstr ""

#: src/gtk/window.ui:726
msgid "Create Model from Existing"
msgstr ""

#: src/gtk/window.ui:730
msgid "Create Model from GGUF File"
msgstr ""

#: src/gtk/live_chat.ui:8
msgid "Live chat dialog"
msgstr ""

#: src/gtk/live_chat.ui:13
msgid "Live Chat"
msgstr ""

#: src/gtk/live_chat.ui:44
msgid "Show Messages"
msgstr ""

#: src/gtk/live_chat.ui:134
msgid "Use Dynamic Backgrounds"
msgstr ""

#: src/gtk/live_chat.ui:135
msgid "When using a model with a profile picture"
msgstr ""

#: src/gtk/live_chat.ui:140
msgid "Turn on Microphone Automatically"
msgstr ""

#: src/gtk/live_chat.ui:141
msgid "When launching Live Chat and after dictation"
msgstr ""

#: src/gtk/quick_ask.ui:8
msgid "Quick ask dialog"
msgstr "Flinke Frage-Dialog"

#: src/gtk/quick_ask.ui:21
msgid "Save Conversation to Alpaca"
msgstr "Konversation in Alpaca speichern"

#: src/widgets/attachments.py:107 src/widgets/attachments.py:309
#: src/widgets/attachments.py:430
msgid "Remove Attachment"
msgstr "Anhang entfernen"

#: src/widgets/attachments.py:116 src/widgets/attachments.py:301
#: src/widgets/attachments.py:425
msgid "Download Attachment"
msgstr ""

#: src/widgets/attachments.py:130
msgid "Replace Notebook Content"
msgstr ""

#: src/widgets/attachments.py:258
msgid "Delete Attachment?"
msgstr ""

#: src/widgets/attachments.py:259 src/widgets/attachments.py:392
#: src/widgets/chat.py:517
#, python-brace-format
msgid "Are you sure you want to delete '{}'?"
msgstr "Sind Sie sicher, dass Sie '{}' löschen möchten?"

#: src/widgets/attachments.py:290
msgid "Save Attachment"
msgstr ""

#: src/widgets/attachments.py:340
msgid "Image"
msgstr "Bild"

#: src/widgets/attachments.py:351 src/widgets/attachments.py:363
msgid "Missing Image"
msgstr "Fehlendes Bild"

#: src/widgets/attachments.py:391
msgid "Delete Image?"
msgstr ""

#: src/widgets/attachments.py:414
msgid "Save Image"
msgstr ""

#: src/widgets/attachments.py:585
msgid "Any compatible Alpaca attachment"
msgstr "Jeglicher Alpaca-kompatibler Anhang"

#: src/widgets/attachments.py:634 src/widgets/message.py:552
msgid "Image recognition is only available on specific models"
msgstr "Bilderkennung ist nur bei bestimmten Modellen verfügbar"

#: src/widgets/attachments.py:660
msgid "Attach File"
msgstr "Datei anhängen"

#: src/widgets/attachments.py:665
msgid "Attach Website"
msgstr "Website anhängen"

#: src/widgets/attachments.py:668 src/widgets/message.py:532
msgid "Attach Website? (Experimental)"
msgstr "Website anhängen? (Experimentell)"

#: src/widgets/attachments.py:669
msgid "Please enter a website URL"
msgstr "Bitte geben Sie eine Website-URL an"

#: src/widgets/attachments.py:676
msgid "Attach YouTube Captions"
msgstr "YouTube-Videountertitel anhängen"

#: src/widgets/attachments.py:679
msgid "Attach YouTube Captions?"
msgstr "YouTube-Untertitel anhängen?"

#: src/widgets/attachments.py:680
msgid "Please enter a YouTube video URL"
msgstr "Bitte geben Sie eine YouTube-Video-URL ein"

#: src/widgets/attachments.py:691
msgid "Attach Screenshot"
msgstr "Bildschirmfoto anhängen"

#: src/widgets/attachments.py:698
msgid "Attach Photo From Camera"
msgstr ""

#: src/widgets/camera.py:102
msgid "Photo"
msgstr ""

#: src/widgets/camera.py:122
msgid "No Camera Detected"
msgstr ""

#: src/widgets/camera.py:123
msgid "Please check if camera is plugged in and turned on"
msgstr ""

#: src/widgets/chat.py:86 src/widgets/instances/ollama_instances.py:76
#: src/widgets/instances/openai_instances.py:106
msgid "Notebook"
msgstr ""

#: src/widgets/chat.py:87
msgid "Start a notebook with a message"
msgstr ""

#: src/widgets/chat.py:95 src/widgets/chat.py:271
msgid "No Messages Found"
msgstr ""

#: src/widgets/chat.py:96 src/widgets/chat.py:272
msgid "Uh oh! No messages found for your search."
msgstr ""

#: src/widgets/chat.py:262
msgid "Try one of these prompts"
msgstr "Teste einen dieser Prompts"

#: src/widgets/chat.py:292
#, python-brace-format
msgid "Send prompt: '{}'"
msgstr "Sende Prompt: '{}'"

#: src/widgets/chat.py:298
msgid "Refresh Prompts"
msgstr "Beispielprompts neu laden"

#: src/widgets/chat.py:494
msgid "Rename Chat?"
msgstr "Chat umbenennen?"

#: src/widgets/chat.py:495
#, python-brace-format
msgid "Renaming '{}'"
msgstr "'{}' umbenennen"

#: src/widgets/chat.py:497
msgid "Chat name"
msgstr "Chat-Name"

#: src/widgets/chat.py:498
msgid "Rename"
msgstr "Umbenennen"

#: src/widgets/chat.py:516
msgid "Delete Chat?"
msgstr "Chat löschen?"

#: src/widgets/chat.py:524
#, python-brace-format
msgid "Copy of {}"
msgstr "Kopie von {}"

#: src/widgets/chat.py:536
msgid "Chat exported successfully"
msgstr "Chatverlauf erfolgreich exportiert"

#: src/widgets/chat.py:556
msgid "User"
msgstr "Nutzer"

#: src/widgets/chat.py:560
msgid "System"
msgstr "System"

#: src/widgets/chat.py:606
msgid "Importable (.db)"
msgstr "Importierbare Datei (.db)"

#: src/widgets/chat.py:607
msgid "Markdown"
msgstr "Markdown"

#: src/widgets/chat.py:608
msgid "Markdown (Obsidian Style)"
msgstr "Markdown (Obsidian-Style)"

#: src/widgets/chat.py:609
msgid "JSON"
msgstr "JSON"

#: src/widgets/chat.py:610
msgid "JSON (Include Metadata)"
msgstr "JSON (Metadaten einbezogen)"

#: src/widgets/chat.py:615
msgid "Select a method to export the chat"
msgstr "Wählen Sie eine Methode, um den Chat zu exportieren"

#: src/widgets/dialog.py:195 src/widgets/dialog.py:208
#: src/widgets/dialog.py:221
msgid "Accept"
msgstr "Akzeptieren"

#: src/widgets/message.py:32
msgid "Remove Message"
msgstr "Nachricht entfernen"

#: src/widgets/message.py:42
msgid "Copy Message"
msgstr "Kopiere Nachricht"

#: src/widgets/message.py:52
msgid "Edit Message"
msgstr "Nachricht bearbeiten"

#: src/widgets/message.py:62
msgid "Regenerate Message"
msgstr "Nachricht regenerieren"

#: src/widgets/message.py:88
msgid "Message copied to the clipboard"
msgstr "Nachricht in die Zwischenablage kopiert"

#: src/widgets/message.py:115
msgid "Message cannot be regenerated while receiving a response"
msgstr ""
"Nachricht kann nicht regeneriert werden, während eine Antwort gesendet wird"

#: src/widgets/message.py:246 src/widgets/message.py:269
msgid "Thought"
msgstr "Gedanke"

#: src/widgets/message.py:525
msgid "Attach YouTube Video?"
msgstr "YouTube-Video anhängen?"

#: src/widgets/message.py:526
msgid "Note that YouTube might block access to captions, please check output"
msgstr ""

#: src/widgets/message.py:533
#, python-brace-format
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"Sind Sie sicher, dass Sie\n"
"'{}' anhängen möchten?"

#: src/widgets/message.py:581
msgid "Send Message"
msgstr "Nachricht senden"

#: src/widgets/message.py:590
msgid "Stop Message"
msgstr "Nachricht anhalten"

#: src/widgets/message.py:618
msgid "Send as User"
msgstr "Als Nutzer senden"

#: src/widgets/message.py:623
msgid "Send as System"
msgstr "Als System senden"

#: src/widgets/terminal.py:17
msgid "Setting up Python environment..."
msgstr "Python-Umgebung wird eingerichtet..."

#: src/widgets/terminal.py:29
msgid "Using Python HTTP server..."
msgstr ""

#: src/widgets/terminal.py:34
msgid "Using Flatpak contained shell..."
msgstr ""

#: src/widgets/terminal.py:38
msgid "Using SSH to run command"
msgstr "Nutzt SSH, um einen Befehl auszuführen"

#: src/widgets/terminal.py:85
msgid "Terminal"
msgstr "Terminal"

#: src/widgets/terminal.py:97
msgid "Open Environment Directory"
msgstr "Umgebungsordner öffnen"

#: src/widgets/terminal.py:181
msgid "Script Exited"
msgstr "Skript beendet"

#: src/widgets/terminal.py:192
msgid "Alpaca Terminal is not compatible with Windows"
msgstr ""

#: src/widgets/voice.py:54
msgid "Dictate Message"
msgstr "Nachricht diktieren"

#: src/widgets/voice.py:169
msgid "Use Speech Recognition"
msgstr "Spracheingabe nutzen"

#: src/widgets/voice.py:214 src/widgets/voice.py:248
msgid "Speech Recognition Error"
msgstr "Fehler bei der Spracherkennung"

#: src/widgets/voice.py:215 src/widgets/voice.py:347
msgid "An error occurred while pulling speech recognition model"
msgstr ""
"Ein Fehler ist beim Herunterladen des Spracherkennungsmodells aufgetreten"

#: src/widgets/voice.py:249
msgid "An error occurred while using speech recognition"
msgstr "Ein Fehler ist bei der Verwendung der Spracherkennung aufgetreten"

#: src/widgets/voice.py:282 src/widgets/voice.py:405
msgid "Download Speech Recognition Model"
msgstr "Spracherkennungs-Modell herunterladen"

#: src/widgets/voice.py:283 src/widgets/voice.py:406
#, python-brace-format
msgid "To use speech recognition you'll need to download a special model ({})"
msgstr ""
"Um die Spracherkennung zu nutzen, muss ein spezielles Modell heruntergeladen "
"werden ({})"

#: src/widgets/voice.py:285 src/widgets/voice.py:408
msgid "Download Model"
msgstr "Modell herunterladen"

#: src/widgets/voice.py:320
msgid "Transcribing Audio"
msgstr ""

#: src/widgets/voice.py:346 src/widgets/voice.py:375
msgid "Transcription Error"
msgstr ""

#: src/widgets/voice.py:376
msgid "An error occurred while transcribing audio"
msgstr ""

#: src/widgets/models/added.py:89
msgid "Change Profile Picture"
msgstr "Profilbilder ändern"

#: src/widgets/models/added.py:110
msgid "Voice"
msgstr "Stimme"

#: src/widgets/models/added.py:115
msgid "Default"
msgstr "Standard"

#: src/widgets/models/added.py:142 src/widgets/models/creator.py:57
msgid "Tag"
msgstr "Tag"

#: src/widgets/models/added.py:143
msgid "Family"
msgstr "Familie"

#: src/widgets/models/added.py:144
msgid "Parameter Size"
msgstr "Parametergröße"

#: src/widgets/models/added.py:145
msgid "Quantization Level"
msgstr "Quantisierungsstufe"

#: src/widgets/models/added.py:148
msgid "Parent Model"
msgstr "Elternmodell"

#: src/widgets/models/added.py:151 src/widgets/models/added.py:153
msgid "Modified At"
msgstr "Geändert am"

#: src/widgets/models/added.py:159
msgid "Description"
msgstr "Beschreibung"

#: src/widgets/models/added.py:170 src/widgets/models/added.py:174
msgid "Files"
msgstr ""

#: src/widgets/models/added.py:193 src/widgets/models/creator.py:73
msgid "Context"
msgstr "Kontext"

#: src/widgets/models/added.py:221 src/widgets/models/added.py:475
#: src/widgets/models/speech.py:23 src/widgets/models/speech.py:170
msgid "Remove Model"
msgstr "Modell entfernen"

#: src/widgets/models/added.py:229 src/widgets/models/added.py:483
msgid "Create Child"
msgstr "Abstammendes Modell aus diesem erstellen"

#: src/widgets/models/added.py:249 src/widgets/models/available.py:156
msgid "Languages"
msgstr ""

#: src/widgets/models/added.py:410 src/widgets/models/added.py:459
#: src/widgets/models/speech.py:136 src/widgets/models/speech.py:279
#: src/widgets/instances/__init__.py:396
msgid "Remove"
msgstr "Entfernen"

#: src/widgets/models/added.py:411
msgid "Change"
msgstr "Ändern"

#: src/widgets/models/added.py:419
msgid "Model Profile Picture"
msgstr "Modell-Profilbild"

#: src/widgets/models/added.py:420
msgid "What do you want to do with the model's profile picture?"
msgstr "Was möchten Sie mit dem Profilbild des Modells tun?"

#: src/widgets/models/added.py:456 src/widgets/models/speech.py:133
#: src/widgets/models/speech.py:276
msgid "Remove Model?"
msgstr "Modell wirklich entfernen?"

#: src/widgets/models/added.py:457 src/widgets/models/speech.py:134
#: src/widgets/models/speech.py:277
#, python-brace-format
msgid "Are you sure you want to remove '{}'?"
msgstr "Sind Sie sich sicher, dass Sie '{}' entfernen möchten?"

#: src/widgets/models/available.py:46
msgid "Already Added"
msgstr ""

#: src/widgets/models/available.py:48
#, python-brace-format
msgid "Pull '{}'"
msgstr ""

#: src/widgets/models/available.py:50
msgid "Add Model"
msgstr "Modell hinzufügen"

#: src/widgets/models/available.py:111
msgid "Add"
msgstr ""

#: src/widgets/models/available.py:120
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""
"Durch das Herunterladen dieses Modells akzeptieren Sie die "
"Lizenzbestimmungen auf der Website des Modells."

#: src/widgets/models/available.py:253
msgid "Pull Latest"
msgstr ""

#: src/widgets/models/common.py:13
msgid "Multilingual"
msgstr "Multilingual"

#: src/widgets/models/common.py:14
msgid "Code"
msgstr "Code"

#: src/widgets/models/common.py:15
msgid "Math"
msgstr "Mathematik"

#: src/widgets/models/common.py:16
msgid "Vision"
msgstr "Sehen"

#: src/widgets/models/common.py:17
msgid "Embedding"
msgstr "Eingebettet"

#: src/widgets/models/common.py:18
msgid "Tools"
msgstr "Werkzeuge"

#: src/widgets/models/common.py:19
msgid "Reasoning"
msgstr "Denken"

#: src/widgets/models/common.py:20
msgid "Small"
msgstr "Klein"

#: src/widgets/models/common.py:21
msgid "Medium"
msgstr "Mittel"

#: src/widgets/models/common.py:22
msgid "Big"
msgstr "Groß"

#: src/widgets/models/common.py:23
msgid "Huge"
msgstr "Riesig"

#: src/widgets/models/creator.py:24
msgid "Identity"
msgstr "Identität"

#: src/widgets/models/creator.py:30
msgid "Base"
msgstr "Basis"

#: src/widgets/models/creator.py:37
msgid "Profile Picture"
msgstr "Profilbild"

#: src/widgets/models/creator.py:41
msgid "Open File"
msgstr "Datei öffnen"

#: src/widgets/models/creator.py:51 src/widgets/instances/__init__.py:45
msgid "Name"
msgstr "Name"

#: src/widgets/models/creator.py:67
msgid "Add Files"
msgstr ""

#: src/widgets/models/creator.py:74
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""
"Beschreiben Sie das gewollte Verhalten des Modells in seiner Hauptsprache "
"(meist ist dies Englisch)."

#: src/widgets/models/creator.py:103
msgid "Behavior"
msgstr "Verhalten"

#: src/widgets/models/creator.py:109
msgid "Imagination"
msgstr "Vorstellungskraft"

#: src/widgets/models/creator.py:110
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr "Ein höherer Wert ergibt diversere Antworten vom Modell. (top_k)"

#: src/widgets/models/creator.py:124
msgid "Focus"
msgstr "Fokus"

#: src/widgets/models/creator.py:125
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "Ein höherer Wert erweitert die Menge an möglichen Antworten. (top_p)"

#: src/widgets/models/creator.py:147 src/widgets/models/creator.py:148
#: src/widgets/instances/__init__.py:259 src/widgets/instances/__init__.py:260
#: src/widgets/blocks/code.py:147 src/widgets/blocks/text.py:157
#: src/widgets/tools/tools.py:105 src/widgets/tools/tools.py:106
msgid "Save"
msgstr "Speichern"

#: src/widgets/models/creator.py:165
msgid "Create Model"
msgstr "Modell erstellen"

#: src/widgets/models/pulling.py:48
msgid "Downloading..."
msgstr ""

#: src/widgets/models/pulling.py:69 src/widgets/models/pulling.py:71
#: src/widgets/models/pulling.py:174
msgid "Stop Download"
msgstr "Download anhalten"

#: src/widgets/models/pulling.py:132
msgid "Dictation Model"
msgstr ""

#: src/widgets/models/pulling.py:188
msgid "Stop Download?"
msgstr "Download stoppen?"

#: src/widgets/models/pulling.py:189
#, python-brace-format
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "Bist du Dir sicher, das beziehen von '{}' abzubrechen?"

#: src/widgets/models/pulling.py:191
msgid "Stop"
msgstr "Stoppen"

#: src/widgets/models/pulling.py:224
msgid "Model Manager Error"
msgstr "Modellmanager-Fehler"

#: src/widgets/models/pulling.py:225
#, python-brace-format
msgid "An error occurred whilst pulling '{}'"
msgstr "Ein Fehler trat beim Download von '{}' auf"

#: src/widgets/models/pulling.py:253
msgid "Download Completed"
msgstr "Download abgeschlossen"

#: src/widgets/models/pulling.py:254
#, python-brace-format
msgid "Model '{}' downloaded successfully."
msgstr "Modell '{}' erfolgreich heruntergeladen."

#: src/widgets/models/speech.py:40
msgid "Local text to speech model provided by Kokoro."
msgstr "Lokales Text-zu-Sprache-Modell wird von Kokoro bereitgestellt."

#: src/widgets/models/speech.py:146 src/widgets/models/speech.py:289
msgid "Delete Model"
msgstr ""

#: src/widgets/models/speech.py:187
msgid "Local speech to text model provided by OpenAI Whisper."
msgstr "Lokales Spracherkennungsmodell wird von OpenAI Whisper bereitgestellt."

#: src/widgets/models/speech.py:242
msgid "Speech to Text"
msgstr "Spracherkennung"

#: src/widgets/instances/ollama_instances.py:68
#: src/widgets/instances/openai_instances.py:98
msgid "Notebook Error"
msgstr ""

#: src/widgets/instances/ollama_instances.py:69
#: src/widgets/instances/ollama_instances.py:155
#: src/widgets/instances/openai_instances.py:99
#: src/widgets/instances/openai_instances.py:169
msgid "An error occurred while running tool"
msgstr "Ein Fehler ist beim Ausführen des Werkzeugs aufgetreten"

#: src/widgets/instances/ollama_instances.py:103
#: src/widgets/instances/openai_instances.py:127
msgid "Selecting tool to use..."
msgstr "Wählt passendes Werkzeug aus..."

#: src/widgets/instances/ollama_instances.py:122
#: src/widgets/instances/openai_instances.py:136
#, python-brace-format
msgid "Using {}"
msgstr "Benutzt {}"

#: src/widgets/instances/ollama_instances.py:154
#: src/widgets/instances/openai_instances.py:168
msgid "Tool Error"
msgstr "Werkzeug-Fehler"

#: src/widgets/instances/ollama_instances.py:234
#: src/widgets/instances/ollama_instances.py:326
#: src/widgets/instances/ollama_instances.py:340
#: src/widgets/instances/ollama_instances.py:550
#: src/widgets/instances/openai_instances.py:230
#: src/widgets/instances/openai_instances.py:302
#: src/widgets/instances/openai_instances.py:357
#: src/widgets/instances/openai_instances.py:402
#: src/widgets/instances/openai_instances.py:462
#: src/widgets/instances/openai_instances.py:501
#: src/widgets/instances/openai_instances.py:534
msgid "Instance Error"
msgstr "Instanzfehler"

#: src/widgets/instances/ollama_instances.py:235
#: src/widgets/instances/openai_instances.py:231
msgid "Message generation failed"
msgstr "Nachrichtengenerierung fehlgeschlagen"

#: src/widgets/instances/ollama_instances.py:327
#: src/widgets/instances/openai_instances.py:303
#: src/widgets/instances/openai_instances.py:358
#: src/widgets/instances/openai_instances.py:403
msgid "Could not retrieve added models"
msgstr "Konnte die hinzugefügten Modelle nicht abrufen"

#: src/widgets/instances/ollama_instances.py:341
msgid "Could not retrieve available models"
msgstr "Konnte die verfügbaren Modelle nicht abrufen"

#: src/widgets/instances/ollama_instances.py:459
msgid "Ollama (Managed)"
msgstr "Ollama (Verwaltet)"

#: src/widgets/instances/ollama_instances.py:460
msgid "Local AI instance managed directly by Alpaca"
msgstr "Lokale KI-Instanz, direkt von Alpaca selbst verwaltet"

#: src/widgets/instances/ollama_instances.py:463
#: src/widgets/instances/ollama_instances.py:565
#: src/widgets/instances/__init__.py:283
msgid "Instance"
msgstr "Instanz"

#: src/widgets/instances/ollama_instances.py:495
msgid "Alpaca Support"
msgstr "Alpaca-Support"

#: src/widgets/instances/ollama_instances.py:502
msgid "Model request too large for system"
msgstr "Modellanfrage zu groß für das System"

#: src/widgets/instances/ollama_instances.py:505
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""
"AMD-GPU erkannt, aber die Erweiterung fehlt; Ollama wird die CPU verwenden."

#: src/widgets/instances/ollama_instances.py:507
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "AMD-GPU erkannt, aber ROCm fehlt; Ollama wird die CPU verwenden."

#: src/widgets/instances/ollama_instances.py:509
#, python-brace-format
msgid "Using AMD GPU type '{}'"
msgstr "Verwende AMD-GPU-Typ '{}'"

#: src/widgets/instances/ollama_instances.py:519
msgid "Integrated Ollama instance is not running"
msgstr "Integrierte Ollama-Instanz läuft nicht"

#: src/widgets/instances/ollama_instances.py:551
msgid "Managed Ollama instance failed to start"
msgstr "Mitverwaltete Ollama-Instanz konnte nicht starten"

#: src/widgets/instances/ollama_instances.py:557
msgid "Integrated Ollama instance is running"
msgstr "Integrierte Ollama-Instanz läuft"

#: src/widgets/instances/ollama_instances.py:562
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "Lokale- oder Remoteinstanz, die nicht durch Alpaca verwaltet wird"

#: src/widgets/instances/openai_instances.py:21
msgid "Instances"
msgstr ""

#: src/widgets/instances/openai_instances.py:175
msgid "Generating message..."
msgstr "Nachricht wird generiert..."

#: src/widgets/instances/openai_instances.py:463
#: src/widgets/instances/openai_instances.py:502
#: src/widgets/instances/openai_instances.py:535
msgid "Could not retrieve models"
msgstr "Konnte Modelle nicht abrufen"

#: src/widgets/instances/openai_instances.py:475
msgid "Alibaba Cloud Qwen large language models via DashScope"
msgstr ""

#: src/widgets/instances/openai_instances.py:481
msgid "Fireworks AI inference platform"
msgstr "Fireworks AI-Inferenzplattform"

#: src/widgets/instances/openai_instances.py:514
msgid "Lambda Labs cloud inference API"
msgstr "Lambda Labs-Cloud-Inferenz-API"

#: src/widgets/instances/openai_instances.py:547
msgid "Cerebras AI cloud inference API"
msgstr "Cerebras AI-Cloud-Inferenz-API"

#: src/widgets/instances/openai_instances.py:553
msgid "Kluster AI cloud inference API"
msgstr "Kluster AI-Cloud-Inferenz-API"

#: src/widgets/instances/openai_instances.py:559
msgid "Kimi large language models by Moonshot AI"
msgstr ""

#: src/widgets/instances/openai_instances.py:566
msgid "Mistral AI large language models"
msgstr ""

#: src/widgets/instances/openai_instances.py:573
msgid "Meta AI Llama API"
msgstr ""

#: src/widgets/instances/openai_instances.py:579
msgid "Novita AI cloud inference API"
msgstr ""

#: src/widgets/instances/openai_instances.py:586
msgid "DeepInfra cloud inference API"
msgstr ""

#: src/widgets/instances/openai_instances.py:590
msgid "OpenAI Compatible Instance"
msgstr "OpenAI-kompatible Instanz"

#: src/widgets/instances/openai_instances.py:592
msgid "AI instance compatible with OpenAI library"
msgstr "KI-Instanz, die mit der OpenAI-Bibliothek kompatibel ist"

#: src/widgets/instances/__init__.py:32 src/widgets/instances/__init__.py:35
msgid "Ollama Log"
msgstr "Ollama-Log"

#: src/widgets/instances/__init__.py:57
msgid "Port"
msgstr "Port"

#: src/widgets/instances/__init__.py:58
#, python-brace-format
msgid "Which network port will '{}' use"
msgstr "Welchen Netzwerk-Port {} nutzen wird"

#: src/widgets/instances/__init__.py:72
msgid "Instance URL"
msgstr "Instanz-URL"

#: src/widgets/instances/__init__.py:78
msgid "API Key"
msgstr "API-Schlüssel"

#: src/widgets/instances/__init__.py:79
msgid "API Key (Unchanged)"
msgstr "API-Schlüssel (Unverändert)"

#: src/widgets/instances/__init__.py:83
msgid "API Key (Optional)"
msgstr "API-Schlüssel (optional)"

#: src/widgets/instances/__init__.py:97
msgid "Thought Processing"
msgstr ""

#: src/widgets/instances/__init__.py:98
msgid ""
"Have compatible reasoning models think about their response before "
"generating a message"
msgstr ""

#: src/widgets/instances/__init__.py:105
msgid "Share Name"
msgstr ""

#: src/widgets/instances/__init__.py:106
msgid "Automatically share your name with the AI models."
msgstr ""

#: src/widgets/instances/__init__.py:121
msgid "Max Tokens"
msgstr "Maximale Tokens"

#: src/widgets/instances/__init__.py:122
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"Definiert die maximale Anzahl an Tokens (Wörter und Leerzeichen), die die KI "
"in einer Antwort generieren kann. Mehr Tokens ermöglichen längere Antworten, "
"können aber auch mehr Zeit oder Kosten in Anspruch nehmen."

#: src/widgets/instances/__init__.py:137
msgid "Temperature"
msgstr "Temperatur"

#: src/widgets/instances/__init__.py:138
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""
"Die Temperatur zu erhöhen, wird die Modelle kreativer antworten lassen."

#: src/widgets/instances/__init__.py:153
msgid "Seed"
msgstr "Seed"

#: src/widgets/instances/__init__.py:154
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""
"Dies zu einer anderen Zahl als 0 zu setzen, wird die Modelle für dieselben "
"Eingaben immer dieselben Ausgaben generieren lassen."

#: src/widgets/instances/__init__.py:169
msgid "Overrides"
msgstr "Überschreibungen"

#: src/widgets/instances/__init__.py:170
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""
"Diese Einträge sind optional, sie werden zur Fehlerbehebung von GPU-"
"bezogenen Problemen mit Ollama genutzt."

#: src/widgets/instances/__init__.py:192
msgid "Model Directory"
msgstr "Modellordner"

#: src/widgets/instances/__init__.py:197
msgid "Select Directory"
msgstr "Verzeichnis auswählen"

#: src/widgets/instances/__init__.py:217
msgid "Default Model"
msgstr "Standardmodell"

#: src/widgets/instances/__init__.py:218
msgid "Model to select when starting a new chat."
msgstr "Auszuwählendes Modell, wenn ein neuer Chat gestartet wird."

#: src/widgets/instances/__init__.py:225
msgid "Title Model"
msgstr "Titel-Modell"

#: src/widgets/instances/__init__.py:226
msgid "Model to use when generating a chat title."
msgstr "Zu nutzendes Modell, um die Chat-Titel zu generieren."

#: src/widgets/instances/__init__.py:277
msgid "Edit Instance"
msgstr "Instanz bearbeiten"

#: src/widgets/instances/__init__.py:277
msgid "Create Instance"
msgstr ""

#: src/widgets/instances/__init__.py:353
msgid "Fallback Instance"
msgstr ""

#: src/widgets/instances/__init__.py:393
msgid "Remove Instance?"
msgstr "Instanz entfernen?"

#: src/widgets/instances/__init__.py:394
msgid "Are you sure you want to remove this instance?"
msgstr "Sicher, dass diese Instanz entfernt werden soll?"

#: src/widgets/blocks/code.py:86
msgid "Code Block"
msgstr "Code-Block"

#: src/widgets/blocks/code.py:113
msgid "Edit Script"
msgstr ""

#: src/widgets/blocks/code.py:121
msgid "Copy Script"
msgstr ""

#: src/widgets/blocks/code.py:129
msgid "Run Script"
msgstr "Starte Script"

#: src/widgets/blocks/code.py:195
msgid "Changes saved successfully"
msgstr ""

#: src/widgets/blocks/code.py:201
msgid "Code copied to the clipboard"
msgstr "Code in die Zwischenablage kopiert"

#: src/widgets/blocks/latex.py:41
msgid "Copy Equation"
msgstr "Gleichung speichern"

#: src/widgets/blocks/latex.py:76
msgid "Equation copied to the clipboard"
msgstr "Gleichung in Zwischenablage kopiert"

#: src/widgets/tools/notebook_tools.py:18
msgid "Read Notebook"
msgstr ""

#: src/widgets/tools/notebook_tools.py:19
msgid "Reads the current notebook."
msgstr ""

#: src/widgets/tools/notebook_tools.py:38
msgid "Write Notebook"
msgstr ""

#: src/widgets/tools/notebook_tools.py:39
msgid "Overwrites the notebook with new text."
msgstr ""

#: src/widgets/tools/notebook_tools.py:58
msgid "Append to Notebook"
msgstr ""

#: src/widgets/tools/notebook_tools.py:59
msgid "Appends text to the notebook."
msgstr ""

#: src/widgets/tools/tools.py:22
msgid "AI Description"
msgstr "KI-Beschreibung"

#: src/widgets/tools/tools.py:23
msgid "The description the AI model will use to understand what the tool does."
msgstr ""
"Die Beschreibung, die das KI-Modell nutzen wird, um zu verstehen, was das "
"Werkzeug tut."

#: src/widgets/tools/tools.py:35
msgid "Arguments"
msgstr "Argumente"

#: src/widgets/tools/tools.py:36
msgid "Variables that are filled by the AI."
msgstr "Variablen, die von dem Sprachmodell ausgefüllt werden."

#: src/widgets/tools/tools.py:49
msgid "Variables"
msgstr "Variablen"

#: src/widgets/tools/tools.py:50
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""
"Nutzer-spezifizierte Werte, die das Tool zum Arbeiten nutzen wird - das "
"Sprachmodell und dessen Anbieter hat auf diese keinen Zugriff."

#: src/widgets/tools/tools.py:219
msgid "Gets the current date and/or time."
msgstr "Ruft das derzeitige Datum und die Zeit ab."

#: src/widgets/tools/tools.py:251
msgid "Gets a recipe by the meal's name"
msgstr "Ruft ein Rezept, basierend auf dem Namen des Gerichts, ab"

#: src/widgets/tools/tools.py:266 src/widgets/tools/tools.py:332
msgid "YouTube Video"
msgstr "YouTube-Video"

#: src/widgets/tools/tools.py:274 src/widgets/tools/tools.py:341
msgid "Source"
msgstr "Quelle"

#: src/widgets/tools/tools.py:311
msgid "Gets a list of food recipes by a specified category"
msgstr "Ruft eine Liste an Rezepten für eine spezifizierte Kategorie ab"

#: src/widgets/tools/tools.py:367
msgid "Extracts an article from Wikipedia by it's title"
msgstr "Extrahiert einen Artikel von Wikipedia mithilfe des Titels"

#: src/widgets/tools/tools.py:408
msgid "Search for a term online using DuckDuckGo"
msgstr "Sucht bei DuckDuckGo online nach einem Begriff"

#: src/widgets/tools/tools.py:411
msgid "Safe Search"
msgstr ""

#: src/widgets/tools/tools.py:415
msgid "On"
msgstr ""

#: src/widgets/tools/tools.py:416
msgid "Moderate"
msgstr ""

#: src/widgets/tools/tools.py:417
msgid "Off"
msgstr ""

#: src/widgets/tools/tools.py:421
msgid "Max Results"
msgstr ""

#: src/widgets/tools/tools.py:445
msgid "Abstract Source"
msgstr "Quelle der Zusammenfassung"

#: src/widgets/tools/tools.py:462
msgid "Web Result Image"
msgstr ""

#: src/widgets/tools/tools.py:492
msgid "Request to run a command using SSH to connect to the device"
msgstr ""
"Fragt an, einen Befehl mittels SSH auf einem verbundenen Gerät auszuführen"

#: src/widgets/tools/tools.py:495
msgid "IP Address"
msgstr "IP-Adresse"

#: src/widgets/tools/tools.py:500
msgid "Username"
msgstr "Nutzername"

#: src/widgets/tools/tools.py:505
msgid "Network Port"
msgstr "Netzwerk-Port"

#: src/widgets/tools/tools.py:522
msgid "Model Requested to Run Command"
msgstr "Modell hat angefragt, einen Befehl auszuführen"

#: src/widgets/tools/tools.py:523
msgid "Command"
msgstr "Befehl"

#: src/widgets/tools/tools.py:525
msgid "Explanation"
msgstr "Erklärung"

#: src/widgets/tools/tools.py:526
msgid "No explanation was provided"
msgstr "Eine Erklärung wurde angegeben"

#: src/widgets/tools/tools.py:527
msgid "Make sure you understand what the command does before running it."
msgstr ""
"Bitte stellen Sie sicher, dass sie voll und ganz verstehen, was der Befehl "
"tut, bevor Sie ihn ausführen."

#: src/widgets/tools/tools.py:573
msgid "Spotify Controller"
msgstr ""

#: src/widgets/tools/tools.py:574
msgid "Control your music's playback"
msgstr ""

#: src/widgets/tools/tools.py:625
msgid "Log Back In"
msgstr ""

#: src/widgets/tools/tools.py:629
msgid "Not logged in"
msgstr ""

#: src/widgets/tools/tools.py:636
msgid "Tutorial"
msgstr ""

#: src/widgets/tools/tools.py:663
msgid "Spotify User"
msgstr ""

#: src/widgets/tools/tools.py:724
msgid "Login Error"
msgstr ""

#: src/widgets/tools/tools.py:725
msgid "Couldn't log in to Spotify"
msgstr ""

#: src/widgets/tools/tools.py:726
msgid "Specify a Client ID and Client Secret"
msgstr ""

#: src/widgets/tools/tools.py:775
msgid "Album Art"
msgstr ""

#~ msgid "Attachment failed, screenshot might be too big"
#~ msgstr "Anhängen schlug fehl; das Bildschirmfoto ist womöglich zu groß."

#~ msgid "Next"
#~ msgstr "Weiter"

#~ msgid "Download Model?"
#~ msgstr "Modell herunterladen?"

#~ msgid "Already Installed!"
#~ msgstr "Bereits installiert!"

#~ msgid "Welcome"
#~ msgstr "Willkommen"

#~ msgid "Previous"
#~ msgstr "Zurück"

#~ msgid "Welcome to Alpaca"
#~ msgstr "Willkommen bei Alpaca"

#~ msgid "Powering your potential"
#~ msgstr "Entfache dein Potenzial"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it.\n"
#~ "\n"
#~ "Alpaca is distributed under GPL v3.0, this software comes with no "
#~ "warranty."
#~ msgstr ""
#~ "Alpaca und dessen Entwickler:innen sind nicht für Schäden jeglicher Art "
#~ "und Weise an Geräten oder Software, entstehend durch die Ausführung KI-"
#~ "generierter Software, verantwortlich. Besondere Vorsicht bei der "
#~ "Ausführung solches Codes ist oberstes Gebot und obliegt Alpacas "
#~ "Nutzer:innen.\n"
#~ "Alpaca wird unter der GPL v3.0 distributiert. Diese Software kommt ohne "
#~ "jegliche Garantie."

#~ msgid "Effortless Code Execution"
#~ msgstr "Mühelose Codeausführung"

#~ msgid ""
#~ "Alpaca can run Python, C++, and even HTML (with a live server) right from "
#~ "your conversations. Give it a try!"
#~ msgstr ""
#~ "Alpaca kann Python, C++ und sogar HTML (mit einem Live-Server) direkt von "
#~ "ihren Konversationen aus ausführen. Probieren Sie es aus!"

#~ msgid "Private by Design"
#~ msgstr "Privat durch Design"

#~ msgid ""
#~ "With Alpaca, your conversations are saved locally on your device, so you "
#~ "can be confident that your data is always secure and private."
#~ msgstr ""
#~ "Mit Alpaca werden ihre Konversationen immer lokal auf ihrem Gerät "
#~ "gespeichert, sodass Sie sich sicher sein können, dass ihre Daten immer "
#~ "sicher und privat bleiben."

#~ msgid "Local AI"
#~ msgstr "Lokale KI"

#~ msgid ""
#~ "Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI "
#~ "models locally on your machine, you'll need to install Ollama within "
#~ "Alpaca. We've made it super easy to do, so you can get started quickly!"
#~ msgstr ""
#~ "Alpaca arbeitet mit KI-Anbietern wie Gemini oder ChatGPT. Um KI-Modelle "
#~ "lokal auf Ihrem Gerät ausführen zu können, müssen Sie Ollama innerhalb "
#~ "von Alpaca installieren. Das haben wir sehr einfach gemacht, sodass Sie "
#~ "ganz schnell loslegen können!"

#~ msgid "Install Ollama"
#~ msgstr "Ollama installieren"

#~ msgid "Creator"
#~ msgstr "Ersteller"

#~ msgid "Model Creator"
#~ msgstr "Modell-Ersteller"

#~ msgid "Select a method of importing a model to continue"
#~ msgstr ""
#~ "Wählen Sie eine Methode, ein Modell zu importieren, um fortzufahren."

#~ msgid "GGUF File"
#~ msgstr "GGUF-Datei"

#~ msgid "Existing Model"
#~ msgstr "Existierendes Modell"

#~ msgid "Run Alpaca In Background"
#~ msgstr "Alpaca im Hintergrund ausführen"

#~ msgid "Show Power Saver Warning"
#~ msgstr "Zeige Energiesparmodus-Warnung"

#~ msgid "When running a managed Ollama instance"
#~ msgstr "Beim Ausführen einer integrierten Ollama-Instanz"

#~ msgid "Zoom"
#~ msgstr "Vergrößerung"

#~ msgid "Speech Recognition Model"
#~ msgstr "Spracherkennungsmodell"

#~ msgid ""
#~ "Models are downloaded upon first use, you can delete them from the model "
#~ "manager"
#~ msgstr ""
#~ "Modelle werden bei der erstmaligen Nutzung heruntergeladen - sie können "
#~ "vom Modell-Manager aus gelöscht werden"

#~ msgid "Speech Recognition Language"
#~ msgstr "Sprache für die Spracherkennung"

#~ msgid "Auto Send Message After Talking"
#~ msgstr "Automatisch Nachricht nach dem Sprechen absenden"

#~ msgid ""
#~ "Voices are downloaded upon first use, each weighing around 1 MB, and you "
#~ "can delete them from the model manager"
#~ msgstr ""
#~ "Sprachen werden bei der erstmaligen Nutzung heruntergeladen - jede "
#~ "benötigt ca. 1 MB - und sie können vom Modell-Manager aus gelöscht werden"

#~ msgid "Delete All Chats"
#~ msgstr "Alle Chats löschen"

#~ msgid "Notice"
#~ msgstr "Information"

#~ msgid "Download Model From Name"
#~ msgstr "Modell anhand eines Namens herunterladen"

#~ msgid "Downloading…"
#~ msgstr "Lädt herunter..."

#~ msgid "A conversation involving a YouTube video transcript"
#~ msgstr "Eine Konversation mit einem YouTube-Video-Transkript"

#~ msgid "Model creator screen"
#~ msgstr "Modellerstellungsoberfläche"

#~ msgid ""
#~ "DeepSeek's first-generation of reasoning models with comparable "
#~ "performance to OpenAI-o1, including six dense models distilled from "
#~ "DeepSeek-R1 based on Llama and Qwen."
#~ msgstr ""
#~ "DeepSeek's erste Generation an Reasoning-Modellen mit vergleichbarer "
#~ "Leistung zu OpenAI-o1, einschließlich sechs dichter Modelle, die von "
#~ "DeepSeek-R1 basierend auf Llama und Qwen destilliert wurden."

#~ msgid "This video does not have any transcriptions"
#~ msgstr "Dieses Video hat keine Transkriptionen"

#~ msgid ""
#~ "{}\n"
#~ "\n"
#~ "Please select a transcript to include"
#~ msgstr ""
#~ "{}\n"
#~ "\n"
#~ "Bitte wählen Sie ein Transkript zum Einbinden aus"

#~ msgid "Error attaching video, please try again"
#~ msgstr ""
#~ "Es gab einen Fehler beim Anfügen des Videos. Versuchen Sie es bitte "
#~ "erneut."

#~ msgid ""
#~ "Hey Alpaca users! We're so excited to bring you a fresh update packed "
#~ "with awesome new features to explore! Get ready to experience Alpaca in a "
#~ "whole new way!"
#~ msgstr ""
#~ "Hey, Alpaca-Nutzer:innen! Wir freuen uns sehr, euch ein frisches Update - "
#~ "vollgestopft mit großartigen neuen Funktionen - zu bringen! Macht euch "
#~ "bereit, Alpaca in einem komplett neuen Weg zu erleben!"

#~ msgid "Smart Tools"
#~ msgstr "Intelligente Werkzeuge"

#~ msgid ""
#~ "Supported AI models can use handy tools to grab information both locally "
#~ "and online. Head over to the brand new \"Tool Manager\" to toggle them on "
#~ "or off."
#~ msgstr ""
#~ "Unterstützte Sprachmodelle können hilfreiche Werkzeuge nutzen, um "
#~ "Informationen von lokalen Quellen und aus dem Internet abzurufen! "
#~ "Wechseln Sie zum brandneuen \"Werkzeug-Manager\", um diese ein- oder "
#~ "auszuschalten."

#~ msgid "Talk to Models"
#~ msgstr "Mit Modellen sprechen"

#~ msgid ""
#~ "You can now dictate your messages using local speech recognition. It's "
#~ "super convenient! You can even customize your language and other settings "
#~ "in the Preferences dialog."
#~ msgstr ""
#~ "Ab jetzt können Nachrichten mittels lokal laufender Spracherkennung "
#~ "diktiert werden. Das ist sehr praktisch! Sogar Sprache und andere "
#~ "Einstellungen können angepasst werden."

#~ msgid "Find Models Faster"
#~ msgstr "Modelle schneller finden"

#~ msgid ""
#~ "Browsing through your Ollama models just got easier! We've added the "
#~ "ability to filter models by their categories in the Model Manager. Now "
#~ "you can quickly find exactly the model you're looking for."
#~ msgstr ""
#~ "Durch Ollama-Modelle zu stöbern, ist jetzt noch einfacher! Wir haben die "
#~ "Möglichkeit, nach Modellen anhand von Kategorien zu filtern, im Modell-"
#~ "Manager hinzugefügt. Jetzt findet man das Modell, nach dem man sucht, "
#~ "noch schneller."

#~ msgid "Math Rendering"
#~ msgstr "Mathematik-Rendering"

#~ msgid ""
#~ "We've improved how LaTeX equations are rendered in messages, making them "
#~ "look cleaner and more consistent. Your mathematical discussions will be "
#~ "clearer than ever!"
#~ msgstr ""
#~ "Wir haben verbessert, wie LaTeX-Gleichungen in Nachrichten gerendert "
#~ "werden, wodurch diese nun noch besser und konsistenter aussehen. "
#~ "Mathematische Diskussionen werden nun klarer denn je ablaufen können!"

#~ msgid "More Instances"
#~ msgstr "Noch mehr Instanzen"

#~ msgid ""
#~ "Get ready to connect Alpaca to a whole universe of AI providers! We've "
#~ "added support for over 5 new AI instance providers, including Anthropic, "
#~ "OpenRouter, and Fireworks. The possibilities are endless!"
#~ msgstr ""
#~ "Machen Sie sich bereit, Alpaca mit einem Universum an KI-Providern zu "
#~ "verbinden. Wir haben über 5 neue KI-Instanz-Provider hinzugefügt, "
#~ "darunter Anthropic, OpenRouter und Fireworks. Die Möglichkeiten sind "
#~ "schier endlos!"

#~ msgid "Attachment Enhancement"
#~ msgstr "Verbesserung der Anhänge"

#~ msgid ""
#~ "You can now attach and ask questions about even more file types, "
#~ "including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
#~ "you'll see it with rich text styling, making it easier to understand the "
#~ "content before you send it."
#~ msgstr ""
#~ "Nun können Fragen zu noch mehr Dateitypen gestellt werden, "
#~ "darunter .docx, .pptx und .xlsx! Dazu kommt ein verbessertes Rendering "
#~ "von Rich Text in der Vorschau dieser Dateien - sodass es noch einfacher "
#~ "wird, den Inhalt vor dem Versenden zu verstehen."

#~ msgid "Official Website"
#~ msgstr "Offizielle Website"

#~ msgid "'{}' does not support tools."
#~ msgstr "'{}' unterstützt leider keine Werkzeuge."

#~ msgid "Open Model Manager"
#~ msgstr "Öffne Modell-Manager"

#~ msgid "Cannot open image"
#~ msgstr "Bild kann nicht geöffnet werden"

#~ msgid "Remove Attachment?"
#~ msgstr "Anhang entfernen?"

#~ msgid "Are you sure you want to remove attachment?"
#~ msgstr "Sind Sie sicher, dass Sie den Anhang entfernen möchten?"

#~ msgid "Text to Speech Voice"
#~ msgstr "Stimme für Text-zu-Sprache"

#~ msgid "Terminal dialog"
#~ msgstr "Terminal-Dialog"

#~ msgid "File preview dialog"
#~ msgstr "Dateivorschau-Dialog"

#~ msgid "Open With Default App"
#~ msgstr "Mit Standard-App öffnen"

#~ msgid "An error occurred while extracting text from the website"
#~ msgstr ""
#~ "Beim Extrahieren von Text von der Website ist ein Fehler aufgetreten"

#~ msgid "Regenerate Response"
#~ msgstr "Antwort regenerieren"

#~ msgid "Save Message"
#~ msgstr "Speichere Nachricht"

#~ msgid "Message edited successfully"
#~ msgstr "Nachricht erfolgreich editiert"

#~ msgid "Response message"
#~ msgstr "Antwortnachricht"

#~ msgid "System message"
#~ msgstr "Systemnachricht"

#~ msgid "User message"
#~ msgstr "Benutzernachricht"

#~ msgid "{}Code Block"
#~ msgstr "{}Code-Block"

#~ msgid "Edit Code Block"
#~ msgstr "Codeblock bearbeiten"

#~ msgid ""
#~ "Make sure you understand what this script does before running it, Alpaca "
#~ "is not responsible for any damages to your device or data"
#~ msgstr ""
#~ "Stellen Sie sicher, dass Sie verstehen, was dieses Skript tut, bevor Sie "
#~ "es ausführen. Alpaca übernimmt keine Verantwortung für Schäden an Ihrem "
#~ "Gerät oder Ihren Daten."

#~ msgid "Execute"
#~ msgstr "Ausführen"

#~ msgid "Missing image"
#~ msgstr "Fehlendes Bild"

#~ msgid "Compiling C++ script..."
#~ msgstr "C++-Skript wird kompiliert..."

#~ msgid "Running local web server"
#~ msgstr "Führt lokalen Webserver aus"

#~ msgid "Using Flatpak contained shell"
#~ msgstr "Nutzt Flatpak-beinhaltete Shell"

#~ msgid "Clear Chat?"
#~ msgstr "Chat leeren?"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "Sind Sie sicher, dass Sie den Chat leeren möchten?"

#~ msgid "Clear"
#~ msgstr "Leeren"

#~ msgid "Clear Chat"
#~ msgstr "Chat leeren"

#~ msgid "Removal of Ollama"
#~ msgstr "Entfernung von Ollama"

#~ msgid ""
#~ "Hey there! With Alpaca 5.1.0, we're making some changes. To keep using "
#~ "Ollama directly within Alpaca, you'll just need to install our new Ollama "
#~ "extension. Don't worry, your models remain untouched!"
#~ msgstr ""
#~ "Hi! Mit Alpaca 5.1.0 haben wir ein paar Änderungen gemacht. Um ab nun "
#~ "Ollama weiterhin direkt in Alpaca nutzen zu können, brauchst du nur kurz "
#~ "unsere neue Ollama-Erweiterung zu installieren. Aber keine Sorge, deine "
#~ "heruntergeladenen Modelle bleiben unberührt."

#~ msgid "Regenerate Equation"
#~ msgstr "Gleichung neu generieren"

#~ msgid "LaTeX Equation"
#~ msgstr "LaTeX-Gleichung"

#~ msgid "Which network port will Ollama use"
#~ msgstr "Welchen Netzwerkport Ollama nutzen wird"

#~ msgid "Built in Ollama instance"
#~ msgstr "Eingebaute Ollama-Instanz"

#~ msgid "The current strongest model that fits on a single GPU."
#~ msgstr "Das derzeit stärkste Modell, dass auf eine einzige GPU passt."

#~ msgid "Visit Website"
#~ msgstr "Website besuchen"

#~ msgid ""
#~ "QwQ is an experimental research model focused on advancing AI reasoning "
#~ "capabilities."
#~ msgstr ""
#~ "QwQ ist ein experimentelles Forschungsmodell mit einem Fokus auf "
#~ "erweiterteFähigkeiten des logischen Denkens einer KI."

#~ msgid "Your AI, Your Choice"
#~ msgstr "Ihre KI, Ihre Wahl."

#~ msgid ""
#~ "Alpaca includes Ollama by default, giving you instant access to AI. "
#~ "Customize your experience further by connecting to Google Gemini, OpenAI "
#~ "ChatGPT, Together.AI, and more."
#~ msgstr ""
#~ "Alpaca kommt standardmäßig mit Ollama gebündelt, sodass Sie direkt "
#~ "Zugriff auf KI haben können. Passen Sie zusätzlich Ihre Nutzungserfahrung "
#~ "weiter an, indem Sie eine Verbindung mit Google Gemini, OpenAI ChatGPT, "
#~ "Together.AI und vielen weiteren Diensten herstellen!"

#~ msgid ""
#~ "It looks like you don't have any models downloaded yet. Download models "
#~ "to get started!"
#~ msgstr ""
#~ "Es sieht so aus, als hätten Sie noch keine Modelle heruntergeladen. Laden "
#~ "Sie Modelle herunter, um loszulegen!"

#~ msgid "Loading"
#~ msgstr "Lädt..."

#~ msgid ""
#~ "Mistral Small is a lightweight model designed for cost-effective use in "
#~ "tasks like translation and summarization."
#~ msgstr ""
#~ "Mistral Small ist ein leichtgewichtiges Modell, das für kostengünstige "
#~ "Anwendungen wie Übersetzung und Zusammenfassung entwickelt wurde."

#~ msgid ""
#~ "DeepSeek's first generation reasoning models with comparable performance "
#~ "to OpenAI-o1."
#~ msgstr ""
#~ "DeepSeek's erste Generation an Reasoning-Modellen mit vergleichbarer "
#~ "Performance zu OpenAI's o1."

#~ msgid "Loading Instance"
#~ msgstr "Lade Instanz"

#~ msgid "General"
#~ msgstr "Allgemein"

#~ msgctxt "shortcut window"
#~ msgid "Search Messages"
#~ msgstr "Nachrichten durchsuchen"

#~ msgid "Not Available"
#~ msgstr "Nicht verfügbar"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Bearer-Token (Optional)"

#~ msgid "Chat with local AI models"
#~ msgstr "Chatten Sie mit lokalen KI-Modellen"

#~ msgid "An Ollama client"
#~ msgstr "Ein Ollama-Client"

#~ msgid "Connect"
#~ msgstr "Verbinden"

#~ msgid "Server URL"
#~ msgstr "Server URL"

#~ msgid "Connect Remote Instance"
#~ msgstr "Remote-Instanz verbinden"

#~ msgid "Enter instance information to continue"
#~ msgstr "Instanzinformationen eingeben, um fortzufahren"

#~ msgid "Close Alpaca"
#~ msgstr "Alpaca schließen"

#~ msgid "Use Local Instance"
#~ msgstr "Verwende lokale Instanz"

#~ msgid "Connection Error"
#~ msgstr "Verbindungsfehler"

#~ msgid "The remote instance has disconnected"
#~ msgstr "Die Remote-Instanz hat die Verbindung getrennt"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Es gab einen Fehler mit der lokalen Ollama-Instanz, daher wurde sie "
#~ "zurückgesetzt"

#~ msgid "An error occurred: {}"
#~ msgstr "Ein Fehler trat auf: {}"

#~ msgid "Ollama instance was shut down due to inactivity"
#~ msgstr "Ollama-Instanz wurde wegen Inaktivität abgeschaltet"

#~ msgid "Local Models"
#~ msgstr "Lokale Modelle"

#~ msgid ""
#~ "It looks a bit empty in here. Try downloading some models to get started!"
#~ msgstr ""
#~ "Hier sieht es ein wenig leer aus! Probieren Sie, ein paar Modelle "
#~ "herunterzuladen, um loszulegen!"

#~ msgid "Available Models"
#~ msgstr "Verfügbare Modelle"

#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Remote-Verbindung zu Ollama verwenden"

#~ msgid "Change Ollama Instance"
#~ msgstr "Ollama-Instanz ändern"

#~ msgid ""
#~ "The default model to use on new chats and when generating chat titles"
#~ msgstr ""
#~ "Das Standardmodell wird in neuen Chats und zur Generierung der Chat-Titel "
#~ "genutzt."

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "Die Temperatur des Modells. Eine Erhöhung der Temperatur lässt das Modell "
#~ "kreativer antworten. (Standard: 0,8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Legt den Zufallszahlenseed für die Generierung fest. Wenn dies auf eine "
#~ "bestimmte Zahl gesetzt wird, generiert das Modell für den gleichen Prompt "
#~ "den gleichen Text. (Standard: 0 (zufällig))"

#~ msgid "Keep Alive Time"
#~ msgstr "Aktivhaltungszeit"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Steuert, wie lange das Modell nach der Anfrage in Minuten im Speicher "
#~ "geladen bleibt (Standard: 5)"

#~ msgid "Ollama Instance"
#~ msgstr "Ollama-Instanz"

#~ msgid "Ollama Overrides"
#~ msgstr "Ollama-Überschreibungen"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Verwalten Sie die in Ollama verwendeten Argumente, Änderungen auf dieser "
#~ "Seite gelten nur für die integrierte Instanz, die Instanz wird bei "
#~ "Änderungen neu gestartet."

#~ msgid "Idle Timer"
#~ msgstr "Leerlauf-Timer"

#~ msgid ""
#~ "Number of minutes the instance should remain idle before it is shut down "
#~ "(0 means it won't be shut down)"
#~ msgstr ""
#~ "Anzahl der Minuten, die die Instanz im Leerlauf bleiben soll, bevor sie "
#~ "heruntergefahren wird (0 bedeutet, dass sie nicht abgeschaltet wird)"

#~ msgid "Change Model Directory"
#~ msgstr "Modellordner ändern"

#~ msgid "Powered by Ollama"
#~ msgstr "Betrieben von Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Ollama-Website"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca und seine Entwickler haften nicht für Schäden an Geräten oder "
#~ "Software, die durch die Ausführung von Code entstehen, der von einem KI-"
#~ "Modell generiert wurde. Bitte seien Sie vorsichtig und überprüfen Sie den "
#~ "Code sorgfältig, bevor Sie ihn ausführen."

#~ msgid "Reload Local Models"
#~ msgstr "Lokale Modelle neu laden"

#~ msgctxt "shortcut window"
#~ msgid "Import Chat"
#~ msgstr "Chat importieren"

#~ msgid "(No system message available)"
#~ msgstr "(Keine Systemnachricht verfügbar)"

#~ msgid "From Existing Model"
#~ msgstr "Aus bestehendem Modell"

#~ msgid "From GGUF File"
#~ msgstr "Aus GGUF-Datei"

#~ msgid "From Name"
#~ msgstr "Nach Namen"

#~ msgid "image"
#~ msgstr "Bild"

#~ msgid "Select Model"
#~ msgstr "Modell auswählen"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Dieses Modell wird als Basis für das neue Modell verwendet"

#~ msgid ""
#~ "Input the name of the model in this format\n"
#~ "name:tag"
#~ msgstr ""
#~ "Geben Sie den Namen des Modells in diesem Format ein\n"
#~ "Name:Tag"

#~ msgid "Manage models dialog"
#~ msgstr "Modelle verwalten-Dialog"

#~ msgid "Try a different search or pull an unlisted model from it's name"
#~ msgstr ""
#~ "Versuchen Sie eine andere Suche oder rufen Sie ein nicht gelistetes "
#~ "Modell über seinen Namen ab"

#~ msgid "Pull Model From Name"
#~ msgstr "Modell nach Namen abrufen"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "Durch das Herunterladen dieses Modells akzeptieren Sie die auf der "
#~ "Website des Modells verfügbare Lizenzvereinbarung."

#~ msgid "Model Details"
#~ msgstr "Modeldetails"

#~ msgid ""
#~ "Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
#~ "instructions automatically. Please visit the model's website or Ollama "
#~ "documentation for more information if you're unsure."
#~ msgstr ""
#~ "Einige Modelle benötigen eine Modelldatei, Alpaca füllt FROM- und SYSTEM-"
#~ "Anweisungen (Kontext) automatisch aus. Bitte besuchen Sie die Website des "
#~ "Modells oder die Ollama-Dokumentation für weitere Informationen, wenn Sie "
#~ "unsicher sind."

#~ msgid "Create"
#~ msgstr "Erstellen"

#~ msgid "Stop Pulling '{}'"
#~ msgstr "Abrufen von '{}' stoppen"

#~ msgid "Details"
#~ msgstr "Details"

#~ msgid "Remove '{}'"
#~ msgstr "'{}' entfernen"

#~ msgid "Delete Model?"
#~ msgstr "Modell löschen?"

#~ msgid "Create Model Based on '{}'"
#~ msgstr "Modell basierend auf '{}' erstellen"

#~ msgid "Format"
#~ msgstr "Format"

#~ msgid "Enter download menu for {}"
#~ msgstr "Download-Menü für {} aufrufen"

#~ msgid "Download {}:{}"
#~ msgstr "{}:{} herunterladen"

#~ msgid "Model deleted successfully"
#~ msgstr "Modell erfolgreich gelöscht"

#~ msgid "Task Complete"
#~ msgstr "Aufgabe abgeschlossen"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "Modell '{}' erfolgreich abgerufen."

#~ msgid "Pull Model Error"
#~ msgstr "Fehler beim Abrufen des Modells"

#~ msgid "Failed to pull model '{}': {}"
#~ msgstr "Abrufen des Modells '{}' fehlgeschlagen: {}"

#~ msgid "Error pulling '{}': {}"
#~ msgstr "Fehler beim Abrufen von '{}': {}"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr ""
#~ "Abrufen des Modells '{}' aufgrund eines Netzwerkfehlers fehlgeschlagen."

#~ msgid "Error pulling '{}'"
#~ msgstr "Fehler beim Abrufen von '{}'"

#~ msgid "Script exited"
#~ msgstr "Skript beendet"

#~ msgid "The script is contained inside Flatpak"
#~ msgstr "Das Skript ist in Flatpak enthalten"

#~ msgid "Close application"
#~ msgstr "Anwendung schließen"

#~ msgid "Import chat"
#~ msgstr "Chat importieren"

#~ msgid "Clear chat"
#~ msgstr "Chat leeren"

#~ msgid "New chat"
#~ msgstr "Neuer Chat"

#~ msgid "Show shortcuts window"
#~ msgstr "Tastenkombinationen-Fenster anzeigen"

#~ msgid "Manage models"
#~ msgstr "Modelle verwalten"

#~ msgid "Toggle sidebar"
#~ msgstr "Seitenleiste ein-/ausblenden"

#~ msgid "Rename chat"
#~ msgstr "Chat umbenennen"

#~ msgid "Editor"
#~ msgstr "Editor"

#~ msgid "Message text box"
#~ msgstr "Nachrichtentextfeld"

#~ msgid "Missing file"
#~ msgstr "Fehlende Datei"

#~ msgid "Image Recognition"
#~ msgstr "Bilderkennung"

#~ msgid "This video is not available"
#~ msgstr "Dieses Video ist nicht verfügbar"

#~ msgid ""
#~ "An upgraded version of DeepSeek-V2 that integrates the general and coding "
#~ "abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
#~ msgstr ""
#~ "Eine verbesserte Version von DeepSeek-V2, die die allgemeinen und "
#~ "Programmierfähigkeiten von DeepSeek-V2-Chat und DeepSeek-Coder-V2-"
#~ "Instruct integriert."

#~ msgid "Select a Model"
#~ msgstr "Wähle ein Modell"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr ""
#~ "Chat kann während des Empfangs einer Nachricht nicht gelöscht werden"

#~ msgid "Create Chat?"
#~ msgstr "Chat erstellen?"

#~ msgid "Enter name for new chat"
#~ msgstr "Namen für neuen Chat eingeben"

#~ msgid "Use local instance"
#~ msgstr "Lokale Instanz verwenden"

#~ msgid "An error occurred while creating the model"
#~ msgstr "Beim Erstellen des Modells ist ein Fehler aufgetreten"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL der Remote-Instanz"

#~ msgid ""
#~ "Google Gemma 2 is a high-performing and efficient model by now available "
#~ "in three sizes: 2B, 9B, and 27B."
#~ msgstr ""
#~ "Google Gemma ist ein leistungsfähiges und effizientes Modell, dass ab "
#~ "sofort in drei Größen verfügbar ist: 2B, 9B und 27B."

#~ msgid "Loading instance"
#~ msgstr "Lade Instanz"

#~ msgid "Applying user preferences"
#~ msgstr "User-Vorgaben anwenden"

#~ msgid "Updating list of local models"
#~ msgstr "Liste der lokalen Modelle aktualisieren"

#~ msgid "Updating list of available models"
#~ msgstr "Liste der verfügbaren Modelle aktualisieren"

#~ msgid "Loading chats"
#~ msgstr "Chats laden"

#~ msgid "Loading Alpaca dialog"
#~ msgstr "Laden des Alpaca Dialogs"

#~ msgid "Loading Alpaca..."
#~ msgstr "Lade Alpaca..."

#~ msgid ""
#~ "A lightweight AI model with 3.8 billion parameters with performance "
#~ "overtaking similarly and larger sized models. "
#~ msgstr ""
#~ "Ein leichtgewichtiges KI-Modell mit 3,8 Milliarden Parametern, dessen "
#~ "Leistung , das ähnliche und größere Modelle übertrifft. "

#~ msgid "Fixed generated titles having '\"S' for some reason"
#~ msgstr "Generierte Titel haben aus irgendeinem Grund '\"S' - behoben"

#~ msgid "Fixed 'code blocks shouldnt be editable'"
#~ msgstr "Behoben: 'Codeblöcke sollten nicht editierbar sein'"

#~ msgid "Failed to connect to server"
#~ msgstr "Verbindung zum Server fehlgeschlagen"

#~ msgid "Stop Creating '{}'"
#~ msgstr "Erstellung von '{}' stoppen"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 ist jetzt in 2 Größen verfügbar, 9B und 27B."

#~ msgid ""
#~ "Codestral is Mistral AI's first-ever code model designed for code "
#~ "generation tasks."
#~ msgstr ""
#~ "Codestral ist das allererste Codemodell von Mistral AI, das für "
#~ "Codegenerierungsaufgaben entwickelt wurde."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr ""
#~ "Sind Sie sicher, dass Sie das Abrufen von '{} ({})' stoppen möchten?"
