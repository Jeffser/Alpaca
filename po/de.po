# German translations for Alpaca package.
# Copyright (C) 2024-2025 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# Marcel Margenberg <dev.margenberg@gmail.com>, 2024.
# Magnus Schlinsog <magnusschlinsog@gmail.com>, 2025.
# Lilith Engelmeier <firleaf@proton.me>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: 5.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-21 23:13-0600\n"
"PO-Revision-Date: 2025-08-07 02:04+0200\n"
"Last-Translator: Lilith Engelmeier <firleaf@proton.me>\n"
"Language-Team: German\n"
"Language: de\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Generator: Gtranslator 48.0\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ki;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "Mit KI-Modellen chatten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "Ein privater KI-Client"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1397
msgid "Features"
msgstr "Funktionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1399
msgid "Talk to multiple models in the same conversation"
msgstr "Sprechen Sie mit mehreren Modellen in derselben Konversation"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1400
msgid "Pull and delete models from the app"
msgstr "Modelle aus der App abrufen und löschen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "Mehrere Konversationen führen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "Bilderkennung (Nur mit kompatiblen Modellen verfügbar)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "Erkennung von Plaintext-Dokumenten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "Chats importieren und exportieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "YouTube-Transkripte zur Eingabeaufforderung hinzufügen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "Text von einer Website zur Eingabeaufforderung hinzufügen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "PDF-Erkennung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/gtk/welcome.ui:62
msgid "Disclaimer"
msgstr "Haftungsausschluss"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"Dieses Projekt ist in keiner Weise mit Ollama verbunden, ich bin nicht "
"verantwortlich für jegliche Schäden an Ihrem Gerät oder Ihrer Software, die "
"durch die Ausführung von Code entstehen, der von Modellen geliefert wird."

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "Eine normale Konversation mit einem KI-Modell"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "Eine Konversation mit Bilderkennung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "Eine Unterhaltung mit einem benutzerdefinierten Modell"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "Eine Konversation mit Code-Hervorhebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "Ein Python-Skript, das im integrierten Terminal läuft"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation with web search"
msgstr "Eine Unterhaltung mit Websuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "Mehrere Modelle werden heruntergeladen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "A Live Chat conversation with a character"
msgstr "Ein Live-Chat mit einem Charakter"

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:118
#: data/com.jeffser.Alpaca.metainfo.xml.in:136
#: data/com.jeffser.Alpaca.metainfo.xml.in:175
#: data/com.jeffser.Alpaca.metainfo.xml.in:197
#: data/com.jeffser.Alpaca.metainfo.xml.in:211
#: data/com.jeffser.Alpaca.metainfo.xml.in:239
#: data/com.jeffser.Alpaca.metainfo.xml.in:291
#: data/com.jeffser.Alpaca.metainfo.xml.in:305
#: data/com.jeffser.Alpaca.metainfo.xml.in:338
#: data/com.jeffser.Alpaca.metainfo.xml.in:385
#: data/com.jeffser.Alpaca.metainfo.xml.in:432
#: data/com.jeffser.Alpaca.metainfo.xml.in:449
#: data/com.jeffser.Alpaca.metainfo.xml.in:479
#: data/com.jeffser.Alpaca.metainfo.xml.in:489
#: data/com.jeffser.Alpaca.metainfo.xml.in:500
#: data/com.jeffser.Alpaca.metainfo.xml.in:527
#: data/com.jeffser.Alpaca.metainfo.xml.in:547
#: data/com.jeffser.Alpaca.metainfo.xml.in:573
#: data/com.jeffser.Alpaca.metainfo.xml.in:588
#: data/com.jeffser.Alpaca.metainfo.xml.in:613
#: data/com.jeffser.Alpaca.metainfo.xml.in:641
#: data/com.jeffser.Alpaca.metainfo.xml.in:651
#: data/com.jeffser.Alpaca.metainfo.xml.in:662
#: data/com.jeffser.Alpaca.metainfo.xml.in:676
#: data/com.jeffser.Alpaca.metainfo.xml.in:688
#: data/com.jeffser.Alpaca.metainfo.xml.in:704
#: data/com.jeffser.Alpaca.metainfo.xml.in:719
#: data/com.jeffser.Alpaca.metainfo.xml.in:754
#: data/com.jeffser.Alpaca.metainfo.xml.in:779
#: data/com.jeffser.Alpaca.metainfo.xml.in:810
#: data/com.jeffser.Alpaca.metainfo.xml.in:836
#: data/com.jeffser.Alpaca.metainfo.xml.in:858
#: data/com.jeffser.Alpaca.metainfo.xml.in:889
#: data/com.jeffser.Alpaca.metainfo.xml.in:911
#: data/com.jeffser.Alpaca.metainfo.xml.in:932
#: data/com.jeffser.Alpaca.metainfo.xml.in:947
#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid "New"
msgstr "Neu"

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "New tool: Image background remover with local processing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
#: data/com.jeffser.Alpaca.metainfo.xml.in:109
#: data/com.jeffser.Alpaca.metainfo.xml.in:126
#: data/com.jeffser.Alpaca.metainfo.xml.in:146
#: data/com.jeffser.Alpaca.metainfo.xml.in:156
#: data/com.jeffser.Alpaca.metainfo.xml.in:165
#: data/com.jeffser.Alpaca.metainfo.xml.in:179
#: data/com.jeffser.Alpaca.metainfo.xml.in:188
#: data/com.jeffser.Alpaca.metainfo.xml.in:201
#: data/com.jeffser.Alpaca.metainfo.xml.in:218
#: data/com.jeffser.Alpaca.metainfo.xml.in:227
#: data/com.jeffser.Alpaca.metainfo.xml.in:254
#: data/com.jeffser.Alpaca.metainfo.xml.in:270
#: data/com.jeffser.Alpaca.metainfo.xml.in:279
#: data/com.jeffser.Alpaca.metainfo.xml.in:295
#: data/com.jeffser.Alpaca.metainfo.xml.in:316
#: data/com.jeffser.Alpaca.metainfo.xml.in:329
#: data/com.jeffser.Alpaca.metainfo.xml.in:344
#: data/com.jeffser.Alpaca.metainfo.xml.in:353
#: data/com.jeffser.Alpaca.metainfo.xml.in:364
#: data/com.jeffser.Alpaca.metainfo.xml.in:373
#: data/com.jeffser.Alpaca.metainfo.xml.in:421
#: data/com.jeffser.Alpaca.metainfo.xml.in:439
#: data/com.jeffser.Alpaca.metainfo.xml.in:455
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:517
#: data/com.jeffser.Alpaca.metainfo.xml.in:563
#: data/com.jeffser.Alpaca.metainfo.xml.in:594
#: data/com.jeffser.Alpaca.metainfo.xml.in:603
#: data/com.jeffser.Alpaca.metainfo.xml.in:666
#: data/com.jeffser.Alpaca.metainfo.xml.in:694
#: data/com.jeffser.Alpaca.metainfo.xml.in:708
#: data/com.jeffser.Alpaca.metainfo.xml.in:725
#: data/com.jeffser.Alpaca.metainfo.xml.in:736
#: data/com.jeffser.Alpaca.metainfo.xml.in:745
#: data/com.jeffser.Alpaca.metainfo.xml.in:762
#: data/com.jeffser.Alpaca.metainfo.xml.in:772
#: data/com.jeffser.Alpaca.metainfo.xml.in:789
#: data/com.jeffser.Alpaca.metainfo.xml.in:799
#: data/com.jeffser.Alpaca.metainfo.xml.in:846
#: data/com.jeffser.Alpaca.metainfo.xml.in:871
#: data/com.jeffser.Alpaca.metainfo.xml.in:896
#: data/com.jeffser.Alpaca.metainfo.xml.in:918
#: data/com.jeffser.Alpaca.metainfo.xml.in:936
#: data/com.jeffser.Alpaca.metainfo.xml.in:954
#: data/com.jeffser.Alpaca.metainfo.xml.in:966
#: data/com.jeffser.Alpaca.metainfo.xml.in:982
msgid "Fixes"
msgstr "Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "Fixed title generation sometimes not working"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:102
msgid "Fixed chat not being selected at launch sometimes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "Fixed TTS being disabled internally"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:120
msgid "Added preference to change max image attachment size"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:121
msgid "Added option to change context window in instances and model creator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "Changed behavior of instance preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Added option to expose a managed Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Added 'Keep Alive' option to Ollama instance preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
msgid "Reimplementation of DDG search tool"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:129
msgid "Fixed model filtering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:138
msgid "Update model list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:139
msgid "Changed design of tool attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:140
msgid "Tool usage optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:141
msgid "Added metadata attachments for Ollama instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:142
msgid "Changed Image Attachment Container min width to 240"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:143
msgid "Added option to use current model for title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:144
msgid "Added option to regenerate tool responses"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:148
msgid "Made DDG_Search library optional (AUR fix)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:149
msgid "Fixed attachments being rendered to the wrong messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:158
msgid "Fixed message generation problems relating to threading"
msgstr ""
"Probleme bei der Generierung von Nachrichten im Zusammenhang mit Threading "
"behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:167
msgid "Fixed message generation problems"
msgstr "Probleme bei der Generierung von Nachrichten behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:168
msgid "Fixed max tokens error with online instances"
msgstr "\"max tokens\" Fehler für Online-Instanzen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:177
msgid "Added option to regenerate responses when messages are edited"
msgstr "Option zum Regenerieren von Nachrichten durch Bearbeitung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Fixed message rendering problems"
msgstr "Nachrichten-Renderingprobleme behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:190
msgid "Fixed inconsistent message generation rendering"
msgstr "Inkonsistente Nachrichtengenerierung behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:199
msgid "Save message edit with ctrl+enter"
msgstr "Nachrichtenbearbeitungen können nun mit Strg+Enter gespeichert werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Fixed Live Chat and Quick Ask not working sometimes"
msgstr "Behoben, dass Live Chat und Flinke Frage manchmal nicht funktionierten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "Fixed model creation and GGUF import"
msgstr "Modellerstellung und GGUF-Import behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Added option to use tools by default"
msgstr "Option, Tools standardmäßig zu nutzen, hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:214
msgid "Redesign model manager"
msgstr "Modellmanager neu designt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:215
msgid "Added option to attach audio and video files (audio transcription)"
msgstr ""
"Option, Audio- und Videodateien mittels Transkription an Nachrichten "
"anzuhängen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:216
msgid "Added Spotify controller tool"
msgstr "Spotify-Tool hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:220
msgid "Fixed thinking mode being on bugs out normal models"
msgstr ""
"Behoben, dass der Reasoning-Modus dafür sorgte, dass normale Modelle nicht "
"mehr antworten konnten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "Fixed Alpaca crashing when chats database has incorrect metadata (type)"
msgstr "Abstürze bei inkorrekten Metadaten der Alpaca-Datenbank behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:230
msgid ""
"Fixed Quick Ask and Live Chat not running when opened from terminal whilst "
"Alpaca is running"
msgstr ""
"Behoben, dass Flinke Frage und Live Chat nicht aus dem Terminal gestartet "
"werden konnten, wenn Alpaca bereits lief"

#: data/com.jeffser.Alpaca.metainfo.xml.in:231
msgid ""
"Fixed stop button not working when pressed before text generation beggins"
msgstr ""
"Bug behoben, der Stopp-Schaltfläche nicht funktionieren ließ, wenn diese vor "
"der Textgenerierung betätigt wurde"

#: data/com.jeffser.Alpaca.metainfo.xml.in:232
msgid "Fixed instances sometimes not appearing"
msgstr "Behoben, dass Instanzen manchmal nicht angezeigt wurden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
msgid "Live Chat (Talk to models as if you were on a call)"
msgstr "Live Chat (sprechen Sie mit Modellen, als wäre es ein Anruf)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:242
msgid "Live message rendering"
msgstr "Live-Nachrichten-Rendering"

#: data/com.jeffser.Alpaca.metainfo.xml.in:243
msgid "Faster dictation"
msgstr "Schnellere Diktierfunktion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:244
msgid "Dictation whilst message is being generated"
msgstr "Ermöglicht, zu diktieren, während eine Nachricht generiert wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:245
msgid "Camera picture attachment"
msgstr "Kameraaufnahmen als Anhänge hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:246
msgid "Quick Ask now supports attachments"
msgstr "Flinke Frage unterstützt nun Anhänge"

#: data/com.jeffser.Alpaca.metainfo.xml.in:247
msgid "Separator element for message and attachment rendering"
msgstr "Trennelement für Nachrichten- und Anhangrendering"

#: data/com.jeffser.Alpaca.metainfo.xml.in:248
msgid "Redesigned popups"
msgstr "Neu designte Pop-ups"

#: data/com.jeffser.Alpaca.metainfo.xml.in:249
msgid "Thought switch for Ollama instances"
msgstr "Reasoning-Schalter für Ollama-Instanzen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:250
msgid "Username sharing for Ollama instances"
msgstr "Teilen des Nutzernamens an Ollama-Instanzen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "Redesign for instance manager and tool manager"
msgstr "Neu designte Instanzen- und Toolverwaltung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:252
msgid "Better web searching tool with options"
msgstr "Bessere Websuche mit neuen Optionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:256
msgid "Fixed duplication of thought attachments"
msgstr "Verdopplung von Reasoning-Anhängen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:257
msgid "Fixed weird behavior with model selector"
msgstr "Merkwürdiges Verhalten des Modell-Managers behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:258
msgid "Ollama (Managed) instances behave better"
msgstr "Ollama (integriert)-Instanzen verhalten sich nun besser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:259
msgid "Better optimizations for RAM (~2GB difference)"
msgstr "Bessere Speicheroptimierungen (ca. 2 GB Unterschied)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "Instant chat rendering"
msgstr "Sofortiges Chat-Rendering"

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Models profile pictures are now saved at a higher resolution"
msgstr "Profilbilder der Modelle werden nun mit höherer Auflösung gespeichert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Quick Ask messages can now be sent by using the enter key"
msgstr "Flinke Frage-Nachrichten können nun mit Enter gesendet werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid "Alpaca is less prone to crashes now"
msgstr "Alpaca ist nun weniger absturzanfällig"

#: data/com.jeffser.Alpaca.metainfo.xml.in:272
msgid "Fixed new chat not being created when the chat list is empty"
msgstr ""
"Behoben, dass neue Chats nicht erstellt werden, wenn die Chat-Liste leer ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:281
msgid "Chat exporting now works as expected"
msgstr "Exportieren von Chats funktioniert nun wie erwartet"

#: data/com.jeffser.Alpaca.metainfo.xml.in:282
msgid "Fixed automatic creation of Ollama instance"
msgstr "Automatische Erstellung der Ollama-Instanz behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:283
msgid "Added Hebrew and Telugu credits"
msgstr ""
"Vermerk an die Autor:innen für Hebräische und Telugu-Übersetzungen "
"hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:284
msgid "Fixed STT model selector"
msgstr "Modellauswahl für Spracherkennung behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:293
msgid "Multiple QuickAsk window rendering"
msgstr "Mehrere \"Flinke Frage\"-Fenster können nun zugleich angezeigt werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Better stability for QuickAsk"
msgstr "Bessere Stabilität für \"Flinke Frage\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:298
msgid "Creating a new chat now selects it"
msgstr "Erstellung eines neuen Chats wählt diesen nun automatisch aus"

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Chat Search"
msgstr "Chatsuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid "Hide \"latest\" and \"custom\" tags from model selector"
msgstr ""
"\"latest\" und \"custom\"-Bezeichner werden nun von der Modellauswahl "
"versteckt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:309
msgid "Hide model's languages behind popup"
msgstr "Sprache des Modells nun hinter Pop-Up verborgen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:310
msgid "New models listed for Ollama"
msgstr "Neue Ollama-Modelle in die Liste aufgenommen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:311
msgid "Added option to autodictate new mesages"
msgstr "Option zur automatischen Diktierung neuer Nachrichten hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Added Meta Llama API to list of instances"
msgstr "Meta Llama API zur Liste an Instanzen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid ""
"Added new env variables options (\"24H hour formatting\" and \"only Ollama "
"mode\")"
msgstr ""
"Neue Umgebungsvariablenoptionen (bzgl. 24h-Format für Uhrzeiten und ein nur-"
"Ollama-Modus)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Made Mermaid scripts executable using Python HTTP server"
msgstr "Mermaid-Grafiken mit dem Python-HTTP-Server sichtbar gemacht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:318
msgid "Better stability when switching instances"
msgstr "Bessere Stabilität beim Wechseln von Instanzen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:319
msgid "Better performance when navigating menus"
msgstr "Bessere Leistung beim Navigieren von Menüs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:320
msgid "Fixed some dialogs not appearing in Quick Ask window"
msgstr ""
"Behoben, dass einige Dialoge im \"Flinke Frage\"-Fenster nicht angezeigt "
"werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:321
msgid "Faster message search"
msgstr "Schnellere Nachrichtensuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:322
msgid "Faster message rendering"
msgstr "Schnelleres Nachrichten-Rendering"

#: data/com.jeffser.Alpaca.metainfo.xml.in:331
msgid "Fixed whisper directory not existing causing error"
msgstr "Fehler durch fehlendes \"whisper\"-Verzeichnis behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
#: data/com.jeffser.Alpaca.metainfo.xml.in:1189
msgid "Updated model list"
msgstr "Modellliste aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
msgid "Alpaca now remembers it's size"
msgstr "Alpaca merkt sich nun die Fenstergröße"

#: data/com.jeffser.Alpaca.metainfo.xml.in:342
msgid "Added reasoning category for Ollama models"
msgstr "Reasoning-Kategorie für Ollama-Modelle hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:346
msgid "Improvements in sample prompts"
msgstr "Verbesserungen in Beispielprompts"

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "Fixed auto creation of Ollama (Managed) instance"
msgstr "Automatische Erstellung einer Ollama (verwaltet)-Instanz behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Removed legacy JSON to SQLite3 migration code"
msgstr "Alten JSON-zu-SQLite3-Migrationscode entfernt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
msgid "Fixed power saving mode appearing whilst using online instances"
msgstr "Warnung vor Energiesparmodus bei Nutzung von Online-Instanzen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:366
msgid "Fixed Ollama (Manged) instance not being able to be created"
msgstr "Fehler bei der Erstellung der integrierten Ollama-Instanz behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:375
msgid "Instance manager now follows default model"
msgstr "Instanz-Manager befolgt nun das Standardmodell"

#: data/com.jeffser.Alpaca.metainfo.xml.in:376
msgid "English text-to-speech voices not working"
msgstr "Englische Text-zu-Sprache-Stimmen funktionieren nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:377
msgid "Instance manager sometimes not saving instances"
msgstr "Instanz-Manager speichert manchmal Instanzen nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:378
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""
"Fehler behoben, durch den Groq- und Deepseek-Instanzen keinen Text "
"generierten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:387
msgid "Smart tools for models"
msgstr "Intelligente Werkzeuge für Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:388
msgid "Speech recognition (message dictation)"
msgstr "Spracherkennung (Diktieren der Eingabe)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:389 src/widgets/models/speech.py:102
msgid "Text to Speech"
msgstr "Text-zu-Sprache"

#: data/com.jeffser.Alpaca.metainfo.xml.in:390
msgid "New Quick Chat system"
msgstr "Neues \"Flinke Frage\"-System"

#: data/com.jeffser.Alpaca.metainfo.xml.in:391
msgid "Filter Ollama models by categories"
msgstr "Filtern von Ollama-Modellen nach Kategorien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:392
msgid "Better math Latex rendering in messages"
msgstr "Verbessertes Mathematik-LaTeX-Rendering in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:393
msgid "Rich text rendering in attachment preview"
msgstr "Rich-Text-Rendering in Anhangsvorschau"

#: data/com.jeffser.Alpaca.metainfo.xml.in:394
msgid "Matplotlib is now included in Python code runner"
msgstr ""
"Matplotlib ist nun in der integrierten Python-Codeausführung mitgeliefert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:395
msgid "Styling for messages being generated"
msgstr "Verschönerung von Nachrichten, die gerade noch generiert werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:397
#: data/com.jeffser.Alpaca.metainfo.xml.in:505
msgid "New Instances"
msgstr "Neue Instanzen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:399
msgid "Deepseek"
msgstr "Deepseek"

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "OpenRouter AI"
msgstr "OpenRouter AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:401
msgid "Anthropic"
msgstr "Anthropic"

#: data/com.jeffser.Alpaca.metainfo.xml.in:402
msgid "Groq Cloud"
msgstr "Groq Cloud"

#: data/com.jeffser.Alpaca.metainfo.xml.in:403
msgid "Fireworks AI"
msgstr "Fireworks AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:404
msgid "Lambda Labs"
msgstr "Lambda Labs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:406
msgid "New Attachment Types"
msgstr "Neue Anhangstypen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:408
msgid "Microsoft Word Document (docx)"
msgstr "Microsoft Word-Dokument (docx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:409
msgid "Microsoft PowerPoint Document (pptx)"
msgstr "Microsoft PowerPoint-Dokument (pptx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid "Microsoft Excel Document (xlsx)"
msgstr "Microsoft Excel-Dokument (xlsx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "New Tools"
msgstr "Neue Werkzeuge"

#: data/com.jeffser.Alpaca.metainfo.xml.in:414 src/widgets/tools/tools.py:566
msgid "Run Command (Testing)"
msgstr "Befehl ausführen (Testing)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:415 src/widgets/tools/tools.py:463
msgid "Online Search"
msgstr "Online-Suche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:416 src/widgets/tools/tools.py:411
msgid "Extract Wikipedia Article"
msgstr "Wikipedia-Artikel extrahieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:417 src/widgets/tools/tools.py:295
msgid "Get Recipe by Name"
msgstr "Rezept durch Namen finden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:418 src/widgets/tools/tools.py:355
msgid "Get Recipes by Category"
msgstr "Rezept durch Kategorie finden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:419 src/widgets/tools/tools.py:263
msgid "Get Current Datetime"
msgstr "Derzeitiges Datum samt Uhrzeit abrufen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""
"Fehler behoben, durch den der Startbildschirm nach dem Löschen einer "
"Nachricht manchmal nicht erschien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:424
msgid "Fixed bold text not rendering correctly in tables"
msgstr "Fehlerhaftes Rendering von fettem Text in Tabellen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:425
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr "Überlaufen von Beispielprompt-Buttons auf kleinen Bildschirmen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:434
msgid "Updated runtime to Gnome 48"
msgstr "Laufzeit auf GNOME 48 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:435
msgid "Added back 'category pills' to model manager"
msgstr "Kategorie-Indikatoren zurück zum Modell-Manager gebracht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:436
msgid "Better appearance for model manager sidebar"
msgstr "Besseres Erscheinungsbild der Seitenleiste im Modell-Manager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:437
#: data/com.jeffser.Alpaca.metainfo.xml.in:453
msgid "New models"
msgstr "Neue Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:441
msgid "Fixed bad title generation with chain-of-thought models"
msgstr "Schlechte Titelgenerierung von Chain-of-Thought-Modellen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:442
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""
"Seitenwechsler im Modell-Manager versteckt, wenn nur eine Seite vorhanden "
"ist (Online-Instanzen)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:451
msgid "Option to delete all chats"
msgstr "Option, alle Chats zu löschen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:452
msgid "Button to refresh sample prompts"
msgstr "Knopf, um Beispielprompts neu zu laden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr "Behoben, dass integrierte Ollama-Instanz beim Speichern absürzt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Fixed stop button"
msgstr "Stopp-Knopf behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Fixed model search not working if there are only pulling models"
msgstr ""
"Nicht funktionierenden Modellsuche behoben, wenn es nur zu ladende Modelle "
"gibt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid "Fixed sample prompts sometimes not appearing"
msgstr "Nicht erscheinende Beispielprompts behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid "Don't clear the building output of C++ scripts"
msgstr "Build-Ausgabe von C++-Skripten wird nicht mehr geleert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:470
msgid "Better handling of attachments"
msgstr "Bessere Handhabung von Anhängen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:471
msgid "Handle remote Ollama instance's API Key better"
msgstr "Bessere Handhabung des API-Schlüssels einer Ollama-Remoteinstanz"

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid "Remove '\\n' characters in instance edit page"
msgstr "Entferne '\\n'-Buchstaben in Instanzbearbeitungsseite"

#: data/com.jeffser.Alpaca.metainfo.xml.in:481
msgid "Dynamic chat loading"
msgstr "Dynamisches Laden von Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:482
msgid "Updated Ollama instance"
msgstr "Ollama-Instanz aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:491
msgid "Tweaked appearance of models in model manager"
msgstr "Aussehen der Modelle im Modell-Manager angepasst"

#: data/com.jeffser.Alpaca.metainfo.xml.in:492
msgid "Updated Ollama instance to 0.5.11"
msgstr "Ollama-Instanz auf 0.5.11 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:493
msgid "Added new models"
msgstr "Neue Modelle hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:502
msgid "New instance manager"
msgstr "Neuer Instanz-Manager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:503
msgid "New welcome screen"
msgstr "Neuer Willkommensbildschirm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:507
msgid "OpenAI ChatGPT"
msgstr "Open AI ChatGPT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:508
msgid "Google Gemini"
msgstr "Google Gemini"

#: data/com.jeffser.Alpaca.metainfo.xml.in:509
msgid "Together AI"
msgstr "Together AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:510
msgid "Venice"
msgstr "Venice"

#: data/com.jeffser.Alpaca.metainfo.xml.in:519
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr "Das Exportieren von Chats mit 'Gedanken'-Anhängen ist behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:520
msgid "Fixed attachment filters"
msgstr "Anhangs-Filter behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:529
msgid "New model manager"
msgstr "Neuer KI-Modell-Manager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:530
msgid "Changed GtkSpinner to AdwSpinner"
msgstr "Von GtkSpinner auf AdwSpinner gewechselt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:531
msgid "Better handling of launch process"
msgstr "Besserer Ablauf des Startprozesses"

#: data/com.jeffser.Alpaca.metainfo.xml.in:532
msgid "New loading screen at launch"
msgstr "Neuer Ladebildschirm beim Start"

#: data/com.jeffser.Alpaca.metainfo.xml.in:533
msgid "Better handling of file types"
msgstr "Bessere Handhabung von Dateitypen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:534
msgid "Better regex expression for LaTeX equations"
msgstr "Bessere RegEx-Ausdrücke für LaTeX-Gleichungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:535
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""
"Bestätigungsdialog, sollte Alpaca während des Downloads eines Modells "
"geschlossen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:536
msgid "Better handling of think tags in messages"
msgstr "Bessere Handhabung von Reasoning-Tags in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:537
msgid "Default model is now in charge of generating titles"
msgstr "Das Standard-Modell generiert nun Titel"

#: data/com.jeffser.Alpaca.metainfo.xml.in:538
msgid "Message header is now shown whilst the message is being generated"
msgstr "Die Nachrichtenkopfzeile wird nun während der Generierung angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:539
msgid "Better handling of model profile pictures"
msgstr "Bessere Handhabung von Profilbildern der Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:540
msgid "New models in 'available models' list"
msgstr "Neue Modelle in der 'Verfügbare Modelle'-Liste"

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "Added option for attaching screenshots"
msgstr "Option zum Anfügen von Screenshots hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""
"Grundlegende LaTeX-Mathematikgleichungen werden nun in Nachrichten gerendert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""
"HTML sowie C++-Skripte können nun innerhalb von Alpaca ausgeführt werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:552
msgid "Added option to open the environment directory from the terminal"
msgstr "Option hinzugefügt, den Umgebungsordner vom Terminal aus zu öffnen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:553
msgid "Added option to edit code blocks directly"
msgstr "Option hinzugefügt, um Codeblöcke direkt bearbeiten zu können"

#: data/com.jeffser.Alpaca.metainfo.xml.in:554
msgid "Complete keyboard shortcut list"
msgstr "Tastenkürzelliste vervollständigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:555
msgid "Images are now attached in 640p resolution"
msgstr "Bilder werden nun in 640p-Auflösung angehangen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:556
msgid "Website attachments now use extracted titles"
msgstr "Website-Anhänge nutzen nun auch extrahierte Titel"

#: data/com.jeffser.Alpaca.metainfo.xml.in:557
msgid "Better chat title generation"
msgstr "Bessere Generierung der Chat-Titel"

#: data/com.jeffser.Alpaca.metainfo.xml.in:558
msgid "Added option to attach any plain text files"
msgstr "Option hinzugefügt, um Klartextdateien anzuhängen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:559
msgid "Added spellchecker to message entry"
msgstr "Rechtschreiberkennung zum Nachrichtenfeld hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr "Alpaca's Einstellungen werden nun mittels SQLite3 gespeichert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:561
msgid "Small appearance changes in text entries"
msgstr "Geringfügige Aussehensanpassungen in Textfeldern"

#: data/com.jeffser.Alpaca.metainfo.xml.in:565
msgid "Alpaca's launch process is more reliable"
msgstr "Alpaca's Startprozess ist zuverlässiger"

#: data/com.jeffser.Alpaca.metainfo.xml.in:566
msgid "Closing the terminal now kills the script subprocess"
msgstr ""
"Das Terminal zu schließen führt nun zum Beenden des Skript-Subprozesses"

#: data/com.jeffser.Alpaca.metainfo.xml.in:575
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr "Chat-Backend von JSON zu SQLite migriert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:576
msgid "Changed appearance of messages"
msgstr "Erscheinungsbild der Nachrichten geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:577
msgid "Added the option to add profile pictures to models"
msgstr "Option hinzugefügt, um Profilbilder zu Modellen hinzuzufügen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:579
#: data/com.jeffser.Alpaca.metainfo.xml.in:1051
#: data/com.jeffser.Alpaca.metainfo.xml.in:1100
msgid "Fix"
msgstr "Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr "Override HIP_VISIBLE_DEVICES zu ROCR_VISIBLE_DEVICES gewechselt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:590
msgid "Added categories to models"
msgstr "Kategorien zu Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:591
msgid "Specified model's languages"
msgstr "Sprachen der Modelle spezifiziert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:592
msgid "Added warning when downloading embedding models"
msgstr "Warnung beim Download von Embedding-Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Replaced low ram warning with big model warning"
msgstr ""
"Warnung über geringen Arbeitsspeicher mit Warnung zu großem Modell ersetzt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Correctly escape markup before rendering message"
msgstr "Markup richtig escapen, bevor es in der Nachricht gerendert wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Fixed about dialog not working if log file was missing"
msgstr ""
"Nicht funktionierenden 'Über Alpaca'-Dialog behoben, sollte die Log-Datei "
"fehlen."

#: data/com.jeffser.Alpaca.metainfo.xml.in:615
msgid "System messages can now be sent directly from Alpaca"
msgstr "Systemnachrichten können nun direkt mit Alpaca gesendet werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
msgid "New redesign for messages and smaller minimum size"
msgstr "Neues Design für Nachrichten und kleinere Minimalgröße"

#: data/com.jeffser.Alpaca.metainfo.xml.in:617
msgid "New models included in 'available models list'"
msgstr "Neue Modelle in 'Verfügbare Modelle'-Liste aufgenommen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:618
msgid "Added symbolic icon when attaching code files"
msgstr "Symbolische Icons beim Anhang von Codedateien hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:619
msgid "When exporting a chat it now includes a markdown file"
msgstr "Der Export eines Chats beinhaltet nun eine Markdown-Datei"

#: data/com.jeffser.Alpaca.metainfo.xml.in:620
msgid "Refresh button in model manager when using a remote instance"
msgstr "'Neu laden'-Knopf im Modellmanager bei Nutzung einer Remoteinstanz"

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Assistant messages are now editable"
msgstr "Assistentnachrichten können nun bearbeitet werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Updated Ollama to v0.5.2"
msgstr "Ollama auf v0.5.2 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "New option to change model directory"
msgstr "Neue Option zum Wechseln des Modellordners"

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "File previewer now resizes dynamically to content"
msgstr "Größe der Dateivorschau wird nun dynamisch zum Inhalt angepasst"

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr "Alpaca angepasst, sodass es ohne integrierte Instanz arbeiten kann"

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Compatibility added with ODT files"
msgstr "Kompatibilität mit ODT-Dateien hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:629
msgid "Restored ROCm compatibility"
msgstr "ROCm-Kompatibilität wiederhergestellt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:630
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Langes Drücken-Geste zu Chatzeilen hinzugefügt, sodass Aktionen auch auf "
"Touchscreens durchgeführt werden können."

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "Fixed edit button not saving changes"
msgstr ""
"Fehler des Bearbeiten-Knopfes behoben, der die Änderungen nicht speicherte"

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Changed max temperature value to 2"
msgstr "Maximal-Modelltemperaturwert auf 2 geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:633
msgid "Made seed 0 actually random"
msgstr "Seed '0' tatsächlich zufällig gemacht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:634
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""
"Nicht funktionierenden GNOME-Search-Provider außerhalb von Flatpak-"
"Installationen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""
"Neue Option '--ask MESSAGE', um ein neues 'Quick Ask'-Fenster zu öffnen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Gnome Search integration now works whilst the app is opened"
msgstr "GNOME-Suche-Integration funktioniert nun, wenn die App geöffnet ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:653
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""
"Startparameter '--ask MESSAGE', '--new-chat CHAT', '--select-chat CHAT', '--"
"list-chats', '--version' hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Added integration as Gnome Search Provider"
msgstr "Integration als GNOME-Suche-Provider hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "Updated Ollama to v0.4.2 with new models"
msgstr "Ollama auf Version v0.4.2 mit neuen Modellen aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:664
msgid "User messages are now compacted into bubbles"
msgstr "Nutzernachrichten sind nun kleiner in Sprechblasen komprimiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:668
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""
"Bei Auswahl von 'Nutzung lokaler Instanz' nicht funktionierenden re-"
"Verbindungsdialog behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:669
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""
"Nicht mit zu großen Systemschriftgrößen funktionierenden Modellmanager "
"behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Details page for models"
msgstr "Detailseite für Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""
"Die Modellauswahl wird durch die Schaltfläche Modelle verwalten ersetzt, "
"wenn keine Modelle heruntergeladen wurden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Added warning when model is too big for the device"
msgstr "Warnung hinzugefügt, wenn das Modell zu groß für das Gerät ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Added AMD GPU indicator in preferences"
msgstr "AMD-GPU-Anzeige in den Einstellungen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:690
msgid "Better system for handling dialogs"
msgstr "Besseres System zur Handhabung von Dialogen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:691
msgid "Better system for handling instance switching"
msgstr "Besseres System für die Handhabung des Instanzenwechsels"

#: data/com.jeffser.Alpaca.metainfo.xml.in:692
msgid "Remote connection dialog"
msgstr "Dialog zur Remoteverbindung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""
"Behoben: Modelle werden beim Wechsel zwischen lokaler und entfernter Instanz "
"dupliziert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
msgid "Better internal instance manager"
msgstr "Besserer interner Instanzmanager"

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""
"Schaltflächen Abbrechen und Speichern beim Bearbeiten einer Nachricht "
"hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:710
msgid "Better handling of image recognition"
msgstr "Bessere Handhabung der Bilderkennung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:711
msgid "Remove unused files when canceling a model download"
msgstr "Entfernen unbenutzter Dateien beim Abbrechen eines Modell-Downloads"

#: data/com.jeffser.Alpaca.metainfo.xml.in:712
msgid "Better message blocks rendering"
msgstr "Bessere Darstellung von Nachrichtenblöcken"

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "Run bash and python scripts straight from chat"
msgstr "Bash- und Python-Skripte direkt aus dem Chat ausführen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:722
msgid "Updated Ollama to 0.3.12"
msgstr "Ollama auf 0.3.12 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "New models!"
msgstr "Neue Modelle!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid "Fixed and made faster the launch sequence"
msgstr "Startsequenz behoben und beschleunigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid "Better detection of code blocks in messages"
msgstr "Verbesserte Erkennung von Codeblöcken in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""
"Behoben, dass die App in bestimmten Setups mit Nvidia-GPUs nicht geladen wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""
"Behoben, dass die Nachrichtenbenachrichtigung manchmal die Textrendering "
"abstürzen lässt, da sie auf unterschiedlichen Threads ausgeführt wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "Fixed message generation sometimes failing"
msgstr "Behoben, dass die Nachrichtenerstellung manchmal fehlschlägt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:756
msgid "Sidebar resizes with the window"
msgstr "Seitenleiste passt sich der Fenstergröße an"

#: data/com.jeffser.Alpaca.metainfo.xml.in:757
msgid "New welcome dialog"
msgstr "Neuer Begrüßungsdialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:758
msgid "Message search"
msgstr "Nachrichtensuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:759
msgid "Updated Ollama to v0.3.11"
msgstr "Ollama auf v0.3.11 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "A lot of new models provided by Ollama repository"
msgstr "Viele neue Modelle aus dem Ollama-Repository"

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""
"Behoben, dass der Text im Modell-Manager bei aktivierter "
"Barrierefreiheitseinstellung 'Großer Text' angezeigt wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:765
msgid "Fixed image recognition on unsupported models"
msgstr "Bild-Erkennung bei nicht unterstützten Modellen behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""
"Behoben, dass der Ladeindikator nicht ausgeblendet wird, wenn das Backend "
"fehlschlägt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:775
msgid "Fixed image recognition with local images"
msgstr "Bild-Erkennung bei lokalen Bildern behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:776
msgid "Changed appearance of delete / stop model buttons"
msgstr "Aussehen der Löschen-/Stopp-Modell-Buttons geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:777
msgid "Fixed stop button crashing the app"
msgstr "Behoben, dass der Stopp-Button die App abstürzen lässt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:781
msgid "Made sidebar resize a little when the window is smaller"
msgstr "Seitenleiste passt sich etwas an, wenn das Fenster kleiner ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:782
msgid "Instant launch"
msgstr "Sofortiger Start"

#: data/com.jeffser.Alpaca.metainfo.xml.in:791
msgid "Fixed error on first run (welcome dialog)"
msgstr "Fehler beim ersten Start (Begrüßungsdialog) behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:792
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr "Prüfer für Ollama-Instanz (verwendet in Systempaketen) behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Fixed 'clear chat' option"
msgstr "'Chat leeren'-Option behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr "Behoben, dass der Begrüßungsdialog die lokale Instanz am Start hindert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:803
msgid "Fixed support for AMD GPUs"
msgstr "Unterstützung für AMD-GPUs behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "Model, message and chat systems have been rewritten"
msgstr "Modell-, Nachrichten und Chatsysteme wurden neugeschrieben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
msgid "New models are available"
msgstr "Neue Modelle verfügbar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
msgid "Ollama updated to v0.3.9"
msgstr "Ollama zu Version v0.3.9 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:815
msgid "Added support for multiple chat generations simultaneously"
msgstr "Support für simultane Multi-Chat-Generationen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:816
msgid "Added experimental AMD GPU support"
msgstr "Experimenteller AMD GPU Support hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:817
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""
"Statusladebalken als Indikator für Nachrichten zum Chat-Tab hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:818
msgid "Added animations"
msgstr "Animationen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:819
msgid "Changed model manager / model selector appearance"
msgstr "Die Gestaltung des Modell Manager / Modellauswähler geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:820
msgid "Changed message appearance"
msgstr "Die Gestaltung der Nachrichten geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Added markdown and code blocks to user messages"
msgstr "Markdown und Codeblöcke für Benutzernachrichten hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Added loading dialog at launch so the app opens faster"
msgstr "Ladedialog beim Start hinzugefügt, damit sich die App schneller öffnet"

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""
"Warnung hinzugefügt, wenn sich das Gerät im 'Batteriesparmodus' befindet"

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Added inactivity timer to integrated instance"
msgstr "Inaktivitäts-Timer zur integrierten Instanz hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:827
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr "Der Chat wird jetzt nach unten gescrollt, wenn er geändert wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:828
msgid "Better handling of focus on messages"
msgstr "Bessere Handhabung von Nachrichten, die im Fokus stehen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:829
msgid "Better general performance on the app"
msgstr "Bessere Grundperformance der App"

#: data/com.jeffser.Alpaca.metainfo.xml.in:838
msgid "New duplicate chat option"
msgstr "Option zum Duplizieren von Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:839
msgid "Changed model selector appearance"
msgstr "Erscheinungsbild des Modellselektors geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:840
msgid "Message entry is focused on launch and chat change"
msgstr "Nachrichteneingabe wird beim Start und Chatwechsel fokussiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:841
msgid "Message is focused when it's being edited"
msgstr "Nachricht wird beim Bearbeiten fokussiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "Added loading spinner when regenerating a message"
msgstr "Ladeanimation beim erneuten Generieren einer Nachricht hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr "Ollama-Debugging zum 'Über Alpaca'-Dialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""
"Erscheinungsbild und Verhalten des YouTube-Transkriptionsdialogs geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr "STRG+W und STRG+Q stoppen die lokale Instanz vor dem Schließen der App"

#: data/com.jeffser.Alpaca.metainfo.xml.in:849
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""
"Erscheinungsbild der Schaltfläche 'Modell-Manager öffnen' auf dem "
"Begrüßungsbildschirm geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:850
msgid "Fixed message generation not working consistently"
msgstr "Nachrichtengenerierung funktioniert nicht konsistent - behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:851
msgid "Fixed message edition not working consistently"
msgstr "Nachrichtenbearbeitung funktioniert nicht konsistent - behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:860
msgid "Model manager opens faster"
msgstr "Modell-Manager öffnet sich schneller"

#: data/com.jeffser.Alpaca.metainfo.xml.in:861
msgid "Delete chat option in secondary menu"
msgstr "Option 'Chat löschen' im sekundären Menü"

#: data/com.jeffser.Alpaca.metainfo.xml.in:862
msgid "New model selector popup"
msgstr "Neues Popup für die Modellauswahl"

#: data/com.jeffser.Alpaca.metainfo.xml.in:863
msgid "Standard shortcuts"
msgstr "Standard-Tastenkombinationen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:864
msgid "Model manager is navigable with keyboard"
msgstr "Modell-Manager ist mit der Tastatur navigierbar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:865
msgid "Changed sidebar collapsing behavior"
msgstr "Verhalten beim Ausblenden der Seitenleiste geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:866
msgid "Focus indicators on messages"
msgstr "Fokus-Indikatoren auf Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:867
msgid "Welcome screen"
msgstr "Begrüßungsbildschirm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:868
msgid "Give message entry focus at launch"
msgstr "Nachrichteneingabe beim Start fokussieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:869
msgid "Generally better code"
msgstr "Allgemein besserer Code"

#: data/com.jeffser.Alpaca.metainfo.xml.in:873
msgid "Better width for dialogs"
msgstr "Bessere Breite für Dialoge"

#: data/com.jeffser.Alpaca.metainfo.xml.in:874
msgid "Better compatibility with screen readers"
msgstr "Bessere Kompatibilität mit Bildschirmlesern"

#: data/com.jeffser.Alpaca.metainfo.xml.in:875
msgid "Fixed message regenerator"
msgstr "Nachrichtengenerator repariert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:876
msgid "Removed 'Featured models' from welcome dialog"
msgstr "'Empfohlene Modelle' aus dem Begrüßungsdialog entfernt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Added default buttons to dialogs"
msgstr "Standard-Schaltflächen zu Dialogen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:878
msgid "Fixed import / export of chats"
msgstr "Import/Export von Chats behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "Changed Python2 title to Python on code blocks"
msgstr "Titel 'Python2' in Codeblöcken zu 'Python' geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:880
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""
"Verhindern Sie die erneute Generierung des Titels, wenn der Benutzer ihn in "
"einen benutzerdefinierten Titel geändert hat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:881
msgid "Show date on stopped messages"
msgstr "Datum bei gestoppten Nachrichten anzeigen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:882
msgid "Fix clear chat error"
msgstr "Fehler beim Leeren des Chats behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:891
msgid "Changed shortcuts to standards"
msgstr "Tastenkombinationen auf Standards geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:892
msgid "Moved 'Manage Models' button to primary menu"
msgstr "Schaltfläche 'Modelle verwalten' in das Hauptmenü verschoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:893
#: data/com.jeffser.Alpaca.metainfo.xml.in:915
msgid "Stable support for GGUF model files"
msgstr "Stabile Unterstützung für GGUF-Modelldateien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:894
#: data/com.jeffser.Alpaca.metainfo.xml.in:1169
msgid "General optimizations"
msgstr "Allgemeine Optimierungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:898
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""
"Bessere Behandlung der Eingabetaste (wichtig für die japanische Eingabe)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:899
msgid "Removed sponsor dialog"
msgstr "Sponsorendialog entfernt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:900
msgid "Added sponsor link in about dialog"
msgstr "Sponsorenlink im Info-Dialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:901
msgid "Changed window and elements dimensions"
msgstr "Fenster- und Elementabmessungen geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:902
msgid "Selected model changes when entering model manager"
msgstr "Ausgewähltes Modell ändert sich beim Aufrufen des Modell-Managers"

#: data/com.jeffser.Alpaca.metainfo.xml.in:903
msgid "Better image tooltips"
msgstr "Bessere Bild-Tooltips"

#: data/com.jeffser.Alpaca.metainfo.xml.in:904
msgid "GGUF Support"
msgstr "GGUF-Unterstützung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:913
msgid "Regenerate any response, even if they are incomplete"
msgstr "Jede Antwort neu generieren, auch wenn sie unvollständig sind"

#: data/com.jeffser.Alpaca.metainfo.xml.in:914
msgid "Support for pulling models by name:tag"
msgstr "Unterstützung für das Abrufen von Modellen nach Name:Tag"

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid "Restored sidebar toggle button"
msgstr "Seitenleisten-Umschalttaste wiederhergestellt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:920
msgid "Reverted back to standard styles"
msgstr "Zu Standardstilen zurückgekehrt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:921
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""
"Es wurde behoben, dass generierte Titel aus irgendeinem Grund \"'S\" "
"enthalten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:922
msgid "Changed min width for model dropdown"
msgstr "Minimale Breite für Modell-Dropdown geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:923
msgid "Changed message entry shadow"
msgstr "Schatten der Nachrichteneingabe geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "The last model used is now restored when the user changes chat"
msgstr ""
"Das zuletzt verwendete Modell wird nun wiederhergestellt, wenn der Benutzer "
"den Chat wechselt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:925
msgid "Better check for message finishing"
msgstr "Bessere Prüfung auf Nachrichtenende"

#: data/com.jeffser.Alpaca.metainfo.xml.in:934
msgid "Added table rendering (Thanks Nokse)"
msgstr "Tabellen-Rendering hinzugefügt (Danke Nokse)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:938
msgid "Made support dialog more common"
msgstr "Support-Dialog gängiger gemacht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:939
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""
"Dialog-Titel auf Tag-Auswahl beim Herunterladen von Modellen wurde nicht "
"richtig angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:940
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""
"Verhindern, dass bei der Chat-Generierung ein mehrzeiliger Titel generiert "
"wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:949
msgid "Bearer Token entry on connection error dialog"
msgstr "Eingabe des Bearer-Tokens im Verbindungsfehler-Dialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Small appearance changes"
msgstr "Kleine Änderungen am Erscheinungsbild"

#: data/com.jeffser.Alpaca.metainfo.xml.in:951
msgid "Compatibility with code blocks without explicit language"
msgstr "Kompatibilität mit Codeblöcken ohne explizite Sprache"

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "Rare, optional and dismissible support dialog"
msgstr "Seltener, optionaler und entfernbarer Support-Dialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:956
msgid "Date format for Simplified Chinese translation"
msgstr "Datumsformat für vereinfachte chinesische Übersetzung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:957
msgid "Bug with unsupported localizations"
msgstr "Fehler bei nicht unterstützten Lokalisierungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:958
msgid "Min height being too large to be used on mobile"
msgstr "Mindesthöhe zu groß für die Verwendung auf Mobilgeräten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
msgid "Remote connection checker bug"
msgstr "Fehler beim Prüfen der Remoteverbindung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:968
msgid "Models with capital letters on their tag don't work"
msgstr "Modelle mit Großbuchstaben in ihrem Tag funktionieren nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:969
msgid "Ollama fails to launch on some systems"
msgstr "Ollama startet auf einigen Systemen nicht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:970
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""
"YouTube-Transkripte werden nicht im richtigen TMP-Verzeichnis gespeichert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:974
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr "Debug-Meldungen werden jetzt im 'Über Alpaca'-Dialog angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:975
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr "Ollama auf v0.3.0 aktualisiert (neue Modelle)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:984
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""
"Modelle mit '-' in ihren Namen funktionierten nicht richtig, dies ist jetzt "
"behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:985
msgid "Better connection check for Ollama"
msgstr "Bessere Verbindungsprüfung für Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:992
msgid "Stable Release"
msgstr "Stabiles Release"

#: data/com.jeffser.Alpaca.metainfo.xml.in:993
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""
"Das neue Icon wurde von Tobias Bernard über Gnome Gitlab erstellt, vielen "
"Dank für das tolle Icon!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:994
msgid "Features and fixes"
msgstr "Funktionen und Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:996
msgid "Updated Ollama instance to 0.2.8"
msgstr "Ollama-Instanz auf 0.2.8 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:997
msgid "Better model selector"
msgstr "Besserer Modellselektor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid "Model manager redesign"
msgstr "Überarbeitung des Modell-Managers"

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid "Better tag selector when pulling a model"
msgstr "Besserer Tag-Selektor beim Abrufen eines Modells"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1000
msgid "Model search"
msgstr "Modellsuche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1001
msgid "Added support for bearer tokens on remote instances"
msgstr "Unterstützung für Bearer-Token auf Remote-Instanzen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1002
msgid "Preferences dialog redesign"
msgstr "Überarbeitung des Einstellungsdialogs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1003
msgid "Added context menus to interact with a chat"
msgstr "Kontextmenüs zur Interaktion mit einem Chat hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1004
msgid "Redesigned primary and secondary menus"
msgstr "Überarbeitete primäre und sekundäre Menüs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1005
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""
"YouTube-Integration: Fügen Sie die URL eines Videos mit Transkript ein und "
"es wird zur Eingabeaufforderung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1006
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""
"Website-Integration (experimentell): Extrahieren Sie den Text aus dem Body "
"einer Website durch Hinzufügen der URL zur Eingabeaufforderung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1007
msgid "Chat title generation"
msgstr "Generierung von Chat-Titeln"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1008
msgid "Auto resizing of message entry"
msgstr "Automatische Größenänderung der Nachrichteneingabe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1009
msgid "Chat notifications"
msgstr "Chat-Benachrichtigungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1010
msgid "Added indicator when an image is missing"
msgstr "Indikator hinzugefügt, wenn ein Bild fehlt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1011
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""
"Automatisches Neuanordnen der Reihenfolge der Chats beim Empfang einer "
"Nachricht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1012
msgid "Redesigned file preview dialog"
msgstr "Überarbeiteter Dateivorschau-Dialog"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1013
msgid "Credited new contributors"
msgstr "Neue Mitwirkende aufgeführt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1014
msgid "Better stability and optimization"
msgstr "Bessere Stabilität und Optimierung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1015
msgid "Edit messages to change the context of a conversation"
msgstr "Nachrichten bearbeiten, um den Kontext einer Unterhaltung zu ändern"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1016
msgid "Added disclaimers when pulling models"
msgstr "Haftungsausschlüsse beim Abrufen von Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1017
msgid "Preview files before sending a message"
msgstr "Vorschau von Dateien vor dem Senden einer Nachricht"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1018
msgid "Better format for date and time on messages"
msgstr "Besseres Format für Datum und Uhrzeit in Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1019
msgid "Error and debug logging on terminal"
msgstr "Fehler- und Debug-Protokollierung im Terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1020
msgid "Auto-hiding sidebar button"
msgstr "Automatisch ausblendbare Seitenleisten-Schaltfläche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1021
msgid "Various UI tweaks"
msgstr "Verschiedene Verbesserungen der Benutzeroberfläche"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1023
msgid "New Models"
msgstr "Neue Modelle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1025
msgid "Gemma2"
msgstr "Gemma2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1026
msgid "GLM4"
msgstr "GLM4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1027
msgid "Codegeex4"
msgstr "Codegeex4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1028
msgid "InternLM2"
msgstr "InternLM2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1029
msgid "Llama3-groq-tool-use"
msgstr "Llama3-groq-tool-use"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1030
msgid "Mathstral"
msgstr "Mathstral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1031
msgid "Mistral-nemo"
msgstr "Mistral-nemo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1032
msgid "Firefunction-v2"
msgstr "Firefunction-v2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1033
msgid "Nuextract"
msgstr "Nuextract"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1035
msgid "Translations"
msgstr "Übersetzungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1036
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""
"Das sind alle verfügbaren Übersetzungen in Version 1.0.0, vielen Dank an "
"alle Mitwirkenden!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1038
msgid "Russian: Alex K"
msgstr "Russisch: Alex K"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1039
msgid "Spanish: Jeffser"
msgstr "Spanisch: Jeffser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1040
msgid "Brazilian Portuguese: Daimar Stein"
msgstr "Brasilianisches Portugiesisch: Daimar Stein"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1041
msgid "French: Louis Chauvet-Villaret"
msgstr "Französisch: Louis Chauvet-Villaret"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1042
msgid "Norwegian: CounterFlow64"
msgstr "Norwegisch: CounterFlow64"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1043
msgid "Bengali: Aritra Saha"
msgstr "Bengalisch: Aritra Saha"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1044
msgid "Simplified Chinese: Yuehao Sui"
msgstr "Vereinfachtes Chinesisch: Yuehao Sui"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1052
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""
"DOCX-Kompatibilität vorübergehend entfernt aufgrund eines Fehlers mit der "
"python-lxml-Abhängigkeit"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1058
#: data/com.jeffser.Alpaca.metainfo.xml.in:1088
#: data/com.jeffser.Alpaca.metainfo.xml.in:1109
#: data/com.jeffser.Alpaca.metainfo.xml.in:1314
#: data/com.jeffser.Alpaca.metainfo.xml.in:1371
msgid "Big Update"
msgstr "Großes Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1060
msgid "Added compatibility for PDF"
msgstr "Kompatibilität für PDF hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1061
msgid "Added compatibility for DOCX"
msgstr "Kompatibilität für DOCX hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1062
msgid "Merged 'file attachment' menu into one button"
msgstr "Menü 'Dateianhang' in eine Schaltfläche zusammengeführt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1069
#: data/com.jeffser.Alpaca.metainfo.xml.in:1262
msgid "Quick Fix"
msgstr "Schnelle Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1070
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""
"Es gab einige Fehler beim Übergang von der alten Version der Chats zur neuen "
"Version. Ich entschuldige mich, wenn dies zu einer Beschädigung Ihres Chat-"
"Verlaufs geführt hat. Dies sollte das einzige Mal sein, dass ein solcher "
"Übergang erforderlich ist."

#: data/com.jeffser.Alpaca.metainfo.xml.in:1076
#: data/com.jeffser.Alpaca.metainfo.xml.in:1228
msgid "Huge Update"
msgstr "Riesiges Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1078
msgid "Added: Support for plain text files"
msgstr "Hinzugefügt: Unterstützung für reine Textdateien"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1079
msgid "Added: New backend system for storing messages"
msgstr "Hinzugefügt: Neues Backend-System zum Speichern von Nachrichten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1080
msgid "Added: Support for changing Ollama's overrides"
msgstr "Hinzugefügt: Unterstützung zum Ändern der Überschreibungen von Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1081
msgid "General Optimization"
msgstr "Allgemeine Optimierung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1090
msgid "Added: Support for GGUF models (experimental)"
msgstr "Hinzugefügt: Unterstützung für GGUF-Modelle (experimentell)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1091
msgid "Added: Support for customization and creation of models"
msgstr ""
"Hinzugefügt: Unterstützung für die Anpassung und Erstellung von Modellen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1092
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr "Behoben: Symbole werden auf Nicht-Gnome-Systemen nicht angezeigt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1093
msgid "Update Ollama to v0.1.39"
msgstr "Ollama auf v0.1.39 aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""
"Behoben: App öffnete sich nicht, wenn Modellanpassungen nicht in den "
"Konfigurationsdateien vorhanden waren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1111
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr "Mehrere Symbole geändert (Papierflugzeug für die Senden-Schaltfläche)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1112
msgid "Combined export / import chat buttons into a menu"
msgstr "Export-/Import-Chat-Schaltflächen in ein Menü zusammengefasst"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1113
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr "'Modellanpassungen' (Temperatur, Seed, Keep_Alive) hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1114
msgid "Fixed send / stop button"
msgstr "Senden-/Stopp-Schaltfläche behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1115
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""
"Behoben, dass die App beim Start nicht prüft, ob die Remoteverbindung "
"funktioniert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1122
msgid "Daily Update"
msgstr "Tägliches Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1124
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""
"Text-Ellipse zum Chatnamen hinzugefügt, damit sich die Schaltflächenbreite "
"nicht ändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1125
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr "Neue Verknüpfung zum Erstellen eines Chats (STRG+N)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1126
msgid "New message entry design"
msgstr "Neues Design für die Nachrichteneingabe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1127
msgid "Fixed: Can't rename the same chat multiple times"
msgstr "Behoben: Derselbe Chat kann nicht mehrmals umbenannt werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1134
msgid "The fix"
msgstr "Die Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1136
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""
"Behoben: Ollama-Instanz läuft weiter im Hintergrund, auch wenn sie "
"deaktiviert ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1137
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""
"Behoben: Modelle können nicht in die integrierte Instanz gezogen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1144
msgid "Quick tweaks"
msgstr "Schnelle Anpassungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1146
msgid "Added progress bar to models that are being pulled"
msgstr "Fortschrittsbalken für Modelle hinzugefügt, die abgerufen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1147
msgid "Added size to tags when pulling a model"
msgstr "Größe zu Tags hinzugefügt, wenn ein Modell abgerufen wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1148
msgid "General optimizations on the background"
msgstr "Allgemeine Optimierungen im Hintergrund"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1155
msgid "Quick fixes"
msgstr "Schnelle Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1157
msgid "Fixed: Scroll when message is received"
msgstr "Behoben: Scrollen, wenn eine Nachricht empfangen wird"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1158
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr "Behoben: Inhalt ändert sich nicht beim Erstellen eines neuen Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1159
msgid "Added 'Featured Models' page on welcome dialog"
msgstr "Seite 'Empfohlene Modelle' im Begrüßungsdialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1166
msgid "Nice Update"
msgstr "Schönes Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1168
msgid "UI tweaks (Thanks Nokse22)"
msgstr "UI-Anpassungen (Danke Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1170
msgid "Metadata fixes"
msgstr "Fehlerbehebungen bei den Metadaten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1177
msgid "Quick fix"
msgstr "Schnelle Fehlerbehebung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1179
msgid "Updated Spanish translation"
msgstr "Spanische Übersetzung aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1180
msgid "Added compatibility for PNG"
msgstr "Kompatibilität für PNG hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1187
msgid "New Update"
msgstr "Neues Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1190
msgid "Added image recognition to more models"
msgstr "Bilderkennung zu weiteren Modellen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1191
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""
"Brasilianische portugiesische Übersetzung hinzugefügt (Danke Daimaar Stein)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1192
msgid "Refined the general UI (Thanks Nokse22)"
msgstr "Allgemeine Benutzeroberfläche verfeinert (Danke Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1193
msgid "Added 'delete message' feature"
msgstr "Funktion 'Nachricht löschen' hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1194
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""
"Metadaten hinzugefügt, damit Softwareanbieter wissen, dass die App mit "
"Mobilgeräten kompatibel ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1195
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""
"'Senden'-Verknüpfung auf die Eingabetaste geändert (für einen Zeilenumbruch "
"Umschalttaste+Eingabetaste verwenden)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1202
msgid "Bug Fixes"
msgstr "Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1204
msgid "Fixed: Minor spelling mistake"
msgstr "Behoben: Kleiner Rechtschreibfehler"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1205
msgid "Added 'mobile' as a supported form factor"
msgstr "'Mobil' als unterstützten Formfaktor hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1206
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr "Behoben: Dialog 'Verbindungsfehler' funktioniert nicht richtig"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1207
msgid "Fixed: App might freeze randomly on startup"
msgstr "Behoben: App kann beim Start zufällig einfrieren"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1208
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr "Bezeichnung 'Chats' in der Seitenleiste in 'Alpaca' geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1215
msgid "Cool Update"
msgstr "Cooles Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1217
msgid "Better design for chat window"
msgstr "Besseres Design für das Chatfenster"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1218
msgid "Better design for chat sidebar"
msgstr "Besseres Design für die Chat-Seitenleiste"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1219
msgid "Fixed remote connections"
msgstr "Remote-Verbindungen repariert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1220
msgid "Fixed Ollama restarting in loop"
msgstr "Ollama-Neustart in Schleife behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1221
msgid "Other cool backend stuff"
msgstr "Andere coole Backend-Sachen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1230
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""
"Ollama als Teil von Alpaca hinzugefügt, Ollama wird in einer Sandbox "
"ausgeführt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1231
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""
"Option zum Verbinden mit Remote-Instanzen hinzugefügt (wie es vorher "
"funktionierte)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1232
msgid "Added option to import and export chats"
msgstr "Option zum Importieren und Exportieren von Chats hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1233
msgid "Added option to run Alpaca with Ollama in the background"
msgstr "Option hinzugefügt, Alpaca mit Ollama im Hintergrund auszuführen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1234
msgid "Added preferences dialog"
msgstr "Einstellungsdialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1235
msgid "Changed the welcome dialog"
msgstr "Begrüßungsdialog geändert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1237
#: data/com.jeffser.Alpaca.metainfo.xml.in:1254
#: data/com.jeffser.Alpaca.metainfo.xml.in:1266
#: data/com.jeffser.Alpaca.metainfo.xml.in:1285
#: data/com.jeffser.Alpaca.metainfo.xml.in:1306
#: data/com.jeffser.Alpaca.metainfo.xml.in:1322
#: data/com.jeffser.Alpaca.metainfo.xml.in:1338
#: data/com.jeffser.Alpaca.metainfo.xml.in:1352
#: data/com.jeffser.Alpaca.metainfo.xml.in:1362
#: data/com.jeffser.Alpaca.metainfo.xml.in:1380
#: data/com.jeffser.Alpaca.metainfo.xml.in:1402
msgid "Please report any errors to the issues page, thank you."
msgstr "Bitte melden Sie alle Fehler auf der Problemseite, danke."

#: data/com.jeffser.Alpaca.metainfo.xml.in:1245
msgid "Yet Another Daily Update"
msgstr "Noch ein tägliches Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1247
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""
"Bessere Benutzeroberfläche für den Dialog 'Modelle verwalten' hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1248
msgid "Added better UI for the chat sidebar"
msgstr "Bessere Benutzeroberfläche für die Chat-Seitenleiste hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1249
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""
"Modellbeschreibung durch eine Schaltfläche zum Öffnen der Ollama-Website für "
"das Modell ersetzt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1250
msgid "Added myself to the credits as the spanish translator"
msgstr "Mich selbst als spanischen Übersetzer zu den Credits hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1251
msgid "Using XDG properly to get config folder"
msgstr "XDG korrekt verwenden, um den Konfigurationsordner zu erhalten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1252
msgid "Update for translations"
msgstr "Update für Übersetzungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1264
msgid "The last update had some mistakes in the description of the update"
msgstr ""
"Das letzte Update enthielt einige Fehler in der Beschreibung des Updates"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1274
msgid "Another Daily Update"
msgstr "Ein weiteres tägliches Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1276
msgid "Added full Spanish translation"
msgstr "Vollständige spanische Übersetzung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1277
msgid "Added support for background pulling of multiple models"
msgstr ""
"Unterstützung für das Abrufen mehrerer Modelle im Hintergrund hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1278
msgid "Added interrupt button"
msgstr "Schaltfläche zum Unterbrechen hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1279
msgid "Added basic shortcuts"
msgstr "Grundlegende Tastenkürzel hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1280
msgid "Better translation support"
msgstr "Bessere Unterstützung für Übersetzungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1281
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""
"Benutzer können jetzt den Chatnamen beim Erstellen eines neuen Chats leer "
"lassen, es wird ein Platzhalter-Name hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1282
msgid "Better scalling for different window sizes"
msgstr "Bessere Skalierung für verschiedene Fenstergrößen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1283
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""
"Behoben: App kann nicht geschlossen werden, wenn die Ersteinrichtung "
"fehlschlägt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1293
msgid "Really Big Update"
msgstr "Wirklich großes Update"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1295
msgid "Added multiple chats support!"
msgstr "Unterstützung für mehrere Chats hinzugefügt!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1296
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""
"Unterstützung für Pango Markup hinzugefügt (fett, Liste, Titel, Untertitel, "
"Monospace)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1297
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""
"Automatisches Scrollen hinzugefügt, wenn der Benutzer am unteren Rand des "
"Chats ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1298
msgid "Added support for multiple tags on a single model"
msgstr "Unterstützung für mehrere Tags bei einem einzelnen Modell hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1299
msgid "Added better model management dialog"
msgstr "Besseren Dialog zur Modellverwaltung hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1300
msgid "Added loading spinner when sending message"
msgstr "Ladespinner beim Senden einer Nachricht hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1301
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""
"Benachrichtigungen hinzugefügt, wenn die App nicht aktiv ist und ein Modell-"
"Pull abgeschlossen ist"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1302
msgid "Added new symbolic icon"
msgstr "Neues symbolisches Icon hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1303
msgid "Added frame to message textview widget"
msgstr "Rahmen zum Nachrichten-Textansichts-Widget hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1304
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr "Behoben: \"Code-Blöcke sollten nicht editierbar sein\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1316
msgid "Added code highlighting"
msgstr "Code-Highlighting hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1317
msgid "Added image recognition (llava model)"
msgstr "Bilderkennung hinzugefügt (LLaVA-Modell)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1318
msgid "Added multiline prompt"
msgstr "Mehrzeilige Eingabe hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1319
msgid "Fixed some small bugs"
msgstr "Einige kleine Fehler behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1320
msgid "General optimization"
msgstr "Allgemeine Optimierung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1330
msgid "Fixes and features"
msgstr "Fehlerbehebungen und Funktionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1332
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr "Russische Übersetzung (Danke github/alexkdeveloper)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1333
msgid "Fixed: Cannot close app on first setup"
msgstr "Behoben: App kann bei der Ersteinrichtung nicht geschlossen werden"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1334
msgid "Fixed: Brand colors for Flathub"
msgstr "Behoben: Markenfarben für Flathub"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1335
msgid "Fixed: App description"
msgstr "Behoben: App-Beschreibung"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1336
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""
"Behoben: Dialog 'Änderungen speichern' nur anzeigen, wenn die URL "
"tatsächlich geändert wurde"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1346
msgid "0.2.2 Bug fixes"
msgstr "0.2.2 Fehlerbehebungen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1348
msgid "Toast messages appearing behind dialogs"
msgstr "Toast-Nachrichten erscheinen hinter Dialogen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1349
msgid "Local model list not updating when changing servers"
msgstr "Lokale Modellliste wird beim Wechseln der Server nicht aktualisiert"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1350
msgid "Closing the setup dialog closes the whole app"
msgstr "Das Schließen des Einrichtungsdialogs schließt die gesamte App"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1360
msgid "0.2.1 Data saving fix"
msgstr "0.2.1 Korrektur beim Speichern von Daten"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1361
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""
"Die App hat die Konfigurationsdateien und den Chatverlauf nicht im richtigen "
"Verzeichnis gespeichert, dies ist jetzt behoben"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1370
msgid "0.2.0"
msgstr "0.2.0"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1372
msgid "New Features"
msgstr "Neue Funktionen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1374
msgid "Restore chat after closing the app"
msgstr "Chat nach dem Schließen der App wiederherstellen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1375
msgid "A button to clear the chat"
msgstr "Eine Schaltfläche zum Leeren des Chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1376
msgid "Fixed multiple bugs involving how messages are shown"
msgstr "Mehrere Fehler behoben, die die Darstellung von Nachrichten betreffen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1377
msgid "Added welcome dialog"
msgstr "Begrüßungsdialog hinzugefügt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1378
msgid "More stability"
msgstr "Mehr Stabilität"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1388
msgid "0.1.2 Quick fixes"
msgstr "0.1.2 Schnelle Korrekturen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1389
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""
"Diese Version behebt einige Metadaten, die für eine ordnungsgemäße Flatpak-"
"Anwendung erforderlich sind"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1395
msgid "0.1.1 Stable Release"
msgstr "0.1.1 Stabiles Release"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1396
msgid "This is the first public version of Alpaca"
msgstr "Dies ist die erste öffentliche Version von Alpaca"

#: src/alpaca_search_provider.py.in:41
msgid "Open chat"
msgstr "Chat öffnen"

#: src/alpaca_search_provider.py.in:42
msgid "Quick ask"
msgstr "Flinke Frage"

#: src/live_chat.py:60 src/live_chat.py:152 src/quick_ask.py:76
msgid "Please select an instance in Alpaca before chatting"
msgstr "Bitte wählen Sie eine Instanz aus, bevor sie Chatten"

#: src/live_chat.py:156 src/quick_ask.py:80
msgid "Please select add a model for this instance in Alpaca before chatting"
msgstr ""
"Bitte wählen Sie \"Modell hinzufügen\" für diese Instanz in Alpaca aus, "
"bevor Sie chatten"

#: src/live_chat.py:159
msgid "Selected model is not available"
msgstr "Ausgewähltes Modell ist nicht verfügbar"

#: src/live_chat.py:227
msgid "No Messages"
msgstr "Keine Nachrichten"

#: src/live_chat.py:228
msgid "Begin by speaking to the model"
msgstr "Beginnen Sie, indem Sie mit dem Modell sprechen"

#: src/main.py:223
msgid "Documentation"
msgstr "Dokumentation"

#: src/main.py:224
msgid "Become a Sponsor"
msgstr "Sponsor werden"

#: src/main.py:225
msgid "Discussions"
msgstr "Diskussionen"

#: src/ollama_models.py:33
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"70B-Modell auf dem neuesten Stand der Technik. Llama 3.3 70B liefert einemit "
"Llama 3.1 405B vergleichbare Leistung."

#: src/ollama_models.py:55
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ ist das Reasoning-Modell aus der Qwen-Serie."

#: src/ollama_models.py:83
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision ist eine Sammlung von besonders auf Anweisungen "
"abgestimmten, logisch denkenden generativen Modellen in Größen von11B und "
"90B Parametern."

#: src/ollama_models.py:119
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Metas Llama 3.2 wird kleiner mit 1B- und 3B-Modellen."

#: src/ollama_models.py:154
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 ist ein neues State-of-the-Art-Modell von Meta, das in den Größen "
"8B, 70B und 405B Parameter verfügbar ist."

#: src/ollama_models.py:181
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: Das derzeit leistungsfähigste offen verfügbare LLM"

#: src/ollama_models.py:204
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr ""
"Das von Mistral AI veröffentlichte 7B-Modell, aktualisiert auf Version 0.3."

#: src/ollama_models.py:228
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Ein leistungsstarkes offenes Einbettungsmodell mit einem großen Token-"
"Kontextfenster."

#: src/ollama_models.py:257
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma ist eine Familie leichtgewichtiger, hochmoderner offener Modelle, die "
"von Google DeepMind entwickelt wurden. Aktualisiert auf Version 1.1"

#: src/ollama_models.py:313
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 ist eine Reihe großer Sprachmodelle von Alibaba Cloud, die von 0,5 "
"Mrd. bis 110 Mrd. Parameter reichen"

#: src/ollama_models.py:377
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 ist eine neue Serie großer Sprachmodelle der Alibaba Group"

#: src/ollama_models.py:406
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 ist eine Familie leichtgewichtiger 3B (Mini) und 14B (Medium) State-of-"
"the-Art Open-Source-Modelle von Microsoft."

#: src/ollama_models.py:438
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 ist eine Sammlung von Grundlagensprachmodellen mit 7B bis 70B "
"Parametern."

#: src/ollama_models.py:500
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Die Qwen2.5-Modelle sind auf Alibabas neuesten groß angelegten Datensatz mit "
"bis zu 18 Billionen Tokens vortrainiert. Das Modell unterstützt bis zu 128K "
"Tokens und bietet mehrsprachige Unterstützung."

#: src/ollama_models.py:532
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 ist ein leistungsstarkes und effizientes Modell, das in drei "
"Größen verfügbar ist: 2B, 9B und 27B."

#: src/ollama_models.py:566
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA ist ein neuartiges End-to-End-trainiertes großes multimodales "
"Modell, das einen Vision-Encoder und Vicuna für das allgemeine Verständnis "
"von Bildern und Sprache kombiniert. Aktualisiert auf Version 1.6."

#: src/ollama_models.py:603
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Ein großes Sprachmodell, das Textaufforderungen verwenden kann, um Code zu "
"generieren und zu diskutieren."

#: src/ollama_models.py:649
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"Die neueste Serie von code-spezifischen Qwen-Modellen mit erheblichen "
"Verbesserungen in der Code-Generierung, dem Code-Verständnis und der Code-"
"Korrektur."

#: src/ollama_models.py:673
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Ein State-of-the-Art 12B-Modell mit 128k Kontextlänge, entwickelt von "
"Mistral AI in Zusammenarbeit mit NVIDIA."

#: src/ollama_models.py:695
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"Das TinyLlama-Projekt ist ein offenes Unterfangen, um ein kompaktes 1,1-"
"Milliarden-Llama-Modell mit 3 Billionen Token zu trainieren."

#: src/ollama_models.py:718
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "State-of-the-Art großes Einbettungsmodell von mixedbread.ai"

#: src/ollama_models.py:751
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 ist die nächste Generation transparent trainierter offener Code-"
"LLMs, die in drei Größen erhältlich ist: 3B, 7B und 15B Parameter."

#: src/ollama_models.py:777
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Eine Reihe von Mixture-of-Experts (MoE)-Modellen mit offenen Gewichten von "
"Mistral AI in den Parametergrößen 8x7b und 8x22b."

#: src/ollama_models.py:803
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Unzensierte, 8x7b und 8x22b feinabgestimmte Modelle basierend auf den "
"Mixtral-Mixture-of-Experts-Modellen, die sich bei Codierungsaufgaben "
"auszeichnen. Erstellt von Eric Hartford."

#: src/ollama_models.py:832
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma ist eine Sammlung leistungsstarker, leichtgewichtiger Modelle, die "
"eine Vielzahl von Codieraufgaben ausführen können, wie z. B. Fill-in-the-"
"Middle-Code-Vervollständigung, Code-Generierung, Verständnis natürlicher "
"Sprache, mathematisches Schlussfolgern und Anweisungsbefolgung."

#: src/ollama_models.py:860
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Ein Open-Source-Mixture-of-Experts-Codesprachmodell, das bei "
"codespezifischen Aufgaben eine Leistung vergleichbar mit GPT4-Turbo erreicht."

#: src/ollama_models.py:882
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: ein 2,7-Milliarden-Sprachmodell von Microsoft Research, das "
"herausragende Fähigkeiten beim Schlussfolgern und Sprachverständnis "
"demonstriert."

#: src/ollama_models.py:909
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Unzensiertes Llama 2-Modell von George Sung und Jarrad Hope."

#: src/ollama_models.py:944
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder ist ein leistungsfähiges Codiermodell, das mit zwei Billionen "
"Code- und natürlichen Sprach-Token trainiert wurde."

#: src/ollama_models.py:985
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Eine Sammlung von Text-Embedding-Modellen von Snowflake, optimiert für die "
"Leistung."

#: src/ollama_models.py:1013
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"State-of-the-Art-Großsprachenmodell von Microsoft AI mit verbesserter "
"Leistung bei komplexen Chat-, mehrsprachigen, Reasoning- und Agenten-"
"Anwendungsfällen."

#: src/ollama_models.py:1036
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"Das unzensierte Dolphin-Modell basierend auf Mistral, das sich bei "
"Codierungsaufgaben auszeichnet. Aktualisiert auf Version 2.8."

#: src/ollama_models.py:1064
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 ist ein neues Modell mit 8B und 70B Größen von Eric Hartford "
"basierend auf Llama 3, das eine Vielzahl von Anweisungs-, Konversations- und "
"Codierungsfähigkeiten besitzt."

#: src/ollama_models.py:1098
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 ist ein leistungsstarkes zweisprachiges Sprachmodell."

#: src/ollama_models.py:1121
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R ist ein großes Sprachmodell, das für die Konversationsinteraktion "
"und Aufgaben mit langem Kontext optimiert ist."

#: src/ollama_models.py:1158
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Ein universelles Modell mit 3 Milliarden bis 70 Milliarden Parametern, "
"geeignet für Einstiegshardware."

#: src/ollama_models.py:1181
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Ein LLaVA-Modell, das von Llama 3 Instruct mit besseren Ergebnissen in "
"mehreren Benchmarks feinabgestimmt wurde."

#: src/ollama_models.py:1208
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr ist eine Reihe von feinabgestimmten Versionen der Mistral- und "
"Mixtral-Modelle, die darauf trainiert sind, als hilfreiche Assistenten zu "
"fungieren."

#: src/ollama_models.py:1230
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Ein leichtgewichtiges KI-Modell mit 3,8 Milliarden Parametern, dessen "
"Leistung vergleichbare und größere Modelle übertrifft."

#: src/ollama_models.py:1258
msgid "Embedding models on very large sentence level datasets."
msgstr "Einbettungsmodelle auf sehr großen Datensätzen auf Satzebene."

#: src/ollama_models.py:1281
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral ist Mistral AIs initiales Code-Modell welches auf Code-"
"Generierungsaufgaben getrimmt ist"

#: src/ollama_models.py:1318
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder ist ein Codegenerierungsmodell, das auf über 80 "
"Programmiersprachen trainiert wurde."

#: src/ollama_models.py:1350
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Allgemeines Chat-Modell basierend auf Llama und Llama 2 mit Kontextgrößen "
"von 2K bis 16K."

#: src/ollama_models.py:1387
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "Eine Familie offener Grundlagenmodelle von IBM für Code Intelligence"

#: src/ollama_models.py:1409
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca ist ein Modell mit 7 Milliarden Parametern, das auf dem "
"Mistral 7B-Modell unter Verwendung des OpenOrca-Datensatzes feinabgestimmt "
"wurde."

#: src/ollama_models.py:1441
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 Eine Familie von kleinen Modellen mit 135M, 360M und 1.7B Parametern, "
"trainiert auf einem neuen hochwertigen Datensatz. "

#: src/ollama_models.py:1473
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored ist ein 7B-, 13B- und 30B-Parametermodell, das auf "
"Llama 2 Uncensored von Eric Hartford basiert."

#: src/ollama_models.py:1502
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Auf Llama 2 basierendes Modell, das zur Verbesserung der chinesischen "
"Dialogfähigkeit feinabgestimmt wurde."

#: src/ollama_models.py:1525
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 ist ein neues Modell von BAAI, das sich durch seine Vielseitigkeit in "
"Multi-Funktionalität, Mehrsprachigkeit und Multigranularität."

#: src/ollama_models.py:1550
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Ein vielseitiges Modell für KI-Softwareentwicklungsszenarien, einschließlich "
"Code-vervollständigung."

#: src/ollama_models.py:1573
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Eine Familie von Open-Source-Modellen, die auf einer Vielzahl von Daten "
"trainiert wurden und ChatGPT bei verschiedenen Benchmarks übertreffen. "
"Aktualisiert auf Version 3.5-0106."

#: src/ollama_models.py:1601
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, veröffentlicht von Cohere, ist eine neue Familie von State-of-the-"
"Art, mehrsprachigen Modellen, die 23 Sprachen unterstützen."

#: src/ollama_models.py:1624
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 ist ein großes Sprachmodell, das auf einer großen Menge von "
"Codedaten vortrainiert wurde."

#: src/ollama_models.py:1652
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"Die leistungsstarke Modellfamilie von Nous Research, die sich bei "
"wissenschaftlichen Diskussionen und Codierungsaufgaben. "

#: src/ollama_models.py:1674
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ ist ein leistungsstarkes, skalierbares großes Sprachmodell, das "
"speziell dafür entwickelt wurde, sich bei realen "
"Unternehmensanwendungsfällen zu bewähren."

#: src/ollama_models.py:1697
msgid "State-of-the-art code generation model"
msgstr "State-of-the-Art-Codegenerierungsmodell"

#: src/ollama_models.py:1721
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B ist ein Codierungsmodell mit Anweisungs- und "
"Codevervollständigungsvarianten, das Modellen wie Code Llama 7B, die 2,5-mal "
"größer sind, ebenbürtig ist."

#: src/ollama_models.py:1743
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Ein experimentelles 1,1-Milliarden-Parameter-Modell, das auf dem neuen "
"Dolphin-2.8-Datensatz von Eric Hartford trainiert und auf TinyLlama basiert "
"wurde."

#: src/ollama_models.py:1770
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 ist ein 7B-Modell, das von Teknium auf Mistral mit "
"vollständig offenen Datensätzen feinabgestimmt wurde."

#: src/ollama_models.py:1794
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 ist Mistrals neues Vorzeigemodell, das bei der "
"Codegenerierung, Mathematik und logischem Denken mit einem 128k-"
"Kontextfenster und Unterstützung für Dutzende von Sprachen deutlich "
"leistungsfähiger ist."

#: src/ollama_models.py:1827
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math  ist eine Reihe von spezialisierten mathematischen "
"Sprachmodellen, die auf den  Qwen2 LLMs aufbaut, die die mathematischen "
"Fähigkeiten von  Open-Source-Modellen und sogar Closed-Source-Modellen (z. "
"B. GPT4o) übertrifft."

#: src/ollama_models.py:1851
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Ein starkes mehrsprachiges allgemeines Sprachmodell mit wettbewerbsfähiger "
"Leistung gegenüber Llama 3."

#: src/ollama_models.py:1885
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 ist ein State-of-the-Art-Sprachmodell mit 1,6 Mrd. und 12 Mrd. "
"Parametern, das auf mehrsprachigen Daten in Englisch, Spanisch, Deutsch, "
"Italienisch, Französisch, Portugiesisch und Niederländisch trainiert wurde."

#: src/ollama_models.py:1908
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA ist ein multimodales Modell, das aus dem Mistral-7B-Basismodell "
"besteht, das um die LLaVA-Architektur erweitert wurde."

#: src/ollama_models.py:1929
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Ein leistungsstarkes Modell, das mit einer neuen Technik namens Reflection-"
"Tuning trainiert wurde, die einem LLM beibringt, Fehler in seinem "
"Denkprozess zu erkennen und zu korrigieren."

#: src/ollama_models.py:1960
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Ein fortschrittliches Sprachmodell, das mit 2 Billionen zweisprachigen Token "
"erstellt wurde."

#: src/ollama_models.py:1987
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Dieses Modell erweitert die Kontextlänge von LLama-3 8B von 8k auf über 1 "
"Million Token."

#: src/ollama_models.py:2020
msgid "Model focused on math and logic problems"
msgstr "Modell, das sich auf Mathematik- und Logikprobleme konzentriert"

#: src/ollama_models.py:2043
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 ist ein kleines Vision-Language-Modell, das für den effizienten "
"Betrieb auf Edge-Geräten entwickelt wurde."

#: src/ollama_models.py:2065
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Ein feinabgestimmtes Modell basierend auf Mistral mit guter Abdeckung von "
"Domäne und Sprache."

#: src/ollama_models.py:2092
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Ein Modell von NVIDIA, das auf Llama 3 basiert und sich bei "
"konversationeller Frage-beantwortung (QA) und abrufgestützter Generierung "
"(RAG) auszeichnet."

#: src/ollama_models.py:2119
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Konversationsmodell basierend auf Llama 2, das bei verschiedenen Benchmarks "
"konkurrenzfähig abschneidet."

#: src/ollama_models.py:2147
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder ist ein Codevervollständigungsmodell, das auf StarCoder für SQL-"
"Generierungsaufgaben feinabgestimmt wurde"

#: src/ollama_models.py:2174
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr ""
"Allgemeine Gebrauchsmodelle basierend auf Llama und Llama 2 von Nous "
"Research."

#: src/ollama_models.py:2197
msgid "Code generation model based on Code Llama."
msgstr "Codegenerierungsmodell basierend auf Code Llama."

#: src/ollama_models.py:2224
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr ""
"Eine Erweiterung von Llama 2, die einen Kontext von bis zu 128k Token "
"unterstützt."

#: src/ollama_models.py:2252
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Eine 7B- und 15B-unzensierte Variante der Dolphin-Modellfamilie, die sich "
"beim Codieren auszeichnet, basierend auf StarCoder2."

#: src/ollama_models.py:2279
msgid "General use model based on Llama 2."
msgstr "Allgemeines Gebrauchsmodell basierend auf Llama 2."

#: src/ollama_models.py:2308
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Ein starkes, wirtschaftliches und effizientes Mixture-of-Experts-"
"Sprachmodell."

#: src/ollama_models.py:2330
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling ist ein großes Sprachmodell, das durch Reinforcement Learning aus "
"KI-Feedback trainiert wurde, um die Nützlichkeit von Chatbots zu verbessern."

#: src/ollama_models.py:2352
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Ein Begleitassistent, der in Philosophie, Psychologie und persönlichen "
"Beziehungen geschult ist. Basierend auf Mistral."

#: src/ollama_models.py:2390
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 ist die neueste Version des Flaggschiffs der Hermes-Reihe von LLM "
"von Nous Research "

#: src/ollama_models.py:2418
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder ist eine Serie von Open-Source-Code-Sprachmodellen, die "
"Spitzenleistungen im Codieren mit weniger als 10 Milliarden Parametern "
"erbringt."

#: src/ollama_models.py:2449
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Ein vom Technology Innovation Institute (TII) entwickeltes LLM zur Nutzung "
"in Zusammenfassung, Textgenerierung und als Chatbot."

#: src/ollama_models.py:2486
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 ist ein 7B-Parametermodell, das auf praktische Szenarien mit "
"herausragender Schlussfolgerungsfähigkeit zugeschnitten ist."

#: src/ollama_models.py:2508
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Ein kompaktes, aber leistungsstarkes 10,7-Milliarden-Large-Language-Modell, "
"das für einmalige Konversation entwickelt wurde."

#: src/ollama_models.py:2532
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 ist ein 72B-Parameter-Modell welches besonders gut in "
"Codevervollständigung, Mathematik und Log-Extrahierungsaufgaben abschneidet."

#: src/ollama_models.py:2555
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr ""
"Ein neues kleines LLaVA-Modell, das von Phi 3 Mini feinabgestimmt wurde."

#: src/ollama_models.py:2583
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 wurde von Microsoft Research entwickelt und ist eine feinabgestimmte "
"Version von Metas Llama-2-Modellen. Das Modell ist speziell darauf "
"ausgelegt, sich besonders beim logischen Schlussfolgern auszuzeichnen."

#: src/ollama_models.py:2614
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Eine Serie multimodaler LLMs (MLLMs), die für das Verständnis von Vision und "
"Sprache entwickelt wurde."

#: src/ollama_models.py:2646
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Auf Llama 2 basierendes Modell, das auf einem Orca-ähnlichen Datensatz "
"feinabgestimmt wurde. Ursprünglich Free Willy genannt."

#: src/ollama_models.py:2675
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""
"Mistral Small 3 setzt neue Maße für die Kategorie an “kleinen” "
"Sprachmodellen unter 70B Parametern."

#: src/ollama_models.py:2697
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"2,7-Milliarden-unzensiertes Dolphin-Modell von Eric Hartford, basierend auf "
"dem Phi-Sprachmodell von Microsoft Research."

#: src/ollama_models.py:2730
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 ist eine Familie von kompakten Sprachmodellen - verfügbar in drei "
"Größen: 135M, 360M und 1.7B Parameter."

#: src/ollama_models.py:2752
msgid "Uncensored version of Wizard LM model"
msgstr "Unzensierte Version des Wizard-LM-Modells"

#: src/ollama_models.py:2775
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Ein kommerziell freundliches kleines Sprachmodell von NVIDIA, optimiert für "
"Rollenspiel, RAG-QA und Funktionsaufrufe."

#: src/ollama_models.py:2797
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Eine Erweiterung von Mistral zur Unterstützung von Kontextfenstern von 64K "
"oder 128K."

#: src/ollama_models.py:2825
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Eine Erweiterung von Llama 2, die sich darauf spezialisiert hat, sowohl "
"allgemeines Sprachverständnis als auch domänenspezifisches Wissen, "
"insbesondere im Bereich Programmierung und Mathematik, zu integrieren."

#: src/ollama_models.py:2847
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Feinabgestimmtes Llama-2-Modell zur Beantwortung medizinischer Fragen "
"basierend auf einem Open-Source-Medizindatensatz."

#: src/ollama_models.py:2874
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Open-Source-medizinisches Großsprachenmodell, das von Llama 2 auf den "
"medizinischen Bereich angepasst wurde."

#: src/ollama_models.py:2902
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Eine Reihe von Modellen von Groq, die einen bedeutenden Fortschritt in den "
"Open-Source-KI-Fähigkeiten für die Verwendung von Werkzeugen/"
"Funktionsaufrufen darstellen."

#: src/ollama_models.py:2924
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct ist ein LLM, welches von NVIDIA verfeinert "
"wurde, um dessen Antworten auf Nutzeranfragen hilfreicher zu machen."

#: src/ollama_models.py:2946
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven ist ein 13B-Anweisungsmodell, das für Funktionsaufrufaufgaben "
"optimiert wurde."

#: src/ollama_models.py:2967
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"Das Nous-Hermes-2-Modell von Nous Research, jetzt über Mixtral trainiert."

#: src/ollama_models.py:2990
msgid "Great code generation model based on Llama2."
msgstr "Großartiges Codegenerierungsmodell basierend auf Llama2."

#: src/ollama_models.py:3012
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Unzensiertes Llama2-basiertes Modell mit Unterstützung für ein 16K-"
"Kontextfenster."

#: src/ollama_models.py:3053
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Die IBM Granite 2B- und 8B-Modelle sind dazu entwickelt, toolbasierte "
"Anwendungsfälle und Unterstützung für abrufaugmentierte Generierung (RAG), "
"vereinfachte Codegenerierung, Übersetzung und das Beheben von Bugs zu "
"unterstützen."

#: src/ollama_models.py:3076
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder ist eine Familie von 7B-Parametermodellen, die mit 75K "
"synthetischen Anweisungsdaten unter Verwendung von OSS-Instruct trainiert "
"wurden, einem neuartigen Ansatz zur Aufklärung von LLMs mit Open-Source-"
"Codeschnipseln."

#: src/ollama_models.py:3098
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Ein leichtgewichtiges Chatmodell, das eine genaue und reaktionsschnelle "
"Ausgabe ermöglicht, ohne High-End-Hardware zu benötigen."

#: src/ollama_models.py:3121
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Ein leistungsstarkes Code-Anweisungsmodell, das durch Zusammenführen von "
"zwei bestehenden Code-Modellen erstellt wurde."

#: src/ollama_models.py:3144
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 ist ein kausales Decoder-only-Modell mit 11B Parametern, das von TII "
"entwickelt und über 5T Token trainiert wurde."

#: src/ollama_models.py:3166
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna ist ein 13B-Parametermodell basierend auf Llama 2, das von "
"MelodysDreamj trainiert wurde."

#: src/ollama_models.py:3188
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite ist ein feinabgestimmtes Modell basierend auf Mistral mit "
"verbesserten Fähigkeiten zur Verarbeitung langer Kontexte."

#: src/ollama_models.py:3211
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: ein 7B-Modell, das von Mistral AI für mathematisches "
"Schlussfolgern und wissenschaftliche Entdeckungen entwickelt wurde."

#: src/ollama_models.py:3233
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr "7B-Parameter-Text-zu-SQL-Modell von MotherDuck und Numbers Station."

#: src/ollama_models.py:3254
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b ist eine Transformation von Dolphin-2.2-70b, die durch "
"Verschachtelung des Modells mit sich selbst erstellt wurde."

#: src/ollama_models.py:3276
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro Preview: ein fortschrittliches großes Sprachmodell (LLM) mit 22 "
"Milliarden Parametern, das für den Einsatz auf einer einzelnen GPU ausgelegt "
"ist."

#: src/ollama_models.py:3303
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Eine Modellreihe, die HTML-Inhalte in Markdown-Inhalte umwandelt, was für "
"Aufgaben der Inhaltskonvertierung nützlich ist."

#: src/ollama_models.py:3324
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Ein leistungsstarkes Mixture-of-Experts-Modell, feinabgestimmt mit "
"hochwertigen Daten."

#: src/ollama_models.py:3346
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Ein 7B-Chatmodell, feinabgestimmt mit hochwertigen Daten und basierend auf "
"Zephyr."

#: src/ollama_models.py:3369
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Zusammenführung des Open-Orca-OpenChat-Modells und des Garage-bAInd-"
"Platypus-2-Modells. Entwickelt für Chat und Codegenerierung."

#: src/ollama_models.py:3386
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Ein Sprachmodell, das durch Kombination von zwei feinabgestimmten "
"Llama-2-70B-Modellen zu einem einzigen Modell erstellt wurde."

#: src/ollama_models.py:3427
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Die IBM Granite 1B- und 3B-Modelle sind die ersten Mixture of Experts (MoE)-"
"Granite-Modelle von IBM, entwickelt für Nutzung mit geringer Latenz."

#: src/ollama_models.py:3449
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Ein 3,8B-Modell, das auf einem privaten synthetischen Datensatz von hoher "
"Qualität für die Informationsextraktion feinabgestimmt wurde, basierend auf "
"Phi-3."

#: src/ollama_models.py:3500
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Cohere For AI's LLMs, trainiert darauf, gut in 23 Sprachen abzuschneiden."

#: src/ollama_models.py:3522
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr ""
"DBRX ist ein offenes, allgemeines LLM, das von Databricks erstellt wurde."

#: src/ollama_models.py:3544
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Ein offenes, großes Reasoning-Modell für Lösungen in der echten Welt von der "
"Alibaba International Digital Commerce Group (AIDC-AI)."

#: src/ollama_models.py:3567
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Einbettungsmodell von BAAI, das Texte auf Vektoren abbildet."

#: src/ollama_models.py:3589
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Ein offenes Funktionsaufrufmodell basierend auf Llama 3, das mit den "
"Funktionsaufruffähigkeiten von GPT-4o konkurrenzfähig ist."

#: src/ollama_models.py:3610
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Ein robustes Konversationsmodell, das sowohl für Chat- als auch für "
"Anweisungs-anwendungsfälle entwickelt wurde."

#: src/ollama_models.py:3632
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Eine verbesserte Version von DeepSeek-V2, welche die generischen sowie "
"Coding-Fähigkeiten von sowohl DeepSeek-V2-Chat als auch DeepSeek-Coder-V2-"
"Instruct vereint."

#: src/ollama_models.py:3665
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma ist eine Sammlung von Anweisungs-getuneten Modellen zur "
"Auswertung von der Sicherheit der Prompteingaben sowie -ausgaben aufgrund "
"einer Sammlung an definierten Sicherheitsregeln."

#: src/ollama_models.py:3687
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr "Ein hochmodernes Faktenprüfungsmodell, entwickelt von Bespoke Labs."

#: src/ollama_models.py:3715
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 ist eine Serie an Modellen, die auf Inhaltsicherheits-"
"Klassifizierung von LLM-Eingaben und -Ausgaben feinabgestimmt wurden."

#: src/ollama_models.py:3739
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Satztransformationsmodell, das für Aufgaben wie Clustering oder semantische "
"Suche verwendet werden kann."

#: src/ollama_models.py:3769
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder ist eine offene, reproduzierbare LLM-Familie, welche 1.5B und 8B-"
"Modelle beinhaltet und Konversationen in Englisch und Chinesisch unterstützt."

#: src/ollama_models.py:3798
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 ist eine Familie an führenden, Anweisungen folgenden Modellen mit "
"quelloffenen Daten, Code und Reproduktionsanweisungen vom The Allen "
"Institute for AI."

#: src/ollama_models.py:3826
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Snowflake's erstklassiges Einbettungsmodell. Arctic Embed 2.0 fügt "
"multilinguale Unterstützung hinzu, ohne die Leistung oder Skalierbarkeit in "
"Englisch zu beeinflussen."

#: src/ollama_models.py:3854
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Die IBM Granite Guardian 3.0 2B- und 8B-Modelle wurden entwickelt, um "
"Risiken in Ein- und Ausgaben zu erkennen."

#: src/ollama_models.py:3888
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 ist ein Sammlung an Anweisungs-feinabgestimmten, bilingualen "
"(Englisch und Koreanisch), generativen Modellen zwischen 2.4B und 32B "
"Parametern, entwickelt und veröffentlicht von LG AI Research."

#: src/ollama_models.py:3936
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 sind multilinguale Sprachmodelle für Südostasien. Verfügbar in 1B-, "
"8B- und 20B-Parametergrößen."

#: src/ollama_models.py:3974
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Eine Familie an effizienten KI-Modellen unter 10B Parametern, die "
"leistungsfähig in Wissenschaft, Mathematik und Programmierung durch "
"innovative Trainingstechniken sind."

#: src/ollama_models.py:4015
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"Die IBM Granite 2B- und 8B-Modelle sind ausschließlich textbasierte, dichte "
"LLMs, welche auf über 12 Billionen Tokens an Daten trainiert wurden und "
"umfangreiche Fortschritte gegenüber deren Vorgängern in Gebieten wie "
"Geschwindigkeit in IBM's initialien Tests zeigen."

#: src/ollama_models.py:4056
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Die IBM Granite 1B- und 3B-Modelle sind Mixture of Experts (MoE)-Modelle für "
"langen Kontext von IBM für die Nutzung mit geringer Latenz."

#: src/ollama_models.py:4097
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"Die IBM Granite Embedding 30M- und 278M-Modelle sind ausschließlich "
"textbasierte, dichte biencoder-embedding-Modelle mit 30M auf "
"Englischdedizierte und 278M auf multilinguale Zwecke dedizierte Parameter."

#: src/ollama_models.py:4119
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4 ist ein 14B-Parameter, modernes und offenes Modell von Microsoft."

#: src/ollama_models.py:4141
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Ein neues, kleines Reasoning-Modell, feinabgestimmt von dem Qwen 2.5 3B-"
"Instruct-Modell"

#: src/ollama_models.py:4165
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 ist die nächste Generation der Dolphin-Serie "
"vonAnweisungs-feinabgestimmten Modellen, die darauf ausgelegt sind, die "
"ultimativen, allgemeinen, lokalen Modelle für Coding, Mathematik, "
"Funktionsaufrufe und generelle Nutzung zu sein."

#: src/ollama_models.py:4215
msgid ""
"DeepSeek-R1 is a family of open reasoning models with performance "
"approaching that of leading models, such as O3 and Gemini 2.5 Pro."
msgstr ""
"DeepSeek-R1 ist eine Familie offener Reasoning-Modelle, deren Leistung sich "
"der von führenden Modellen wie o3 und Gemini 2.5 Pro annähert."

#: src/ollama_models.py:4236
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Ein starkes Mixture of Experts (MoE)-Sprachmodell mit 671B Parametern "
"insgesamt und 37B Parametern, die für jeden Token aktiviert werden."

#: src/ollama_models.py:4263
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 ist eine neue Familie von 7B- und 13B-Modellen, trainiert auf bis zu "
"5 Billionen Token. Diese Modelle haben eine ähnliche oder sogar bessere "
"Leistung als ähnliche, vollständig offene Modelle und sind mit anderen open-"
"weight-Modellen wie Llama 3.1 in englischen, akademischen Benchmarks "
"kompetetiv."

#: src/ollama_models.py:4311
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"Das kleinste Modell in Cohere's R-Serie liefert höchste Geschwindigkeit, "
"Effizienz und Qualität, um starke KI-Anwendungen auf handelsüblichen GPUs "
"und Edge-Geräten auszuführen."

#: src/ollama_models.py:4338
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"Eine vollständig quelloffenene Familie an Reasoning-Modellen, erstellt "
"mithilfe von Datensätzen, die von DeepSeek-R1 abgeleitet wurden."

#: src/ollama_models.py:4361
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"Eine feinabgestimmte Version von Deepseek-R1-Distilled-Qwen-1.5B, die die "
"Leistung von OpenAI's o1-preview mit nur 1.5B Parametern auf häufigen "
"Mathematikgleichungen übertrifft."

#: src/ollama_models.py:4390
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"Eine version vom DeepSeek-R1-Modell, welche durch Perplexity nachtrainiert "
"wurde, um unvoreingenommene, akkruate und faktenbasierte "
"Informationswiedergabe zu ermöglichen."

#: src/ollama_models.py:4427
msgid "The current, most capable model that runs on a single GPU."
msgstr "Das neue, leistungsstärkste Modell, das auf einer einzigen GPU läuft."

#: src/ollama_models.py:4474
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini bringt ausschlaggebende Verbesserungen in den multilingualen, "
"Reasoning- und mathematischen Fähigkeiten und unterstützt nun die "
"langerwarteten Funktionsaufruf-Fähigkeiten."

#: src/ollama_models.py:4498
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"Ein kompaktes und effizienties Vision-Sprachmodell, das besonders für das "
"visuelle Verstehen von Dokumenten, automatischer Extraktion von Inhalten aus "
"Tabellen, Diagrammen, Infografiken und mehr trainiert wurde."

#: src/ollama_models.py:4538
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 ist eine Familie von KI-Modellen mit langem Kontextfenster von "
"IBM, das für das Denken feinabgestimmt wurde."

#: src/ollama_models.py:4562
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"Eine hochmoderne Version des leichtgewichtigen Command R7B-Modells, das mit "
"seiner erweiterten arabischen Sprachfähigkeit für Unternehmen im mittleren "
"Osten und Nordafrika beeindruckt."

#: src/ollama_models.py:4608
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""
"111-Milliaren-Parameter-Modell optimiert für aufwändige Unternehmen, die "
"schnelle, sichere und hochqualitative KI benötigen."

#: src/ollama_models.py:4649
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""
"Qwen 3 ist die neueste Generation an großen Sprachmodellen der Qwen-Serie, "
"welche mit einer umfassenden Sammlung an Dense- und Mixture-of-Experts-"
"Modellen kommt."

#: src/ollama_models.py:4795
msgid "Devstral: the best open source model for coding agents"
msgstr "Devstral: das beste Open-Source-Modell für Coding-Agents."

#: src/ollama_models.py:4823
msgid "Meta's latest collection of multimodal models."
msgstr "Meta's neueste Sammlung an multimodalen Modellen."

#: src/ollama_models.py:4871
msgid ""
"Flagship vision-language model of Qwen and also a significant leap from the "
"previous Qwen2-VL."
msgstr ""
"Flaggschiff-Vision-Language-Modell von Qwen und ein deutlicher Sprung "
"gegenüber dem vorherigen Qwen2-VL."

#: src/ollama_models.py:4901
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"DeepCoder ist ein vollständig quelloffenes 14B-Coder-Modell auf dem Level "
"von o3-mini - eine 1.5B-Version ist ebenfalls erhältlich."

#: src/ollama_models.py:4925
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"Auf Mistral Small 3 aufbauend fügt Mistral Small 3.1 (2503) modernstes, "
"visuelles Verstehen und Fähigkeiten, mit längerem Kontext von bis zu 128.000 "
"Tokens umzugehen, ohne Kompromisse bei der Text-Leistungsfähigkeit "
"einzugehen, hinzu."

#: src/ollama_models.py:4965
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"Cogito v1 Preview ist eine Familie an hybriden Reasoning-Modellen von Deep "
"Cogito, die die besten verfügbaren, offenen Modelle derselben Größe "
"übertreffen - dazu gehören Gegenstücke von Llama, Deepseek und Qwen über die "
"Standard-Benchmarks hinweg."

#: src/ollama_models.py:4994
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""
"IBM Granite 2B und 8B sind Modelle mit 128K-Kontext-Länge, die auf das "
"Nachdenken und Befolgen von Anweisungen feinabgestimmt wurden."

#: src/ollama_models.py:5032
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""
"Phi 4 Reasoning und Reasoning Plus sind 14B-Parameter-Reasoning-Modelle mit "
"offenen Gewichten, die deutlich größeren Modelle bei komplexen Denkaufgaben "
"konkurrieren."

#: src/ollama_models.py:5064
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"EXAONE Deep zeigt überlegene Fähigkeiten in verschiedensten Denkaufgaben, "
"darunter Mathematik- und Coding-Benchmarks, mit Größen von 2.4 bis 32 "
"Milliaren Parametern - entwickelt und herausgegeben von LG AI Research."

#: src/ollama_models.py:5090
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""
"Phi 4 Mini Reasoning ist ein leichtgewichtiges Modell, das Effizienz mit "
"fortschrittlicher Denkfähigkeit balanciert."

#: src/ollama_models.py:5117
msgid ""
"Gemma 3n models are designed for efficient execution on everyday devices "
"such as laptops, tablets or phones."
msgstr ""
"Gemma 3n-Modelle sind für eine effiziente Ausführung auf Alltagsgeräten wie "
"Laptops, Tablets oder Smartphones konzipiert."

#: src/ollama_models.py:5140
msgid "Magistral is a small, efficient reasoning model with 24B parameters."
msgstr ""
"Magistral ist ein kleines, effizientes Reasoning-Modell mit 24 Milliarden "
"Parametern."

#: src/ollama_models.py:5187
msgid ""
"An update to Mistral Small that improves on function calling, instruction "
"following, and less repetition errors."
msgstr ""
"Ein Update für Mistral Small, das Funktionsaufrufe, Befolgung von "
"Anweisungen und weniger Wiederholungsfehler verbessert."

#: src/ollama_models.py:5215
msgid ""
"OpenAI’s open-weight models designed for powerful reasoning, agentic tasks, "
"and versatile developer use cases."
msgstr ""

#: src/ollama_models.py:5238
msgid "Alibaba's performant long context models for agentic and coding tasks."
msgstr ""

#: src/quick_ask.py:138 src/gtk/quick_ask.ui:11
msgid "Quick Ask"
msgstr "Flinke Frage"

#: src/sql_manager.py:33
#, python-brace-format
msgid "{} seconds"
msgstr ""

#: src/sql_manager.py:37
msgid "Total Duration"
msgstr ""

#: src/sql_manager.py:38
msgid "Load Duration"
msgstr ""

#: src/sql_manager.py:41
msgid "Prompt Eval Count"
msgstr ""

#: src/sql_manager.py:41 src/sql_manager.py:46
#, python-brace-format
msgid "{} tokens"
msgstr ""

#: src/sql_manager.py:42
msgid "Prompt Eval Duration"
msgstr ""

#: src/sql_manager.py:44
msgid "Prompt Eval Rate"
msgstr ""

#: src/sql_manager.py:44 src/sql_manager.py:49
#, python-brace-format
msgid "{} tokens/s"
msgstr ""

#: src/sql_manager.py:46
msgid "Eval Count"
msgstr ""

#: src/sql_manager.py:47
msgid "Eval Duration"
msgstr ""

#: src/sql_manager.py:49
msgid "Eval Rate"
msgstr ""

#: src/sql_manager.py:50
msgid "Metric"
msgstr ""

#: src/sql_manager.py:50 src/widgets/instances/ollama_instances.py:133
#: src/widgets/instances/openai_instances.py:169
msgid "Value"
msgstr ""

#: src/window.py:92
msgid "Ollama Was Not Found"
msgstr "Ollama wurde nicht gefunden"

#: src/window.py:93
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""
"Um eine von Alpaca verwaltete, integrierte Ollama-Instanz zu nutzen, musst "
"du Ollama auf deinem Gerät installiert haben. Das ist aber ganz einfach und "
"sollte nicht länger als 5 Minuten dauern!"

#: src/window.py:95
msgid "Open Tutorial in Web Browser"
msgstr "Anleitung im Browser öffnen"

#: src/window.py:113 src/gtk/window.ui:309 src/gtk/window.ui:319
#: src/gtk/window.ui:341
msgid "Add Instance"
msgstr "Instanz hinzufügen"

#: src/window.py:114
msgid "Select a type of instance to add"
msgstr "Auswählen, welcher Typ von Instanz hinzugefügt werden soll"

#: src/window.py:168 src/window.py:524 src/widgets/dialog.py:197
#: src/widgets/dialog.py:210 src/widgets/dialog.py:223 src/widgets/voice.py:305
#: src/widgets/voice.py:308 src/widgets/models/added.py:410
#: src/widgets/models/creator.py:158 src/widgets/models/creator.py:159
#: src/widgets/instances/__init__.py:357 src/widgets/instances/__init__.py:358
#: src/widgets/blocks/code.py:136 src/widgets/blocks/text.py:151
#: src/widgets/tools/tools.py:115 src/widgets/tools/tools.py:116
#: src/widgets/tools/tools.py:911
msgid "Cancel"
msgstr "Abbrechen"

#: src/window.py:169
msgid "Hide"
msgstr "Verbergen"

#: src/window.py:170 src/gtk/window.ui:255 src/widgets/camera.py:118
msgid "Close"
msgstr "Schließen"

#: src/window.py:173
msgid "Close Alpaca?"
msgstr "Alpaca schließen?"

#: src/window.py:174
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr ""
"Eine Aufgabe wird derzeit bearbeitet. Sind Sie sicher, dass Sie Alpaca "
"schließen möchten?"

#: src/window.py:277
msgid "No tools enabled."
msgstr "Keine Werkzeuge aktiviert"

#: src/window.py:277
msgid "Open Tool Manager"
msgstr "Werkzeug-Manager öffnen"

#: src/window.py:280
msgid "Please select a model before chatting"
msgstr "Bitte wählen Sie ein Modell aus, bevor Sie chatten"

#: src/window.py:420 src/gtk/window.ui:51 src/gtk/window.ui:640
#: src/widgets/chat.py:231 src/widgets/instances/ollama_instances.py:38
#: src/widgets/instances/ollama_instances.py:55
#: src/widgets/instances/ollama_instances.py:94
#: src/widgets/instances/openai_instances.py:72
#: src/widgets/instances/openai_instances.py:90
#: src/widgets/instances/openai_instances.py:139
msgid "New Chat"
msgstr "Neuer Chat"

#: src/window.py:503
msgid "Chat imported successfully"
msgstr "Chatverlauf erfolgreich importiert"

#: src/window.py:526
msgid "Can't Run Live Chat"
msgstr "Kann den Live-Chat nicht ausführen"

#: src/window.py:527
msgid "You are missing TTS libraries"
msgstr "Ihnen fehlen Text-zu-Sprache-Bibliotheken"

#: src/window.py:577
msgid "Pull Model"
msgstr "Modell abrufen"

#: src/window.py:578
msgid "Please enter the model name following this template: name:tag"
msgstr "Bitte geben Sie den Modellnamen nach folgendem Schema an: name:tag"

#: src/window.py:585
msgid "Delete All Chats?"
msgstr "Alle Chats löschen?"

#: src/window.py:586
msgid "Are you sure you want to delete all chats?"
msgstr "Sind Sie sich sicher, dass Sie alle Chats löschen möchten?"

#: src/window.py:588 src/widgets/attachments.py:259
#: src/widgets/attachments.py:392 src/widgets/chat.py:523
msgid "Delete"
msgstr "Löschen"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "Allgemein"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "Tastenkürzel anzeigen"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "Einstellungen"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr "Flinke Frage"

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "Modellmanager"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "Instanz-Manager"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr "Werkzeug-Manager"

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "Seitenleiste auf-/zuklappen"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Zoom In"
msgstr ""

#: src/gtk/help-overlay.ui:62
msgctxt "shortcut window"
msgid "Zoom Out"
msgstr ""

#: src/gtk/help-overlay.ui:68
msgctxt "shortcut window"
msgid "Quit"
msgstr "Beenden"

#: src/gtk/help-overlay.ui:76
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "Chatverwaltung"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "Chat erstellen"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "Chat löschen"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "Chat leeren"

#: src/gtk/help-overlay.ui:97
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "Chat umbenennen"

#: src/gtk/help-overlay.ui:103
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr "Suchleisten ein-/ausklappen"

#: src/gtk/help-overlay.ui:111
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "Nachricht-Eingabe"

#: src/gtk/help-overlay.ui:114
msgid "Copy"
msgstr "Kopieren"

#: src/gtk/help-overlay.ui:120
msgid "Paste"
msgstr "Einfügen"

#: src/gtk/help-overlay.ui:126
msgid "Open Emoji Menu"
msgstr "Emoji-Menü öffnen"

#: src/gtk/help-overlay.ui:132
msgid "Insert new line"
msgstr "Neue Zeile einfügen"

#: src/gtk/help-overlay.ui:138
msgid "Send Message as System"
msgstr "Nachricht als System senden"

#: src/gtk/help-overlay.ui:139
msgid "System messages are taken as literal instructions by models"
msgstr ""
"Systemnachrichten werden als tatsächliche Anweisung vom Modell interpretiert."

#: src/gtk/help-overlay.ui:145 src/widgets/message.py:652
msgid "Use Tools"
msgstr "Werkzeuge verwenden"

#: src/gtk/help-overlay.ui:146
msgid "Ask model to use tools to generate a message"
msgstr "Modell anweisen, Werkzeuge zur Generierung einer Nachricht zu nutzen"

#: src/gtk/help-overlay.ui:152
msgid "Send Message as User"
msgstr "Nachricht als Nutzer senden"

#: src/gtk/window.ui:62
msgid "Menu"
msgstr "Menü"

#: src/gtk/window.ui:69
msgid "Search Chats"
msgstr "Chats durchsuchen"

#: src/gtk/window.ui:78
msgid "Chat search bar"
msgstr "Chat-Suchleiste"

#: src/gtk/window.ui:86 src/gtk/window.ui:88
msgid "Search chats"
msgstr "Chats suchen"

#: src/gtk/window.ui:124
msgid "No Chats Found"
msgstr "Keine Chats gefunden"

#: src/gtk/window.ui:125
msgid "Oh no! It looks like there are no chats found for your search."
msgstr ""
"Oh nein! Es sieht so aus, als wären für die Suche keine Chats gefunden "
"worden."

#: src/gtk/window.ui:142
msgid "Toggle Sidebar"
msgstr "Seitenleiste ein-/ausblenden"

#: src/gtk/window.ui:149
msgid "Search Messages"
msgstr "Suche Nachrichten"

#: src/gtk/window.ui:176
msgid "Add Models"
msgstr "Modelle hinzufügen"

#: src/gtk/window.ui:180 src/gtk/window.ui:196 src/gtk/window.ui:660
msgid "Manage Models"
msgstr "Modelle verwalten"

#: src/gtk/window.ui:216
msgid "Chat Menu"
msgstr "Chat-Menü"

#: src/gtk/window.ui:229
msgid "Message search bar"
msgstr "Nachrichtensuchleiste"

#: src/gtk/window.ui:238 src/gtk/window.ui:240
msgid "Search messages"
msgstr "Nachrichten durchsuchen"

#: src/gtk/window.ui:256
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""
"Warnung: Der Energiesparmodus ist aktiviert, dies verlangsamt die "
"Nachrichtenerstellung"

#: src/gtk/window.ui:290
msgid "Instance Manager"
msgstr "Instanz-Manager"

#: src/gtk/window.ui:305
msgid "No Instances Found"
msgstr "Keine Instanzen gefunden"

#: src/gtk/window.ui:306
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr ""
"Hier sieht es ein wenig leer aus. Versuchen Sie, eine Instanz hinzuzufügen, "
"um loszulegen!"

#: src/gtk/window.ui:335
msgid "Added Instances"
msgstr "Hinzugefügte Instanzen"

#: src/gtk/window.ui:336
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""
"Verwalten Sie ihre KI-Instanzen - Chats und Nachrichten sind zwischen diesen "
"geteilt, wenn Antworten generiert werden."

#: src/gtk/window.ui:372
msgid "Tool Manager"
msgstr "Werkzeug-Manager"

#: src/gtk/window.ui:383
msgid "Available Tools"
msgstr "Verfügbare Werkzeuge"

#: src/gtk/window.ui:384
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""
"Funktionen, die Sprachmodelle nutzen können, wenn eine Nachricht durch die "
"\"Werkzeuge nutzen\"-Option im Kontextmenü des Senden-Buttons verschickt "
"wird."

#: src/gtk/window.ui:395
msgid "Help us build better AI tools! Submit your ideas here."
msgstr ""
"Helfen Sie uns, bessere KI-Tools zu bauen! Geben Sie hier ihre Ideen ab."

#: src/gtk/window.ui:403
msgid "Request Form"
msgstr "Anfrageformular"

#: src/gtk/window.ui:417
msgid "Model Manager"
msgstr "Modellmanager"

#: src/gtk/window.ui:427
msgid "Search Model"
msgstr "Modell suchen"

#: src/gtk/window.ui:441
msgid "Model Manager Menu"
msgstr "Modellmanager-Menü"

#: src/gtk/window.ui:454
msgid "Model search bar"
msgstr "Modell-Suchleiste"

#: src/gtk/window.ui:466 src/gtk/window.ui:468
msgid "Search models"
msgstr "Modelle suchen"

#: src/gtk/window.ui:475
msgid "Filter Models"
msgstr "Nach Modellen filtern"

#: src/gtk/window.ui:492 src/widgets/models/available.py:111
msgid "Added"
msgstr "Hinzugefügt"

#: src/gtk/window.ui:502 src/gtk/window.ui:561 src/gtk/window.ui:613
msgid "No Models Found"
msgstr "Keine Modelle gefunden"

#: src/gtk/window.ui:503
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""
"Hier sieht es ein wenig leer aus! Versuchen Sie, ein paar Modelle "
"herunterzuladen, oder ändern Sie die ausgewählte Instanz, um loszulegen!"

#: src/gtk/window.ui:506 src/gtk/window.ui:516 src/gtk/window.ui:656
msgid "Manage Instances"
msgstr "Instanzen verwalten"

#: src/gtk/window.ui:562 src/gtk/window.ui:614
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"Es scheint, als gäbe es für's Erste keine Modelle für diese Anfrage. "
"Probieren Sie, die Suche etwas abzuändern oder entdecken Sie etwas Neues!"

#: src/gtk/window.ui:574
msgid "Available"
msgstr "Verfügbar"

#: src/gtk/window.ui:644 src/widgets/chat.py:20
msgid "New Notebook"
msgstr "Neues Notizbuch"

#: src/gtk/window.ui:652
msgid "Import Chat"
msgstr "Chat importieren"

#: src/gtk/window.ui:664
msgid "Manage Tools"
msgstr "Werkzeuge verwalten"

#: src/gtk/window.ui:670
msgid "Start Quick Ask"
msgstr "\"Flinke Frage\" starten"

#: src/gtk/window.ui:674
msgid "Start Live Chat"
msgstr "Live-Chat starten"

#: src/gtk/window.ui:678 src/gtk/live_chat.ui:56 src/gtk/live_chat.ui:127
#: src/gtk/preferences.ui:7
msgid "Preferences"
msgstr "Einstellungen"

#: src/gtk/window.ui:682
msgid "Keyboard Shortcuts"
msgstr "Tastenkombinationen"

#: src/gtk/window.ui:686
msgid "About Alpaca"
msgstr "Über Alpaca"

#: src/gtk/window.ui:694 src/widgets/chat.py:455
msgid "Rename Chat"
msgstr "Chat umbenennen"

#: src/gtk/window.ui:698 src/widgets/chat.py:460
msgid "Duplicate Chat"
msgstr "Chat duplizieren"

#: src/gtk/window.ui:702 src/widgets/chat.py:465 src/widgets/chat.py:618
msgid "Export Chat"
msgstr "Chat exportieren"

#: src/gtk/window.ui:708 src/widgets/chat.py:472
msgid "Delete Chat"
msgstr "Chat löschen"

#: src/gtk/window.ui:716 src/gtk/live_chat.ui:146
msgid "Reload Added Models"
msgstr "Neu hinzugefügte Modelle neu laden"

#: src/gtk/window.ui:720
msgid "Add Model by Name"
msgstr "Modell mittels Namen hinzufügen"

#: src/gtk/window.ui:726
msgid "Create Model from Existing"
msgstr "Modell aus Bestehendem erstellen"

#: src/gtk/window.ui:730
msgid "Create Model from GGUF File"
msgstr "Modell aus GGUF-Datei erstellen"

#: src/gtk/live_chat.ui:8
msgid "Live chat dialog"
msgstr "Live-Chat-Dialog"

#: src/gtk/live_chat.ui:13
msgid "Live Chat"
msgstr "Live-Chat"

#: src/gtk/live_chat.ui:44
msgid "Show Messages"
msgstr "Nachrichten anzeigen"

#: src/gtk/live_chat.ui:134
msgid "Use Dynamic Backgrounds"
msgstr "Dynamische Hintergründe nutzen"

#: src/gtk/live_chat.ui:135
msgid "When using a model with a profile picture"
msgstr "Wenn ein Modell mit einem Profilbild verwendet wird"

#: src/gtk/live_chat.ui:140
msgid "Turn on Microphone Automatically"
msgstr "Mikrofon automatisch einschalten"

#: src/gtk/live_chat.ui:141
msgid "When launching Live Chat and after dictation"
msgstr "Wenn der Live-Chat nach der Diktierung gestartet wird"

#: src/gtk/quick_ask.ui:8
msgid "Quick ask dialog"
msgstr "Flinke Frage-Dialog"

#: src/gtk/quick_ask.ui:21
msgid "Save Conversation to Alpaca"
msgstr "Konversation in Alpaca speichern"

#: src/gtk/notice.ui:7
msgid "Notice"
msgstr "Information"

#: src/gtk/notice.ui:27
msgid ""
"Hey Alpaca users! Get ready for a huge update packed with enhancements and "
"exciting new features designed to make your experience even better."
msgstr ""
"Hallo Alpaca-Nutzer! Freut euch auf ein umfangreiches Update mit zahlreichen "
"Verbesserungen und spannenden neuen Funktionen, die eure Nutzererfahrung "
"noch besser machen."

#: src/gtk/notice.ui:34
msgid "Introducing Live Chat"
msgstr "Neu: Live-Chat"

#: src/gtk/notice.ui:35
msgid ""
"Experience a whole new way to interact with your AI models! Live Chat lets "
"you converse as if you're on a call, with a strong focus on real-time speech "
"recognition and live message dictation. Access it easily by selecting \"Live "
"Chat\" from the primary menu."
msgstr ""
"Erleben Sie eine völlig neue Art der Interaktion mit Ihren KI-Modellen! Mit "
"Live Chat können Sie sich wie in einem Telefonat unterhalten, wobei der "
"Schwerpunkt auf Echtzeit-Spracherkennung und Live-Nachrichtendiktat liegt. "
"Sie können ganz einfach darauf zugreifen, indem Sie im Hauptmenü „Live Chat“ "
"auswählen."

#: src/gtk/notice.ui:42
msgid "Live Message Rendering"
msgstr "Live-Nachrichten-Rendering"

#: src/gtk/notice.ui:43
msgid ""
"See your conversations unfold in real-time! Messages are now rendered as "
"they're being generated, and you can even use dictation simultaneously for a "
"more fluid interaction."
msgstr ""
"Verfolgen Sie Ihre Unterhaltungen in Echtzeit! Nachrichten werden nun sofort "
"nach ihrer Eingabe angezeigt, und Sie können sogar gleichzeitig die "
"Diktierfunktion nutzen, um eine flüssigere Interaktion zu ermöglichen."

#: src/gtk/notice.ui:50
msgid "Camera Attachment"
msgstr "Kamera-Anhang"

#: src/gtk/notice.ui:51
msgid ""
"You can now take pictures directly within Alpaca and attach them to your "
"messages with the new Camera Attachment feature."
msgstr ""
"Mit der neuen Funktion „Kamera-Anhang“ können Sie jetzt direkt in Alpaca "
"Fotos aufnehmen und diese an Ihre Nachrichten anhängen."

#: src/gtk/notice.ui:58
msgid "Enhanced Web Search Tool"
msgstr "Verbessertes Web-Suchwerkzeug"

#: src/gtk/notice.ui:59
msgid ""
"Our Web Search Tool just got a major upgrade! Enjoy more accurate results "
"and powerful new options to find exactly what you're looking for."
msgstr ""
"Unser Web-Suchtool wurde gerade umfassend aktualisiert! Freuen Sie sich auf "
"genauere Ergebnisse und leistungsstarke neue Optionen, mit denen Sie genau "
"das finden, wonach Sie suchen."

#: src/gtk/notice.ui:66
msgid "Redesign"
msgstr "Neugestaltung"

#: src/gtk/notice.ui:67
msgid ""
"Alpaca has a brand new look! Enjoy a redesigned interface with updated "
"popups and sleek new dialogs for managing your AI instances and tools."
msgstr ""
"Alpaca hat einen brandneuen Look! Genießen Sie eine neu gestaltete "
"Benutzeroberfläche mit aktualisierten Popups und eleganten neuen "
"Dialogfeldern für die Verwaltung Ihrer KI-Instanzen und -Tools."

#: src/gtk/preferences.ui:11
msgid "General"
msgstr "Allgemein"

#: src/gtk/preferences.ui:16
msgid "Run Alpaca In Background"
msgstr "Alpaca im Hintergrund ausführen"

#: src/gtk/preferences.ui:21
msgid "Show Power Saver Warning"
msgstr "Zeige Energiesparmodus-Warnung"

#: src/gtk/preferences.ui:22
msgid "When running a managed Ollama instance"
msgstr "Beim Ausführen einer integrierten Ollama-Instanz"

#: src/gtk/preferences.ui:28
msgid "Zoom"
msgstr "Vergrößerung"

#: src/gtk/preferences.ui:44
msgid "Prefer to Use Tools"
msgstr "Werkzeugnutzung bevorzugen"

#: src/gtk/preferences.ui:45
msgid "Always try to use tools when sending a message"
msgstr "Immer versuchen beim versenden einer Nachricht Werkzeuge zu verwenden"

#: src/gtk/preferences.ui:50
msgid "Regenerate Response After Editing Message"
msgstr "Antwort nach dem Bearbeiten der Nachricht neu generieren"

#: src/gtk/preferences.ui:51
msgid "Applicable when the next message was generated by an AI model"
msgstr "Gilt, wenn die nächste Nachricht von einem KI-Modell generiert wurde"

#: src/gtk/preferences.ui:56
msgid "Max Image Attachment Size"
msgstr ""

#: src/gtk/preferences.ui:57
msgid "This might affect the performance of vision models"
msgstr ""

#: src/gtk/preferences.ui:76
msgid "Delete All Chats"
msgstr "Alle Chats löschen"

#: src/gtk/preferences.ui:87
msgid "Audio"
msgstr "Audio"

#: src/gtk/preferences.ui:92
msgid "Speech Recognition Model"
msgstr "Spracherkennungsmodell"

#: src/gtk/preferences.ui:93
msgid ""
"Models are downloaded upon first use, you can delete them from the model "
"manager"
msgstr ""
"Modelle werden bei der erstmaligen Nutzung heruntergeladen - \n"
"\n"
" können vom Modell-Manager aus gelöscht werden"

#: src/gtk/preferences.ui:98
msgid "Speech Recognition Language"
msgstr "Sprache für die Spracherkennung"

#: src/gtk/preferences.ui:104
msgid "Auto Send Message After Talking"
msgstr "Automatisch Nachricht nach dem Sprechen absenden"

#: src/gtk/preferences.ui:114
msgid "Default Text to Speech Voice"
msgstr "Standard-Text-zu-Sprache-Stimme"

#: src/gtk/preferences.ui:115
msgid ""
"Voices are downloaded upon first use, each weighing around 1 MB, and you can "
"delete them from the model manager"
msgstr ""
"Sprachen werden bei der erstmaligen Nutzung heruntergeladen - jede benötigt "
"ca. 1 MB - und sie können vom Modell-Manager aus gelöscht werden"

#: src/gtk/preferences.ui:120
msgid "Dictate New Messages Automatically"
msgstr "Neue Nachrichten automatisch vorsprechen"

#: src/gtk/preferences.ui:121
msgid "Dictate new messages as they are generated"
msgstr "Neue Nachrichten vorlesen, während sie erstellt werden"

#: src/gtk/welcome.ui:6
msgid "Welcome"
msgstr "Willkommen"

#: src/gtk/welcome.ui:18 src/gtk/welcome.ui:19
msgid "Previous"
msgstr "Zurück"

#: src/gtk/welcome.ui:34 src/gtk/welcome.ui:35
msgid "Next"
msgstr "Weiter"

#: src/gtk/welcome.ui:54
msgid "Welcome to Alpaca"
msgstr "Willkommen bei Alpaca"

#: src/gtk/welcome.ui:55
msgid "Powering your potential"
msgstr "Entfache dein Potenzial"

#: src/gtk/welcome.ui:63
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""
"Alpaca und dessen Entwickler:innen sind nicht für Schäden jeglicher Art und "
"Weise an Geräten oder Software, entstehend durch die Ausführung KI-"
"generierter Software, verantwortlich. Besondere Vorsicht bei der Ausführung "
"solches Codes ist oberstes Gebot und obliegt Alpacas Nutzer:innen.\n"
"Alpaca wird unter der GPL v3.0 distributiert. Diese Software kommt ohne "
"jegliche Garantie."

#: src/gtk/welcome.ui:72
msgid "Effortless Code Execution"
msgstr "Mühelose Codeausführung"

#: src/gtk/welcome.ui:73
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""
"Alpaca kann Python, C++ und sogar HTML (mit einem Live-Server) direkt von "
"ihren Konversationen aus ausführen. Probieren Sie es aus!"

#: src/gtk/welcome.ui:79
msgid "Private by Design"
msgstr "Privat durch Design"

#: src/gtk/welcome.ui:80
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""
"Mit Alpaca werden ihre Konversationen immer lokal auf ihrem Gerät "
"gespeichert, sodass Sie sich sicher sein können, dass ihre Daten immer "
"sicher und privat bleiben."

#: src/gtk/welcome.ui:86
msgid "Local AI"
msgstr "Lokale KI"

#: src/gtk/welcome.ui:87
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""
"Alpaca arbeitet mit KI-Anbietern wie Gemini oder ChatGPT. Um KI-Modelle "
"lokal auf Ihrem Gerät ausführen zu können, müssen Sie Ollama innerhalb von "
"Alpaca installieren. Das haben wir sehr einfach gemacht, sodass Sie ganz "
"schnell loslegen können!"

#: src/gtk/welcome.ui:91
msgid "Install Ollama"
msgstr "Ollama installieren"

#: src/widgets/attachments.py:105 src/widgets/attachments.py:307
#: src/widgets/attachments.py:428
msgid "Remove Attachment"
msgstr "Anhang entfernen"

#: src/widgets/attachments.py:114 src/widgets/attachments.py:299
#: src/widgets/attachments.py:423
msgid "Download Attachment"
msgstr "Anhang speichern"

#: src/widgets/attachments.py:128
msgid "Replace Notebook Content"
msgstr "Notizbuch-Inhalte ersetzen"

#: src/widgets/attachments.py:256
msgid "Delete Attachment?"
msgstr "Anhang löschen?"

#: src/widgets/attachments.py:257 src/widgets/attachments.py:390
#: src/widgets/chat.py:521
#, python-brace-format
msgid "Are you sure you want to delete '{}'?"
msgstr "Sind Sie sicher, dass Sie '{}' löschen möchten?"

#: src/widgets/attachments.py:288
msgid "Save Attachment"
msgstr "Anhang speichern"

#: src/widgets/attachments.py:338
msgid "Image"
msgstr "Bild"

#: src/widgets/attachments.py:349 src/widgets/attachments.py:361
msgid "Missing Image"
msgstr "Fehlendes Bild"

#: src/widgets/attachments.py:389
msgid "Delete Image?"
msgstr "Bild löschen?"

#: src/widgets/attachments.py:412
msgid "Save Image"
msgstr "Bild speichern"

#: src/widgets/attachments.py:565
msgid "This model might not be compatible with image recognition"
msgstr ""

#: src/widgets/attachments.py:586
msgid "Any compatible Alpaca attachment"
msgstr "Jeglicher Alpaca-kompatibler Anhang"

#: src/widgets/attachments.py:658
msgid "Attach File"
msgstr "Datei anhängen"

#: src/widgets/attachments.py:663
msgid "Attach Website"
msgstr "Website anhängen"

#: src/widgets/attachments.py:666 src/widgets/message.py:556
msgid "Attach Website? (Experimental)"
msgstr "Website anhängen? (Experimentell)"

#: src/widgets/attachments.py:667
msgid "Please enter a website URL"
msgstr "Bitte geben Sie eine Website-URL an"

#: src/widgets/attachments.py:674
msgid "Attach YouTube Captions"
msgstr "YouTube-Videountertitel anhängen"

#: src/widgets/attachments.py:677
msgid "Attach YouTube Captions?"
msgstr "YouTube-Untertitel anhängen?"

#: src/widgets/attachments.py:678
msgid "Please enter a YouTube video URL"
msgstr "Bitte geben Sie eine YouTube-Video-URL ein"

#: src/widgets/attachments.py:685
msgid "Attach Screenshot"
msgstr "Bildschirmfoto anhängen"

#: src/widgets/attachments.py:690
msgid "Attach Photo From Camera"
msgstr "Foto von Kamera anhängen"

#: src/widgets/camera.py:101
msgid "Photo"
msgstr "Foto"

#: src/widgets/camera.py:121
msgid "No Camera Detected"
msgstr "Keine Kamera erkannt"

#: src/widgets/camera.py:122
msgid "Please check if camera is plugged in and turned on"
msgstr "Bitte überprüfen Sie, ob die Kamera eingesteckt und eingeschaltet ist"

#: src/widgets/chat.py:86 src/widgets/instances/ollama_instances.py:78
#: src/widgets/instances/openai_instances.py:124
msgid "Notebook"
msgstr "Notizbuch"

#: src/widgets/chat.py:87
msgid "Start a notebook with a message"
msgstr "Neues Notizbuch mit einer Nachricht starten"

#: src/widgets/chat.py:95 src/widgets/chat.py:273
msgid "No Messages Found"
msgstr "Keine Nachrichten gefunden"

#: src/widgets/chat.py:96 src/widgets/chat.py:274
msgid "Uh oh! No messages found for your search."
msgstr "Oh nein! Für diese Suche konnten keine Nachrichten gefunden werden."

#: src/widgets/chat.py:264
msgid "Try one of these prompts"
msgstr "Teste einen dieser Prompts"

#: src/widgets/chat.py:294
#, python-brace-format
msgid "Send prompt: '{}'"
msgstr "Sende Prompt: '{}'"

#: src/widgets/chat.py:300
msgid "Refresh Prompts"
msgstr "Beispielprompts neu laden"

#: src/widgets/chat.py:498
msgid "Rename Chat?"
msgstr "Chat umbenennen?"

#: src/widgets/chat.py:499
#, python-brace-format
msgid "Renaming '{}'"
msgstr "'{}' umbenennen"

#: src/widgets/chat.py:501
msgid "Chat name"
msgstr "Chat-Name"

#: src/widgets/chat.py:502
msgid "Rename"
msgstr "Umbenennen"

#: src/widgets/chat.py:520
msgid "Delete Chat?"
msgstr "Chat löschen?"

#: src/widgets/chat.py:528
#, python-brace-format
msgid "Copy of {}"
msgstr "Kopie von {}"

#: src/widgets/chat.py:540
msgid "Chat exported successfully"
msgstr "Chatverlauf erfolgreich exportiert"

#: src/widgets/chat.py:560
msgid "User"
msgstr "Nutzer"

#: src/widgets/chat.py:564
msgid "System"
msgstr "System"

#: src/widgets/chat.py:610
msgid "Importable (.db)"
msgstr "Importierbare Datei (.db)"

#: src/widgets/chat.py:611
msgid "Markdown"
msgstr "Markdown"

#: src/widgets/chat.py:612
msgid "Markdown (Obsidian Style)"
msgstr "Markdown (Obsidian-Style)"

#: src/widgets/chat.py:613
msgid "JSON"
msgstr "JSON"

#: src/widgets/chat.py:614
msgid "JSON (Include Metadata)"
msgstr "JSON (Metadaten einbezogen)"

#: src/widgets/chat.py:619
msgid "Select a method to export the chat"
msgstr "Wählen Sie eine Methode, um den Chat zu exportieren"

#: src/widgets/dialog.py:195 src/widgets/dialog.py:208
#: src/widgets/dialog.py:221
msgid "Accept"
msgstr "Akzeptieren"

#: src/widgets/message.py:32
msgid "Remove Message"
msgstr "Nachricht entfernen"

#: src/widgets/message.py:42
msgid "Copy Message"
msgstr "Kopiere Nachricht"

#: src/widgets/message.py:52
msgid "Edit Message"
msgstr "Nachricht bearbeiten"

#: src/widgets/message.py:62
msgid "Regenerate Message"
msgstr "Nachricht regenerieren"

#: src/widgets/message.py:88
msgid "Message copied to the clipboard"
msgstr "Nachricht in die Zwischenablage kopiert"

#: src/widgets/message.py:133
msgid "Message cannot be regenerated while receiving a response"
msgstr ""
"Nachricht kann nicht regeneriert werden, während eine Antwort gesendet wird"

#: src/widgets/message.py:264 src/widgets/message.py:287
msgid "Thought"
msgstr "Gedanke"

#: src/widgets/message.py:492
msgid "Metadata"
msgstr ""

#: src/widgets/message.py:549
msgid "Attach YouTube Video?"
msgstr "YouTube-Video anhängen?"

#: src/widgets/message.py:550
msgid "Note that YouTube might block access to captions, please check output"
msgstr ""
"YouTube könnte den Zugriff auf die Untertitel blockieren - bitte Ausgabe "
"überprüfen!"

#: src/widgets/message.py:557
#, python-brace-format
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"Sind Sie sicher, dass Sie\n"
"'{}' anhängen möchten?"

#: src/widgets/message.py:576
msgid "Image recognition is only available on specific models"
msgstr "Bilderkennung ist nur bei bestimmten Modellen verfügbar"

#: src/widgets/message.py:605
msgid "Send Message"
msgstr "Nachricht senden"

#: src/widgets/message.py:614
msgid "Stop Message"
msgstr "Nachricht anhalten"

#: src/widgets/message.py:642
msgid "Send as User"
msgstr "Als Nutzer senden"

#: src/widgets/message.py:647
msgid "Send as System"
msgstr "Als System senden"

#: src/widgets/terminal.py:17
msgid "Setting up Python environment..."
msgstr "Python-Umgebung wird eingerichtet..."

#: src/widgets/terminal.py:29
msgid "Using Python HTTP server..."
msgstr "Nutzt den Python-HTTP-Server..."

#: src/widgets/terminal.py:34
msgid "Using Flatpak contained shell..."
msgstr "Nutzt die isolierte Flatpak-Eingabeaufforderung..."

#: src/widgets/terminal.py:38
msgid "Using SSH to run command"
msgstr "Nutzt SSH, um einen Befehl auszuführen"

#: src/widgets/terminal.py:85
msgid "Terminal"
msgstr "Terminal"

#: src/widgets/terminal.py:97
msgid "Open Environment Directory"
msgstr "Umgebungsordner öffnen"

#: src/widgets/terminal.py:181
msgid "Script Exited"
msgstr "Skript beendet"

#: src/widgets/terminal.py:192
msgid "Alpaca Terminal is not compatible with Windows"
msgstr "Das Alpaca-Terminal ist nicht mit Windows kompatibel"

#: src/widgets/voice.py:54
msgid "Dictate Message"
msgstr "Nachricht diktieren"

#: src/widgets/voice.py:167
msgid "Use Speech Recognition"
msgstr "Spracheingabe nutzen"

#: src/widgets/voice.py:212 src/widgets/voice.py:246
msgid "Speech Recognition Error"
msgstr "Fehler bei der Spracherkennung"

#: src/widgets/voice.py:213 src/widgets/voice.py:345
msgid "An error occurred while pulling speech recognition model"
msgstr ""
"Ein Fehler ist beim Herunterladen des Spracherkennungsmodells aufgetreten"

#: src/widgets/voice.py:247
msgid "An error occurred while using speech recognition"
msgstr "Ein Fehler ist bei der Verwendung der Spracherkennung aufgetreten"

#: src/widgets/voice.py:280 src/widgets/voice.py:403
msgid "Download Speech Recognition Model"
msgstr "Spracherkennungs-Modell herunterladen"

#: src/widgets/voice.py:281 src/widgets/voice.py:404
#, python-brace-format
msgid "To use speech recognition you'll need to download a special model ({})"
msgstr ""
"Um die Spracherkennung zu nutzen, muss ein spezielles Modell heruntergeladen "
"werden ({})"

#: src/widgets/voice.py:283 src/widgets/voice.py:406
#: src/widgets/tools/tools.py:914
msgid "Download Model"
msgstr "Modell herunterladen"

#: src/widgets/voice.py:318
msgid "Transcribing Audio"
msgstr "Audio transkribieren"

#: src/widgets/voice.py:344 src/widgets/voice.py:373
msgid "Transcription Error"
msgstr "Transkriptionsfehler"

#: src/widgets/voice.py:374
msgid "An error occurred while transcribing audio"
msgstr "Ein Fehler ist bei der Transkription des Audios aufgetreten"

#: src/widgets/models/added.py:89
msgid "Change Profile Picture"
msgstr "Profilbilder ändern"

#: src/widgets/models/added.py:110
msgid "Voice"
msgstr "Stimme"

#: src/widgets/models/added.py:115
msgid "Default"
msgstr "Standard"

#: src/widgets/models/added.py:142 src/widgets/models/creator.py:57
msgid "Tag"
msgstr "Tag"

#: src/widgets/models/added.py:143
msgid "Family"
msgstr "Familie"

#: src/widgets/models/added.py:144
msgid "Parameter Size"
msgstr "Parametergröße"

#: src/widgets/models/added.py:145
msgid "Quantization Level"
msgstr "Quantisierungsstufe"

#: src/widgets/models/added.py:148
msgid "Parent Model"
msgstr "Elternmodell"

#: src/widgets/models/added.py:151 src/widgets/models/added.py:153
msgid "Modified At"
msgstr "Geändert am"

#: src/widgets/models/added.py:159
msgid "Description"
msgstr "Beschreibung"

#: src/widgets/models/added.py:170 src/widgets/models/added.py:174
msgid "Files"
msgstr "Dateien"

#: src/widgets/models/added.py:193 src/widgets/models/creator.py:73
msgid "Context"
msgstr "Kontext"

#: src/widgets/models/added.py:221 src/widgets/models/added.py:476
#: src/widgets/models/speech.py:23 src/widgets/models/speech.py:177
msgid "Remove Model"
msgstr "Modell entfernen"

#: src/widgets/models/added.py:229 src/widgets/models/added.py:484
msgid "Create Child"
msgstr "Abstammendes Modell aus diesem erstellen"

#: src/widgets/models/added.py:249 src/widgets/models/available.py:156
msgid "Languages"
msgstr "Sprachen"

#: src/widgets/models/added.py:411 src/widgets/models/added.py:460
#: src/widgets/models/speech.py:143 src/widgets/models/speech.py:286
#: src/widgets/instances/__init__.py:513
msgid "Remove"
msgstr "Entfernen"

#: src/widgets/models/added.py:412
msgid "Change"
msgstr "Ändern"

#: src/widgets/models/added.py:420
msgid "Model Profile Picture"
msgstr "Modell-Profilbild"

#: src/widgets/models/added.py:421
msgid "What do you want to do with the model's profile picture?"
msgstr "Was möchten Sie mit dem Profilbild des Modells tun?"

#: src/widgets/models/added.py:457 src/widgets/models/speech.py:140
#: src/widgets/models/speech.py:283
msgid "Remove Model?"
msgstr "Modell wirklich entfernen?"

#: src/widgets/models/added.py:458 src/widgets/models/speech.py:141
#: src/widgets/models/speech.py:284
#, python-brace-format
msgid "Are you sure you want to remove '{}'?"
msgstr "Sind Sie sich sicher, dass Sie '{}' entfernen möchten?"

#: src/widgets/models/available.py:46
msgid "Already Added"
msgstr "Bereits hinzugefügt"

#: src/widgets/models/available.py:48
#, python-brace-format
msgid "Pull '{}'"
msgstr "'{}' herunterladen"

#: src/widgets/models/available.py:50
msgid "Add Model"
msgstr "Modell hinzufügen"

#: src/widgets/models/available.py:111
msgid "Add"
msgstr "Hinzufügen"

#: src/widgets/models/available.py:120
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""
"Durch das Herunterladen dieses Modells akzeptieren Sie die "
"Lizenzbestimmungen auf der Website des Modells."

#: src/widgets/models/available.py:253
msgid "Pull Latest"
msgstr "Neueste Version herunterladen"

#: src/widgets/models/common.py:13
msgid "Multilingual"
msgstr "Multilingual"

#: src/widgets/models/common.py:14
msgid "Code"
msgstr "Code"

#: src/widgets/models/common.py:15
msgid "Math"
msgstr "Mathematik"

#: src/widgets/models/common.py:16
msgid "Vision"
msgstr "Sehen"

#: src/widgets/models/common.py:17
msgid "Embedding"
msgstr "Eingebettet"

#: src/widgets/models/common.py:18
msgid "Tools"
msgstr "Werkzeuge"

#: src/widgets/models/common.py:19
msgid "Reasoning"
msgstr "Denken"

#: src/widgets/models/common.py:20
msgid "Small"
msgstr "Klein"

#: src/widgets/models/common.py:21
msgid "Medium"
msgstr "Mittel"

#: src/widgets/models/common.py:22
msgid "Big"
msgstr "Groß"

#: src/widgets/models/common.py:23
msgid "Huge"
msgstr "Riesig"

#: src/widgets/models/creator.py:24
msgid "Identity"
msgstr "Identität"

#: src/widgets/models/creator.py:30
msgid "Base"
msgstr "Basis"

#: src/widgets/models/creator.py:37
msgid "Profile Picture"
msgstr "Profilbild"

#: src/widgets/models/creator.py:41
msgid "Open File"
msgstr "Datei öffnen"

#: src/widgets/models/creator.py:51 src/widgets/instances/__init__.py:45
msgid "Name"
msgstr "Name"

#: src/widgets/models/creator.py:67
msgid "Add Files"
msgstr "Dateien hinzufügen"

#: src/widgets/models/creator.py:74
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""
"Beschreiben Sie das gewollte Verhalten des Modells in seiner Hauptsprache "
"(meist ist dies Englisch)."

#: src/widgets/models/creator.py:103
msgid "Behavior"
msgstr "Verhalten"

#: src/widgets/models/creator.py:109
msgid "Imagination"
msgstr "Vorstellungskraft"

#: src/widgets/models/creator.py:110
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr "Ein höherer Wert ergibt diversere Antworten vom Modell. (top_k)"

#: src/widgets/models/creator.py:125
msgid "Focus"
msgstr "Fokus"

#: src/widgets/models/creator.py:126
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "Ein höherer Wert erweitert die Menge an möglichen Antworten. (top_p)"

#: src/widgets/models/creator.py:140 src/widgets/instances/__init__.py:197
msgid "Context Window Size"
msgstr ""

#: src/widgets/models/creator.py:141 src/widgets/instances/__init__.py:198
msgid ""
"Controls how many tokens (pieces of text) the model can process and remember "
"at once."
msgstr ""

#: src/widgets/models/creator.py:165 src/widgets/models/creator.py:166
#: src/widgets/instances/__init__.py:364 src/widgets/instances/__init__.py:365
#: src/widgets/blocks/code.py:145 src/widgets/blocks/text.py:160
#: src/widgets/tools/tools.py:122 src/widgets/tools/tools.py:123
msgid "Save"
msgstr "Speichern"

#: src/widgets/models/creator.py:183
msgid "Create Model"
msgstr "Modell erstellen"

#: src/widgets/models/pulling.py:48
msgid "Downloading..."
msgstr "Herunterladen..."

#: src/widgets/models/pulling.py:69 src/widgets/models/pulling.py:71
#: src/widgets/models/pulling.py:174
msgid "Stop Download"
msgstr "Download anhalten"

#: src/widgets/models/pulling.py:132
msgid "Dictation Model"
msgstr "Diktierungsmodell"

#: src/widgets/models/pulling.py:188
msgid "Stop Download?"
msgstr "Download stoppen?"

#: src/widgets/models/pulling.py:189
#, python-brace-format
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "Bist du Dir sicher, das beziehen von '{}' abzubrechen?"

#: src/widgets/models/pulling.py:191
msgid "Stop"
msgstr "Stoppen"

#: src/widgets/models/pulling.py:224
msgid "Model Manager Error"
msgstr "Modellmanager-Fehler"

#: src/widgets/models/pulling.py:225
#, python-brace-format
msgid "An error occurred whilst pulling '{}'"
msgstr "Ein Fehler trat beim Download von '{}' auf"

#: src/widgets/models/pulling.py:253
msgid "Download Completed"
msgstr "Download abgeschlossen"

#: src/widgets/models/pulling.py:254
#, python-brace-format
msgid "Model '{}' downloaded successfully."
msgstr "Modell '{}' erfolgreich heruntergeladen."

#: src/widgets/models/speech.py:40
msgid "Local text to speech model provided by Kokoro."
msgstr "Lokales Text-zu-Sprache-Modell wird von Kokoro bereitgestellt."

#: src/widgets/models/speech.py:153 src/widgets/models/speech.py:296
msgid "Delete Model"
msgstr "Modell löschen"

#: src/widgets/models/speech.py:194
msgid "Local speech to text model provided by OpenAI Whisper."
msgstr "Lokales Spracherkennungsmodell wird von OpenAI Whisper bereitgestellt."

#: src/widgets/models/speech.py:249
msgid "Speech to Text"
msgstr "Spracherkennung"

#: src/widgets/instances/ollama_instances.py:70
#: src/widgets/instances/openai_instances.py:116
msgid "Notebook Error"
msgstr "Notizbuchfehler"

#: src/widgets/instances/ollama_instances.py:71
#: src/widgets/instances/ollama_instances.py:171
#: src/widgets/instances/openai_instances.py:117
#: src/widgets/instances/openai_instances.py:205
msgid "An error occurred while running tool"
msgstr "Ein Fehler ist beim Ausführen des Werkzeugs aufgetreten"

#: src/widgets/instances/ollama_instances.py:105
#: src/widgets/instances/openai_instances.py:152
msgid "Selecting tool to use..."
msgstr "Wählt passendes Werkzeug aus..."

#: src/widgets/instances/ollama_instances.py:124
#: src/widgets/instances/openai_instances.py:161
#, python-brace-format
msgid "Using {}"
msgstr "Benutzt {}"

#: src/widgets/instances/ollama_instances.py:132
#: src/widgets/instances/openai_instances.py:168 src/widgets/tools/tools.py:37
msgid "Arguments"
msgstr "Argumente"

#: src/widgets/instances/ollama_instances.py:133
#: src/widgets/instances/openai_instances.py:169
msgid "Argument"
msgstr ""

#: src/widgets/instances/ollama_instances.py:139
#: src/widgets/instances/openai_instances.py:175
msgid "Result"
msgstr ""

#: src/widgets/instances/ollama_instances.py:170
#: src/widgets/instances/openai_instances.py:204
msgid "Tool Error"
msgstr "Werkzeug-Fehler"

#: src/widgets/instances/ollama_instances.py:255
#: src/widgets/instances/ollama_instances.py:361
#: src/widgets/instances/ollama_instances.py:375
#: src/widgets/instances/ollama_instances.py:593
#: src/widgets/instances/openai_instances.py:267
#: src/widgets/instances/openai_instances.py:339
#: src/widgets/instances/openai_instances.py:394
#: src/widgets/instances/openai_instances.py:439
#: src/widgets/instances/openai_instances.py:499
#: src/widgets/instances/openai_instances.py:538
#: src/widgets/instances/openai_instances.py:571
msgid "Instance Error"
msgstr "Instanzfehler"

#: src/widgets/instances/ollama_instances.py:256
#: src/widgets/instances/openai_instances.py:268
msgid "Message generation failed"
msgstr "Nachrichtengenerierung fehlgeschlagen"

#: src/widgets/instances/ollama_instances.py:362
#: src/widgets/instances/openai_instances.py:340
#: src/widgets/instances/openai_instances.py:395
#: src/widgets/instances/openai_instances.py:440
msgid "Could not retrieve added models"
msgstr "Konnte die hinzugefügten Modelle nicht abrufen"

#: src/widgets/instances/ollama_instances.py:376
msgid "Could not retrieve available models"
msgstr "Konnte die verfügbaren Modelle nicht abrufen"

#: src/widgets/instances/ollama_instances.py:494
msgid "Ollama (Managed)"
msgstr "Ollama (Verwaltet)"

#: src/widgets/instances/ollama_instances.py:495
msgid "Local AI instance managed directly by Alpaca"
msgstr "Lokale KI-Instanz, direkt von Alpaca selbst verwaltet"

#: src/widgets/instances/ollama_instances.py:498
#: src/widgets/instances/ollama_instances.py:608
#: src/widgets/instances/__init__.py:388
msgid "Instance"
msgstr "Instanz"

#: src/widgets/instances/ollama_instances.py:535
msgid "Alpaca Support"
msgstr "Alpaca-Support"

#: src/widgets/instances/ollama_instances.py:542
msgid "Model request too large for system"
msgstr "Modellanfrage zu groß für das System"

#: src/widgets/instances/ollama_instances.py:545
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""
"AMD-GPU erkannt, aber die Erweiterung fehlt; Ollama wird die CPU verwenden."

#: src/widgets/instances/ollama_instances.py:547
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "AMD-GPU erkannt, aber ROCm fehlt; Ollama wird die CPU verwenden."

#: src/widgets/instances/ollama_instances.py:549
#, python-brace-format
msgid "Using AMD GPU type '{}'"
msgstr "Verwende AMD-GPU-Typ '{}'"

#: src/widgets/instances/ollama_instances.py:559
msgid "Integrated Ollama instance is not running"
msgstr "Integrierte Ollama-Instanz läuft nicht"

#: src/widgets/instances/ollama_instances.py:594
msgid "Managed Ollama instance failed to start"
msgstr "Mitverwaltete Ollama-Instanz konnte nicht starten"

#: src/widgets/instances/ollama_instances.py:600
msgid "Integrated Ollama instance is running"
msgstr "Integrierte Ollama-Instanz läuft"

#: src/widgets/instances/ollama_instances.py:605
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "Lokale- oder Remoteinstanz, die nicht durch Alpaca verwaltet wird"

#: src/widgets/instances/openai_instances.py:21
msgid "Instances"
msgstr "Instanzen"

#: src/widgets/instances/openai_instances.py:211
msgid "Generating message..."
msgstr "Nachricht wird generiert..."

#: src/widgets/instances/openai_instances.py:500
#: src/widgets/instances/openai_instances.py:539
#: src/widgets/instances/openai_instances.py:572
msgid "Could not retrieve models"
msgstr "Konnte Modelle nicht abrufen"

#: src/widgets/instances/openai_instances.py:512
msgid "Alibaba Cloud Qwen large language models via DashScope"
msgstr "Alibaba Cloud Qwen LLMs über DashScope"

#: src/widgets/instances/openai_instances.py:518
msgid "Fireworks AI inference platform"
msgstr "Fireworks AI-Inferenzplattform"

#: src/widgets/instances/openai_instances.py:551
msgid "Lambda Labs cloud inference API"
msgstr "Lambda Labs-Cloud-Inferenz-API"

#: src/widgets/instances/openai_instances.py:584
msgid "Cerebras AI cloud inference API"
msgstr "Cerebras AI-Cloud-Inferenz-API"

#: src/widgets/instances/openai_instances.py:590
msgid "Kluster AI cloud inference API"
msgstr "Kluster AI-Cloud-Inferenz-API"

#: src/widgets/instances/openai_instances.py:596
msgid "Kimi large language models by Moonshot AI"
msgstr "Kimi-LLMs von Moonshot AI"

#: src/widgets/instances/openai_instances.py:603
msgid "Mistral AI large language models"
msgstr "Mistral AI-LLMs"

#: src/widgets/instances/openai_instances.py:610
msgid "Meta AI Llama API"
msgstr "Meta AI Llama API"

#: src/widgets/instances/openai_instances.py:616
msgid "Novita AI cloud inference API"
msgstr "Novita AI Cloud-Inference-API"

#: src/widgets/instances/openai_instances.py:623
msgid "DeepInfra cloud inference API"
msgstr "DeepInfra-Cloud-Inference-API"

#: src/widgets/instances/openai_instances.py:627
msgid "OpenAI Compatible Instance"
msgstr "OpenAI-kompatible Instanz"

#: src/widgets/instances/openai_instances.py:629
msgid "AI instance compatible with OpenAI library"
msgstr "KI-Instanz, die mit der OpenAI-Bibliothek kompatibel ist"

#: src/widgets/instances/__init__.py:32 src/widgets/instances/__init__.py:35
msgid "Ollama Log"
msgstr "Ollama-Log"

#: src/widgets/instances/__init__.py:57
msgid "Port"
msgstr "Port"

#: src/widgets/instances/__init__.py:58
#, python-brace-format
msgid "Which network port will '{}' use"
msgstr "Welchen Netzwerk-Port {} nutzen wird"

#: src/widgets/instances/__init__.py:72
msgid "Instance URL"
msgstr "Instanz-URL"

#: src/widgets/instances/__init__.py:78
msgid "API Key"
msgstr "API-Schlüssel"

#: src/widgets/instances/__init__.py:79
msgid "API Key (Unchanged)"
msgstr "API-Schlüssel (Unverändert)"

#: src/widgets/instances/__init__.py:83
msgid "API Key (Optional)"
msgstr "API-Schlüssel (optional)"

#: src/widgets/instances/__init__.py:97
msgid "Thought Processing"
msgstr "Gedankenverarbeitung"

#: src/widgets/instances/__init__.py:98
msgid ""
"Have compatible reasoning models think about their response before "
"generating a message."
msgstr ""

#: src/widgets/instances/__init__.py:105
msgid "Expose Ollama to Network"
msgstr ""

#: src/widgets/instances/__init__.py:106
msgid "Make Ollama available for other devices and software in local network"
msgstr ""

#: src/widgets/instances/__init__.py:113
msgid "Share Name"
msgstr "Namen teilen"

#: src/widgets/instances/__init__.py:114
msgid "Automatically share your name with the AI models."
msgstr "Teilt den Nutzernamen automatisch mit den KI-Modellen."

#: src/widgets/instances/__init__.py:119
msgid "Do Not Share"
msgstr ""

#: src/widgets/instances/__init__.py:120 src/widgets/tools/tools.py:575
msgid "Username"
msgstr "Nutzername"

#: src/widgets/instances/__init__.py:121
msgid "Full Name"
msgstr ""

#: src/widgets/instances/__init__.py:129
msgid "Show Response Metadata"
msgstr ""

#: src/widgets/instances/__init__.py:130
msgid "Add the option to show reply metadata in the message as an attachment."
msgstr ""

#: src/widgets/instances/__init__.py:137
msgid "Max Tokens"
msgstr "Maximale Tokens"

#: src/widgets/instances/__init__.py:138
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"Definiert die maximale Anzahl an Tokens (Wörter und Leerzeichen), die die KI "
"in einer Antwort generieren kann. Mehr Tokens ermöglichen längere Antworten, "
"können aber auch mehr Zeit oder Kosten in Anspruch nehmen."

#: src/widgets/instances/__init__.py:154
msgid "Override Parameters"
msgstr ""

#: src/widgets/instances/__init__.py:155
msgid "These parameters overrides the behavior of the instance and models."
msgstr ""

#: src/widgets/instances/__init__.py:165
msgid "Temperature"
msgstr "Temperatur"

#: src/widgets/instances/__init__.py:166
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""
"Die Temperatur zu erhöhen, wird die Modelle kreativer antworten lassen."

#: src/widgets/instances/__init__.py:181
msgid "Seed"
msgstr "Seed"

#: src/widgets/instances/__init__.py:182
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""
"Dies zu einer anderen Zahl als 0 zu setzen, wird die Modelle für dieselben "
"Eingaben immer dieselben Ausgaben generieren lassen."

#: src/widgets/instances/__init__.py:219
msgid "Keep Alive Presets"
msgstr ""

#: src/widgets/instances/__init__.py:220
msgid "How the instance should handle idle models."
msgstr ""

#: src/widgets/instances/__init__.py:225
msgid "Set Timer"
msgstr ""

#: src/widgets/instances/__init__.py:226
msgid "Keep Alive Forever"
msgstr ""

#: src/widgets/instances/__init__.py:227
msgid "Unload After Use"
msgstr ""

#: src/widgets/instances/__init__.py:234
msgid "Minutes"
msgstr ""

#: src/widgets/instances/__init__.py:235
msgid ""
"The amount of time the instance should keep models loaded after they go idle."
msgstr ""

#: src/widgets/instances/__init__.py:271
msgid "Overrides"
msgstr "Überschreibungen"

#: src/widgets/instances/__init__.py:272
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""
"Diese Einträge sind optional, sie werden zur Fehlerbehebung von GPU-"
"bezogenen Problemen mit Ollama genutzt."

#: src/widgets/instances/__init__.py:294
msgid "Model Directory"
msgstr "Modellordner"

#: src/widgets/instances/__init__.py:299
msgid "Select Directory"
msgstr "Verzeichnis auswählen"

#: src/widgets/instances/__init__.py:319
msgid "Default Model"
msgstr "Standardmodell"

#: src/widgets/instances/__init__.py:320
msgid "Model to select when starting a new chat."
msgstr "Auszuwählendes Modell, wenn ein neuer Chat gestartet wird."

#: src/widgets/instances/__init__.py:327
msgid "Title Model"
msgstr "Titel-Modell"

#: src/widgets/instances/__init__.py:328
msgid "Model to use when generating a chat title."
msgstr "Zu nutzendes Modell, um die Chat-Titel zu generieren."

#: src/widgets/instances/__init__.py:336
msgid "Use Current Model"
msgstr ""

#: src/widgets/instances/__init__.py:382
msgid "Edit Instance"
msgstr "Instanz bearbeiten"

#: src/widgets/instances/__init__.py:382
msgid "Create Instance"
msgstr "Instanz erstellen"

#: src/widgets/instances/__init__.py:470
msgid "Fallback Instance"
msgstr "Ersatzinstanz"

#: src/widgets/instances/__init__.py:510
msgid "Remove Instance?"
msgstr "Instanz entfernen?"

#: src/widgets/instances/__init__.py:511
msgid "Are you sure you want to remove this instance?"
msgstr "Sicher, dass diese Instanz entfernt werden soll?"

#: src/widgets/blocks/code.py:84
msgid "Code Block"
msgstr "Code-Block"

#: src/widgets/blocks/code.py:111
msgid "Edit Script"
msgstr "Skript bearbeiten"

#: src/widgets/blocks/code.py:119
msgid "Copy Script"
msgstr "Skript kopieren"

#: src/widgets/blocks/code.py:127
msgid "Run Script"
msgstr "Starte Script"

#: src/widgets/blocks/code.py:193
msgid "Changes saved successfully"
msgstr "Änderungen erfolgreich gespeichert"

#: src/widgets/blocks/code.py:199
msgid "Code copied to the clipboard"
msgstr "Code in die Zwischenablage kopiert"

#: src/widgets/blocks/latex.py:41
msgid "Copy Equation"
msgstr "Gleichung speichern"

#: src/widgets/blocks/latex.py:76
msgid "Equation copied to the clipboard"
msgstr "Gleichung in Zwischenablage kopiert"

#: src/widgets/tools/notebook_tools.py:18
msgid "Read Notebook"
msgstr "Notizbuch lesen"

#: src/widgets/tools/notebook_tools.py:19
msgid "Reads the current notebook."
msgstr "Liest das derzeitige Notizbuch aus."

#: src/widgets/tools/notebook_tools.py:38
msgid "Write Notebook"
msgstr "Notizbuch schreiben"

#: src/widgets/tools/notebook_tools.py:39
msgid "Overwrites the notebook with new text."
msgstr "Überschreibt das gesamte Notizbuch mit neuem Text."

#: src/widgets/tools/notebook_tools.py:58
msgid "Append to Notebook"
msgstr "Zum Notizbuch hinzufügen"

#: src/widgets/tools/notebook_tools.py:59
msgid "Appends text to the notebook."
msgstr "Fügt Text in das Notizbuch hinzu."

#: src/widgets/tools/tools.py:24
msgid "AI Description"
msgstr "KI-Beschreibung"

#: src/widgets/tools/tools.py:25
msgid "The description the AI model will use to understand what the tool does."
msgstr ""
"Die Beschreibung, die das KI-Modell nutzen wird, um zu verstehen, was das "
"Werkzeug tut."

#: src/widgets/tools/tools.py:38
msgid "Variables that are filled by the AI."
msgstr "Variablen, die von dem Sprachmodell ausgefüllt werden."

#: src/widgets/tools/tools.py:62
msgid "Variables"
msgstr "Variablen"

#: src/widgets/tools/tools.py:63
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""
"Nutzer-spezifizierte Werte, die das Tool zum Arbeiten nutzen wird - das "
"Sprachmodell und dessen Anbieter hat auf diese keinen Zugriff."

#: src/widgets/tools/tools.py:264
msgid "Gets the current date and/or time."
msgstr "Ruft das derzeitige Datum und die Zeit ab."

#: src/widgets/tools/tools.py:296
msgid "Gets a recipe by the meal's name"
msgstr "Ruft ein Rezept, basierend auf dem Namen des Gerichts, ab"

#: src/widgets/tools/tools.py:311 src/widgets/tools/tools.py:377
msgid "YouTube Video"
msgstr "YouTube-Video"

#: src/widgets/tools/tools.py:319 src/widgets/tools/tools.py:386
msgid "Source"
msgstr "Quelle"

#: src/widgets/tools/tools.py:356
msgid "Gets a list of food recipes by a specified category"
msgstr "Ruft eine Liste an Rezepten für eine spezifizierte Kategorie ab"

#: src/widgets/tools/tools.py:412
msgid "Extracts an article from Wikipedia by it's title"
msgstr "Extrahiert einen Artikel von Wikipedia mithilfe des Titels"

#: src/widgets/tools/tools.py:464
msgid "Search for a term online using DuckDuckGo"
msgstr "Sucht bei DuckDuckGo online nach einem Begriff"

#: src/widgets/tools/tools.py:467
msgid "Safe Search"
msgstr "Sichere Suche"

#: src/widgets/tools/tools.py:471
msgid "On"
msgstr "An"

#: src/widgets/tools/tools.py:472
msgid "Moderate"
msgstr "Moderat"

#: src/widgets/tools/tools.py:473
msgid "Off"
msgstr "Aus"

#: src/widgets/tools/tools.py:477
msgid "Max Results"
msgstr "Maximale Anzahl an Ergebnissen"

#: src/widgets/tools/tools.py:511
msgid "Abstract Source"
msgstr "Quelle der Zusammenfassung"

#: src/widgets/tools/tools.py:531
msgid "Web Result Image"
msgstr "Web-Ergebnis-Bild"

#: src/widgets/tools/tools.py:567
msgid "Request to run a command using SSH to connect to the device"
msgstr ""
"Fragt an, einen Befehl mittels SSH auf einem verbundenen Gerät auszuführen"

#: src/widgets/tools/tools.py:570
msgid "IP Address"
msgstr "IP-Adresse"

#: src/widgets/tools/tools.py:580
msgid "Network Port"
msgstr "Netzwerk-Port"

#: src/widgets/tools/tools.py:597
msgid "Model Requested to Run Command"
msgstr "Modell hat angefragt, einen Befehl auszuführen"

#: src/widgets/tools/tools.py:598
msgid "Command"
msgstr "Befehl"

#: src/widgets/tools/tools.py:600
msgid "Explanation"
msgstr "Erklärung"

#: src/widgets/tools/tools.py:601
msgid "No explanation was provided"
msgstr "Eine Erklärung wurde angegeben"

#: src/widgets/tools/tools.py:602
msgid "Make sure you understand what the command does before running it."
msgstr ""
"Bitte stellen Sie sicher, dass sie voll und ganz verstehen, was der Befehl "
"tut, bevor Sie ihn ausführen."

#: src/widgets/tools/tools.py:648
msgid "Spotify Controller"
msgstr "Spotify-Steuerung"

#: src/widgets/tools/tools.py:649
msgid "Control your music's playback"
msgstr "Steuern Sie das Abspielen ihrer Musik"

#: src/widgets/tools/tools.py:700
msgid "Log Back In"
msgstr "Erneut anmelden"

#: src/widgets/tools/tools.py:704
msgid "Not logged in"
msgstr "Nicht angemeldet"

#: src/widgets/tools/tools.py:711
msgid "Tutorial"
msgstr "Anleitung"

#: src/widgets/tools/tools.py:738
msgid "Spotify User"
msgstr "Spotify-Nutzer"

#: src/widgets/tools/tools.py:799
msgid "Login Error"
msgstr "Anmeldefehler"

#: src/widgets/tools/tools.py:800
msgid "Couldn't log in to Spotify"
msgstr "Konnte sich nicht bei Spotify anmelden"

#: src/widgets/tools/tools.py:801
msgid "Specify a Client ID and Client Secret"
msgstr "Client-ID und Client-Geheimnis angeben"

#: src/widgets/tools/tools.py:850
msgid "Album Art"
msgstr "Album-Artwork"

#: src/widgets/tools/tools.py:876
msgid "Image Background Remover"
msgstr ""

#: src/widgets/tools/tools.py:877
msgid "Removes the background of the last image sent"
msgstr ""

#: src/widgets/tools/tools.py:880
msgid "Background Remover Model"
msgstr ""

#: src/widgets/tools/tools.py:898
msgid "Loading Image..."
msgstr ""

#: src/widgets/tools/tools.py:921
msgid "Download Background Removal Model"
msgstr ""

#: src/widgets/tools/tools.py:922
#, python-brace-format
msgid "To use this tool you'll need to download a special model ({})"
msgstr ""

#: src/widgets/tools/tools.py:933
msgid "Removing Background..."
msgstr ""

#: src/widgets/tools/tools.py:942
msgid "Output"
msgstr ""

#~ msgid ""
#~ "Have compatible reasoning models think about their response before "
#~ "generating a message"
#~ msgstr ""
#~ "Lässt kompatible Modelle über ihre Antwort nachdenken, bevor sie eine "
#~ "Nachricht generieren"

#~ msgid "Attachment failed, screenshot might be too big"
#~ msgstr "Anhängen schlug fehl; das Bildschirmfoto ist womöglich zu groß."

#~ msgid "Download Model?"
#~ msgstr "Modell herunterladen?"

#~ msgid "Already Installed!"
#~ msgstr "Bereits installiert!"

#~ msgid "Creator"
#~ msgstr "Ersteller"

#~ msgid "Model Creator"
#~ msgstr "Modell-Ersteller"

#~ msgid "Select a method of importing a model to continue"
#~ msgstr ""
#~ "Wählen Sie eine Methode, ein Modell zu importieren, um fortzufahren."

#~ msgid "GGUF File"
#~ msgstr "GGUF-Datei"

#~ msgid "Existing Model"
#~ msgstr "Existierendes Modell"

#~ msgid "Download Model From Name"
#~ msgstr "Modell anhand eines Namens herunterladen"

#~ msgid "Downloading…"
#~ msgstr "Lädt herunter..."

#~ msgid "A conversation involving a YouTube video transcript"
#~ msgstr "Eine Konversation mit einem YouTube-Video-Transkript"

#~ msgid "Model creator screen"
#~ msgstr "Modellerstellungsoberfläche"

#~ msgid ""
#~ "DeepSeek's first-generation of reasoning models with comparable "
#~ "performance to OpenAI-o1, including six dense models distilled from "
#~ "DeepSeek-R1 based on Llama and Qwen."
#~ msgstr ""
#~ "DeepSeek's erste Generation an Reasoning-Modellen mit vergleichbarer "
#~ "Leistung zu OpenAI-o1, einschließlich sechs dichter Modelle, die von "
#~ "DeepSeek-R1 basierend auf Llama und Qwen destilliert wurden."

#~ msgid "This video does not have any transcriptions"
#~ msgstr "Dieses Video hat keine Transkriptionen"

#~ msgid ""
#~ "{}\n"
#~ "\n"
#~ "Please select a transcript to include"
#~ msgstr ""
#~ "{}\n"
#~ "\n"
#~ "Bitte wählen Sie ein Transkript zum Einbinden aus"

#~ msgid "Error attaching video, please try again"
#~ msgstr ""
#~ "Es gab einen Fehler beim Anfügen des Videos. Versuchen Sie es bitte "
#~ "erneut."

#~ msgid ""
#~ "Hey Alpaca users! We're so excited to bring you a fresh update packed "
#~ "with awesome new features to explore! Get ready to experience Alpaca in a "
#~ "whole new way!"
#~ msgstr ""
#~ "Hey, Alpaca-Nutzer:innen! Wir freuen uns sehr, euch ein frisches Update - "
#~ "vollgestopft mit großartigen neuen Funktionen - zu bringen! Macht euch "
#~ "bereit, Alpaca in einem komplett neuen Weg zu erleben!"

#~ msgid "Smart Tools"
#~ msgstr "Intelligente Werkzeuge"

#~ msgid ""
#~ "Supported AI models can use handy tools to grab information both locally "
#~ "and online. Head over to the brand new \"Tool Manager\" to toggle them on "
#~ "or off."
#~ msgstr ""
#~ "Unterstützte Sprachmodelle können hilfreiche Werkzeuge nutzen, um "
#~ "Informationen von lokalen Quellen und aus dem Internet abzurufen! "
#~ "Wechseln Sie zum brandneuen \"Werkzeug-Manager\", um diese ein- oder "
#~ "auszuschalten."

#~ msgid "Talk to Models"
#~ msgstr "Mit Modellen sprechen"

#~ msgid ""
#~ "You can now dictate your messages using local speech recognition. It's "
#~ "super convenient! You can even customize your language and other settings "
#~ "in the Preferences dialog."
#~ msgstr ""
#~ "Ab jetzt können Nachrichten mittels lokal laufender Spracherkennung "
#~ "diktiert werden. Das ist sehr praktisch! Sogar Sprache und andere "
#~ "Einstellungen können angepasst werden."

#~ msgid "Find Models Faster"
#~ msgstr "Modelle schneller finden"

#~ msgid ""
#~ "Browsing through your Ollama models just got easier! We've added the "
#~ "ability to filter models by their categories in the Model Manager. Now "
#~ "you can quickly find exactly the model you're looking for."
#~ msgstr ""
#~ "Durch Ollama-Modelle zu stöbern, ist jetzt noch einfacher! Wir haben die "
#~ "Möglichkeit, nach Modellen anhand von Kategorien zu filtern, im Modell-"
#~ "Manager hinzugefügt. Jetzt findet man das Modell, nach dem man sucht, "
#~ "noch schneller."

#~ msgid "Math Rendering"
#~ msgstr "Mathematik-Rendering"

#~ msgid ""
#~ "We've improved how LaTeX equations are rendered in messages, making them "
#~ "look cleaner and more consistent. Your mathematical discussions will be "
#~ "clearer than ever!"
#~ msgstr ""
#~ "Wir haben verbessert, wie LaTeX-Gleichungen in Nachrichten gerendert "
#~ "werden, wodurch diese nun noch besser und konsistenter aussehen. "
#~ "Mathematische Diskussionen werden nun klarer denn je ablaufen können!"

#~ msgid "More Instances"
#~ msgstr "Noch mehr Instanzen"

#~ msgid ""
#~ "Get ready to connect Alpaca to a whole universe of AI providers! We've "
#~ "added support for over 5 new AI instance providers, including Anthropic, "
#~ "OpenRouter, and Fireworks. The possibilities are endless!"
#~ msgstr ""
#~ "Machen Sie sich bereit, Alpaca mit einem Universum an KI-Providern zu "
#~ "verbinden. Wir haben über 5 neue KI-Instanz-Provider hinzugefügt, "
#~ "darunter Anthropic, OpenRouter und Fireworks. Die Möglichkeiten sind "
#~ "schier endlos!"

#~ msgid "Attachment Enhancement"
#~ msgstr "Verbesserung der Anhänge"

#~ msgid ""
#~ "You can now attach and ask questions about even more file types, "
#~ "including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
#~ "you'll see it with rich text styling, making it easier to understand the "
#~ "content before you send it."
#~ msgstr ""
#~ "Nun können Fragen zu noch mehr Dateitypen gestellt werden, "
#~ "darunter .docx, .pptx und .xlsx! Dazu kommt ein verbessertes Rendering "
#~ "von Rich Text in der Vorschau dieser Dateien - sodass es noch einfacher "
#~ "wird, den Inhalt vor dem Versenden zu verstehen."

#~ msgid "Official Website"
#~ msgstr "Offizielle Website"

#~ msgid "'{}' does not support tools."
#~ msgstr "'{}' unterstützt leider keine Werkzeuge."

#~ msgid "Open Model Manager"
#~ msgstr "Öffne Modell-Manager"

#~ msgid "Cannot open image"
#~ msgstr "Bild kann nicht geöffnet werden"

#~ msgid "Remove Attachment?"
#~ msgstr "Anhang entfernen?"

#~ msgid "Are you sure you want to remove attachment?"
#~ msgstr "Sind Sie sicher, dass Sie den Anhang entfernen möchten?"

#~ msgid "Text to Speech Voice"
#~ msgstr "Stimme für Text-zu-Sprache"

#~ msgid "Terminal dialog"
#~ msgstr "Terminal-Dialog"

#~ msgid "File preview dialog"
#~ msgstr "Dateivorschau-Dialog"

#~ msgid "Open With Default App"
#~ msgstr "Mit Standard-App öffnen"

#~ msgid "An error occurred while extracting text from the website"
#~ msgstr ""
#~ "Beim Extrahieren von Text von der Website ist ein Fehler aufgetreten"

#~ msgid "Regenerate Response"
#~ msgstr "Antwort regenerieren"

#~ msgid "Save Message"
#~ msgstr "Speichere Nachricht"

#~ msgid "Message edited successfully"
#~ msgstr "Nachricht erfolgreich editiert"

#~ msgid "Response message"
#~ msgstr "Antwortnachricht"

#~ msgid "System message"
#~ msgstr "Systemnachricht"

#~ msgid "User message"
#~ msgstr "Benutzernachricht"

#~ msgid "{}Code Block"
#~ msgstr "{}Code-Block"

#~ msgid "Edit Code Block"
#~ msgstr "Codeblock bearbeiten"

#~ msgid ""
#~ "Make sure you understand what this script does before running it, Alpaca "
#~ "is not responsible for any damages to your device or data"
#~ msgstr ""
#~ "Stellen Sie sicher, dass Sie verstehen, was dieses Skript tut, bevor Sie "
#~ "es ausführen. Alpaca übernimmt keine Verantwortung für Schäden an Ihrem "
#~ "Gerät oder Ihren Daten."

#~ msgid "Execute"
#~ msgstr "Ausführen"

#~ msgid "Missing image"
#~ msgstr "Fehlendes Bild"

#~ msgid "Compiling C++ script..."
#~ msgstr "C++-Skript wird kompiliert..."

#~ msgid "Running local web server"
#~ msgstr "Führt lokalen Webserver aus"

#~ msgid "Using Flatpak contained shell"
#~ msgstr "Nutzt Flatpak-beinhaltete Shell"

#~ msgid "Clear Chat?"
#~ msgstr "Chat leeren?"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "Sind Sie sicher, dass Sie den Chat leeren möchten?"

#~ msgid "Clear"
#~ msgstr "Leeren"

#~ msgid "Clear Chat"
#~ msgstr "Chat leeren"

#~ msgid "Removal of Ollama"
#~ msgstr "Entfernung von Ollama"

#~ msgid ""
#~ "Hey there! With Alpaca 5.1.0, we're making some changes. To keep using "
#~ "Ollama directly within Alpaca, you'll just need to install our new Ollama "
#~ "extension. Don't worry, your models remain untouched!"
#~ msgstr ""
#~ "Hi! Mit Alpaca 5.1.0 haben wir ein paar Änderungen gemacht. Um ab nun "
#~ "Ollama weiterhin direkt in Alpaca nutzen zu können, brauchst du nur kurz "
#~ "unsere neue Ollama-Erweiterung zu installieren. Aber keine Sorge, deine "
#~ "heruntergeladenen Modelle bleiben unberührt."

#~ msgid "Regenerate Equation"
#~ msgstr "Gleichung neu generieren"

#~ msgid "LaTeX Equation"
#~ msgstr "LaTeX-Gleichung"

#~ msgid "Which network port will Ollama use"
#~ msgstr "Welchen Netzwerkport Ollama nutzen wird"

#~ msgid "Built in Ollama instance"
#~ msgstr "Eingebaute Ollama-Instanz"

#~ msgid "The current strongest model that fits on a single GPU."
#~ msgstr "Das derzeit stärkste Modell, dass auf eine einzige GPU passt."

#~ msgid "Visit Website"
#~ msgstr "Website besuchen"

#~ msgid ""
#~ "QwQ is an experimental research model focused on advancing AI reasoning "
#~ "capabilities."
#~ msgstr ""
#~ "QwQ ist ein experimentelles Forschungsmodell mit einem Fokus auf "
#~ "erweiterteFähigkeiten des logischen Denkens einer KI."

#~ msgid "Your AI, Your Choice"
#~ msgstr "Ihre KI, Ihre Wahl."

#~ msgid ""
#~ "Alpaca includes Ollama by default, giving you instant access to AI. "
#~ "Customize your experience further by connecting to Google Gemini, OpenAI "
#~ "ChatGPT, Together.AI, and more."
#~ msgstr ""
#~ "Alpaca kommt standardmäßig mit Ollama gebündelt, sodass Sie direkt "
#~ "Zugriff auf KI haben können. Passen Sie zusätzlich Ihre Nutzungserfahrung "
#~ "weiter an, indem Sie eine Verbindung mit Google Gemini, OpenAI ChatGPT, "
#~ "Together.AI und vielen weiteren Diensten herstellen!"

#~ msgid ""
#~ "It looks like you don't have any models downloaded yet. Download models "
#~ "to get started!"
#~ msgstr ""
#~ "Es sieht so aus, als hätten Sie noch keine Modelle heruntergeladen. Laden "
#~ "Sie Modelle herunter, um loszulegen!"

#~ msgid "Loading"
#~ msgstr "Lädt..."

#~ msgid ""
#~ "Mistral Small is a lightweight model designed for cost-effective use in "
#~ "tasks like translation and summarization."
#~ msgstr ""
#~ "Mistral Small ist ein leichtgewichtiges Modell, das für kostengünstige "
#~ "Anwendungen wie Übersetzung und Zusammenfassung entwickelt wurde."

#~ msgid ""
#~ "DeepSeek's first generation reasoning models with comparable performance "
#~ "to OpenAI-o1."
#~ msgstr ""
#~ "DeepSeek's erste Generation an Reasoning-Modellen mit vergleichbarer "
#~ "Performance zu OpenAI's o1."

#~ msgid "Loading Instance"
#~ msgstr "Lade Instanz"

#~ msgctxt "shortcut window"
#~ msgid "Search Messages"
#~ msgstr "Nachrichten durchsuchen"

#~ msgid "Not Available"
#~ msgstr "Nicht verfügbar"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Bearer-Token (Optional)"

#~ msgid "Chat with local AI models"
#~ msgstr "Chatten Sie mit lokalen KI-Modellen"

#~ msgid "An Ollama client"
#~ msgstr "Ein Ollama-Client"

#~ msgid "Connect"
#~ msgstr "Verbinden"

#~ msgid "Server URL"
#~ msgstr "Server URL"

#~ msgid "Connect Remote Instance"
#~ msgstr "Remote-Instanz verbinden"

#~ msgid "Enter instance information to continue"
#~ msgstr "Instanzinformationen eingeben, um fortzufahren"

#~ msgid "Close Alpaca"
#~ msgstr "Alpaca schließen"

#~ msgid "Use Local Instance"
#~ msgstr "Verwende lokale Instanz"

#~ msgid "Connection Error"
#~ msgstr "Verbindungsfehler"

#~ msgid "The remote instance has disconnected"
#~ msgstr "Die Remote-Instanz hat die Verbindung getrennt"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Es gab einen Fehler mit der lokalen Ollama-Instanz, daher wurde sie "
#~ "zurückgesetzt"

#~ msgid "An error occurred: {}"
#~ msgstr "Ein Fehler trat auf: {}"

#~ msgid "Ollama instance was shut down due to inactivity"
#~ msgstr "Ollama-Instanz wurde wegen Inaktivität abgeschaltet"

#~ msgid "Local Models"
#~ msgstr "Lokale Modelle"

#~ msgid ""
#~ "It looks a bit empty in here. Try downloading some models to get started!"
#~ msgstr ""
#~ "Hier sieht es ein wenig leer aus! Probieren Sie, ein paar Modelle "
#~ "herunterzuladen, um loszulegen!"

#~ msgid "Available Models"
#~ msgstr "Verfügbare Modelle"

#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Remote-Verbindung zu Ollama verwenden"

#~ msgid "Change Ollama Instance"
#~ msgstr "Ollama-Instanz ändern"

#~ msgid ""
#~ "The default model to use on new chats and when generating chat titles"
#~ msgstr ""
#~ "Das Standardmodell wird in neuen Chats und zur Generierung der Chat-Titel "
#~ "genutzt."

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "Die Temperatur des Modells. Eine Erhöhung der Temperatur lässt das Modell "
#~ "kreativer antworten. (Standard: 0,8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Legt den Zufallszahlenseed für die Generierung fest. Wenn dies auf eine "
#~ "bestimmte Zahl gesetzt wird, generiert das Modell für den gleichen Prompt "
#~ "den gleichen Text. (Standard: 0 (zufällig))"

#~ msgid "Keep Alive Time"
#~ msgstr "Aktivhaltungszeit"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Steuert, wie lange das Modell nach der Anfrage in Minuten im Speicher "
#~ "geladen bleibt (Standard: 5)"

#~ msgid "Ollama Instance"
#~ msgstr "Ollama-Instanz"

#~ msgid "Ollama Overrides"
#~ msgstr "Ollama-Überschreibungen"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Verwalten Sie die in Ollama verwendeten Argumente, Änderungen auf dieser "
#~ "Seite gelten nur für die integrierte Instanz, die Instanz wird bei "
#~ "Änderungen neu gestartet."

#~ msgid "Idle Timer"
#~ msgstr "Leerlauf-Timer"

#~ msgid ""
#~ "Number of minutes the instance should remain idle before it is shut down "
#~ "(0 means it won't be shut down)"
#~ msgstr ""
#~ "Anzahl der Minuten, die die Instanz im Leerlauf bleiben soll, bevor sie "
#~ "heruntergefahren wird (0 bedeutet, dass sie nicht abgeschaltet wird)"

#~ msgid "Change Model Directory"
#~ msgstr "Modellordner ändern"

#~ msgid "Powered by Ollama"
#~ msgstr "Betrieben von Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Ollama-Website"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca und seine Entwickler haften nicht für Schäden an Geräten oder "
#~ "Software, die durch die Ausführung von Code entstehen, der von einem KI-"
#~ "Modell generiert wurde. Bitte seien Sie vorsichtig und überprüfen Sie den "
#~ "Code sorgfältig, bevor Sie ihn ausführen."

#~ msgid "Reload Local Models"
#~ msgstr "Lokale Modelle neu laden"

#~ msgctxt "shortcut window"
#~ msgid "Import Chat"
#~ msgstr "Chat importieren"

#~ msgid "(No system message available)"
#~ msgstr "(Keine Systemnachricht verfügbar)"

#~ msgid "From Existing Model"
#~ msgstr "Aus bestehendem Modell"

#~ msgid "From GGUF File"
#~ msgstr "Aus GGUF-Datei"

#~ msgid "From Name"
#~ msgstr "Nach Namen"

#~ msgid "image"
#~ msgstr "Bild"

#~ msgid "Select Model"
#~ msgstr "Modell auswählen"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Dieses Modell wird als Basis für das neue Modell verwendet"

#~ msgid ""
#~ "Input the name of the model in this format\n"
#~ "name:tag"
#~ msgstr ""
#~ "Geben Sie den Namen des Modells in diesem Format ein\n"
#~ "Name:Tag"

#~ msgid "Manage models dialog"
#~ msgstr "Modelle verwalten-Dialog"

#~ msgid "Try a different search or pull an unlisted model from it's name"
#~ msgstr ""
#~ "Versuchen Sie eine andere Suche oder rufen Sie ein nicht gelistetes "
#~ "Modell über seinen Namen ab"

#~ msgid "Pull Model From Name"
#~ msgstr "Modell nach Namen abrufen"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "Durch das Herunterladen dieses Modells akzeptieren Sie die auf der "
#~ "Website des Modells verfügbare Lizenzvereinbarung."

#~ msgid "Model Details"
#~ msgstr "Modeldetails"

#~ msgid ""
#~ "Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
#~ "instructions automatically. Please visit the model's website or Ollama "
#~ "documentation for more information if you're unsure."
#~ msgstr ""
#~ "Einige Modelle benötigen eine Modelldatei, Alpaca füllt FROM- und SYSTEM-"
#~ "Anweisungen (Kontext) automatisch aus. Bitte besuchen Sie die Website des "
#~ "Modells oder die Ollama-Dokumentation für weitere Informationen, wenn Sie "
#~ "unsicher sind."

#~ msgid "Create"
#~ msgstr "Erstellen"

#~ msgid "Stop Pulling '{}'"
#~ msgstr "Abrufen von '{}' stoppen"

#~ msgid "Details"
#~ msgstr "Details"

#~ msgid "Remove '{}'"
#~ msgstr "'{}' entfernen"

#~ msgid "Delete Model?"
#~ msgstr "Modell löschen?"

#~ msgid "Create Model Based on '{}'"
#~ msgstr "Modell basierend auf '{}' erstellen"

#~ msgid "Format"
#~ msgstr "Format"

#~ msgid "Enter download menu for {}"
#~ msgstr "Download-Menü für {} aufrufen"

#~ msgid "Download {}:{}"
#~ msgstr "{}:{} herunterladen"

#~ msgid "Model deleted successfully"
#~ msgstr "Modell erfolgreich gelöscht"

#~ msgid "Task Complete"
#~ msgstr "Aufgabe abgeschlossen"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "Modell '{}' erfolgreich abgerufen."

#~ msgid "Pull Model Error"
#~ msgstr "Fehler beim Abrufen des Modells"

#~ msgid "Failed to pull model '{}': {}"
#~ msgstr "Abrufen des Modells '{}' fehlgeschlagen: {}"

#~ msgid "Error pulling '{}': {}"
#~ msgstr "Fehler beim Abrufen von '{}': {}"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr ""
#~ "Abrufen des Modells '{}' aufgrund eines Netzwerkfehlers fehlgeschlagen."

#~ msgid "Error pulling '{}'"
#~ msgstr "Fehler beim Abrufen von '{}'"

#~ msgid "Script exited"
#~ msgstr "Skript beendet"

#~ msgid "The script is contained inside Flatpak"
#~ msgstr "Das Skript ist in Flatpak enthalten"

#~ msgid "Close application"
#~ msgstr "Anwendung schließen"

#~ msgid "Import chat"
#~ msgstr "Chat importieren"

#~ msgid "Clear chat"
#~ msgstr "Chat leeren"

#~ msgid "New chat"
#~ msgstr "Neuer Chat"

#~ msgid "Show shortcuts window"
#~ msgstr "Tastenkombinationen-Fenster anzeigen"

#~ msgid "Manage models"
#~ msgstr "Modelle verwalten"

#~ msgid "Toggle sidebar"
#~ msgstr "Seitenleiste ein-/ausblenden"

#~ msgid "Rename chat"
#~ msgstr "Chat umbenennen"

#~ msgid "Editor"
#~ msgstr "Editor"

#~ msgid "Message text box"
#~ msgstr "Nachrichtentextfeld"

#~ msgid "Missing file"
#~ msgstr "Fehlende Datei"

#~ msgid "Image Recognition"
#~ msgstr "Bilderkennung"

#~ msgid "This video is not available"
#~ msgstr "Dieses Video ist nicht verfügbar"

#~ msgid ""
#~ "An upgraded version of DeepSeek-V2 that integrates the general and coding "
#~ "abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
#~ msgstr ""
#~ "Eine verbesserte Version von DeepSeek-V2, die die allgemeinen und "
#~ "Programmierfähigkeiten von DeepSeek-V2-Chat und DeepSeek-Coder-V2-"
#~ "Instruct integriert."

#~ msgid "Select a Model"
#~ msgstr "Wähle ein Modell"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr ""
#~ "Chat kann während des Empfangs einer Nachricht nicht gelöscht werden"

#~ msgid "Create Chat?"
#~ msgstr "Chat erstellen?"

#~ msgid "Enter name for new chat"
#~ msgstr "Namen für neuen Chat eingeben"

#~ msgid "Use local instance"
#~ msgstr "Lokale Instanz verwenden"

#~ msgid "An error occurred while creating the model"
#~ msgstr "Beim Erstellen des Modells ist ein Fehler aufgetreten"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL der Remote-Instanz"

#~ msgid ""
#~ "Google Gemma 2 is a high-performing and efficient model by now available "
#~ "in three sizes: 2B, 9B, and 27B."
#~ msgstr ""
#~ "Google Gemma ist ein leistungsfähiges und effizientes Modell, dass ab "
#~ "sofort in drei Größen verfügbar ist: 2B, 9B und 27B."

#~ msgid "Loading instance"
#~ msgstr "Lade Instanz"

#~ msgid "Applying user preferences"
#~ msgstr "User-Vorgaben anwenden"

#~ msgid "Updating list of local models"
#~ msgstr "Liste der lokalen Modelle aktualisieren"

#~ msgid "Updating list of available models"
#~ msgstr "Liste der verfügbaren Modelle aktualisieren"

#~ msgid "Loading chats"
#~ msgstr "Chats laden"

#~ msgid "Loading Alpaca dialog"
#~ msgstr "Laden des Alpaca Dialogs"

#~ msgid "Loading Alpaca..."
#~ msgstr "Lade Alpaca..."

#~ msgid ""
#~ "A lightweight AI model with 3.8 billion parameters with performance "
#~ "overtaking similarly and larger sized models. "
#~ msgstr ""
#~ "Ein leichtgewichtiges KI-Modell mit 3,8 Milliarden Parametern, dessen "
#~ "Leistung , das ähnliche und größere Modelle übertrifft. "

#~ msgid "Fixed generated titles having '\"S' for some reason"
#~ msgstr "Generierte Titel haben aus irgendeinem Grund '\"S' - behoben"

#~ msgid "Fixed 'code blocks shouldnt be editable'"
#~ msgstr "Behoben: 'Codeblöcke sollten nicht editierbar sein'"

#~ msgid "Failed to connect to server"
#~ msgstr "Verbindung zum Server fehlgeschlagen"

#~ msgid "Stop Creating '{}'"
#~ msgstr "Erstellung von '{}' stoppen"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 ist jetzt in 2 Größen verfügbar, 9B und 27B."

#~ msgid ""
#~ "Codestral is Mistral AI's first-ever code model designed for code "
#~ "generation tasks."
#~ msgstr ""
#~ "Codestral ist das allererste Codemodell von Mistral AI, das für "
#~ "Codegenerierungsaufgaben entwickelt wurde."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr ""
#~ "Sind Sie sicher, dass Sie das Abrufen von '{} ({})' stoppen möchten?"
