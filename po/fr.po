# French translation for Alpaca package.
# Copyright (C) 2024 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# Louis Chauvet-Villaret <louis@revuejazz.fr>, 2024-2025.
#
msgid ""
msgstr ""
"Project-Id-Version: 3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-12 11:09-0600\n"
"PO-Revision-Date: 2025-03-12 22:44+0100\n"
"Last-Translator: Louis Chauvet-Villaret <louis@revuejazz.fr>\n"
"Language-Team: French\n"
"Language: fr\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Gtranslator 47.1\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ia;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1119
msgid "Features"
msgstr "Fonctionnalités"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1121
msgid "Talk to multiple models in the same conversation"
msgstr "Discutez avec plusieurs modèles dans un même discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1122
msgid "Pull and delete models from the app"
msgstr "Gestion des modèles depuis l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "Plusieurs conversations"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "Reconnaissance d'image (modèles compatibles)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "Reconnaissance de documents en texte brut"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "Importez et exportez les discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "Ajouter une transcription YouTube au prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "Ajouter le texte d'un site web au prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "Reconnaissance des PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/window.ui:90
msgid "Disclaimer"
msgstr "Avertissement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"Ce projet n'est pas affilié avec Ollama. Nous ne sommes aucunement "
"responsable des dommages causés à votre appareil ou vos logiciels suite à "
"l'exécution de code donné par un modèle."

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "Une discussion normale avec un modèle d'IA"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "Une discussion impliquant de la reconnaissance d'image"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "Une discussion avec un modèle personnalisé"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "Une discussion montrant de la coloration syntaxique de code"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "Un script Python lancé dans le terminal intégré"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation involving a YouTube video transcript"
msgstr "Une discussion impliquant une transcription d'une vidéo YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "Plusieurs modèles en téléchargement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "Model creator screen"
msgstr "Fenêtre de création de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:143
#: data/com.jeffser.Alpaca.metainfo.xml.in:161
#: data/com.jeffser.Alpaca.metainfo.xml.in:177
#: data/com.jeffser.Alpaca.metainfo.xml.in:189
#: data/com.jeffser.Alpaca.metainfo.xml.in:239
#: data/com.jeffser.Alpaca.metainfo.xml.in:285
#: data/com.jeffser.Alpaca.metainfo.xml.in:316
#: data/com.jeffser.Alpaca.metainfo.xml.in:325
#: data/com.jeffser.Alpaca.metainfo.xml.in:388
#: data/com.jeffser.Alpaca.metainfo.xml.in:416
#: data/com.jeffser.Alpaca.metainfo.xml.in:430
#: data/com.jeffser.Alpaca.metainfo.xml.in:447
#: data/com.jeffser.Alpaca.metainfo.xml.in:458
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:484
#: data/com.jeffser.Alpaca.metainfo.xml.in:494
#: data/com.jeffser.Alpaca.metainfo.xml.in:511
#: data/com.jeffser.Alpaca.metainfo.xml.in:521
#: data/com.jeffser.Alpaca.metainfo.xml.in:568
#: data/com.jeffser.Alpaca.metainfo.xml.in:593
#: data/com.jeffser.Alpaca.metainfo.xml.in:618
#: data/com.jeffser.Alpaca.metainfo.xml.in:640
#: data/com.jeffser.Alpaca.metainfo.xml.in:658
#: data/com.jeffser.Alpaca.metainfo.xml.in:676
#: data/com.jeffser.Alpaca.metainfo.xml.in:688
#: data/com.jeffser.Alpaca.metainfo.xml.in:704
msgid "Fixes"
msgstr "Correctifs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Instance manager now follows default model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:98
msgid "English text-to-speech voices not working"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
msgid "Instance manager sometimes not saving instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:100
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:107
#: data/com.jeffser.Alpaca.metainfo.xml.in:154
#: data/com.jeffser.Alpaca.metainfo.xml.in:171
#: data/com.jeffser.Alpaca.metainfo.xml.in:201
#: data/com.jeffser.Alpaca.metainfo.xml.in:211
#: data/com.jeffser.Alpaca.metainfo.xml.in:222
#: data/com.jeffser.Alpaca.metainfo.xml.in:249
#: data/com.jeffser.Alpaca.metainfo.xml.in:269
#: data/com.jeffser.Alpaca.metainfo.xml.in:295
#: data/com.jeffser.Alpaca.metainfo.xml.in:310
#: data/com.jeffser.Alpaca.metainfo.xml.in:335
#: data/com.jeffser.Alpaca.metainfo.xml.in:363
#: data/com.jeffser.Alpaca.metainfo.xml.in:373
#: data/com.jeffser.Alpaca.metainfo.xml.in:384
#: data/com.jeffser.Alpaca.metainfo.xml.in:398
#: data/com.jeffser.Alpaca.metainfo.xml.in:410
#: data/com.jeffser.Alpaca.metainfo.xml.in:426
#: data/com.jeffser.Alpaca.metainfo.xml.in:441
#: data/com.jeffser.Alpaca.metainfo.xml.in:476
#: data/com.jeffser.Alpaca.metainfo.xml.in:501
#: data/com.jeffser.Alpaca.metainfo.xml.in:532
#: data/com.jeffser.Alpaca.metainfo.xml.in:558
#: data/com.jeffser.Alpaca.metainfo.xml.in:580
#: data/com.jeffser.Alpaca.metainfo.xml.in:611
#: data/com.jeffser.Alpaca.metainfo.xml.in:633
#: data/com.jeffser.Alpaca.metainfo.xml.in:654
#: data/com.jeffser.Alpaca.metainfo.xml.in:669
#: data/com.jeffser.Alpaca.metainfo.xml.in:694
msgid "New"
msgstr "Nouveautés"

#: data/com.jeffser.Alpaca.metainfo.xml.in:109
msgid "Smart tools for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:110
msgid "Speech recognition (message dictation)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "Text to Speech"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:112
msgid "New Quick Chat system"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:113
msgid "Filter Ollama models by categories"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:114
msgid "Better math Latex rendering in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:115
msgid "Rich text rendering in attachment preview"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
msgid "Matplotlib is now included in Python code runner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:117
msgid "Styling for messages being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:119
#: data/com.jeffser.Alpaca.metainfo.xml.in:227
msgid "New Instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:121
msgid "Deepseek"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "OpenRouter AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Anthropic"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Groq Cloud"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Fireworks AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Lambda Labs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
msgid "New Attachment Types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:130
msgid "Microsoft Word Document (docx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:131
msgid "Microsoft PowerPoint Document (pptx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:132
msgid "Microsoft Excel Document (xlsx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "New Tools"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:136 src/tool_manager.py:431
msgid "Run Command (Testing)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:137 src/tool_manager.py:348
msgid "Online Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:138 src/tool_manager.py:306
msgid "Extract Wikipedia Article"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:139 src/tool_manager.py:210
msgid "Get Recipe by Name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:140 src/tool_manager.py:261
msgid "Get Recipes by Category"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:141 src/tool_manager.py:176
msgid "Get Current Datetime"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:145
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:146
msgid "Fixed bold text not rendering correctly in tables"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:147
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:156
msgid "Updated runtime to Gnome 48"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:157
msgid "Added back 'category pills' to model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:158
msgid "Better appearance for model manager sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:159
#: data/com.jeffser.Alpaca.metainfo.xml.in:175
msgid "New models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:163
msgid "Fixed bad title generation with chain-of-thought models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:164
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:173
msgid "Option to delete all chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:174
msgid "Button to refresh sample prompts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:179
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:180
msgid "Fixed stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Fixed model search not working if there are only pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Fixed sample prompts sometimes not appearing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:191
msgid "Don't clear the building output of C++ scripts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:192
msgid "Better handling of attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:193
msgid "Handle remote Ollama instance's API Key better"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:194
msgid "Remove '\\n' characters in instance edit page"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Dynamic chat loading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "Updated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Tweaked appearance of models in model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:214
msgid "Updated Ollama instance to 0.5.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:215
msgid "Added new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:224
msgid "New instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:225
msgid "New welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "OpenAI ChatGPT"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:230
msgid "Google Gemini"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:231
msgid "Together AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:232
msgid "Venice"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:242
msgid "Fixed attachment filters"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "New model manager"
msgstr "Nouveau gestionnaire de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:252
msgid "Changed GtkSpinner to AdwSpinner"
msgstr "Modifié : GtkSpinner vers AdwSpinner"

#: data/com.jeffser.Alpaca.metainfo.xml.in:253
msgid "Better handling of launch process"
msgstr "Modifié : meilleure gestion du démarrage"

#: data/com.jeffser.Alpaca.metainfo.xml.in:254
msgid "New loading screen at launch"
msgstr "Modifié : nouveau chargement au démarrage"

#: data/com.jeffser.Alpaca.metainfo.xml.in:255
msgid "Better handling of file types"
msgstr "Modifié : meilleure gestion des types de fichiers"

#: data/com.jeffser.Alpaca.metainfo.xml.in:256
msgid "Better regex expression for LaTeX equations"
msgstr "Modifié : meilleure expression régulière des équations LaTeX"

#: data/com.jeffser.Alpaca.metainfo.xml.in:257
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""
"Ajouté : fenêtre de confirmation si l'utilisateur quitte Alpaca lors du "
"téléchargement d'un modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:258
msgid "Better handling of think tags in messages"
msgstr "Modifié : meilleure gestion des étiquettes de pensée dans les messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:259
msgid "Default model is now in charge of generating titles"
msgstr "Modifié : le modèle par défaut génère maintenant les titres"

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "Message header is now shown whilst the message is being generated"
msgstr ""
"Modifié : l'entête des messages est maintenant affiché durant la génération"

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Better handling of model profile pictures"
msgstr "Modifié : meilleure gestion des photos de profil des modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "New models in 'available models' list"
msgstr "Ajouté : nouveaux modèles dans la listes des 'modèles disponibles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:271
msgid "Added option for attaching screenshots"
msgstr "Ajouté : option pour joindre des captures d'écran"

#: data/com.jeffser.Alpaca.metainfo.xml.in:272
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr "Modifié : les équations LaTeX sont maintenant généré dans les messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:273
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""
"Ajouté : les scripts HTML et C++ peuvent maintenant être exécuté dans Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:274
msgid "Added option to open the environment directory from the terminal"
msgstr ""
"Ajouté : option pour ouvrir le dossier environnement depuis le terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid "Added option to edit code blocks directly"
msgstr "Ajouté : option pour éditer les blocs de code directement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Complete keyboard shortcut list"
msgstr "Ajouté : raccourci clavier complété"

#: data/com.jeffser.Alpaca.metainfo.xml.in:277
msgid "Images are now attached in 640p resolution"
msgstr ""
"Modifié : les images sont maintenant jointe dans une résolution de 640p"

#: data/com.jeffser.Alpaca.metainfo.xml.in:278
msgid "Website attachments now use extracted titles"
msgstr "Modifié : l'ajout de site web utilise dorénavant les titres extraits"

#: data/com.jeffser.Alpaca.metainfo.xml.in:279
msgid "Better chat title generation"
msgstr "Modifié : meilleure génération des titres des discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:280
msgid "Added option to attach any plain text files"
msgstr "Ajouté : option pour ajouter n'importe quel type de fichiers textes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:281
msgid "Added spellchecker to message entry"
msgstr "Ajouté : vérification de l'orthographe dans la saisie de messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:282
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr ""
"Modifié : les paramètres de l'application sont maintenant stockés dans une "
"base de donnée SQLite3"

#: data/com.jeffser.Alpaca.metainfo.xml.in:283
msgid "Small appearance changes in text entries"
msgstr "Modifié : petit changement d'apparence dans la saisie de messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:287
msgid "Alpaca's launch process is more reliable"
msgstr "Corrigé : le processus de lancement d'Alpaca et plus sûr"

#: data/com.jeffser.Alpaca.metainfo.xml.in:288
msgid "Closing the terminal now kills the script subprocess"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:298
msgid "Changed appearance of messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:299
msgid "Added the option to add profile pictures to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:301
#: data/com.jeffser.Alpaca.metainfo.xml.in:773
#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Fix"
msgstr "Correctif"

#: data/com.jeffser.Alpaca.metainfo.xml.in:303
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Added categories to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid "Specified model's languages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Added warning when downloading embedding models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:318
msgid "Replaced low ram warning with big model warning"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:327
msgid "Correctly escape markup before rendering message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:328
msgid "Fixed about dialog not working if log file was missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:337
msgid "System messages can now be sent directly from Alpaca"
msgstr ""
"Changé : les messages systèmes peuvent désormais être envoyés depuis Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:338
msgid "New redesign for messages and smaller minimum size"
msgstr "Changé : nouveau design des messages et de la taille minimale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:339
msgid "New models included in 'available models list'"
msgstr "Ajouté : nouveaux modèles dans la 'liste des modèles disponibles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
msgid "Added symbolic icon when attaching code files"
msgstr "Ajouté : icône symbolique pour l'ajout de fichier de code"

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
msgid "When exporting a chat it now includes a markdown file"
msgstr ""
"Changé : lors de l'export d'une discussion un fichier markdown est "
"maintenant inclus"

#: data/com.jeffser.Alpaca.metainfo.xml.in:342
msgid "Refresh button in model manager when using a remote instance"
msgstr ""
"Ajouté : bouton d'actualisation dans le gestionnaire de modèle lors de "
"l'utilisation de l'instance distante"

#: data/com.jeffser.Alpaca.metainfo.xml.in:343
msgid "Assistant messages are now editable"
msgstr "Ajouté : les messages de l'assistant sont désormais éditable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:344
msgid "Updated Ollama to v0.5.2"
msgstr "Changé : Ollama mis-à-jour vers la version 0.5.2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:345
msgid "New option to change model directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:346
msgid "File previewer now resizes dynamically to content"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:347
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:348
msgid "Compatibility added with ODT files"
msgstr "Ajouté : compatibilité des fichiers ODT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:351
msgid "Restored ROCm compatibility"
msgstr "Changé : compatibilité ROCm restaurée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:352
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Ajouté : appui long sur les discussions fonctionnent maintenant avec les "
"écrans tactiles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "Fixed edit button not saving changes"
msgstr "Résolu : le bouton d'édition ne sauvegardait pas les changements"

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "Changed max temperature value to 2"
msgstr "Changé : valeur max de la température à 2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "Made seed 0 actually random"
msgstr "Résolu : mettre la graine à 0 est réellement aléatoire"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""
"Résolu : l'intégration Gnome Search ne fonctionnait pas en dehors des "
"installations Flatpak"

#: data/com.jeffser.Alpaca.metainfo.xml.in:365
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""
"Ajouté : nouvelle option --ask MESSAGE, pour ouvrir une nouvelle fenêtre "
"\"Question rapide\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:366
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""
"Changé : l'intégration à Gnome Search fonctionne maintenant lorsque "
"l'application est ouverte"

#: data/com.jeffser.Alpaca.metainfo.xml.in:375
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""
"Ajouté : paramètre d'exécution : --ask MESSAGE, --new-chat CHAT, --select-"
"chat CHAT, --list-chats, --version"

#: data/com.jeffser.Alpaca.metainfo.xml.in:376
msgid "Added integration as Gnome Search Provider"
msgstr "Ajouté : intégration à Gnome Search"

#: data/com.jeffser.Alpaca.metainfo.xml.in:377
msgid "Updated Ollama to v0.4.2 with new models"
msgstr ""
"Changé : Ollama mis-à-jour vers la versions 0.4.2 avec de nouveaux modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:386
msgid "User messages are now compacted into bubbles"
msgstr ""
"Changé : les messages utilisateurs sont maintenant compactés dans des bulles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:390
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""
"Résolu : la boite de dialogue de reconnexion ne fonctionnait pas lorsque "
"'utiliser l'instance local' était sélectionné"

#: data/com.jeffser.Alpaca.metainfo.xml.in:391
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""
"Résolu : le gestionnaire de modèle ne s'adaptait pas au système avec une "
"grande taille de police"

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "Details page for models"
msgstr "Ajouté : page de détails des modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:401
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""
"Ajouté : sélecteur de modèle remplacé par le bouton 'gestionnaire de modèle' "
"lorsqu'il y a aucun modèle de téléchargé"

#: data/com.jeffser.Alpaca.metainfo.xml.in:402
msgid "Added warning when model is too big for the device"
msgstr ""
"Ajouté : avertissement lorsque le modèle est trop lourd pour l'appareil"

#: data/com.jeffser.Alpaca.metainfo.xml.in:403
msgid "Added AMD GPU indicator in preferences"
msgstr "Ajouté : indicateur de GPU AMD dans les paramètres"

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "Better system for handling dialogs"
msgstr "Changé : meilleur système de prise en charge des boites de dialogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:413
msgid "Better system for handling instance switching"
msgstr "Changé : meilleur système de prise en charge du changement d'instance"

#: data/com.jeffser.Alpaca.metainfo.xml.in:414
msgid "Remote connection dialog"
msgstr "Ajouté : boite de dialogue de connexion distante"

#: data/com.jeffser.Alpaca.metainfo.xml.in:418
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""
"Résolu : les modèles se voyaient doublés lors du changement entre l'instance "
"distante vers l'instance locale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:419
msgid "Better internal instance manager"
msgstr "Changé : meilleur gestionnaire de l'instance interne"

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""
"Ajouté : bouton 'Annuler' et 'Sauvegarder' lors de l'édition d'un message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:432
msgid "Better handling of image recognition"
msgstr "Changé : meilleure prise en charge de la reconnaissance d'image"

#: data/com.jeffser.Alpaca.metainfo.xml.in:433
msgid "Remove unused files when canceling a model download"
msgstr ""
"Résolu : suppression des fichiers inutilisés lors de l'arrêt du "
"téléchargement d'un modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:434
msgid "Better message blocks rendering"
msgstr "Changé : meilleur rendu de l'arrêt de génération de message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:443
msgid "Run bash and python scripts straight from chat"
msgstr ""
"Ajouté : exécutez des scripts Python et bash directement depuis la discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:444
msgid "Updated Ollama to 0.3.12"
msgstr "Changé : Ollama mis-à-jour vers la version 0.3.12"

#: data/com.jeffser.Alpaca.metainfo.xml.in:445
msgid "New models!"
msgstr "Ajouté : nouveaux modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:449
msgid "Fixed and made faster the launch sequence"
msgstr "Résolu : séquence de lancement plus rapide"

#: data/com.jeffser.Alpaca.metainfo.xml.in:450
msgid "Better detection of code blocks in messages"
msgstr "Résolu : meilleur détection des blocs de code dans les messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:451
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""
"Résolu : l'application ne se lançait pas dans certaines configuration avec "
"des GPU Nvidia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""
"Résolu : la notification de message plantait sur le rendu du texte parce "
"qu'elle fonctionnait sur un thread différent"

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid "Fixed message generation sometimes failing"
msgstr "Résolu : la génération de messages plantait parfois"

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Sidebar resizes with the window"
msgstr "Changé : la barre latérale se redimensionne avec la fenêtre"

#: data/com.jeffser.Alpaca.metainfo.xml.in:479
msgid "New welcome dialog"
msgstr "Ajouté : nouvelle boite de dialogue de bienvenue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:480
msgid "Message search"
msgstr "Ajouté : recherche de message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:481
msgid "Updated Ollama to v0.3.11"
msgstr "Changé : Ollama mis-à-jour vers la version 0.3.11"

#: data/com.jeffser.Alpaca.metainfo.xml.in:482
msgid "A lot of new models provided by Ollama repository"
msgstr "Ajouté : beaucoup de nouveau modèles du dépôt d'Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:486
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""
"Résolu : texte à l'intérieur du gestionnaire de modèle quand l'option "
"d’accessibilité 'grand texte' est activée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:487
msgid "Fixed image recognition on unsupported models"
msgstr "Résolu : reconnaissance d'image sur certains modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""
"Résolu : l'indicateur de chargement ne se masquait pas lorsque la tâche "
"échouait"

#: data/com.jeffser.Alpaca.metainfo.xml.in:497
msgid "Fixed image recognition with local images"
msgstr "Résolu : reconnaissance d'image locales"

#: data/com.jeffser.Alpaca.metainfo.xml.in:498
msgid "Changed appearance of delete / stop model buttons"
msgstr "Changé : apparence des boutons de suppression et arrêt de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:499
msgid "Fixed stop button crashing the app"
msgstr "Résolu : le bouton arrêter faisait planter l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:503
msgid "Made sidebar resize a little when the window is smaller"
msgstr ""
"Changé : la barre latérale est légèrement redimmensionnée lorsque la fenêtre "
"est petite"

#: data/com.jeffser.Alpaca.metainfo.xml.in:504
msgid "Instant launch"
msgstr "Changé : lancement instantanée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:513
msgid "Fixed error on first run (welcome dialog)"
msgstr "Résolu : erreur au lancement (boite de dialogue de bienvenue)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:514
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""
"Résolu : vérification de l'instance Ollama (utilisé en tant que paquet "
"système)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:523
msgid "Fixed 'clear chat' option"
msgstr "Résolu : option 'effacer la discussion'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:524
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""
"Résolu : la boite de dialogue de bienvenue empêchait l'instance locale de "
"démarrer"

#: data/com.jeffser.Alpaca.metainfo.xml.in:525
msgid "Fixed support for AMD GPUs"
msgstr "Résolu : support des GPU AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:534
msgid "Model, message and chat systems have been rewritten"
msgstr ""
"Changé : réécriture du système de discussion, gestion des modèles et messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:535
msgid "New models are available"
msgstr "Ajouté : nouveau modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:536
msgid "Ollama updated to v0.3.9"
msgstr "Changé : Ollama mis à jour vers la version v0.3.9"

#: data/com.jeffser.Alpaca.metainfo.xml.in:537
msgid "Added support for multiple chat generations simultaneously"
msgstr "Ajouté : support de la génération de plusieurs discussions simultanées"

#: data/com.jeffser.Alpaca.metainfo.xml.in:538
msgid "Added experimental AMD GPU support"
msgstr "Ajouté : support expérimental des GPU AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:539
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""
"Ajouté : icône de chargement des messages et un indicateur de message sur "
"l'onglet discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:540
msgid "Added animations"
msgstr "Ajouté : animation"

#: data/com.jeffser.Alpaca.metainfo.xml.in:541
msgid "Changed model manager / model selector appearance"
msgstr "Changé : apparence du gestionnaire et sélecteur de modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:542
msgid "Changed message appearance"
msgstr "Changé : apparence des messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:543
msgid "Added markdown and code blocks to user messages"
msgstr ""
"Ajouté : support du markdown et des blocs de code pour les messages "
"utilisateurs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:544
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""
"Ajouté : boite de dialogue de chargement au démarrage pour que l'application "
"s'ouvre plus rapidement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""
"Ajouté : avertissement lorsque l'appareil est en mode 'économisateur de "
"batterie'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:546
msgid "Added inactivity timer to integrated instance"
msgstr "Ajouté : minuteur d'inactivité pour l'instance intégrée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr ""
"Résolu : la discussion est maintenant scrollé en bas lorsqu'elle est changée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid "Better handling of focus on messages"
msgstr "Ajouté : meilleur prise en charge de l'indicateur de sélection"

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Better general performance on the app"
msgstr "Résolu : meilleures performances générales dans l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "New duplicate chat option"
msgstr "Ajouté : option pour dupliquer la discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:561
msgid "Changed model selector appearance"
msgstr "Changé : apparence du sélecteur de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:562
msgid "Message entry is focused on launch and chat change"
msgstr ""
"Changé : la saisie des messages est sélectionnée au démarrage et lors du "
"changement de discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:563
msgid "Message is focused when it's being edited"
msgstr "Changé : le message est sélectionné lorsqu'il est édité"

#: data/com.jeffser.Alpaca.metainfo.xml.in:564
msgid "Added loading spinner when regenerating a message"
msgstr "Ajouté : loader lorsque l'on regénère un message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:565
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr "Ajouté : débogage Ollama à la boite de dialogue 'À propos d'Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:566
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr "Changé : apparence de la boite de dialogue des transcriptions YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:570
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""
"Résolu : Ctrl + W et Ctrl + Q stoppent désormais l'instance local avant de "
"fermer l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:571
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""
"Changé : apparence du bouton \"Ouvrir le Gestionnaire de modèle\" sur "
"l'écran de bienvenue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:572
msgid "Fixed message generation not working consistently"
msgstr "Résolu : la génération de messages fonctionnait mal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:573
msgid "Fixed message edition not working consistently"
msgstr "Résolu : l'édition de message fonctionnait mal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:582
msgid "Model manager opens faster"
msgstr "Changé : le gestionnaire de modèle s'ouvre plus rapidement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:583
msgid "Delete chat option in secondary menu"
msgstr "Ajouté : option pour supprimer la discussion dans le menu secondaire"

#: data/com.jeffser.Alpaca.metainfo.xml.in:584
msgid "New model selector popup"
msgstr "Ajouté : nouveau pop-up de sélection de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:585
msgid "Standard shortcuts"
msgstr "Ajouté : raccourcis claviers standards"

#: data/com.jeffser.Alpaca.metainfo.xml.in:586
msgid "Model manager is navigable with keyboard"
msgstr "Ajouté : le gestionnaire de modèle est navigable avec le clavier"

#: data/com.jeffser.Alpaca.metainfo.xml.in:587
msgid "Changed sidebar collapsing behavior"
msgstr "Changé : comportement de la barre latérale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:588
msgid "Focus indicators on messages"
msgstr "Ajouté : indicateur de sélection sur les messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:589
msgid "Welcome screen"
msgstr "Ajouté : écran de bienvenue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:590
msgid "Give message entry focus at launch"
msgstr "Ajouté : saisie sélectionnée au démarrage"

#: data/com.jeffser.Alpaca.metainfo.xml.in:591
msgid "Generally better code"
msgstr "Meilleur code en général"

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Better width for dialogs"
msgstr "Changé : meilleur largeur des boites de dialogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Better compatibility with screen readers"
msgstr "Ajouté : meilleur compatibilité pour les lecteurs d'écran"

#: data/com.jeffser.Alpaca.metainfo.xml.in:597
msgid "Fixed message regenerator"
msgstr "Résolu : générateur de message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Removed 'Featured models' from welcome dialog"
msgstr ""
"Changé : modèles recommandés supprimés de la boite de dialogue de bienvenue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid "Added default buttons to dialogs"
msgstr "Ajouté : bouton par défaut sur les boites de dialogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:600
msgid "Fixed import / export of chats"
msgstr "Résolu : import/export des discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:601
msgid "Changed Python2 title to Python on code blocks"
msgstr "Résolu : titre \"python2\" changé en \"python\" sur les blocs de code"

#: data/com.jeffser.Alpaca.metainfo.xml.in:602
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""
"Résolu : empêcher la génération d'un titre lorsque l'utilisateur en avait "
"déjà choisi un"

#: data/com.jeffser.Alpaca.metainfo.xml.in:603
msgid "Show date on stopped messages"
msgstr "Résolu : afficher la date sur les messages stoppés"

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Fix clear chat error"
msgstr "Résolu : erreur d'effacement de discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Changed shortcuts to standards"
msgstr "Changé : raccourcis clavier standards"

#: data/com.jeffser.Alpaca.metainfo.xml.in:614
msgid "Moved 'Manage Models' button to primary menu"
msgstr "Changé : bouton 'Gestion des modèles' déplacé dans le menu principal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:615
#: data/com.jeffser.Alpaca.metainfo.xml.in:637
msgid "Stable support for GGUF model files"
msgstr "Ajout : support stable des fichiers de modèle GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
#: data/com.jeffser.Alpaca.metainfo.xml.in:891
msgid "General optimizations"
msgstr "Optimisations générales"

#: data/com.jeffser.Alpaca.metainfo.xml.in:620
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""
"Changé : meilleur support de la touche entrée (important pour les entrées en "
"Japonais)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Removed sponsor dialog"
msgstr "Changé : suppression de la boite de dialogue pour de sponsor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Added sponsor link in about dialog"
msgstr ""
"Ajouté : ajout d'un lien pour sponsoriser dans la boite de dialogue À propos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Changed window and elements dimensions"
msgstr "Changé : dimension de la fenêtre et des éléments"

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "Selected model changes when entering model manager"
msgstr ""
"Changé : les modèles sélectionnés change lorsqu'on entre dans le "
"gestionnaire de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Better image tooltips"
msgstr "Ajouté : meilleur infobulles pour les images"

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "GGUF Support"
msgstr "Ajouté : support des fichiers GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:635
msgid "Regenerate any response, even if they are incomplete"
msgstr "Régénérer n'importe quelles réponses, même si elles sont incomplètes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:636
msgid "Support for pulling models by name:tag"
msgstr ""
"Ajouté : support du téléchargement de modèle son id de type nom: étiquette "
"(name:tag)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:638
msgid "Restored sidebar toggle button"
msgstr "Changé : bouton de basculement d'état de la barre latérale restorée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid "Reverted back to standard styles"
msgstr "Changé : retour au style standard"

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr "Résolu : la génération de titre avait des \"S\" pour certaines raisons"

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Changed min width for model dropdown"
msgstr "Changé : largeur minimum pour le menu de sélection de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Changed message entry shadow"
msgstr "Changé : ombre de la saisie des messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "The last model used is now restored when the user changes chat"
msgstr ""
"Ajouté : le dernier modèle utilisé est maintenant lorsque l'utilisateur "
"change de discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Better check for message finishing"
msgstr "Changé : meilleur vérification de la fin des messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:656
msgid "Added table rendering (Thanks Nokse)"
msgstr "Ajouté : rendu des tableau (Merci Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:660
msgid "Made support dialog more common"
msgstr "Changé : boite de dialogue de support plus commune"

#: data/com.jeffser.Alpaca.metainfo.xml.in:661
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""
"Résolu : le titre de la boite de dialogue du sélecteur d'étiquettes lors du "
"téléchargement de modèle ne s'affichait pas correctement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:662
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr "Changé : empêche la génération d'un titre avec plusieurs lignes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Bearer Token entry on connection error dialog"
msgstr ""
"Ajouté : boite de dialogue d'erreur pour saisir le Bearer Token lors de la "
"connexion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:672
msgid "Small appearance changes"
msgstr "Changé : petits changements d'apparences"

#: data/com.jeffser.Alpaca.metainfo.xml.in:673
msgid "Compatibility with code blocks without explicit language"
msgstr "Ajouté : compatibilité des blocs de code sans langage explicité"

#: data/com.jeffser.Alpaca.metainfo.xml.in:674
msgid "Rare, optional and dismissible support dialog"
msgstr "Ajouté : boite de dialogue de support rare, optionnel et masquable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Date format for Simplified Chinese translation"
msgstr "Ajouté : format de date pour la traduction en Chinois simplifié"

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid "Bug with unsupported localizations"
msgstr "Résolu : bogue avec les localisations non supportés"

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Min height being too large to be used on mobile"
msgstr ""
"Résolu : la hauteur minimum était trop élevée pour être utilisée sur mobile"

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Remote connection checker bug"
msgstr "Résolu : bogue du vérificateur de la connexion à distance"

#: data/com.jeffser.Alpaca.metainfo.xml.in:690
msgid "Models with capital letters on their tag don't work"
msgstr ""
"Résolu : les modèles avec des lettres capital dans leur étiquette ne "
"fonctionnait pas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:691
msgid "Ollama fails to launch on some systems"
msgstr "Résolu : Ollama ne démarrait pas sur certains systèmes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:692
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""
"Résolu : les transcriptions YouTube n'étaient pas sauvegardées dans le bon "
"dossier TMP"

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""
"Ajouté : les messages de débogage sont maintenant affichés dans la boite de "
"dialogue 'À propos d'Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr "Changé : Ollama mis à jour vers la version 0.3.0 (nouveau modèles)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""
"Résolu : les modèles avec des '-' dans leur nom ne fonctionnait pas "
"correctement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:707
msgid "Better connection check for Ollama"
msgstr "Ajouté : meilleure vérification de connexion pour Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:714
msgid "Stable Release"
msgstr "Version stable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:715
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""
"Changé : la nouvelle icône a été créée par Tobias Bernard à travers le "
"Gitlab de Gnome, merci pour cette belle icône !"

#: data/com.jeffser.Alpaca.metainfo.xml.in:716
msgid "Features and fixes"
msgstr "Correctifs et fonctionnalités"

#: data/com.jeffser.Alpaca.metainfo.xml.in:718
msgid "Updated Ollama instance to 0.2.8"
msgstr "Changé : instance Ollama mise à jour vers la version 0.2.8"

#: data/com.jeffser.Alpaca.metainfo.xml.in:719
msgid "Better model selector"
msgstr "Ajouté : meilleur sélecteur de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:720
msgid "Model manager redesign"
msgstr "Changé : redesign du gestionnaire de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "Better tag selector when pulling a model"
msgstr ""
"Ajouté : meilleur sélecteur d'étiquette lors du téléchargement d'un modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:722
msgid "Model search"
msgstr "Recherche de modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Added support for bearer tokens on remote instances"
msgstr ""
"Ajouté : support des jetons porteurs (Bearer Token) pour les instances "
"distantes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid "Preferences dialog redesign"
msgstr "Changé : boite de dialogue des préférences redesigné"

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Added context menus to interact with a chat"
msgstr "Ajouté : menu contextuel pour interagir avec une discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:726
msgid "Redesigned primary and secondary menus"
msgstr "Changé : menu primaire et secondaire redesigné"

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""
"Intégration YouTube : Collez l'URL d'une vidéo avec une transcription et "
"elle sera ajoutée au prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""
"Intégration des site web (Expérimental) : Extrait le texte du corps du site "
"en ajoutant son URL au prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Chat title generation"
msgstr "Ajouté : génération du titre des discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:730
msgid "Auto resizing of message entry"
msgstr "Changé : auto redimensionnement de la boite de saisie"

#: data/com.jeffser.Alpaca.metainfo.xml.in:731
msgid "Chat notifications"
msgstr "Ajouté : notification de discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:732
msgid "Added indicator when an image is missing"
msgstr "Ajouté : indicateur d'image manquante"

#: data/com.jeffser.Alpaca.metainfo.xml.in:733
msgid "Auto rearrange the order of chats when a message is received"
msgstr "Ajouté : réarrange l'ordre des discussions lorsqu'un message est reçu"

#: data/com.jeffser.Alpaca.metainfo.xml.in:734
msgid "Redesigned file preview dialog"
msgstr "Changé : boite de dialogue de prévisualisation de fichier redesigné"

#: data/com.jeffser.Alpaca.metainfo.xml.in:735
msgid "Credited new contributors"
msgstr "Ajouté : crédit aux nouveaux contributeurs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:736
msgid "Better stability and optimization"
msgstr "Meilleur stabilité et optimisation"

#: data/com.jeffser.Alpaca.metainfo.xml.in:737
msgid "Edit messages to change the context of a conversation"
msgstr ""
"Ajouté : éditez les messages pour changer le contexte d'une conversation"

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Added disclaimers when pulling models"
msgstr "Ajouté : avertissement lors du téléchargement d'un modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:739
msgid "Preview files before sending a message"
msgstr "Ajouté : prévisualisation des fichiers avant d'envoyer un message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Better format for date and time on messages"
msgstr "Changé : meilleur format pour la date et le temps sur les messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:741
msgid "Error and debug logging on terminal"
msgstr "Ajouté : journalisation des erreurs et du débogage sur le terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Auto-hiding sidebar button"
msgstr "Changé : masquage automatique du bouton de la barre latéral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Various UI tweaks"
msgstr "Changé : ajustements d'interface variés"

#: data/com.jeffser.Alpaca.metainfo.xml.in:745
msgid "New Models"
msgstr "Ajouté : nouveau modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "Gemma2"
msgstr "Gemma2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:748
msgid "GLM4"
msgstr "GLM4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:749
msgid "Codegeex4"
msgstr "Codegeex4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:750
msgid "InternLM2"
msgstr "InternLM2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Llama3-groq-tool-use"
msgstr "Llama3-groq-tool-use"

#: data/com.jeffser.Alpaca.metainfo.xml.in:752
msgid "Mathstral"
msgstr "Mathstral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:753
msgid "Mistral-nemo"
msgstr "Mistral-nemo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "Firefunction-v2"
msgstr "Firefunction-v2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:755
msgid "Nuextract"
msgstr "Nuextract"

#: data/com.jeffser.Alpaca.metainfo.xml.in:757
msgid "Translations"
msgstr "Traductions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:758
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""
"Voici toutes les traductions disponibles pour la version 1.0.0, merci à tout "
"les contributeurs !"

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Russian: Alex K"
msgstr "Russe: Alex K"

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Spanish: Jeffser"
msgstr "Espagnol: Jeffser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Brazilian Portuguese: Daimar Stein"
msgstr "Portugais brésilien: Daimar Stein"

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "French: Louis Chauvet-Villaret"
msgstr "Français: Louis Chauvet-Villaret"

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "Norwegian: CounterFlow64"
msgstr "Norvégien : CounterFlow64"

#: data/com.jeffser.Alpaca.metainfo.xml.in:765
msgid "Bengali: Aritra Saha"
msgstr "Bengali : Aritra Saha"

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Simplified Chinese: Yuehao Sui"
msgstr "Chinois simplifié : Yuehao Sui"

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""
"Changé : Suppression de la compatibilité des documents .docx à cause d'une "
"erreur avec la dépendance python-lxml"

#: data/com.jeffser.Alpaca.metainfo.xml.in:780
#: data/com.jeffser.Alpaca.metainfo.xml.in:810
#: data/com.jeffser.Alpaca.metainfo.xml.in:831
#: data/com.jeffser.Alpaca.metainfo.xml.in:1036
#: data/com.jeffser.Alpaca.metainfo.xml.in:1093
msgid "Big Update"
msgstr "Mise à jour majeure"

#: data/com.jeffser.Alpaca.metainfo.xml.in:782
msgid "Added compatibility for PDF"
msgstr "Ajouté : compatibilité pour les documents PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid "Added compatibility for DOCX"
msgstr "Ajouté : compatibilité pour les documents Word (.docx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:784
msgid "Merged 'file attachment' menu into one button"
msgstr "Changé : fusion du menu \"ajouter un fichier\" en un unique bouton"

#: data/com.jeffser.Alpaca.metainfo.xml.in:791
#: data/com.jeffser.Alpaca.metainfo.xml.in:984
msgid "Quick Fix"
msgstr "Petite correction de bogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:792
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""
"Résolu : il y avait quelques erreurs lors de la transition de l'ancienne "
"version des discussions vers la nouvelle. Nous nous excusons si cela a "
"corrompu votre historique de discussion. Cela devrait être la seule fois "
"qu'une telle modification ait lieu."

#: data/com.jeffser.Alpaca.metainfo.xml.in:798
#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Huge Update"
msgstr "Mise à jour majeure"

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
msgid "Added: Support for plain text files"
msgstr "Ajouté : support des documents de type texte brut"

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Added: New backend system for storing messages"
msgstr "Ajouté : nouveau système en arrière-plan de sauvegarde des messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Added: Support for changing Ollama's overrides"
msgstr "Ajouté : support pour changer les paramètres d'Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:803
msgid "General Optimization"
msgstr "Optimisation générale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "Added: Support for GGUF models (experimental)"
msgstr "Ajouté : support des modèles GGUF (éxpérimental)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
msgid "Added: Support for customization and creation of models"
msgstr "Ajouté : support de la personnalisation et création de modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr ""
"Résolu : certaines icônes n'apparaissait pas sur les systèmes ne "
"fonctionnant pas avec le bureau Gnome"

#: data/com.jeffser.Alpaca.metainfo.xml.in:815
msgid "Update Ollama to v0.1.39"
msgstr "Mise à jour vers Ollama 0.1.39"

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""
"Résolu : l'application ne s'ouvrait pas si les ajustements de modèles "
"n'étaient pas présents dans les fichiers de configuration"

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr "Changé : plusieurs icônes (avion en papier pour envoyer)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:834
msgid "Combined export / import chat buttons into a menu"
msgstr "Changé : bouton d'import et export des discussions combiné"

#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr "Ajouté :  options de modèle (temperature, seed, keep_alive)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid "Fixed send / stop button"
msgstr "Résolu : bouton envoyer / stopper"

#: data/com.jeffser.Alpaca.metainfo.xml.in:837
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""
"Résolu : l'application ne vérifiait si la connexion à distance fonctionnait "
"au démarrage"

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Daily Update"
msgstr "Mise à jour quotidienne"

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""
"Résolu : ajout de point de suspension sur les noms des discussions pour ne "
"pas changer la position des boutons"

#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr "Ajouté : nouveau raccourci pour créer un chat (Ctrl+N)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "New message entry design"
msgstr "Changé : nouveau design de la barre de message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:849
msgid "Fixed: Can't rename the same chat multiple times"
msgstr "Résolu : impossible de renommer la même discussion plusieurs fois"

#: data/com.jeffser.Alpaca.metainfo.xml.in:856
msgid "The fix"
msgstr "Correction de bogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:858
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""
"Résolu : Ollama continuait de s'exécuter en arrière plan même étant désactivé"

#: data/com.jeffser.Alpaca.metainfo.xml.in:859
msgid "Fixed: Can't pull models on the integrated instance"
msgstr "Résolu : impossible de télécharger les modèles sur l'instance locale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:866
msgid "Quick tweaks"
msgstr "Petites ajustements"

#: data/com.jeffser.Alpaca.metainfo.xml.in:868
msgid "Added progress bar to models that are being pulled"
msgstr "Ajouté : barre de progression sur les modèles en téléchargement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:869
msgid "Added size to tags when pulling a model"
msgstr "Ajouté : taille des étiquettes de modèle avant le téléchargement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:870
msgid "General optimizations on the background"
msgstr "Optimisations générales en arrière-plan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Quick fixes"
msgstr "Petites corrections de bogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "Fixed: Scroll when message is received"
msgstr "Résolu : défilement lors de la réception d'un message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:880
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr ""
"Résolu : Le contenu ne change pas lors de la création d'un nouveau chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:881
msgid "Added 'Featured Models' page on welcome dialog"
msgstr "Ajouté : page 'Modèles Suggérés' sur la fenêtre de dialogue d'accueil"

#: data/com.jeffser.Alpaca.metainfo.xml.in:888
msgid "Nice Update"
msgstr "Mise à jour sympa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:890
msgid "UI tweaks (Thanks Nokse22)"
msgstr "Changé : ajustement de l'interface utilisateur (Merci Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:892
msgid "Metadata fixes"
msgstr "Résolu : métadonnées"

#: data/com.jeffser.Alpaca.metainfo.xml.in:899
msgid "Quick fix"
msgstr "Petite correction de bogue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:901
msgid "Updated Spanish translation"
msgstr "Changé : mise à jour de la traduction Espagnol"

#: data/com.jeffser.Alpaca.metainfo.xml.in:902
msgid "Added compatibility for PNG"
msgstr "Ajouté : compatibilité pour les images PNG"

#: data/com.jeffser.Alpaca.metainfo.xml.in:909
msgid "New Update"
msgstr "Mise à jour"

#: data/com.jeffser.Alpaca.metainfo.xml.in:911
msgid "Updated model list"
msgstr "Changé : Liste des modèles mise à jour"

#: data/com.jeffser.Alpaca.metainfo.xml.in:912
msgid "Added image recognition to more models"
msgstr "Ajouté : reconnaissance d'image à plus de modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:913
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr "Ajouté : traduction en Portugais Brésilien (merci à Daimaar Stein)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:914
msgid "Refined the general UI (Thanks Nokse22)"
msgstr "Changé : peaufinage de l'interface utilisateur (merci à Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:915
msgid "Added 'delete message' feature"
msgstr "Ajouté : option 'supprimer le message'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""
"Ajouté : métadonnées pour que les distributeurs de logiciels sachent que "
"l'application est compatible avec les téléphones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:917
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""
"Changé : remplacement du raccourci 'envoyer' en une simple touche retour/"
"entrée (pour ajouter une nouvelle ligne, utiliser shift+retour)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "Bug Fixes"
msgstr "Correction de bogues"

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid "Fixed: Minor spelling mistake"
msgstr "Résolu : petite faute d'orthographe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:927
msgid "Added 'mobile' as a supported form factor"
msgstr "Ajouté : mise en page 'mobile'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr ""
"Résolu : La boîte de dialogue « Erreur de connexion » ne fonctionnait pas "
"correctement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "Fixed: App might freeze randomly on startup"
msgstr "Résolu : L'application pouvait se bloquer aléatoirement au démarrage"

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr ""
"Changé : remplacement du titre 'chats' de la barre latéral par 'Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:937
msgid "Cool Update"
msgstr "Mise à jour sympa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:939
msgid "Better design for chat window"
msgstr "Changé : meilleur design pour de fenêtre de discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:940
msgid "Better design for chat sidebar"
msgstr "Changé : meilleur design pour de la barre latérale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:941
msgid "Fixed remote connections"
msgstr "Résolu : connexions à distance"

#: data/com.jeffser.Alpaca.metainfo.xml.in:942
msgid "Fixed Ollama restarting in loop"
msgstr "Résolu : Ollama redémarrait en boucle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:943
msgid "Other cool backend stuff"
msgstr "Autre trucs sympa en arrière-plan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr "Ajouté : Ollama intégré à Alpaca dans un bac à sable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:953
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""
"Ajouté : option pour se connecter à des instances distantes (comme cela "
"fonctionnait précédemment)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:954
msgid "Added option to import and export chats"
msgstr "Ajouté : option pour importer et exporter les discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:955
msgid "Added option to run Alpaca with Ollama in the background"
msgstr "Ajouté : option pour exécuter Alpaca avec Ollama en arrière-plan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:956
msgid "Added preferences dialog"
msgstr "Ajouté : boite de dialogue des préférences"

#: data/com.jeffser.Alpaca.metainfo.xml.in:957
msgid "Changed the welcome dialog"
msgstr "Changé : boite de dialogue de bienvenue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
#: data/com.jeffser.Alpaca.metainfo.xml.in:976
#: data/com.jeffser.Alpaca.metainfo.xml.in:988
#: data/com.jeffser.Alpaca.metainfo.xml.in:1007
#: data/com.jeffser.Alpaca.metainfo.xml.in:1028
#: data/com.jeffser.Alpaca.metainfo.xml.in:1044
#: data/com.jeffser.Alpaca.metainfo.xml.in:1060
#: data/com.jeffser.Alpaca.metainfo.xml.in:1074
#: data/com.jeffser.Alpaca.metainfo.xml.in:1084
#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
#: data/com.jeffser.Alpaca.metainfo.xml.in:1124
msgid "Please report any errors to the issues page, thank you."
msgstr ""
"Merci de reporter n'importe quel problèmes sur la page 'issues' du GitHub."

#: data/com.jeffser.Alpaca.metainfo.xml.in:967
msgid "Yet Another Daily Update"
msgstr "Mise à jour quotidienne"

#: data/com.jeffser.Alpaca.metainfo.xml.in:969
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""
"Ajouté : une meilleure interface utilisateur pour la boite de dialogue "
"'Gestion des modèles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:970
msgid "Added better UI for the chat sidebar"
msgstr "Ajouté : meilleure interface utilisateur pour la barre latérale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:971
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""
"Changé : remplacement de la description du modèle par un bouton pour ouvrir "
"le site web Ollama pour le modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid "Added myself to the credits as the spanish translator"
msgstr "Ajouté : moi-même aux crédits en tant que traducteur espagnol"

#: data/com.jeffser.Alpaca.metainfo.xml.in:973
msgid "Using XDG properly to get config folder"
msgstr ""
"Changé : utilisation de XDG correctement pour avoir un dossier de "
"configuration"

#: data/com.jeffser.Alpaca.metainfo.xml.in:974
msgid "Update for translations"
msgstr "Mise à jour concernant les traductions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:986
msgid "The last update had some mistakes in the description of the update"
msgstr "La dernière mise à jour avait quelques erreurs dans sa description"

#: data/com.jeffser.Alpaca.metainfo.xml.in:996
msgid "Another Daily Update"
msgstr "Mise à jour quotidienne"

#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid "Added full Spanish translation"
msgstr "Ajouté : traduction complète Espagnol"

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid "Added support for background pulling of multiple models"
msgstr ""
"Ajouté : support pour le téléchargement de plusieurs modèles en arrière-plan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1000
msgid "Added interrupt button"
msgstr "Ajouté : bouton d'interruptions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1001
msgid "Added basic shortcuts"
msgstr "Ajouté : raccourcis claviers simples"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1002
msgid "Better translation support"
msgstr "Ajouté : meilleur support des traductions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1003
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""
"Ajouté : l'utilisateur peut maintenant quitter une discussion vide quand il "
"en crée un nouvelle, cela va ajouter un nom de remplacement"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1004
msgid "Better scalling for different window sizes"
msgstr "Résolu : meilleure mise à l'échelle pour différente taille de fenêtre"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1005
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""
"Résolu : impossible de fermer l'application si la première configuration "
"échouait"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1015
msgid "Really Big Update"
msgstr "Mise à jour majeure"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1017
msgid "Added multiple chats support!"
msgstr "Ajouté : support de plusieurs discussions"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1018
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""
"Ajouté : support de Pango Markup (gras, liste, titre, sous-titre, chasse-"
"fixe)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1019
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""
"Ajouté : défilement automatique si l'utilisateur est en haut d'une discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1020
msgid "Added support for multiple tags on a single model"
msgstr "Ajouté : support de plusieurs étiquettes sur un seul modèle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1021
msgid "Added better model management dialog"
msgstr "Ajouté : meilleure boite de dialogue pour la gestion des modèles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1022
msgid "Added loading spinner when sending message"
msgstr "Ajouté : icône de chargement lors de l'envoie d'un message"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1023
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""
"Ajouté : notification si l'application n'est pas active et que le "
"téléchargement d'un modèle est en cours"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "Added new symbolic icon"
msgstr "Ajouté : nouveau icônes symboliques"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1025
msgid "Added frame to message textview widget"
msgstr "Ajouté : cadre pour le widget des messages"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1026
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr "Résolu : 'les blocs de codes ne devraient pas être édité'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1038
msgid "Added code highlighting"
msgstr "Ajouté : coloration syntaxique du code"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1039
msgid "Added image recognition (llava model)"
msgstr "Ajouté : reconnaissance d'image (modèle llava)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1040
msgid "Added multiline prompt"
msgstr "Ajouté : prompt multilignes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1041
msgid "Fixed some small bugs"
msgstr "Quelques petits bogues résolus"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1042
msgid "General optimization"
msgstr "Optimisation générale"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1052
msgid "Fixes and features"
msgstr "Correctifs et fonctionnalités"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1054
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr "Traduction russe (Merci github/alexkdeveloper)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1055
msgid "Fixed: Cannot close app on first setup"
msgstr ""
"Résolu : impossible de fermer l'application lors de la première configuration"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1056
msgid "Fixed: Brand colors for Flathub"
msgstr "Résolu : couleur de marque pour Flathub"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1057
msgid "Fixed: App description"
msgstr "Résolu : description de l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1058
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""
"Résolu : affiche uniquement la 'boite de dialogue enregistrement des "
"modifications' lorsque vous changez réellement l'URL"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1068
msgid "0.2.2 Bug fixes"
msgstr "0.2.2 Correctifs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1070
msgid "Toast messages appearing behind dialogs"
msgstr ""
"Résolu : les messages pop-up (toast) apparaissaient derrière les boites de "
"dialogue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1071
msgid "Local model list not updating when changing servers"
msgstr ""
"Résolu : la liste des modèles locaux ne se mettait pas à jour lors du "
"changement de serveur"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1072
msgid "Closing the setup dialog closes the whole app"
msgstr ""
"Résolu : fermer la boite de dialogue de configuration fermait l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1082
msgid "0.2.1 Data saving fix"
msgstr "0.2.1 Correction de la sauvegarde des données"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1083
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""
"Résolu : l'application ne sauvegardait pas le fichier de configuration et "
"l'historique des discussions dans le bon dossier"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1092
msgid "0.2.0"
msgstr "0.2.0"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1094
msgid "New Features"
msgstr "Nouvelles fonctionnalités"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1096
msgid "Restore chat after closing the app"
msgstr "Ajouté : restaure la discussion après la fermeture de l'application"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1097
msgid "A button to clear the chat"
msgstr "Ajouté : bouton pour effacer la discussion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1098
msgid "Fixed multiple bugs involving how messages are shown"
msgstr ""
"Résolu : correction de plusieurs bogues impliquant comment les messages sont "
"affichés"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1099
msgid "Added welcome dialog"
msgstr "Ajouté : boite de dialogue de bienvenue"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1100
msgid "More stability"
msgstr "Plus de stabilité"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1110
msgid "0.1.2 Quick fixes"
msgstr "0.1.2 Petits correctifs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1111
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""
"Cette version corrige certaine métadonnées nécessaires pour avoir une "
"application Flatpak appropriée"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1117
msgid "0.1.1 Stable Release"
msgstr "0.1.1 Version stable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1118
msgid "This is the first public version of Alpaca"
msgstr "Ceci est la première version publique d'Alpaca"

#: src/main.py:193
msgid "Documentation"
msgstr ""

#: src/main.py:194
msgid "Become a Sponsor"
msgstr ""

#: src/main.py:195
msgid "Discussions"
msgstr ""

#: src/window.py:185
msgid "Speech recognition model is being downloaded ({})"
msgstr ""

#: src/window.py:210 src/window.py:240
msgid "Speech Recognition Error"
msgstr ""

#: src/window.py:210
msgid "An error occurred while pulling speech recognition model"
msgstr ""

#: src/window.py:240
msgid "An error occurred while using speech recognition"
msgstr ""

#: src/window.py:275
msgid "Ollama Was Not Found"
msgstr ""

#: src/window.py:276
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""

#: src/window.py:278
msgid "Open Tutorial in Web Browser"
msgstr ""

#: src/window.py:284 src/window.py:291 src/window.ui:472 src/window.ui:482
#: src/window.ui:504
msgid "Add Instance"
msgstr ""

#: src/window.py:292
msgid "Select a type of instance to add"
msgstr ""

#: src/window.py:527
msgid "No tools enabled."
msgstr ""

#: src/window.py:527
msgid "Open Tool Manager"
msgstr ""

#: src/window.py:530
msgid "'{}' does not support tools."
msgstr ""

#: src/window.py:530
msgid "Open Model Manager"
msgstr "Ouvrir le gestionnaire de modèles"

#: src/window.py:533 src/window.py:1122
msgid "Please select a model before chatting"
msgstr "Merci de sélectionner un modèle avant de discuter"

#: src/window.py:581 src/window.py:582 src/window.py:651 src/window.ui:288
msgid "Close"
msgstr "Fermer"

#: src/window.py:584 src/window.py:585 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "Suivant"

#: src/window.py:649 src/instance_manager.py:405 src/instance_manager.py:406
#: src/tool_manager.py:136 src/window.ui:968 src/window.ui:972
#: src/custom_widgets/message_widget.py:79
#: src/custom_widgets/message_widget.py:229
#: src/custom_widgets/model_manager_widget.py:422
#: src/custom_widgets/dialog_widget.py:148
#: src/custom_widgets/dialog_widget.py:160
#: src/custom_widgets/dialog_widget.py:172
msgid "Cancel"
msgstr "Annuler"

#: src/window.py:650
msgid "Hide"
msgstr "Masquer"

#: src/window.py:654
msgid "Close Alpaca?"
msgstr "Fermer Alpaca ?"

#: src/window.py:655
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr "Une tâche est en cours. Êtes-vous sur de fermer Alpaca ?"

#: src/window.py:899
msgid "Cannot open image"
msgstr "Impossible d'ouvrir l'image"

#: src/window.py:978
msgid "Delete Chat?"
msgstr "Supprimer la discussion ?"

#: src/window.py:979
msgid "Are you sure you want to delete '{}'?"
msgstr "Êtes-vous sur de vouloir supprimer '{}' ?"

#: src/window.py:981 src/window.py:1450
msgid "Delete"
msgstr "Supprimer"

#: src/window.py:988
msgid "Rename Chat?"
msgstr "Renommer la discussion ?"

#: src/window.py:989
msgid "Renaming '{}'"
msgstr "Renommer '{}'"

#: src/window.py:991
msgid "Chat name"
msgstr "Nom de la discussion"

#: src/window.py:992
msgid "Rename"
msgstr "Renommer"

#: src/window.py:997
msgid "Importable (.db)"
msgstr "Importable (.db)"

#: src/window.py:998
msgid "Markdown"
msgstr "Markdown"

#: src/window.py:999
msgid "Markdown (Obsidian Style)"
msgstr "Markdown (version Obsidian)"

#: src/window.py:1000
msgid "JSON"
msgstr "JSON"

#: src/window.py:1001
msgid "JSON (Include Metadata)"
msgstr "JSON (avec métadonnées)"

#: src/window.py:1004 src/window.ui:1405 src/window.ui:1439
msgid "Export Chat"
msgstr "Exporter la discussion"

#: src/window.py:1005
msgid "Select a method to export the chat"
msgstr "Sélectionnez une méthode pour exporter la discussion"

#: src/window.py:1021
msgid "This video does not have any transcriptions"
msgstr "Cette vidéo n'a aucune transcriptions"

#: src/window.py:1028
msgid "Attach YouTube Video?"
msgstr "Ajouter une vidéo YouTube ?"

#: src/window.py:1029
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"Merci de sélectionner une transcription à inclure"

#: src/window.py:1035
msgid "Error attaching video, please try again"
msgstr "Erreur lors de l'ajout de la vidéo, merci de réessayer"

#: src/window.py:1056 src/window.py:1444
msgid "Attach Website? (Experimental)"
msgstr "Ajouter un site web ? (Expérimental)"

#: src/window.py:1057
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"Êtes-vous sur d'attacher\n"
"'{}' ?"

#: src/window.py:1075 src/window.py:1087 src/window.py:1443
#: src/generic_actions.py:105
msgid "Image recognition is only available on specific models"
msgstr ""
"La reconnaissance d'image est disponible seulement sur certains modèles"

#: src/window.py:1106 src/window.ui:1189
msgid "Quick Ask"
msgstr "Question rapide"

#: src/window.py:1276
msgid "Attachment failed, screenshot might be too big"
msgstr "Erreur de l'ajout, la capture d'écran est peut-être trop lourde"

#: src/window.py:1290
msgid "Any compatible Alpaca attachment"
msgstr "N'importe quel fichier compatible avec Alpaca"

#: src/window.py:1419
msgid "Attach Screenshot"
msgstr "Ajouter une capture d'écran"

#: src/window.py:1444
msgid "Please enter a website URL"
msgstr "Merci d'entrer un site web"

#: src/window.py:1445
msgid "Attach YouTube Captions?"
msgstr "Ajouter les sous-titres YouTube ?"

#: src/window.py:1445
msgid "Please enter a YouTube video URL"
msgstr "Merci d'entrer l'URL d'une vidéo YouTube"

#: src/window.py:1448
msgid "Download Model?"
msgstr "Télécharger le modèle ?"

#: src/window.py:1448
msgid "Please enter the model name following this template: name:tag"
msgstr ""
"Merci d'entrer le nom du modèle suivant ce modèle : nom:étiquette (name:tag)"

#: src/window.py:1450
msgid "Delete All Chats?"
msgstr ""

#: src/window.py:1450
msgid "Are you sure you want to delete all chats?"
msgstr ""

#: src/window.py:1461
msgid "Remove Attachment?"
msgstr "Supprimer la pièce-jointe ?"

#: src/window.py:1461
msgid "Are you sure you want to remove attachment?"
msgstr "Êtes-vous sur de supprimer la pièce-jointe ?"

#: src/window.py:1461 src/instance_manager.py:885
#: src/custom_widgets/model_manager_widget.py:423
#: src/custom_widgets/model_manager_widget.py:463
msgid "Remove"
msgstr "Suprimmer"

#: src/window.py:1476
msgid "Already Installed!"
msgstr ""

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""

#: src/available_models_descriptions.py:3
msgid "QwQ is the reasoning model of the Qwen series."
msgstr ""

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision est une collection de modèles génératifs de raisonnement "
"sur les images, ajustés par instructions, avec des tailles de 11B et 90B."

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr ""
"Meta's Llama 3.2 se décline en petits modèles avec 1B et 3B paramètres."

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 est un nouveau modèle de pointe de Meta disponible en tailles de "
"8B, 70B et 405B paramètres."

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr ""
"Meta Llama 3 : Le modèle de langage ouvert le plus performant à ce jour."

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "Le modèle 7B publié par Mistral AI, mis à jour à la version 0.3."

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Un modèle d'embedding performant avec une grande fenêtre de contexte de "
"tokens."

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma est une famille de modèles légers et de pointe ouverts, développée par "
"Google DeepMind. Mis à jour à la version 1.1."

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 est une série de grands modèles de langage par Alibaba Cloud allant "
"de 0.5B à 110B paramètres."

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr ""
"Qwen2 est une nouvelle série de grands modèles de langage du groupe Alibaba."

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 est une famille de modèles légers de pointe avec 3B (Mini) et 14B "
"(Medium) paramètres, développée par Microsoft."

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 est une collection de modèles de langage de fondation allant de 7B à "
"70B paramètres."

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Les modèles Qwen2.5 sont préentraînés sur le dernier jeu de données à grande "
"échelle d'Alibaba, couvrant jusqu'à 18 000 milliards de tokens. Le modèle "
"supporte jusqu'à 128K tokens et propose un support multilingue."

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 est un modèle performant et efficace disponible en trois "
"tailles : 2B, 9B et 27B."

#: src/available_models_descriptions.py:17
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA est un nouveau modèle multimodal de grande taille, formé de bout en "
"bout, combinant un encodeur de vision et Vicuna pour la compréhension "
"générale visuelle et du langage. Mis à jour à la version 1.6."

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Un grand modèle de langage capable d'utiliser des invites textuelles pour "
"générer et discuter de code."

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"La dernière série de modèles Qwen spécifiques au code, avec des "
"améliorations significatives dans la génération, le raisonnement et la "
"correction de code."

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Un modèle de pointe de 12B avec une longueur de contexte de 128k, construit "
"par Mistral AI en collaboration avec NVIDIA."

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"Le projet TinyLlama est une initiative ouverte pour entraîner un modèle "
"Llama compact de 1.1B sur 3 trillions de tokens."

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "Modèle d'embedding de pointe de large taille par mixedbread.ai."

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 est la nouvelle génération de modèles de langage de code "
"transparents, disponibles en trois tailles : 3B, 7B et 15B paramètres."

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Un ensemble de modèles Mixture of Experts (MoE) avec des poids ouverts par "
"Mistral AI en tailles 8x7b et 8x22b paramètres."

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Modèles non censurés, 8x7b et 8x22b, affinés sur la base des modèles Mixtral "
"mixture of experts, excellant dans les tâches de codage. Créés par Eric "
"Hartford."

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma est une collection de modèles puissants et légers capables "
"d'accomplir diverses tâches de codage telles que la complétion de code en "
"milieu de phrase, la génération de code, la compréhension du langage "
"naturel, le raisonnement mathématique et le suivi des instructions."

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Un modèle open-source de code utilisant un mélange d'experts qui atteint des "
"performances comparables à GPT-4 Turbo dans des tâches spécifiques au code."

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2 : un modèle de langage de 2.7B développé par Microsoft Research qui "
"démontre des capacités exceptionnelles de raisonnement et de compréhension "
"du langage."

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Modèle Llama 2 non censuré par George Sung et Jarrad Hope."

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder est un modèle de codage performant entraîné sur deux "
"trillions de tokens de code et de langage naturel."

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Une suite de modèles d'embedding textuel par Snowflake, optimisée pour la "
"performance."

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Modèle de langage de pointe de Microsoft AI avec des performances améliorées "
"sur les tâches complexes de chat, multilingues, de raisonnement et "
"d'utilisation d'agents."

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"Modèle non censuré Dolphin basé sur Mistral, excelle dans les tâches de "
"codage. Mis à jour à la version 2.8."

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 est un nouveau modèle avec des tailles de 8B et 70B par Eric "
"Hartford, basé sur Llama 3, ayant diverses compétences en instruction, "
"conversation et codage."

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 est un modèle de langage bilingue très performant."

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R est un grand modèle de langage optimisé pour les interactions "
"conversationnelles et les tâches à long contexte."

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Un modèle généraliste allant de 3 milliards de paramètres à 70 milliards, "
"adapté au matériel de base."

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Un modèle LLaVA affiné à partir de Llama 3 Instruct avec de meilleurs scores "
"dans plusieurs benchmarks."

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr est une série de versions affinées des modèles Mistral et Mixtral, "
"entraînées pour agir comme des assistants utiles."

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Un modèle d'IA léger avec 3,8 milliards de paramètres, surpassant en "
"performance des modèles de taille similaire ou supérieure."

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Modèles d'embedding sur des datasets très larges au niveau des phrases."

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral est le tout premier modèle de code de Mistral AI, conçu pour les "
"tâches de génération de code."

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder est un modèle de génération de code entraîné sur plus de 80 "
"langages de programmation."

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Modèle de chat généraliste basé sur Llama et Llama 2 avec des tailles de "
"contexte de 2K à 16K."

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr ""
"Une famille de modèles de fondation ouverts par IBM pour l'intelligence de "
"code."

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca est un modèle de 7 milliards de paramètres, affiné à partir "
"du modèle Mistral 7B en utilisant le dataset OpenOrca."

#: src/available_models_descriptions.py:47
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 Une famille de petits modèles avec 135M, 360M et 1,7B paramètres, "
"entraînés sur un nouveau dataset de haute qualité."

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored est un modèle de 7B, 13B, et 30B paramètres basé "
"sur Llama 2, non censuré par Eric Hartford."

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Modèle basé sur Llama 2 affiné pour améliorer la capacité de dialogue en "
"chinois."

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 est un nouveau modèle de BAAI, distingué par sa polyvalence en termes "
"de multi-fonctionnalité, multi-linguisme et multi-granularité."

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Un modèle polyvalent pour les scénarios de développement logiciel d'IA, y "
"compris la complétion de code."

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Une famille de modèles open-source entraînés sur une grande variété de "
"données, surpassant ChatGPT sur divers benchmarks. Mis à jour à la version "
"3.5-0106."

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, publié par Cohere, est une nouvelle famille de modèles multilingues "
"de pointe supportant 23 langues."

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 est un grand modèle de langage préentraîné sur une grande "
"quantité de données de code."

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"La famille de modèles puissants par Nous Research, excelle dans les "
"discussions scientifiques et les tâches de codage."

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ est un puissant grand modèle de langage évolutif spécialement "
"conçu pour exceller dans les cas d'usage en entreprise."

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "Modèle de génération de code de pointe."

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B est un modèle de codage avec des variantes d'instruction et "
"de complétion de code, comparable à des modèles tels que Code Llama 7B, qui "
"sont 2.5 fois plus grands."

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Un modèle expérimental de 1.1B paramètres entraîné sur le nouveau dataset "
"Dolphin 2.8 par Eric Hartford et basé sur TinyLlama."

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 est un modèle de 7B affiné par Teknium sur Mistral avec des "
"datasets entièrement ouverts."

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 est le nouveau modèle phare de Mistral, nettement plus "
"performant en génération de code, mathématiques et raisonnement, avec une "
"fenêtre de contexte de 128k et prenant en charge des dizaines de langues."

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math est une série de modèles linguistiques spécialisés en "
"mathématiques, construits à partir des LLMs Qwen2, surpassant de manière "
"significative les capacités mathématiques des modèles open-source et même "
"des modèles propriétaires (par exemple, GPT4o)."

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Un modèle généraliste multilingue performant, compétitif par rapport à Llama "
"3."

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 est un modèle de langage de pointe de 1.6B et 12B paramètres "
"entraîné sur des données multilingues en anglais, espagnol, allemand, "
"italien, français, portugais et néerlandais."

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA est un modèle multimodal composé du modèle de base Mistral 7B, "
"augmenté avec l'architecture LLaVA."

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Un modèle performant entraîné avec une nouvelle technique appelée "
"\"Reflection-tuning\" qui apprend à un LLM à détecter les erreurs dans son "
"raisonnement et à corriger son cours."

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Un modèle de langage avancé élaboré avec 2 trillions de tokens bilingues."

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Ce modèle étend la longueur du contexte de Llama-3 8B de 8k à plus de 1M "
"tokens."

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "Modèle axé sur les problèmes de mathématiques et de logique."

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 est un petit modèle de vision et de langage conçu pour "
"fonctionner efficacement sur des dispositifs de périphérie."

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Un modèle affiné basé sur Mistral avec une bonne couverture des domaines et "
"des langues."

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Un modèle de NVIDIA basé sur Llama 3 qui excelle en question-réponse "
"conversationnelle (QA) et génération augmentée par récupération (RAG)."

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Modèle conversationnel basé sur Llama 2 qui se montre compétitif sur divers "
"benchmarks."

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder est un modèle de complétion de code affiné sur StarCoder pour les "
"tâches de génération SQL."

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Modèles d'usage général basés sur Llama et Llama 2 de Nous Research."

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "Modèle de génération de code basé sur Code Llama."

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr ""
"Une extension de Llama 2 qui supporte un contexte allant jusqu'à 128k tokens."

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Une variante non censurée de 7B et 15B du modèle Dolphin qui excelle en "
"codage, basée sur StarCoder2."

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "Modèle d'usage général basé sur Llama 2."

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "Un modèle de langage Mixture-of-Experts fort, économique et efficace."

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling est un grand modèle de langage entraîné par apprentissage par "
"renforcement à partir de feedbacks d'IA, axé sur l'amélioration de l'utilité "
"des chatbots."

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Un assistant compagnon entraîné en philosophie, psychologie et relations "
"personnelles. Basé sur Mistral."

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 est la dernière version de la série phare Hermes de LLMs par Nous "
"Research."

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder est une série de modèles de langage de code open-source offrant des "
"performances de codage à la pointe de la technologie avec moins de 10 "
"milliards de paramètres."

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Un grand modèle linguistique développé par le Technology Innovation "
"Institute (TII), conçu pour la synthèse, la génération de texte et les "
"chatbots."

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 est un modèle de 7B paramètres adapté aux scénarios pratiques, "
"avec une capacité de raisonnement exceptionnelle."

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Un modèle compact, mais puissant de 10.7B conçu pour des conversations à un "
"seul tour."

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 est un modèle de 72 milliards de paramètres qui excelle dans les "
"tâches de complétion de code, de mathématiques et d'extraction de journaux."

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Un nouveau petit modèle LLaVA affiné à partir de Phi 3 Mini."

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 est un modèle développé par Microsoft Research, affiné à partir des "
"modèles Llama 2 de Meta. Le modèle est conçu pour exceller particulièrement "
"en raisonnement."

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Une série de modèles multimodaux (MLLMs) conçus pour la compréhension vision-"
"langage."

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Modèle basé sur Llama 2, affiné sur un dataset de style Orca. Initialement "
"appelé Free Willy."

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Un modèle Dolphin non censuré de 2.7B paramètres par Eric Hartford, basé sur "
"le modèle Phi de Microsoft Research."

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 est une famille de modèles linguistiques compacts disponible en "
"trois tailles : 135M, 360M et 1,7B paramètres."

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "Version non censurée du modèle Wizard LM."

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Un petit modèle de langage à usage commercial proposé par NVIDIA, optimisé "
"pour les jeux de rôle, la RAG QA et les appels de fonctions."

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Une extension de Mistral pour supporter des fenêtres de contexte de 64K ou "
"128K."

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Une expansion de Llama 2 qui se spécialise dans l'intégration de la "
"compréhension générale du langage et des connaissances spécifiques aux "
"domaines, en particulier en programmation et en mathématiques."

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Modèle Llama 2 affiné pour répondre aux questions médicales, basé sur un "
"dataset médical open-source."

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Modèle de langage médical open-source, adapté de Llama 2 au domaine médical."

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Une série de modèles de Groq qui représente une avancée significative dans "
"les capacités open-source de l'IA pour l'utilisation d'outils/appels de "
"fonction."

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct est un grand modèle linguistique "
"personnalisé par NVIDIA pour améliorer l’utilité des réponses générées par "
"les LLM aux requêtes des utilisateurs."

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven est un modèle de 13B paramètres optimisé pour les tâches d'appel "
"de fonctions."

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"Le modèle Nous Hermes 2 de Nous Research, maintenant entraîné sur Mixtral."

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "Un excellent modèle de génération de code basé sur Llama 2."

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Modèle basé sur Llama 2 non censuré avec support pour une fenêtre de "
"contexte de 16K tokens."

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Les modèles IBM Granite 2B et 8B sont conçus pour prendre en charge des cas "
"d'utilisation basés sur des outils, ainsi que la génération augmentée par "
"récupération (RAG), simplifiant la génération de code, la traduction et la "
"correction d'erreurs."

#: src/available_models_descriptions.py:109
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder est une famille de modèles de 7B paramètres entraînés sur 75K "
"données d'instructions synthétiques en utilisant OSS-Instruct, une approche "
"novatrice pour éclairer les LLMs avec des extraits de code open-source."

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Un modèle de chat léger permettant une sortie précise et réactive sans "
"nécessiter de matériel haut de gamme."

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Un modèle code instruct performant créé en fusionnant deux modèles de code "
"existants."

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 est un modèle causale de 11B paramètres, développé par TII et "
"entraîné sur 5T tokens."

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna est un modèle de 13B paramètres basé sur Llama 2, entraîné par "
"MelodysDreamj."

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite est un modèle affiné basé sur Mistral avec des capacités "
"améliorées de traitement des contextes longs."

#: src/available_models_descriptions.py:115
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral : un modèle de 7B conçu pour le raisonnement mathématique et la "
"découverte scientifique par Mistral AI."

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Modèle de text-to-SQL de 7B paramètres développé par MotherDuck et Numbers "
"Station."

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b est une transformation du modèle Dolphin-2.2-70b créée "
"en entrelaçant le modèle avec lui-même."

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro Preview : un modèle de langage de grande taille (LLM) avancé avec "
"22 milliards de paramètres conçu pour tenir sur un seul GPU."

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Une série de modèles qui convertissent le contenu HTML en contenu Markdown, "
"utile pour les tâches de conversion de contenu."

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Un modèle Mixture of Experts de haute performance, affiné avec des données "
"de haute qualité."

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Modèle de chat de 7B affiné avec des données de haute qualité, basé sur "
"Zephyr."

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Fusion du modèle Open Orca OpenChat et du modèle Garage-bAInd Platypus 2, "
"conçu pour le chat et la génération de code."

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Un modèle de langage créé en combinant deux modèles Llama 2 de 70B "
"paramètres affinés en un seul."

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Les modèles IBM Granite 1B et 3B sont les premiers modèles Granite avec "
"mélange d'experts (MoE) d'IBM, conçus pour un usage à faible latence."

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Un modèle de 3.8B affiné sur un dataset synthétique privé de haute qualité "
"pour l'extraction d'informations, basé sur Phi-3."

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Les modèles linguistiques de Cohere For AI sont entraînés pour bien "
"performer dans 23 langues différentes."

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX est un modèle de langage généraliste ouvert créé par Databricks."

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Un grand modèle de raisonnement ouvert pour des solutions pratiques, "
"développé par le groupe Alibaba International Digital Commerce (AIDC-AI)."

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Modèle d'embedding de BAAI, mappant les textes en vecteurs."

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Un modèle d'appel de fonctions avec des poids ouverts basé sur Llama 3, "
"compétitif avec les capacités d'appel de fonctions de GPT-4."

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Un modèle conversationnel robuste conçu pour être utilisé à la fois pour le "
"chat et les cas d'usage d'instructions."

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Une version améliorée de DeepSeek-V2 qui intègre les capacités générales et "
"de codage de DeepSeek-V2-Chat et DeepSeek-Coder-V2-Instruct."

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma est un ensemble de modèles ajustés par des instructions, conçus "
"pour évaluer la sécurité des invites textuelles et des réponses textuelles "
"en fonction d'un ensemble de politiques de sécurité définies."

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Un modèle de vérification des faits de pointe développé par Bespoke Labs."

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 est une série de modèles ajustés pour la classification de la "
"sécurité des contenus dans les entrées et réponses des LLM."

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Modèle sentence-transformers pouvant être utilisé pour des tâches comme le "
"clustering ou la recherche sémantique."

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder est une famille de modèles linguistiques ouverts et reproductibles "
"pour le code, incluant des modèles de 1,5B et 8B, prenant en charge les "
"conversations en anglais et en chinois."

#: src/available_models_descriptions.py:138
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 est une famille de modèles spécialisés dans le suivi d'instructions, "
"proposant des données, du code et des recettes entièrement open-source, "
"développés par l'Allen Institute for AI."

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Modèle d'intégration avancé de Snowflake. Arctic Embed 2.0 ajoute un support "
"multilingue sans compromettre les performances ou l'évolutivité en anglais."

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Les modèles IBM Granite Guardian 3.0 2B et 8B sont conçus pour détecter les "
"risques dans les invites et/ou les réponses."

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 est une collection de modèles génératifs bilingues (anglais et "
"coréen), ajustés pour suivre des instructions, avec des tailles allant de "
"2,4 milliards à 32 milliards de paramètres. Développé et publié par LG AI "
"Research."

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 est une gamme de modèles multilingues conçus pour l'Asie du Sud-Est, "
"disponibles en tailles de 1 milliard, 8 milliards et 20 milliards de "
"paramètres."

#: src/available_models_descriptions.py:143
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""

#: src/available_models_descriptions.py:144
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""

#: src/available_models_descriptions.py:145
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: src/available_models_descriptions.py:146
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""

#: src/available_models_descriptions.py:147
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""

#: src/available_models_descriptions.py:148
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""

#: src/available_models_descriptions.py:149
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""

#: src/available_models_descriptions.py:150
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""

#: src/available_models_descriptions.py:151
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""

#: src/available_models_descriptions.py:152
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""

#: src/available_models_descriptions.py:153
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""

#: src/available_models_descriptions.py:154
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""

#: src/available_models_descriptions.py:155
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""

#: src/available_models_descriptions.py:156
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""

#: src/available_models_descriptions.py:157
msgid "The current, most capable model that runs on a single GPU."
msgstr ""

#: src/available_models_descriptions.py:158
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""

#: src/available_models_descriptions.py:159
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""

#: src/available_models_descriptions.py:160
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""

#: src/available_models_descriptions.py:161
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""

#: src/available_models_descriptions.py:162
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""

#: src/available_models_descriptions.py:163
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""

#: src/available_models_descriptions.py:164
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""

#: src/available_models_descriptions.py:165
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""

#: src/available_models_descriptions.py:166
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""

#: src/instance_manager.py:30 src/instance_manager.py:366
msgid "Instance"
msgstr ""

#: src/instance_manager.py:60 src/instance_manager.py:69 src/window.ui:154
#: src/custom_widgets/chat_widget.py:423
msgid "New Chat"
msgstr "Nouvelle discussion"

#: src/instance_manager.py:76
msgid "Selecting tool to use..."
msgstr ""

#: src/instance_manager.py:85
msgid "Using {}"
msgstr ""

#: src/instance_manager.py:111
msgid "Tool Error"
msgstr ""

#: src/instance_manager.py:111
msgid "An error occurred while running tool"
msgstr ""

#: src/instance_manager.py:114
msgid "Generating message..."
msgstr ""

#: src/instance_manager.py:162 src/instance_manager.py:462
#: src/instance_manager.py:472 src/instance_manager.py:616
#: src/instance_manager.py:688 src/instance_manager.py:730
#: src/instance_manager.py:759 src/instance_manager.py:802
#: src/instance_manager.py:822 src/instance_manager.py:843
msgid "Instance Error"
msgstr ""

#: src/instance_manager.py:162
msgid "Message generation failed"
msgstr ""

#: src/instance_manager.py:218 src/window.ui:885
msgid "Name"
msgstr "Nom"

#: src/instance_manager.py:226
msgid "Port"
msgstr ""

#: src/instance_manager.py:227
msgid "Which network port will '{}' use"
msgstr ""

#: src/instance_manager.py:241
msgid "Instance URL"
msgstr ""

#: src/instance_manager.py:244 src/instance_manager.py:254
#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key (Unchanged)"
msgstr ""

#: src/instance_manager.py:244 src/instance_manager.py:254
msgid "API Key (Optional)"
msgstr ""

#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key"
msgstr ""

#: src/instance_manager.py:267
msgid "Max Tokens"
msgstr ""

#: src/instance_manager.py:268
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""

#: src/instance_manager.py:283
msgid "Temperature"
msgstr "Température"

#: src/instance_manager.py:284
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""

#: src/instance_manager.py:299
msgid "Seed"
msgstr "Graine"

#: src/instance_manager.py:300
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""

#: src/instance_manager.py:315
msgid "Overrides"
msgstr ""

#: src/instance_manager.py:315
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""

#: src/instance_manager.py:333
msgid "Model Directory"
msgstr "Dossier des modèles"

#: src/instance_manager.py:335
msgid "Select Directory"
msgstr ""

#: src/instance_manager.py:346
msgid "Default Model"
msgstr "Modèle par défaut"

#: src/instance_manager.py:346
msgid "Model to select when starting a new chat."
msgstr ""

#: src/instance_manager.py:348
msgid "Title Model"
msgstr ""

#: src/instance_manager.py:348
msgid "Model to use when generating a chat title."
msgstr ""

#: src/instance_manager.py:412 src/instance_manager.py:413
#: src/custom_widgets/message_widget.py:233
msgid "Save"
msgstr "Sauvegarder"

#: src/instance_manager.py:462 src/instance_manager.py:688
#: src/instance_manager.py:730 src/instance_manager.py:759
msgid "Could not retrieve added models"
msgstr ""

#: src/instance_manager.py:472
msgid "Could not retrieve available models"
msgstr ""

#: src/instance_manager.py:539
msgid "Ollama (Managed)"
msgstr ""

#: src/instance_manager.py:547
msgid "Local AI instance managed directly by Alpaca"
msgstr ""

#: src/instance_manager.py:570
msgid "Alpaca Support"
msgstr "Support d'Alpaca"

#: src/instance_manager.py:577
msgid "Model request too large for system"
msgstr "Modèle demandé trop lourd pour le système"

#: src/instance_manager.py:580
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""
"GPU AMD détecté mais l'extension est manquante. Ollama utilisera  le CPU."

#: src/instance_manager.py:582
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "GPU AMD détecté mais ROCm est manquant. Ollama utilisera le CPU."

#: src/instance_manager.py:584
msgid "Using AMD GPU type '{}'"
msgstr "Utilisation de GPU AMD type '{}'"

#: src/instance_manager.py:594
msgid "Integrated Ollama instance is not running"
msgstr "L'instance intégrée d'Ollama est inactive"

#: src/instance_manager.py:616
msgid "Managed Ollama instance failed to start"
msgstr ""

#: src/instance_manager.py:619
msgid "Integrated Ollama instance is running"
msgstr "L'instance intégrée d'Ollama est active"

#: src/instance_manager.py:624 src/instance_manager.py:625
msgid "Ollama Log"
msgstr ""

#: src/instance_manager.py:637
msgid "Local or remote AI instance not managed by Alpaca"
msgstr ""

#: src/instance_manager.py:802 src/instance_manager.py:822
#: src/instance_manager.py:843
msgid "Could not retrieve models"
msgstr ""

#: src/instance_manager.py:811
msgid "Fireworks AI inference platform"
msgstr ""

#: src/instance_manager.py:831
msgid "Lambda Labs cloud inference API"
msgstr ""

#: src/instance_manager.py:852
msgid "Cerebras AI cloud inference API"
msgstr ""

#: src/instance_manager.py:858
msgid "Kluster AI cloud inference API"
msgstr ""

#: src/instance_manager.py:862
msgid "OpenAI Compatible Instance"
msgstr ""

#: src/instance_manager.py:863
msgid "AI instance compatible with OpenAI library"
msgstr ""

#: src/instance_manager.py:885
msgid "Remove Instance?"
msgstr ""

#: src/instance_manager.py:885
msgid "Are you sure you want to remove this instance?"
msgstr ""

#: src/instance_manager.py:900
msgid "Edit Instance"
msgstr ""

#: src/tool_manager.py:71
msgid "AI Description"
msgstr ""

#: src/tool_manager.py:72
msgid "The description the AI model will use to understand what the tool does."
msgstr ""

#: src/tool_manager.py:83
msgid "Arguments"
msgstr ""

#: src/tool_manager.py:84
msgid "Variables that are filled by the AI."
msgstr ""

#: src/tool_manager.py:97
msgid "Variables"
msgstr ""

#: src/tool_manager.py:98
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""

#: src/tool_manager.py:140 src/custom_widgets/dialog_widget.py:146
#: src/custom_widgets/dialog_widget.py:158
#: src/custom_widgets/dialog_widget.py:170
msgid "Accept"
msgstr "Accepter"

#: src/tool_manager.py:177
msgid "Gets the current date and/or time."
msgstr ""

#: src/tool_manager.py:211
msgid "Gets a recipe by the meal's name"
msgstr ""

#: src/tool_manager.py:224 src/tool_manager.py:281
msgid "YouTube Video"
msgstr ""

#: src/tool_manager.py:227 src/tool_manager.py:284
msgid "Source"
msgstr ""

#: src/tool_manager.py:262
msgid "Gets a list of food recipes by a specified category"
msgstr ""

#: src/tool_manager.py:307
msgid "Extracts an article from Wikipedia by it's title"
msgstr ""

#: src/tool_manager.py:349
msgid "Search for a term online using DuckDuckGo"
msgstr ""

#: src/tool_manager.py:365
msgid "Abstract Source"
msgstr ""

#: src/tool_manager.py:384
msgid "Official Website"
msgstr ""

#: src/tool_manager.py:432
msgid "Request to run a command using SSH to connect to the device"
msgstr ""

#: src/tool_manager.py:435
msgid "IP Address"
msgstr ""

#: src/tool_manager.py:440
msgid "Username"
msgstr ""

#: src/tool_manager.py:445
msgid "Network Port"
msgstr ""

#: src/tool_manager.py:462
msgid "Model Requested to Run Command"
msgstr ""

#: src/tool_manager.py:463
msgid "Command"
msgstr ""

#: src/tool_manager.py:465
msgid "Explanation"
msgstr ""

#: src/tool_manager.py:466
msgid "No explanation was provided"
msgstr ""

#: src/tool_manager.py:467
msgid "Make sure you understand what the command does before running it."
msgstr ""

#: src/window.ui:34
msgid "Welcome"
msgstr ""

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "Précédent"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "Bienvenue sur Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr ""

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr ""

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""

#: src/window.ui:107
msgid "Private by Design"
msgstr ""

#: src/window.ui:108
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""

#: src/window.ui:114
msgid "Local AI"
msgstr ""

#: src/window.ui:115
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""

#: src/window.ui:120 src/window.ui:121
msgid "Install Ollama"
msgstr ""

#: src/window.ui:165
msgid "Menu"
msgstr "Menu"

#: src/window.ui:187
msgid "Toggle Sidebar"
msgstr "Basculer la barre latérale"

#: src/window.ui:194
msgid "Search Messages"
msgstr "Chercher des messages"

#: src/window.ui:211 src/window.ui:236 src/window.ui:1371
msgid "Manage Models"
msgstr "Gestion des modèles"

#: src/window.ui:232
msgid "Add Models"
msgstr ""

#: src/window.ui:249
msgid "Chat Menu"
msgstr "Menu de la discussion"

#: src/window.ui:262
msgid "Message search bar"
msgstr "Barre de recherche des messages"

#: src/window.ui:271 src/window.ui:273
msgid "Search messages"
msgstr "Chercher un message"

#: src/window.ui:289
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""
"Attention : mode Économie d'énergie activé, cela pourrait ralentir la "
"génération des messages"

#: src/window.ui:336 src/window.ui:1469
msgid "Attach File"
msgstr "Ajouter un fichier"

#: src/window.ui:369 src/window.ui:1238
msgid "Use Speech Recognition"
msgstr ""

#: src/window.ui:404
msgid "Send Message"
msgstr "Envoyer le message"

#: src/window.ui:423
msgid "Stop Message"
msgstr "Arrêter le message"

#: src/window.ui:453
msgid "Instance Manager"
msgstr ""

#: src/window.ui:468
msgid "No Instances Found"
msgstr ""

#: src/window.ui:469
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr ""

#: src/window.ui:498
msgid "Added Instances"
msgstr ""

#: src/window.ui:499
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""

#: src/window.ui:535
msgid "Tool Manager"
msgstr ""

#: src/window.ui:546
msgid "Available Tools"
msgstr ""

#: src/window.ui:547
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""

#: src/window.ui:566
msgid "Model Manager"
msgstr "Gestionnaire de modèles"

#: src/window.ui:604
msgid "Search Model"
msgstr "Chercher un modèle"

#: src/window.ui:618
msgid "Model Manager Menu"
msgstr "Menu du gestionnaire de modèles"

#: src/window.ui:631
msgid "Model search bar"
msgstr "Barre de recherche des modèles"

#: src/window.ui:643 src/window.ui:645
msgid "Search models"
msgstr "Chercher des modèles"

#: src/window.ui:652
msgid "Filter Models"
msgstr ""

#: src/window.ui:668
msgid "Added"
msgstr ""

#: src/window.ui:678 src/window.ui:739 src/window.ui:793
msgid "No Models Found"
msgstr "Aucun modèle trouvé"

#: src/window.ui:679
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""

#: src/window.ui:682 src/window.ui:692 src/window.ui:1367
msgid "Manage Instances"
msgstr ""

#: src/window.ui:740 src/window.ui:794
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"On dirait qu'on n'a pas de modèles pour cette recherche. Modifiez vos mots-"
"clés ou explorez quelque chose de nouveau !"

#: src/window.ui:752
msgid "Available"
msgstr ""

#: src/window.ui:806
msgid "Creator"
msgstr ""

#: src/window.ui:817
msgid "Model Creator"
msgstr "Créateur de modèle"

#: src/window.ui:818
msgid "Select a method of importing a model to continue"
msgstr "Sélectionner une méthode d'importation de modèle pour continuer"

#: src/window.ui:830
msgid "GGUF File"
msgstr "Fichier GGUF"

#: src/window.ui:841
msgid "Existing Model"
msgstr "Modèles existants"

#: src/window.ui:859
msgid "Identity"
msgstr "Identité"

#: src/window.ui:862
msgid "Base"
msgstr "Base"

#: src/window.ui:869
msgid "Profile Picture"
msgstr "Photo de profile"

#: src/window.ui:874
msgid "Open File"
msgstr "Ouvrir un fichier"

#: src/window.ui:890 src/custom_widgets/model_manager_widget.py:257
msgid "Tag"
msgstr "Étiquette"

#: src/window.ui:897 src/custom_widgets/model_manager_widget.py:274
msgid "Context"
msgstr "Contexte"

#: src/window.ui:898
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""
"Décrivez le comportement désiré du modèle dans sa première langue "
"(généralement l'Anglais)"

#: src/window.ui:926
msgid "Behavior"
msgstr "Comportement"

#: src/window.ui:929
msgid "Imagination"
msgstr "Imagination"

#: src/window.ui:930
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr "Une valeur plus élevés rend les réponses plus diversifiées. (top_k)"

#: src/window.ui:944
msgid "Focus"
msgstr "Sélectionner"

#: src/window.ui:945
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr ""
"Une valeur plus élevé augmente le nombre de réponses possibles. (top_p)"

#: src/window.ui:978 src/window.ui:986
msgid "Add Model"
msgstr "Ajouter un modèle"

#: src/window.ui:1020 src/window.ui:1381
msgid "Preferences"
msgstr "Préférences"

#: src/window.ui:1028
msgid "Run Alpaca In Background"
msgstr "Exécuter Alpaca en arrière-plan"

#: src/window.ui:1034
msgid "Show Power Saver Warning"
msgstr "Voir l'avertissement lorsque le mode Économie d'énergie est activé"

#: src/window.ui:1035
msgid "When running a managed Ollama instance"
msgstr ""

#: src/window.ui:1041
msgid "Zoom"
msgstr ""

#: src/window.ui:1058
msgid "Auto Send Message After Talking"
msgstr ""

#: src/window.ui:1064
msgid "Speech Recognition Language"
msgstr ""

#: src/window.ui:1074
msgid "Text to Speech Voice"
msgstr ""

#: src/window.ui:1086
msgid "Delete All Chats"
msgstr ""

#: src/window.ui:1098
msgid "Notice"
msgstr ""

#: src/window.ui:1118
msgid ""
"Hey Alpaca users! We're so excited to bring you a fresh update packed with "
"awesome new features to explore! Get ready to experience Alpaca in a whole "
"new way!"
msgstr ""

#: src/window.ui:1125
msgid "Smart Tools"
msgstr ""

#: src/window.ui:1126
msgid ""
"Supported AI models can use handy tools to grab information both locally and "
"online. Head over to the brand new \"Tool Manager\" to toggle them on or off."
msgstr ""

#: src/window.ui:1133
msgid "Talk to Models"
msgstr ""

#: src/window.ui:1134
msgid ""
"You can now dictate your messages using local speech recognition. It's super "
"convenient! You can even customize your language and other settings in the "
"Preferences dialog."
msgstr ""

#: src/window.ui:1141
msgid "Find Models Faster"
msgstr ""

#: src/window.ui:1142
msgid ""
"Browsing through your Ollama models just got easier! We've added the ability "
"to filter models by their categories in the Model Manager. Now you can "
"quickly find exactly the model you're looking for."
msgstr ""

#: src/window.ui:1149
msgid "Math Rendering"
msgstr ""

#: src/window.ui:1150
msgid ""
"We've improved how LaTeX equations are rendered in messages, making them "
"look cleaner and more consistent. Your mathematical discussions will be "
"clearer than ever!"
msgstr ""

#: src/window.ui:1157
msgid "More Instances"
msgstr ""

#: src/window.ui:1158
msgid ""
"Get ready to connect Alpaca to a whole universe of AI providers! We've added "
"support for over 5 new AI instance providers, including Anthropic, "
"OpenRouter, and Fireworks. The possibilities are endless!"
msgstr ""

#: src/window.ui:1165
msgid "Attachment Enhancement"
msgstr ""

#: src/window.ui:1166
msgid ""
"You can now attach and ask questions about even more file types, "
"including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
"you'll see it with rich text styling, making it easier to understand the "
"content before you send it."
msgstr ""

#: src/window.ui:1187
msgid "Quick ask dialog"
msgstr "Boite de dialogue de question rapide"

#: src/window.ui:1199
msgid "Save Conversation to Alpaca"
msgstr "Enregistrer la discussion dans Alpaca"

#: src/window.ui:1268
msgid "Terminal dialog"
msgstr "Fenêtre du terminal"

#: src/window.ui:1271
msgid "Terminal"
msgstr "Terminal"

#: src/window.ui:1285
msgid "Open Environment Directory"
msgstr "Ouvrir le dossier d'environnement"

#: src/window.ui:1306
msgid "File preview dialog"
msgstr "Boite de dialogue de la prévisualisation des fichiers"

#: src/window.ui:1317
msgid "Open With Default App"
msgstr "Ouvrir avec l'application par défaut"

#: src/window.ui:1325
msgid "Remove Attachment"
msgstr "Supprimer la pièce-jointe"

#: src/window.ui:1359
msgid "Start Quick Ask"
msgstr ""

#: src/window.ui:1363
msgid "Import Chat"
msgstr "Importer une discussion"

#: src/window.ui:1375
msgid "Manage Tools"
msgstr ""

#: src/window.ui:1385
msgid "Keyboard Shortcuts"
msgstr "Raccourcis claviers"

#: src/window.ui:1389
msgid "About Alpaca"
msgstr "À propos d'Alpaca"

#: src/window.ui:1397 src/window.ui:1431
msgid "Rename Chat"
msgstr "Renommer la discussion"

#: src/window.ui:1401 src/window.ui:1435
msgid "Duplicate Chat"
msgstr "Dupliquer la discussion"

#: src/window.ui:1411 src/window.ui:1445
msgid "Delete Chat"
msgstr "Supprimer la discussion"

#: src/window.ui:1419
msgid "Reload Added Models"
msgstr ""

#: src/window.ui:1423
msgid "Download Model From Name"
msgstr "Télécharger un modèle à partir de son nom"

#: src/window.ui:1453
msgid "Send as User"
msgstr "Envoyer en tant qu'utilisateur"

#: src/window.ui:1457
msgid "Send as System"
msgstr "Envoyer en tant que système"

#: src/window.ui:1461 src/gtk/help-overlay.ui:133
msgid "Use Tools"
msgstr ""

#: src/window.ui:1473
msgid "Attach Website"
msgstr "Ajouter un site web"

#: src/window.ui:1477
msgid "Attach YouTube Captions"
msgstr "Ajouter des sous-titres YouTube"

#: src/alpaca_search_provider.py.in:43
msgid "Open chat"
msgstr "Ouvrir la discussion"

#: src/alpaca_search_provider.py.in:44
msgid "Quick ask"
msgstr "Question rapide"

#: src/generic_actions.py:79
msgid "An error occurred while extracting text from the website"
msgstr "Une erreur est survenue lors de l'extraction du texte du site web"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "Général"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "Voir les raccourcis"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "Préférences"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr ""

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "Gestionnaire de modèle"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr ""

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr ""

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "Basculer la barre latérale"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr "Quitter"

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "Gestion des chats"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "Créer un discusion"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "Supprimer une discussion"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "Effacer la discussion"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "Renommer la discussion"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr ""

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "Saisie du message"

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "Copier"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "Coller"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr "Ouvrir le menu d'emoji"

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "Insérer une ligne"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr "Envoyer un message en tant que Système"

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr ""
"Les messages systèmes sont interprétés comme des instructions par les modèles"

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr ""

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr "Envoyer un message en tant qu'Utilisateur"

#: src/custom_widgets/chat_widget.py:92
msgid "Try one of these prompts"
msgstr "Essayez un des ces prompts"

#: src/custom_widgets/chat_widget.py:121
msgid "Send prompt: '{}'"
msgstr "Envoyer le prompt : '{}'"

#: src/custom_widgets/chat_widget.py:127
msgid "Refresh Prompts"
msgstr ""

#: src/custom_widgets/chat_widget.py:185
msgid "Chat exported successfully"
msgstr "Discussion exportée avec succès"

#: src/custom_widgets/chat_widget.py:205
msgid "User"
msgstr "Utilisateur"

#: src/custom_widgets/chat_widget.py:209
#: src/custom_widgets/message_widget.py:680
msgid "System"
msgstr "Système"

#: src/custom_widgets/chat_widget.py:297
msgid "Regenerate Response"
msgstr "Regénérer la réponse"

#: src/custom_widgets/chat_widget.py:461
msgid "Copy of {}"
msgstr "Copie de {}"

#: src/custom_widgets/chat_widget.py:474
msgid "Chat imported successfully"
msgstr "Discussion importée avec succès"

#: src/custom_widgets/message_widget.py:88
msgid "Save Message"
msgstr "Sauvegarder le message"

#: src/custom_widgets/message_widget.py:129
#: src/custom_widgets/message_widget.py:268
msgid "Message edited successfully"
msgstr "Message édité avec succès"

#: src/custom_widgets/message_widget.py:155
msgid "Response message"
msgstr "Message de réponse"

#: src/custom_widgets/message_widget.py:157
msgid "System message"
msgstr "Message système"

#: src/custom_widgets/message_widget.py:159
msgid "User message"
msgstr "Message de l'utilisateur"

#: src/custom_widgets/message_widget.py:218
msgid "{}Code Block"
msgstr "{}Bloc de code"

#: src/custom_widgets/message_widget.py:220
msgid "Code Block"
msgstr "Bloc de code"

#: src/custom_widgets/message_widget.py:221
#: src/custom_widgets/message_widget.py:530
msgid "Copy Message"
msgstr "Copier le message"

#: src/custom_widgets/message_widget.py:225
msgid "Edit Code Block"
msgstr "Éditer le code"

#: src/custom_widgets/message_widget.py:237
#: src/custom_widgets/message_widget.py:313
msgid "Run Script"
msgstr "Lancer le script"

#: src/custom_widgets/message_widget.py:277
msgid "Code copied to the clipboard"
msgstr "Code copié dans le presse-papier"

#: src/custom_widgets/message_widget.py:314
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""
"Assurez-vous de ce que le script effectue avant de le lancer. Alpaca n'est "
"pas responsable des dommages causés à votre appareil ou à vos données.\t"

#: src/custom_widgets/message_widget.py:316
msgid "Execute"
msgstr "Exécuter"

#: src/custom_widgets/message_widget.py:395
#: src/custom_widgets/message_widget.py:397
msgid "Image"
msgstr "Image"

#: src/custom_widgets/message_widget.py:406
#: src/custom_widgets/message_widget.py:418
msgid "Missing Image"
msgstr "Image manquante"

#: src/custom_widgets/message_widget.py:420
msgid "Missing image"
msgstr "Image manquante"

#: src/custom_widgets/message_widget.py:493
msgid "Copy Equation"
msgstr "Copier l'équation"

#: src/custom_widgets/message_widget.py:500
msgid "Equation copied to the clipboard"
msgstr "Équation copié dans le presse-papier"

#: src/custom_widgets/message_widget.py:520
msgid "Remove Message"
msgstr "Supprimer le message"

#: src/custom_widgets/message_widget.py:540
msgid "Edit Message"
msgstr "Éditer le message"

#: src/custom_widgets/message_widget.py:551
msgid "Regenerate Message"
msgstr "Regénérer le message"

#: src/custom_widgets/message_widget.py:563
msgid "Dictate Message"
msgstr ""

#: src/custom_widgets/message_widget.py:583
msgid "Message copied to the clipboard"
msgstr "Message copié dans le presse-papier"

#: src/custom_widgets/message_widget.py:648
msgid "Message cannot be regenerated while receiving a response"
msgstr ""
"Le message ne peut pas être regénéré lors de la réception d'une réponse"

#: src/custom_widgets/message_widget.py:957
msgid "Thought"
msgstr "Pensée"

#: src/custom_widgets/model_manager_widget.py:67
#: src/custom_widgets/model_manager_widget.py:69
msgid "Stop Download"
msgstr "Arrêter le téléchargement"

#: src/custom_widgets/model_manager_widget.py:74
msgid "Stop Download?"
msgstr "Arrêter le téléchargement ?"

#: src/custom_widgets/model_manager_widget.py:75
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "Ếtes-vous sur de vouloir arrêter de télécharger '{}'?"

#: src/custom_widgets/model_manager_widget.py:77
msgid "Stop"
msgstr "Arrêter"

#: src/custom_widgets/model_manager_widget.py:147
msgid "Model Manager Error"
msgstr "Erreur du gestionnaire de modèle"

#: src/custom_widgets/model_manager_widget.py:147
msgid "An error occurred whilst pulling '{}'"
msgstr "Une erreur est survenue lors du téléchargement de '{}'"

#: src/custom_widgets/model_manager_widget.py:172
msgid "Download Completed"
msgstr "Téléchargement terminé"

#: src/custom_widgets/model_manager_widget.py:172
msgid "Model '{}' downloaded successfully."
msgstr "Modèle '{}' téléchargé avec succè"

#: src/custom_widgets/model_manager_widget.py:235
msgid "Change Profile Picture"
msgstr "Changer la photo de profil"

#: src/custom_widgets/model_manager_widget.py:258
msgid "Family"
msgstr "Famille"

#: src/custom_widgets/model_manager_widget.py:259
msgid "Parameter Size"
msgstr "Taille de paramètre"

#: src/custom_widgets/model_manager_widget.py:260
msgid "Quantization Level"
msgstr "Niveau de quantification"

#: src/custom_widgets/model_manager_widget.py:263
msgid "Parent Model"
msgstr "Modèle parent"

#: src/custom_widgets/model_manager_widget.py:266
#: src/custom_widgets/model_manager_widget.py:268
msgid "Modified At"
msgstr "Modifié à"

#: src/custom_widgets/model_manager_widget.py:276
msgid "Description"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:424
msgid "Change"
msgstr "Changer"

#: src/custom_widgets/model_manager_widget.py:427
msgid "Model Profile Picture"
msgstr "Photo de profil du modèle"

#: src/custom_widgets/model_manager_widget.py:427
msgid "What do you want to do with the model's profile picture?"
msgstr "Que voulez-vous faire avec la photo de profil du modèle? ?"

#: src/custom_widgets/model_manager_widget.py:449
msgid "Create Child"
msgstr "Créer un enfant"

#: src/custom_widgets/model_manager_widget.py:457
msgid "Remove Model"
msgstr "Supprimer le modèle"

#: src/custom_widgets/model_manager_widget.py:460
msgid "Remove Model?"
msgstr "Supprimer le modèle ?"

#: src/custom_widgets/model_manager_widget.py:461
msgid "Are you sure you want to remove '{}'?"
msgstr "Êtes-vous sur de vouloirs supprimer '{}' ?"

#: src/custom_widgets/model_manager_widget.py:475
msgid "Multilingual"
msgstr "Multilingue"

#: src/custom_widgets/model_manager_widget.py:476
msgid "Code"
msgstr "Code"

#: src/custom_widgets/model_manager_widget.py:477
msgid "Math"
msgstr "Math"

#: src/custom_widgets/model_manager_widget.py:478
msgid "Vision"
msgstr "Vision"

#: src/custom_widgets/model_manager_widget.py:479
msgid "Embedding"
msgstr "Intégré"

#: src/custom_widgets/model_manager_widget.py:480
msgid "Tools"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:481
msgid "Small"
msgstr "Petit"

#: src/custom_widgets/model_manager_widget.py:482
msgid "Medium"
msgstr "Moyen"

#: src/custom_widgets/model_manager_widget.py:483
msgid "Big"
msgstr "Grand"

#: src/custom_widgets/model_manager_widget.py:484
msgid "Huge"
msgstr "Gigantesque"

#: src/custom_widgets/model_manager_widget.py:573
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""
"En téléchargeant ce modèle, vous acceptez l'accord de licence disponible sur "
"le site web du modèle"

#: src/custom_widgets/terminal_widget.py:80
msgid "Setting up Python environment..."
msgstr "Paramétrage de l'environnement Python..."

#: src/custom_widgets/terminal_widget.py:98
msgid "Compiling C++ script..."
msgstr "Compilation du script C++..."

#: src/custom_widgets/terminal_widget.py:111
msgid "Running local web server"
msgstr "Exécution d'un serveur local"

#: src/custom_widgets/terminal_widget.py:136
msgid "Using Flatpak contained shell"
msgstr "Utilisation du terminal conteneurisé de Flatpak"

#: src/custom_widgets/terminal_widget.py:136
msgid "Using SSH to run command"
msgstr ""

#: src/custom_widgets/terminal_widget.py:142
msgid "Script Exited"
msgstr ""

#~ msgid "Clear Chat?"
#~ msgstr "Effacer la discussion ?"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "Êtes-vous sur de vouloir effacer la discussion ?"

#~ msgid "Clear"
#~ msgstr "Effacer"

#~ msgid "Clear Chat"
#~ msgstr "Effacer la discussion"

#~ msgid "Regenerate Equation"
#~ msgstr "Régénérer l'équation"

#~ msgid "LaTeX Equation"
#~ msgstr "Équation LaTeX"

#~ msgid "Built in Ollama instance"
#~ msgstr "Ollama pré-intégré"

#~ msgid "Chat with local AI models"
#~ msgstr "Discutez avec des modèles d'IA localement grâce à Ollama"

#~ msgid "An Ollama client"
#~ msgstr "Un client pour Ollama"

#~ msgid "Connect"
#~ msgstr "Connecter"

#~ msgid "Server URL"
#~ msgstr "URL du serveur"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Bearer Token (optionnel)"

#~ msgid "Connect Remote Instance"
#~ msgstr "Connecter l'instance distante"

#~ msgid "Enter instance information to continue"
#~ msgstr "Entrer les informations de l'instance distante pour continuer"

#~ msgid "Close Alpaca"
#~ msgstr "Fermer Alpaca"

#~ msgid "Use Local Instance"
#~ msgstr "Utiliser l'instance locale"

#~ msgid "Connection Error"
#~ msgstr "Erreur de connexion"

#~ msgid "The remote instance has disconnected"
#~ msgstr "L'instance distante s'est deconnectée"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Une erreur est survenue avec l'instance local d'Ollama, elle a donc été "
#~ "reinitialisée"

#~ msgid "An error occurred: {}"
#~ msgstr "Une erreur est survenue : {}"

#~ msgid ""
#~ "QwQ is an experimental research model focused on advancing AI reasoning "
#~ "capabilities."
#~ msgstr ""
#~ "QwQ est un modèle de recherche expérimental conçu pour faire progresser "
#~ "les capacités de raisonnement de l'IA."

#~ msgid ""
#~ "Mistral Small is a lightweight model designed for cost-effective use in "
#~ "tasks like translation and summarization."
#~ msgstr ""
#~ "Mistral Small est un modèle léger conçu pour un usage rentable dans des "
#~ "tâches comme la traduction et la synthèse."

#~ msgid "Ollama instance was shut down due to inactivity"
#~ msgstr "Ollama a été désactivée faute d'activitée"

#~ msgid "Loading Instance"
#~ msgstr "Chargement de l'instance"

#~ msgid "Local Models"
#~ msgstr "Modèles locaux"

#~ msgid ""
#~ "It looks a bit empty in here. Try downloading some models to get started!"
#~ msgstr ""
#~ "Ça l'air un peu vide par ici. Essayez de télécharger quelques modèles "
#~ "pour commencer !"

#~ msgid "Available Models"
#~ msgstr "Modèles disponibles"

#~ msgid "General"
#~ msgstr "Général"

#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Utiliser une instance externe d'Ollama"

#~ msgid "Change Ollama Instance"
#~ msgstr "Changer l'instance Ollama"

#~ msgid ""
#~ "The default model to use on new chats and when generating chat titles"
#~ msgstr ""
#~ "Le modèle par défaut utilisé pour les nouvelles discussions et pour la "
#~ "génération des titres des dicussions"

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "Augmenter la température rendra le modèle plus créatif. (Défaut : 0.8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Nombre aléatoire utilisé pour la génération. Définie sur une valeur, le "
#~ "modèle génèrera le même texte pour le même prompt. (Défaut : 0 "
#~ "(aléatoire))"

#~ msgid "Keep Alive Time"
#~ msgstr "Temps chargé en mémoire"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Contrôlez combien de temps le modèle restera chargé en mémoire suivant la "
#~ "demande en minute (Défaut : 5)"

#~ msgid "Ollama Instance"
#~ msgstr "Instance Ollama"

#~ msgid "Ollama Overrides"
#~ msgstr "Paramètres d'Ollama"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Gérer les arguments utilisés par Ollama. Tout les changements sur cette "
#~ "page ne s'appliquent qu'à l'instance intégrée. L'instance va redémarrer "
#~ "si vous effectuez des changements."

#~ msgid "Idle Timer"
#~ msgstr "Minuteur d'inactivité"

#~ msgid ""
#~ "Number of minutes the instance should remain idle before it is shut down "
#~ "(0 means it won't be shut down)"
#~ msgstr ""
#~ "Nombre de minutes durant laquelle l'instance reste inactive avant de "
#~ "s'éteindre (0 signifie qu'elle ne s'éteindra pas)"

#~ msgid "Change Model Directory"
#~ msgstr "Changer le dossier des modèles"

#~ msgid "Powered by Ollama"
#~ msgstr "Fonctionne grâce à Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Site web d'Ollama"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca et ses développeurs ne sont pas responsables d'aucun dommages "
#~ "causés à vos appareils ou logiciels lors de l'exécution de code généré "
#~ "par un modèle d'IA. Merci de faire attention et de vérifier prudemment le "
#~ "code avant de l'exécuter."

#~ msgid "Reload Local Models"
#~ msgstr "Recharger les modèles locaux"

#~ msgctxt "shortcut window"
#~ msgid "Import Chat"
#~ msgstr "Importer une discussion"

#~ msgctxt "shortcut window"
#~ msgid "Search Messages"
#~ msgstr "Recherche un message"

#~ msgid ""
#~ "It looks like you don't have any models downloaded yet. Download models "
#~ "to get started!"
#~ msgstr ""
#~ "On dirait que vous n'avez pas encore de modèles téléchargé. Télécharger "
#~ "un modèle pour commencer !"

#~ msgid "Not Available"
#~ msgstr "Non disponible"

#~ msgid "(No system message available)"
#~ msgstr "(Pas de message système disponible)"

#~ msgid "Visit Website"
#~ msgstr "Site web"

#~ msgid "From Existing Model"
#~ msgstr "Depuis un modèle existant"

#~ msgid "From GGUF File"
#~ msgstr "Depuis un fichier GGUF"

#~ msgid "From Name"
#~ msgstr "Depuis l'ID"

#~ msgid "image"
#~ msgstr "Image"

#~ msgid "Select Model"
#~ msgstr "Sélectionner un modèle"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Ce modèle va être utilisé comme base pour le nouveau modèle"

#~ msgid "Pull Model"
#~ msgstr "Télécharger le modèle"

#~ msgid ""
#~ "Input the name of the model in this format\n"
#~ "name:tag"
#~ msgstr ""
#~ "Entrez l'ID du modèle dans ce format\n"
#~ "nom:étiquette (name:tag)"

#~ msgid ""
#~ "The default model to use on new chats and when Alpaca is launched with "
#~ "the option --ask \"message\""
#~ msgstr ""
#~ "Le modèle par défaut utilisé pour les nouvelles discussions et lorsque "
#~ "Alpaca est exécuté avec l'option --ask \"message\""

#~ msgid "Manage models dialog"
#~ msgstr "Boite de dialogue "

#~ msgid "Create Model"
#~ msgstr "Créer un modèle"

#~ msgid "Refresh Local Models"
#~ msgstr "Actualiser les modèles locaux"

#~ msgid "Try a different search or pull an unlisted model from it's name"
#~ msgstr ""
#~ "Essayez une recherche différente ou téléchargez un modèle non listé "
#~ "depuis son nom"

#~ msgid "Pull Model From Name"
#~ msgstr "Télécharger un modèle depuis son nom"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "En téléchargeant ce modèle, vous acceptez le contrat de licence "
#~ "disponible sur le site du modèle."

#~ msgid "Model Details"
#~ msgstr "Détails du modèle"

#~ msgid ""
#~ "Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
#~ "instructions automatically. Please visit the model's website or Ollama "
#~ "documentation for more information if you're unsure."
#~ msgstr ""
#~ "Certain modèle requiert un 'modelfile', Alpaca complète les instructions "
#~ "FROM et SYSTEM (contexte) automatiquement. Merci de visiter le site du "
#~ "modèle ou la documentation d'Ollama pour plus d'information si vous "
#~ "n'êtes pas sûr."

#~ msgid "Create"
#~ msgstr "Créer"

#~ msgid "Stop Pulling '{}'"
#~ msgstr "Arrêter de télécharger '{}'"

#~ msgid "Details"
#~ msgstr "Détails"

#~ msgid "Remove '{}'"
#~ msgstr "Supprimer '{}'"

#~ msgid "Delete Model?"
#~ msgstr "Supprimer le modèle ?"

#~ msgid "Create Model Based on '{}'"
#~ msgstr "Créer un modèle basé sur '{}'"

#~ msgid "Format"
#~ msgstr "Format"

#~ msgid "Enter download menu for {}"
#~ msgstr "Accédez au menu de téléchargement pour {}"

#~ msgid "Download"
#~ msgstr "Télécharger"

#~ msgid "Large Model"
#~ msgstr "Grand modèle"

#~ msgid "Download {}:{}"
#~ msgstr "Télécharger {}:{}"

#~ msgid "Model deleted successfully"
#~ msgstr "Modèle supprimer avec succès"

#~ msgid "Task Complete"
#~ msgstr "Tâche complétée"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "Modèle '{}' téléchargé avec succès."

#~ msgid "Pull Model Error"
#~ msgstr "Erreur de téléchargement du modèle"

#~ msgid "Failed to pull model '{}': {}"
#~ msgstr "Échec de téléchargement du modèle '{}': {}"

#~ msgid "Error pulling '{}': {}"
#~ msgstr "Erreur lors du téléchargement de '{}': {}"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr ""
#~ "Échec du téléchargement du modèle '{}' du à une erreur de connexion."

#~ msgid "Error pulling '{}'"
#~ msgstr "Erreur lors du téléchargement de '{}'"

#~ msgid ""
#~ "New state of the art 70B model. Llama 3.3 70B offers similar performance "
#~ "compared to Llama 3.1 405B model."
#~ msgstr ""
#~ "Nouveau modèle de pointe avec 70 milliards de paramètres. Llama 3.3 70B "
#~ "offre des performances similaires au modèle Llama 3.1 405B."

#~ msgid "Script exited"
#~ msgstr "Script terminé"

#~ msgid "The script is contained inside Flatpak"
#~ msgstr "Le script est conteneurisé dans Flatpak"

#~ msgid "Close application"
#~ msgstr "Fermer l'application"

#~ msgid "Import chat"
#~ msgstr "Importer la discussion"

#~ msgid "Clear chat"
#~ msgstr "Effacer la discussion"

#~ msgid "New chat"
#~ msgstr "Nouvelle discussion"

#~ msgid "Show shortcuts window"
#~ msgstr "Voir les raccourcis claviers"

#~ msgid "Manage models"
#~ msgstr "Gestion des modèles"

#~ msgid "Toggle sidebar"
#~ msgstr "Basculer la barre latérale"

#~ msgid "Rename chat"
#~ msgstr "Renommer la discussion"

#~ msgid "Editor"
#~ msgstr "Éditeur"

#~ msgid "Message text box"
#~ msgstr "Boite de saisie des messages"

#~ msgid "Missing file"
#~ msgstr "Fichier manquant"

#~ msgid "Image Recognition"
#~ msgstr "Reconnaissance d'image"

#~ msgid ""
#~ "Your system's available RAM suggests that this model might be too large "
#~ "to run optimally. Are you sure you want to download it anyway?"
#~ msgstr ""
#~ "La RAM de votre système indique que ce modèle est peut-être trop grand "
#~ "pour être exécuter optimalement. Le télécharger quand même ?"

#~ msgid "This video is not available"
#~ msgstr "Cette vidéo n'est pas disponible"

#~ msgid "Select a Model"
#~ msgstr "Sélectionnez un modèle"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr ""
#~ "La discussion ne peut pas être effacée lors de la réception d'un message"

#~ msgid "Create Chat?"
#~ msgstr "Créer une discussion ?"

#~ msgid "Enter name for new chat"
#~ msgstr "Entrer le nom de la nouvelle discussion"

#~ msgid "Use local instance"
#~ msgstr "Utilisez l'instance locale"

#~ msgid "An error occurred while creating the model"
#~ msgstr "Une erreur est survenue lors de la création du modèle"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL de l'instance externe"

#~ msgid ""
#~ "Google Gemma 2 is a high-performing and efficient model by now available "
#~ "in three sizes: 2B, 9B, and 27B."
#~ msgstr ""
#~ "Google Gemma 2 est un modèle performant et efficace, désormais disponible "
#~ "en trois tailles : 2B, 9B et 27B."

#~ msgid "Loading instance"
#~ msgstr "Chargement de l'instance"

#~ msgid "Applying user preferences"
#~ msgstr "Application des préférences utilisateurs"

#~ msgid "Updating list of local models"
#~ msgstr "Mise-à-jour de la liste des modèles locaux"

#~ msgid "Updating list of available models"
#~ msgstr "Mise-à-jour de la liste des modèles disponibles"

#~ msgid "Loading chats"
#~ msgstr "Chargement des discussions"

#~ msgid "Loading Alpaca dialog"
#~ msgstr "Ajouté : boite de dialogue de lancement d'Alpaca"

#~ msgid "Loading Alpaca..."
#~ msgstr "Chargement d'Alpaca..."

#~ msgid "Failed to connect to server"
#~ msgstr "Échec de connexion au serveur"

#~ msgid "Stop Creating '{}'"
#~ msgstr "Arrêter de créer '{}'"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 est désormais disponible en 2 tailles, 9B et 27B."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr "Êtes-vous sur de vouloir arrêter de télécharger '{} ({})'?"

#~ msgid "Try a different search"
#~ msgstr "Essayez une autre recherche"

#~ msgid "Pulling in the background..."
#~ msgstr "Téléchargement en arrière plan..."

#~ msgid "Featured Models"
#~ msgstr "Modèles suggérés"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later.\n"
#~ "\n"
#~ "By downloading any model you accept their license agreement available on "
#~ "the model's website.\n"
#~ "                  "
#~ msgstr ""
#~ "Alpaca fonctionne localement sur votre appareil, pour commencer à "
#~ "discuter vous aurez besoin d'un modèle d'IA, vous pouvez soit télécharger "
#~ "des modèles depuis cette liste soit depuis le menu \"Gestion des "
#~ "modèles\" plus tard.\n"
#~ "\n"
#~ "En téléchargeant n'importe quels modèles, vous acceptez son contrat de "
#~ "licence disponible sur le site du modèle.\n"
#~ "                  "

#~ msgid "Built by Meta"
#~ msgstr "Développé par Meta"

#~ msgid "Built by Google DeepMind"
#~ msgstr "Développé par Google DeepMind"

#~ msgid "Built by Microsoft"
#~ msgstr "Développé par Microsoft"

#~ msgid "Multimodal AI with image recognition"
#~ msgstr "IA multimodale avec reconnaissance d'image"

#~ msgid "A conversation showing code highlight"
#~ msgstr "Code avec coloration syntaxique"

#~ msgid "A conversation involving multiple models"
#~ msgstr "Utilisation de plusieurs modèles"

#~ msgid "Managing models"
#~ msgstr "Gestion des modèles"
