# Brazilian Portuguese translations for Alpaca package.
# Copyright (C) 2024 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# Daimar Stein <daimarstein@pm.me>, 2024.
#
msgid ""
msgstr ""
"Project-Id-Version: 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-12 13:12-0600\n"
"PO-Revision-Date: 2024-05-23 23:29-0600\n"
"Last-Translator: Bruno Antunes <antunes.dll@gmail.com>\n"
"Language-Team: Brazilian Portuguese\n"
"Language: pt_BR\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ai;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1128
msgid "Features"
msgstr "Funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1130
msgid "Talk to multiple models in the same conversation"
msgstr "Fale com múltiplos modelos na mesma conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1131
msgid "Pull and delete models from the app"
msgstr "Baixe e delete modelos através do app"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
#, fuzzy
msgid "Have multiple conversations"
msgstr "Tenha múltiplas conversas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
#, fuzzy
msgid "Image recognition (Only available with compatible models)"
msgstr "Reconhecimento de imagem (Disponível apenas com o modelo LLaVA)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "Reconhecimento de documentos de texto simples"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
#, fuzzy
msgid "Import and export chats"
msgstr "Importe e exporte conversas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "Anexe transcrições do YouTube ao prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "Anexar texto de um site ao prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "Reconhecimento de PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/window.ui:90
msgid "Disclaimer"
msgstr "Aviso Legal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"Esse projeto não é afiliado de nenhuma forma com Ollama. Não sou responsável "
"por quaisquer danos ao seu dispositivo ou software causados por código "
"gerado por qualquer um dos modelos disponíveis."

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "Uma conversa normal com um modelo de IA"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "Uma conversa envolvendo reconhecimento de imagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "Uma conversa mostrando código em destaque"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "Um script Python rodando dentro do terminal integrado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation involving a YouTube video transcript"
msgstr "Uma conversa envolvendo uma transcrição de vídeo do YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "Vários modelos sendo baixados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "Model creator screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:104
#: data/com.jeffser.Alpaca.metainfo.xml.in:152
#: data/com.jeffser.Alpaca.metainfo.xml.in:170
#: data/com.jeffser.Alpaca.metainfo.xml.in:186
#: data/com.jeffser.Alpaca.metainfo.xml.in:198
#: data/com.jeffser.Alpaca.metainfo.xml.in:248
#: data/com.jeffser.Alpaca.metainfo.xml.in:294
#: data/com.jeffser.Alpaca.metainfo.xml.in:325
#: data/com.jeffser.Alpaca.metainfo.xml.in:334
#: data/com.jeffser.Alpaca.metainfo.xml.in:397
#: data/com.jeffser.Alpaca.metainfo.xml.in:425
#: data/com.jeffser.Alpaca.metainfo.xml.in:439
#: data/com.jeffser.Alpaca.metainfo.xml.in:456
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:476
#: data/com.jeffser.Alpaca.metainfo.xml.in:493
#: data/com.jeffser.Alpaca.metainfo.xml.in:503
#: data/com.jeffser.Alpaca.metainfo.xml.in:520
#: data/com.jeffser.Alpaca.metainfo.xml.in:530
#: data/com.jeffser.Alpaca.metainfo.xml.in:577
#: data/com.jeffser.Alpaca.metainfo.xml.in:602
#: data/com.jeffser.Alpaca.metainfo.xml.in:627
#: data/com.jeffser.Alpaca.metainfo.xml.in:649
#: data/com.jeffser.Alpaca.metainfo.xml.in:667
#: data/com.jeffser.Alpaca.metainfo.xml.in:685
#: data/com.jeffser.Alpaca.metainfo.xml.in:697
#: data/com.jeffser.Alpaca.metainfo.xml.in:713
msgid "Fixes"
msgstr "Correções"

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Fixed Ollama (Manged) instance not being able to be created"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:106
msgid "Instance manager now follows default model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:107
msgid "English text-to-speech voices not working"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:108
msgid "Instance manager sometimes not saving instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:109
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
#: data/com.jeffser.Alpaca.metainfo.xml.in:163
#: data/com.jeffser.Alpaca.metainfo.xml.in:180
#: data/com.jeffser.Alpaca.metainfo.xml.in:210
#: data/com.jeffser.Alpaca.metainfo.xml.in:220
#: data/com.jeffser.Alpaca.metainfo.xml.in:231
#: data/com.jeffser.Alpaca.metainfo.xml.in:258
#: data/com.jeffser.Alpaca.metainfo.xml.in:278
#: data/com.jeffser.Alpaca.metainfo.xml.in:304
#: data/com.jeffser.Alpaca.metainfo.xml.in:319
#: data/com.jeffser.Alpaca.metainfo.xml.in:344
#: data/com.jeffser.Alpaca.metainfo.xml.in:372
#: data/com.jeffser.Alpaca.metainfo.xml.in:382
#: data/com.jeffser.Alpaca.metainfo.xml.in:393
#: data/com.jeffser.Alpaca.metainfo.xml.in:407
#: data/com.jeffser.Alpaca.metainfo.xml.in:419
#: data/com.jeffser.Alpaca.metainfo.xml.in:435
#: data/com.jeffser.Alpaca.metainfo.xml.in:450
#: data/com.jeffser.Alpaca.metainfo.xml.in:485
#: data/com.jeffser.Alpaca.metainfo.xml.in:510
#: data/com.jeffser.Alpaca.metainfo.xml.in:541
#: data/com.jeffser.Alpaca.metainfo.xml.in:567
#: data/com.jeffser.Alpaca.metainfo.xml.in:589
#: data/com.jeffser.Alpaca.metainfo.xml.in:620
#: data/com.jeffser.Alpaca.metainfo.xml.in:642
#: data/com.jeffser.Alpaca.metainfo.xml.in:663
#: data/com.jeffser.Alpaca.metainfo.xml.in:678
#: data/com.jeffser.Alpaca.metainfo.xml.in:703
msgid "New"
msgstr "Novo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:118
msgid "Smart tools for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:119
msgid "Speech recognition (message dictation)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:120
msgid "Text to Speech"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:121
msgid "New Quick Chat system"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "Filter Ollama models by categories"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Better math Latex rendering in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Rich text rendering in attachment preview"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Matplotlib is now included in Python code runner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Styling for messages being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
#: data/com.jeffser.Alpaca.metainfo.xml.in:236
msgid "New Instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:130
msgid "Deepseek"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:131
msgid "OpenRouter AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:132
msgid "Anthropic"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:133
msgid "Groq Cloud"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "Fireworks AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:135
msgid "Lambda Labs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:137
msgid "New Attachment Types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:139
msgid "Microsoft Word Document (docx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:140
msgid "Microsoft PowerPoint Document (pptx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:141
msgid "Microsoft Excel Document (xlsx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:143
msgid "New Tools"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:145 src/tool_manager.py:431
msgid "Run Command (Testing)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:146 src/tool_manager.py:348
msgid "Online Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:147 src/tool_manager.py:306
msgid "Extract Wikipedia Article"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:148 src/tool_manager.py:210
msgid "Get Recipe by Name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:149 src/tool_manager.py:261
msgid "Get Recipes by Category"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:150 src/tool_manager.py:176
msgid "Get Current Datetime"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:154
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:155
msgid "Fixed bold text not rendering correctly in tables"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:156
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:165
msgid "Updated runtime to Gnome 48"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:166
msgid "Added back 'category pills' to model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:167
msgid "Better appearance for model manager sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:168
#: data/com.jeffser.Alpaca.metainfo.xml.in:184
msgid "New models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:172
msgid "Fixed bad title generation with chain-of-thought models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:173
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Option to delete all chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:183
msgid "Button to refresh sample prompts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:188
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:189
msgid "Fixed stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:190
msgid "Fixed model search not working if there are only pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:191
msgid "Fixed sample prompts sometimes not appearing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:200
msgid "Don't clear the building output of C++ scripts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:201
msgid "Better handling of attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:202
msgid "Handle remote Ollama instance's API Key better"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Remove '\\n' characters in instance edit page"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:212
msgid "Dynamic chat loading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Updated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:222
msgid "Tweaked appearance of models in model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:223
msgid "Updated Ollama instance to 0.5.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:224
msgid "Added new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:233
msgid "New instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:234
msgid "New welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:238
msgid "OpenAI ChatGPT"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "Google Gemini"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:240
msgid "Together AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
msgid "Venice"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:250
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "Fixed attachment filters"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "New model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Changed GtkSpinner to AdwSpinner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Better handling of launch process"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid "New loading screen at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:264
msgid "Better handling of file types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:265
msgid "Better regex expression for LaTeX equations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:266
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:267
msgid "Better handling of think tags in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:268
msgid "Default model is now in charge of generating titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:269
msgid "Message header is now shown whilst the message is being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:270
msgid "Better handling of model profile pictures"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:271
msgid "New models in 'available models' list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:280
msgid "Added option for attaching screenshots"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:281
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:282
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:283
msgid "Added option to open the environment directory from the terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:284
msgid "Added option to edit code blocks directly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:285
msgid "Complete keyboard shortcut list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Images are now attached in 640p resolution"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:287
msgid "Website attachments now use extracted titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:288
msgid "Better chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:289
msgid "Added option to attach any plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:290
msgid "Added spellchecker to message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:291
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:292
msgid "Small appearance changes in text entries"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:296
msgid "Alpaca's launch process is more reliable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Closing the terminal now kills the script subprocess"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:306
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Changed appearance of messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid "Added the option to add profile pictures to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:310
#: data/com.jeffser.Alpaca.metainfo.xml.in:782
#: data/com.jeffser.Alpaca.metainfo.xml.in:831
msgid "Fix"
msgstr "Corrigido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:321
msgid "Added categories to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:322
msgid "Specified model's languages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Added warning when downloading embedding models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:327
msgid "Replaced low ram warning with big model warning"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:336
msgid "Correctly escape markup before rendering message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:337
msgid "Fixed about dialog not working if log file was missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:346
msgid "System messages can now be sent directly from Alpaca"
msgstr "As mensagens do sistema agora podem ser enviadas diretamente do Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:347
msgid "New redesign for messages and smaller minimum size"
msgstr "Novo design para mensagens e tamanho mínimo menor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:348
msgid "New models included in 'available models list'"
msgstr "Novos modelos incluídos na ‘lista de modelos disponíveis’"

#: data/com.jeffser.Alpaca.metainfo.xml.in:349
msgid "Added symbolic icon when attaching code files"
msgstr "Adicionado ícone simbólico ao anexar arquivos de código"

#: data/com.jeffser.Alpaca.metainfo.xml.in:350
msgid "When exporting a chat it now includes a markdown file"
msgstr "Ao exportar uma conversa, ele agora inclui um arquivo markdown"

#: data/com.jeffser.Alpaca.metainfo.xml.in:351
msgid "Refresh button in model manager when using a remote instance"
msgstr "Botão Atualizar no gerenciador de modelos ao usar uma instância remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:352
msgid "Assistant messages are now editable"
msgstr "As mensagens do assistente agora são editáveis"

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "Updated Ollama to v0.5.2"
msgstr "Ollama atualizado para v0.5.2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "New option to change model directory"
msgstr "Nova opção para alterar o diretório do modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "File previewer now resizes dynamically to content"
msgstr ""
"O visualizador de arquivos agora é redimensionado dinamicamente para o "
"conteúdo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr "Alpaca adaptado para funcionar sem instância integrada do Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
msgid "Compatibility added with ODT files"
msgstr "Compatibilidade adicionada com arquivos ODT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:360
msgid "Restored ROCm compatibility"
msgstr "Compatibilidade ROCm restaurada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Adicionado gesto de toque longo nas linhas da conversa para que as ações "
"possam ser feitas em telas sensíveis ao toque"

#: data/com.jeffser.Alpaca.metainfo.xml.in:362
msgid "Fixed edit button not saving changes"
msgstr "Corrigido o botão de edição que não salvava as alterações"

#: data/com.jeffser.Alpaca.metainfo.xml.in:363
msgid "Changed max temperature value to 2"
msgstr "Valor de temperatura máxima alterado para 2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:364
msgid "Made seed 0 actually random"
msgstr "Tornou a semente 0 realmente aleatória"

#: data/com.jeffser.Alpaca.metainfo.xml.in:365
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""
"Corrigido o provedor de pesquisa do Gnome que não funcionava fora das "
"instalações do Flatpak"

#: data/com.jeffser.Alpaca.metainfo.xml.in:374
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""
"Nova opção --ask MESSAGE, para abrir uma nova janela de 'Pergunta Rápida'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:375
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""
"A integração do Gnome Search agora funciona enquanto o aplicativo está aberto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:384
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""
"Adicionados parâmetros de inicialização --ask MESSAGE, --new-chat CHAT, --"
"select-chat CHAT, --list-chart, --version"

#: data/com.jeffser.Alpaca.metainfo.xml.in:385
msgid "Added integration as Gnome Search Provider"
msgstr "Adicionada integração como Gnome Search Provider"

#: data/com.jeffser.Alpaca.metainfo.xml.in:386
msgid "Updated Ollama to v0.4.2 with new models"
msgstr "Ollama atualizado para v0.4.2 com novos modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:395
msgid "User messages are now compacted into bubbles"
msgstr "As mensagens do usuário agora estão compactadas em bolhas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:399
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""
"Corrigida a caixa de diálogo de reconexão que não funcionava quando 'usar "
"instância local' era selecionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""
"Corrigido o gerenciador de modelos que não se adaptava a fontes grandes do "
"sistema"

#: data/com.jeffser.Alpaca.metainfo.xml.in:409
msgid "Details page for models"
msgstr "Página de detalhes dos modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""
"O seletor de modelo é substituído pelo botão ‘gerenciar modelos’ quando não "
"hámodelos baixados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:411
msgid "Added warning when model is too big for the device"
msgstr "Adicionado aviso quando o modelo é muito grande para o dispositivo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "Added AMD GPU indicator in preferences"
msgstr "Adicionado indicador de GPU AMD nas preferências"

#: data/com.jeffser.Alpaca.metainfo.xml.in:421
msgid "Better system for handling dialogs"
msgstr "Melhor sistema para lidar com diálogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:422
msgid "Better system for handling instance switching"
msgstr "Melhor sistema para lidar com a troca de instâncias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "Remote connection dialog"
msgstr "Caixa de diálogo de conexão remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:427
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""
"Corrigido: os modelos eram duplicados ao alternar instâncias remotas e locais"

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "Better internal instance manager"
msgstr "Melhor gerenciador de instâncias internas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:437
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr "Adicionados botões 'Cancelar' e 'Salvar' ao editar uma mensagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:441
msgid "Better handling of image recognition"
msgstr "Melhor manuseio do reconhecimento de imagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:442
msgid "Remove unused files when canceling a model download"
msgstr "Remova arquivos não utilizados ao cancelar o download de um modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:443
msgid "Better message blocks rendering"
msgstr "Melhor renderização de blocos de mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:452
msgid "Run bash and python scripts straight from chat"
msgstr "Execute scripts bash e python diretamente do chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:453
msgid "Updated Ollama to 0.3.12"
msgstr "Ollama atualizado para 0.3.12"

#: data/com.jeffser.Alpaca.metainfo.xml.in:454
msgid "New models!"
msgstr "Novos modelos!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Fixed and made faster the launch sequence"
msgstr "Corrigida e agilizada a sequência de lançamento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Better detection of code blocks in messages"
msgstr "Melhor detecção de blocos de código em mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""
"Corrigido o aplicativo que não carregava em certas configurações com GPUs "
"Nvidia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""
"Notificação de mensagem corrigida que às vezes travava a renderização de "
"texto porque eles eramexecutados em threads diferentes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Fixed message generation sometimes failing"
msgstr "Corrigida a geração de mensagens que às vezes falhava"

#: data/com.jeffser.Alpaca.metainfo.xml.in:487
msgid "Sidebar resizes with the window"
msgstr "A barra lateral é redimensionada com a janela"

#: data/com.jeffser.Alpaca.metainfo.xml.in:488
msgid "New welcome dialog"
msgstr "Nova caixa de diálogo de boas-vindas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:489
msgid "Message search"
msgstr "Pesquisa de mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:490
msgid "Updated Ollama to v0.3.11"
msgstr "Ollama atualizado para v0.3.11"

#: data/com.jeffser.Alpaca.metainfo.xml.in:491
msgid "A lot of new models provided by Ollama repository"
msgstr "Muitos novos modelos fornecidos pelo repositório Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""
"Texto corrigido dentro do gerenciador de modelos quando a opção de "
"acessibilidade 'texto grande' está ativada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Fixed image recognition on unsupported models"
msgstr "Reconhecimento de imagem corrigido em modelos não suportados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:505
msgid "Fixed spinner not hiding if the back end fails"
msgstr "Corrigido o spinner que não se ocultava se o back-end falhasse"

#: data/com.jeffser.Alpaca.metainfo.xml.in:506
msgid "Fixed image recognition with local images"
msgstr "Reconhecimento de imagem corrigido com imagens locais"

#: data/com.jeffser.Alpaca.metainfo.xml.in:507
msgid "Changed appearance of delete / stop model buttons"
msgstr "Aparência alterada dos botões excluir/parar modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:508
msgid "Fixed stop button crashing the app"
msgstr "Botão de parada corrigido travando o aplicativo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:512
msgid "Made sidebar resize a little when the window is smaller"
msgstr "A barra lateral foi redimensionada um pouco quando a janela é menor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:513
msgid "Instant launch"
msgstr "Lançamento instantâneo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:522
msgid "Fixed error on first run (welcome dialog)"
msgstr "Erro corrigido na primeira execução (caixa de diálogo de boas-vindas)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:523
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""
"Verificador corrigido para instância do Ollama (usado em pacotes do sistema)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:532
msgid "Fixed 'clear chat' option"
msgstr "Opção de 'limpar conversa' corrigida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:533
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""
"Foi corrigida a caixa de diálogo de boas-vindas que fazia com que a "
"instância local não fosse iniciada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:534
msgid "Fixed support for AMD GPUs"
msgstr "Suporte fixo para GPUs AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:543
msgid "Model, message and chat systems have been rewritten"
msgstr "Modelo, sistemas de mensagens e chat foram reescritos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:544
msgid "New models are available"
msgstr "Novos modelos estão disponíveis"

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Ollama updated to v0.3.9"
msgstr "Ollama atualizado para v0.3.9"

#: data/com.jeffser.Alpaca.metainfo.xml.in:546
msgid "Added support for multiple chat generations simultaneously"
msgstr "Adicionado suporte para múltiplas gerações de chat simultaneamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:547
msgid "Added experimental AMD GPU support"
msgstr "Adicionado suporte experimental para GPU AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:548
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""
"Adicionado botão giratório de carregamento de mensagens e indicador de nova "
"mensagem na guia de conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "Added animations"
msgstr "Animações adicionadas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid "Changed model manager / model selector appearance"
msgstr "Aparência do gerenciador de modelo/seletor de modelo alterada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Changed message appearance"
msgstr "Aparência da mensagem alterada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:552
msgid "Added markdown and code blocks to user messages"
msgstr "Adicionados markdown e blocos de código às mensagens do usuário"

#: data/com.jeffser.Alpaca.metainfo.xml.in:553
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""
"Adicionada caixa de diálogo de carregamento na inicialização para que o "
"aplicativo abra mais rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:554
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""
"Adicionado aviso quando o dispositivo está no modo 'economia de bateria'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:555
msgid "Added inactivity timer to integrated instance"
msgstr "Adicionado temporizador de inatividade à instância integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:558
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr "A conversa agora rola para baixo quando é alterado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:559
msgid "Better handling of focus on messages"
msgstr "Melhor tratamento do foco nas mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "Better general performance on the app"
msgstr "Melhor desempenho geral do aplicativo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:569
msgid "New duplicate chat option"
msgstr "Nova opção de conversa duplicado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:570
msgid "Changed model selector appearance"
msgstr "Alterada a aparência do seletor de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:571
msgid "Message entry is focused on launch and chat change"
msgstr "A entrada de mensagens é focada no lançamento e na mudança do chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:572
msgid "Message is focused when it's being edited"
msgstr "A mensagem é focada quando está sendo editada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:573
msgid "Added loading spinner when regenerating a message"
msgstr "Adicionado botão giratório de carregamento ao regenerar uma mensagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:574
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr "Adicionada depuração Ollama à caixa de diálogo 'Sobre Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:575
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""
"Aparência e comportamento da caixa de diálogo de transcrição do YouTube "
"alterados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:579
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""
"CTRL+W e CTRL+Q interrompem a instância local antes de fechar o aplicativo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:580
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""
"Alterada a aparência do botão 'Abrer Gerenciador de Modelo' na tela de boas-"
"vindas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Fixed message generation not working consistently"
msgstr ""
"Corrigida a geração de mensagens que não funcionava de forma consistente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:582
msgid "Fixed message edition not working consistently"
msgstr "Edição de mensagem corrigida que não funcionava de forma consistente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:591
msgid "Model manager opens faster"
msgstr "O gerenciador de modelos abre mais rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:592
msgid "Delete chat option in secondary menu"
msgstr "Excluir opção de conversa no menu secundário"

#: data/com.jeffser.Alpaca.metainfo.xml.in:593
msgid "New model selector popup"
msgstr "Pop-up de seletor de novo modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:594
msgid "Standard shortcuts"
msgstr "Atalhos padrão"

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Model manager is navigable with keyboard"
msgstr "O gerenciador de modelos é navegável com teclado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Changed sidebar collapsing behavior"
msgstr "Comportamento de recolhimento da barra lateral alterado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:597
msgid "Focus indicators on messages"
msgstr "Indicadores de foco nas mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Welcome screen"
msgstr "Tela de boas-vindas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid "Give message entry focus at launch"
msgstr "Dê foco à entrada de mensagens no lançamento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:600
msgid "Generally better code"
msgstr "Geralmente código melhor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Better width for dialogs"
msgstr "Melhor largura para diálogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Better compatibility with screen readers"
msgstr "Melhor compatibilidade com leitores de tela"

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Fixed message regenerator"
msgstr "Corrigido regenerador de mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:607
msgid "Removed 'Featured models' from welcome dialog"
msgstr "Removido 'Modelos em destaque' da caixa de diálogo de boas-vindas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:608
msgid "Added default buttons to dialogs"
msgstr "Adicionados botões padrão às caixas de diálogo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:609
msgid "Fixed import / export of chats"
msgstr "Corrigido importação/exportação de conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:610
msgid "Changed Python2 title to Python on code blocks"
msgstr "Alterado o título Python2 para Python em blocos de código"

#: data/com.jeffser.Alpaca.metainfo.xml.in:611
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""
"Impedir a regeneração do título quando o usuário o alterou para um título "
"personalizado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:612
msgid "Show date on stopped messages"
msgstr "Mostrar data nas mensagens interrompidas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Fix clear chat error"
msgstr "Corrigir erro de limpeza de conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Changed shortcuts to standards"
msgstr "Alterado atalhos para padrões"

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Moved 'Manage Models' button to primary menu"
msgstr "Botão 'Gerenciar modelos' movido para o menu principal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "Stable support for GGUF model files"
msgstr "Suporte estável para arquivos de modelo GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
#: data/com.jeffser.Alpaca.metainfo.xml.in:900
#, fuzzy
msgid "General optimizations"
msgstr "Otimização geral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:629
msgid "Better handling of enter key (important for Japanese input)"
msgstr "Melhor manuseio da tecla Enter (importante para entrada em japonês)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:630
msgid "Removed sponsor dialog"
msgstr "Revovido diálogo do patrocinador"

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "Added sponsor link in about dialog"
msgstr "Adicionado link de patrocinador na caixa de diálogo sobre"

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Changed window and elements dimensions"
msgstr "Alteradas as dimensões de janelas e elementos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:633
msgid "Selected model changes when entering model manager"
msgstr "O modelo selecionado muda ao entrar no gerenciador de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:634
msgid "Better image tooltips"
msgstr "Melhores dicas de ferramentas de imagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:635
msgid "GGUF Support"
msgstr "Suporte GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Regenerate any response, even if they are incomplete"
msgstr "Gere novamente qualquer resposta, mesmo que esteja incompleta"

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Support for pulling models by name:tag"
msgstr "Suporte para puxar modelos por nome:tag"

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Restored sidebar toggle button"
msgstr "Botão de alternância da barra lateral restaurado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:651
msgid "Reverted back to standard styles"
msgstr "Revertido para estilos padrão"

#: data/com.jeffser.Alpaca.metainfo.xml.in:652
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr "Corrigidos títulos gerados com \"'S\" por algum motivo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:653
msgid "Changed min width for model dropdown"
msgstr "Largura mínima alterada para o menu suspenso do modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Changed message entry shadow"
msgstr "Sombra de entrada de mensagem alterada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "The last model used is now restored when the user changes chat"
msgstr ""
"O último modelo utilizado agora é restaurado quando o usuário muda de "
"conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:656
msgid "Better check for message finishing"
msgstr "É melhor verificar o final da mensagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
msgid "Added table rendering (Thanks Nokse)"
msgstr "Adicionada renderização de tabela (Obrigado Nokse)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:669
msgid "Made support dialog more common"
msgstr "Tornou o diálogo de suporte mais comum"

#: data/com.jeffser.Alpaca.metainfo.xml.in:670
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""
"O título da caixa de diálogo no seletor de tags ao baixar modelos não era "
"exibido corretamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr "Impedir que a geração de chat gere um título com múltiplas linhas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Bearer Token entry on connection error dialog"
msgstr "Entrada do Bearer Token na caixa de diálogo de erro de conexão"

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Small appearance changes"
msgstr "Pequenas mudanças na aparência"

#: data/com.jeffser.Alpaca.metainfo.xml.in:682
msgid "Compatibility with code blocks without explicit language"
msgstr "Compatibilidade com blocos de código sem linguagem explícita"

#: data/com.jeffser.Alpaca.metainfo.xml.in:683
msgid "Rare, optional and dismissible support dialog"
msgstr "Diálogo de suporte raro, opcional e dispensável"

#: data/com.jeffser.Alpaca.metainfo.xml.in:687
msgid "Date format for Simplified Chinese translation"
msgstr "Formato de data para tradução em chinês simplificado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:688
msgid "Bug with unsupported localizations"
msgstr "Bug com localizações não suportadas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:689
msgid "Min height being too large to be used on mobile"
msgstr "A altura mínima é muito grande para ser usada em dispositivos móveis"

#: data/com.jeffser.Alpaca.metainfo.xml.in:690
msgid "Remote connection checker bug"
msgstr "Bug no verificador de conexão remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:699
msgid "Models with capital letters on their tag don't work"
msgstr "Modelos com letras maiúsculas na etiqueta não funcionam"

#: data/com.jeffser.Alpaca.metainfo.xml.in:700
msgid "Ollama fails to launch on some systems"
msgstr "Ollama não consegue iniciar em alguns sistemas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:701
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""
"As transcrições do YouTube não estão sendo salvas no diretório TMP correto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:705
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""
"Mensagens de depuração agora são mostradas na caixa de diálogo 'Sobre Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr "Ollama atualizado para v0.3.0 (novos modelos)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:715
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""
"Modelos com '-' em seus nomes não funcionavam corretamente, isso foi "
"corrigido agora"

#: data/com.jeffser.Alpaca.metainfo.xml.in:716
msgid "Better connection check for Ollama"
msgstr "Melhor verificação de conexão para Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Stable Release"
msgstr "Lançamento estável"

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""
"O novo ícone foi feito por Tobias Bernard no Gnome Gitlab, obrigadopelo "
"ótimo ícone!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Features and fixes"
msgstr "Recursos e correções"

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid "Updated Ollama instance to 0.2.8"
msgstr "Instância Ollama atualizada para 0.2.8"

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid "Better model selector"
msgstr "Melhor seletor de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Model manager redesign"
msgstr "Redesenho do gerenciador de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:730
msgid "Better tag selector when pulling a model"
msgstr "Melhor seletor de tags ao extrair um modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:731
msgid "Model search"
msgstr "Pesquisa de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:732
msgid "Added support for bearer tokens on remote instances"
msgstr "Adicionado suporte para tokens ao portador em instâncias remotas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:733
msgid "Preferences dialog redesign"
msgstr "Redesenho da caixa de diálogo de preferências"

#: data/com.jeffser.Alpaca.metainfo.xml.in:734
msgid "Added context menus to interact with a chat"
msgstr "Adicionados menus de contexto para interagir com uma conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:735
msgid "Redesigned primary and secondary menus"
msgstr "Menus primários e secundários redesenhados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:736
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""
"Integração com o YouTube: cole o URL de um vídeo com uma transcrição e ele "
"seráadicionado ao prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:737
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""
"Integração de site (Experimental): Extraia o texto do corpo de umsite "
"adicionando sua URL ao prompt"

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Chat title generation"
msgstr "Geração de título de conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:739
msgid "Auto resizing of message entry"
msgstr "Redimensionamento automático da entrada de mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Chat notifications"
msgstr "Notificações de conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:741
msgid "Added indicator when an image is missing"
msgstr "Adicionado indicador quando uma imagem está faltando"

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""
"Reorganizar automaticamente a ordem dos chats quando uma mensagem é recebida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Redesigned file preview dialog"
msgstr "Caixa de diálogo de visualização de arquivo redesenhada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Credited new contributors"
msgstr "Novos contribuidores creditados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:745
msgid "Better stability and optimization"
msgstr "Melhor estabilidade e otimização"

#: data/com.jeffser.Alpaca.metainfo.xml.in:746
msgid "Edit messages to change the context of a conversation"
msgstr "Edite mensagens para alterar o contexto de uma conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "Added disclaimers when pulling models"
msgstr "Adicionadas isenções de responsabilidade ao extrair modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:748
msgid "Preview files before sending a message"
msgstr "Visualize arquivos antes de enviar uma mensagem"

#: data/com.jeffser.Alpaca.metainfo.xml.in:749
msgid "Better format for date and time on messages"
msgstr "Melhor formato de data e hora nas mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:750
msgid "Error and debug logging on terminal"
msgstr "Registro de erros e depuração no terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Auto-hiding sidebar button"
msgstr "Botão de ocultação automática da barra lateral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:752
msgid "Various UI tweaks"
msgstr "Vários ajustes de interface do usuário"

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "New Models"
msgstr "Novos Modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:756
msgid "Gemma2"
msgstr "Gemma2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:757
msgid "GLM4"
msgstr "GLM4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:758
msgid "Codegeex4"
msgstr "Codegeex4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:759
msgid "InternLM2"
msgstr "InternLM2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Llama3-groq-tool-use"
msgstr "Llama3-groq-tool-use"

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Mathstral"
msgstr "Mathstral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Mistral-nemo"
msgstr "Mistral-nemo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "Firefunction-v2"
msgstr "Firefunction-v2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "Nuextract"
msgstr "Nuextract"

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Translations"
msgstr "Traduções"

#: data/com.jeffser.Alpaca.metainfo.xml.in:767
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""
"Estas são todas as traduções disponíveis na versão 1.0.0, obrigado a todosos "
"contribuidores!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:769
msgid "Russian: Alex K"
msgstr "Russo: Alex K."

#: data/com.jeffser.Alpaca.metainfo.xml.in:770
msgid "Spanish: Jeffser"
msgstr "Espanhol: Jeffser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:771
msgid "Brazilian Portuguese: Daimar Stein"
msgstr "Português Brasileiro: Daimar Stein"

#: data/com.jeffser.Alpaca.metainfo.xml.in:772
msgid "French: Louis Chauvet-Villaret"
msgstr "Francês: Louis Chauvet-Villaret"

#: data/com.jeffser.Alpaca.metainfo.xml.in:773
msgid "Norwegian: CounterFlow64"
msgstr "Norueguês: CounterFlow64"

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid "Bengali: Aritra Saha"
msgstr "Bengali: Aritra Saha"

#: data/com.jeffser.Alpaca.metainfo.xml.in:775
msgid "Simplified Chinese: Yuehao Sui"
msgstr "Chinês simplificado: Yuehao Sui"

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""
"Compatibilidade DOCX removida temporariamente devido a erro comdependência "
"python-lxml"

#: data/com.jeffser.Alpaca.metainfo.xml.in:789
#: data/com.jeffser.Alpaca.metainfo.xml.in:819
#: data/com.jeffser.Alpaca.metainfo.xml.in:840
#: data/com.jeffser.Alpaca.metainfo.xml.in:1045
#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
msgid "Big Update"
msgstr "Grande Atualização"

#: data/com.jeffser.Alpaca.metainfo.xml.in:791
#, fuzzy
msgid "Added compatibility for PDF"
msgstr "Compatibilidade com PDF adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:792
#, fuzzy
msgid "Added compatibility for DOCX"
msgstr "Compatibilidade com DOCX adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:793
msgid "Merged 'file attachment' menu into one button"
msgstr "Mesclado menu de 'anexo de arquivo' em um botão"

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
#: data/com.jeffser.Alpaca.metainfo.xml.in:993
#, fuzzy
msgid "Quick Fix"
msgstr "Correção rápida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""
"Ocorreram alguns erros durante a transição da versão antiga dos chats paraa "
"nova versão. Peço desculpas se isso causou alguma corrupção em seu histórico "
"de chat.Este deverá ser o único momento em que tal transição será necessária."

#: data/com.jeffser.Alpaca.metainfo.xml.in:807
#: data/com.jeffser.Alpaca.metainfo.xml.in:959
#, fuzzy
msgid "Huge Update"
msgstr "Atualização Enorme"

#: data/com.jeffser.Alpaca.metainfo.xml.in:809
#, fuzzy
msgid "Added: Support for plain text files"
msgstr "Suporte para múltiplas tags em um único modelo foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:810
msgid "Added: New backend system for storing messages"
msgstr "Adicionado: Novo sistema backend para armazenamento de mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:811
#, fuzzy
msgid "Added: Support for changing Ollama's overrides"
msgstr "Suporte para múltiplas tags em um único modelo foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
#, fuzzy
msgid "General Optimization"
msgstr "Otimização geral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Added: Support for GGUF models (experimental)"
msgstr "Adicionado: Suporte para modelos GGUF (experimental)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
#, fuzzy
msgid "Added: Support for customization and creation of models"
msgstr "Suporte para múltiplas tags em um único modelo foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr "Corrigido: os ícones não aparecem em sistemas que não sejam Gnome"

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Update Ollama to v0.1.39"
msgstr "Atualizar Ollama para v0.1.39"

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""
"Corrigido: o aplicativo não abria se os ajustes dos modelos não estivessem "
"presentes nos arquivos de configuração"

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr "Vários ícones alterados (avião de papel para o botão enviar)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Combined export / import chat buttons into a menu"
msgstr "Botões combinados de exportação/importação de chat em um menu"

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr "Adicionado 'ajustes de modelo' (temperatura, seed, keep_alive)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:845
msgid "Fixed send / stop button"
msgstr "Botão enviar / parar fixo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""
"Corrigido o aplicativo que não verificava se a conexão remota funcionava ao "
"iniciar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:853
#, fuzzy
msgid "Daily Update"
msgstr "Outra Atualização Diária"

#: data/com.jeffser.Alpaca.metainfo.xml.in:855
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""
"Adicionadas reticências de texto ao nome da conversa para que não altere a "
"largura do botão"

#: data/com.jeffser.Alpaca.metainfo.xml.in:856
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr "Novo atalho para criar um chat (Ctrl+N)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:857
msgid "New message entry design"
msgstr "Novo design de entrada de mensagens"

#: data/com.jeffser.Alpaca.metainfo.xml.in:858
msgid "Fixed: Can't rename the same chat multiple times"
msgstr "Corrigido: não é possível renomear o mesmo chat várias vezes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:865
msgid "The fix"
msgstr "A correção"

#: data/com.jeffser.Alpaca.metainfo.xml.in:867
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""
"Corrigido: a instância do Ollama continua sendo executada em segundo plano "
"mesmo quando está desativada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:868
msgid "Fixed: Can't pull models on the integrated instance"
msgstr "Corrigido: não é possível extrair modelos na instância integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:875
#, fuzzy
msgid "Quick tweaks"
msgstr "Consertos Rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Added progress bar to models that are being pulled"
msgstr "Adicionada barra de progresso aos modelos que estão sendo extraídos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:878
msgid "Added size to tags when pulling a model"
msgstr "Adicionado tamanho às tags ao puxar um modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
#, fuzzy
msgid "General optimizations on the background"
msgstr "Otimização geral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:886
#, fuzzy
msgid "Quick fixes"
msgstr "Consertos Rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:888
msgid "Fixed: Scroll when message is received"
msgstr "Corrigido: rolar quando a mensagem é recebida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:889
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr "Corrigido: o conteúdo não muda ao criar um nova conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:890
#, fuzzy
msgid "Added 'Featured Models' page on welcome dialog"
msgstr "Um melhor diálogo de gerenciamento de modelos foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:897
#, fuzzy
msgid "Nice Update"
msgstr "Nova Atualização"

#: data/com.jeffser.Alpaca.metainfo.xml.in:899
#, fuzzy
msgid "UI tweaks (Thanks Nokse22)"
msgstr "A interface de usuário foi refinada (obrigado, Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:901
msgid "Metadata fixes"
msgstr "Correções de metadados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:908
#, fuzzy
msgid "Quick fix"
msgstr "Consertos Rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:910
#, fuzzy
msgid "Updated Spanish translation"
msgstr "Tradução para o Espanhol atualizada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:911
msgid "Added compatibility for PNG"
msgstr "Compatibilidade com PNG adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:918
#, fuzzy
msgid "New Update"
msgstr "Nova Atualização"

#: data/com.jeffser.Alpaca.metainfo.xml.in:920
msgid "Updated model list"
msgstr "Lista de modelos atualizada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:921
#, fuzzy
msgid "Added image recognition to more models"
msgstr "Reconhecimento de imagem foi adicionado para mais modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:922
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""
"Tradução para Português do Brasil foi adicionada (Obrigado, Daimar Stein)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:923
msgid "Refined the general UI (Thanks Nokse22)"
msgstr "A interface de usuário foi refinada (Obrigado, Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "Added 'delete message' feature"
msgstr "A funcionalidade de 'deletar mensagem' foi adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:925
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""
"Metadados foram adicionados para que distribuidores saibam que o app é "
"compatível com dispositivos móveis"

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""
"O atalho de 'enviar mensagem' foi modificado para 'Enter/Return'(para "
"adicionar uma nova linha use 'shift+enter/return)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:933
#, fuzzy
msgid "Bug Fixes"
msgstr "Conserto de Bugs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:935
msgid "Fixed: Minor spelling mistake"
msgstr "Consertado: Pequenos erros de escrita"

#: data/com.jeffser.Alpaca.metainfo.xml.in:936
#, fuzzy
msgid "Added 'mobile' as a supported form factor"
msgstr "Suporte ao formato de dispositivos móveis foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:937
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr "Consertado: Diálogo de 'Erro de Conexão' não funcionando corretamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:938
msgid "Fixed: App might freeze randomly on startup"
msgstr "Consertado: O app travava de forma aleatória ao iniciar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:939
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr "O nome 'chats' na barra lateral foi alterado para 'Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:946
#, fuzzy
msgid "Cool Update"
msgstr "Atualização Legal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:948
#, fuzzy
msgid "Better design for chat window"
msgstr "Design da janela da conversa foi melhorado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:949
#, fuzzy
msgid "Better design for chat sidebar"
msgstr "A interface da barra lateral das conversas foi melhorada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:950
#, fuzzy
msgid "Fixed remote connections"
msgstr "Conexões remotas foram consertadas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:951
msgid "Fixed Ollama restarting in loop"
msgstr "Erro que fazia o Ollama reiniciar em loop foi consertado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "Other cool backend stuff"
msgstr "Outras coisas legais de backend"

#: data/com.jeffser.Alpaca.metainfo.xml.in:961
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr "Ollama foi adicionado como parte do Alpaca, executado em sandbox"

#: data/com.jeffser.Alpaca.metainfo.xml.in:962
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""
"A opção de conectar com uma instância remota (como funcionava antes) foi "
"adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:963
msgid "Added option to import and export chats"
msgstr "A opção de importar e exportar conversas foi adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:964
msgid "Added option to run Alpaca with Ollama in the background"
msgstr "A opção de continuar sendo executado em segundo plano foi adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:965
#, fuzzy
msgid "Added preferences dialog"
msgstr "Diálogo de preferências foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:966
#, fuzzy
msgid "Changed the welcome dialog"
msgstr "O diálogo de boas-vindas foi modificado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:968
#: data/com.jeffser.Alpaca.metainfo.xml.in:985
#: data/com.jeffser.Alpaca.metainfo.xml.in:997
#: data/com.jeffser.Alpaca.metainfo.xml.in:1016
#: data/com.jeffser.Alpaca.metainfo.xml.in:1037
#: data/com.jeffser.Alpaca.metainfo.xml.in:1053
#: data/com.jeffser.Alpaca.metainfo.xml.in:1069
#: data/com.jeffser.Alpaca.metainfo.xml.in:1083
#: data/com.jeffser.Alpaca.metainfo.xml.in:1093
#: data/com.jeffser.Alpaca.metainfo.xml.in:1111
#: data/com.jeffser.Alpaca.metainfo.xml.in:1133
msgid "Please report any errors to the issues page, thank you."
msgstr "Por favor, reportar quaisquer erros na página de issues, obrigado."

#: data/com.jeffser.Alpaca.metainfo.xml.in:976
#, fuzzy
msgid "Yet Another Daily Update"
msgstr "Mais Uma Atualização Diária"

#: data/com.jeffser.Alpaca.metainfo.xml.in:978
#, fuzzy
msgid "Added better UI for 'Manage Models' dialog"
msgstr "Uma melhor interface para 'Gerenciar Modelos' foi adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:979
msgid "Added better UI for the chat sidebar"
msgstr "Uma interface melhor para a barra lateral das conversas foi adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:980
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""
"A descrição dos modelos foi substituída com um botão para abrir o site do "
"Ollama para cada modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:981
msgid "Added myself to the credits as the spanish translator"
msgstr "Me adicionei aos créditos como o tradutor para espanhol"

#: data/com.jeffser.Alpaca.metainfo.xml.in:982
msgid "Using XDG properly to get config folder"
msgstr "Agora a spec XDG é usada propriamente para ter uma pasta de config"

#: data/com.jeffser.Alpaca.metainfo.xml.in:983
#, fuzzy
msgid "Update for translations"
msgstr "Melhor suporte a traduções"

#: data/com.jeffser.Alpaca.metainfo.xml.in:995
msgid "The last update had some mistakes in the description of the update"
msgstr "A última atualização teve alguns erros na descrição da mesma"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1005
msgid "Another Daily Update"
msgstr "Outra Atualização Diária"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1007
msgid "Added full Spanish translation"
msgstr "Tradução completa para o Espanhol foi adicionada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1008
#, fuzzy
msgid "Added support for background pulling of multiple models"
msgstr ""
"Suporte para o download de múltiplos modelos em segundo planofoi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1009
msgid "Added interrupt button"
msgstr "Um botão de interromper foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1010
#, fuzzy
msgid "Added basic shortcuts"
msgstr "Atalhos de teclado básicos foram adicionados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1011
msgid "Better translation support"
msgstr "Melhor suporte a traduções"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1012
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""
"O usuário agora pode deixar o nome da conversa vazio ao criar uma nova, um "
"nome substituto será gerado em seu lugar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1013
msgid "Better scalling for different window sizes"
msgstr "Melhor escala para diferentes tamanhos de janela"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1014
#, fuzzy
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""
"Consertado: Não era possível fechar o app caso a configuração inicial "
"falhasse"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "Really Big Update"
msgstr "Uma Atualização Realmente Grande"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1026
msgid "Added multiple chats support!"
msgstr "Suporte para múltiplas conversas foi adicionado!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1027
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""
"Suporte para Pango Markup (negrito, lista, título, subtítulo, monospace) foi "
"adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1028
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""
"Rolagem automática caso o usuário esteja na mensagem mais recente da "
"conversa foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1029
msgid "Added support for multiple tags on a single model"
msgstr "Suporte para múltiplas tags em um único modelo foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1030
msgid "Added better model management dialog"
msgstr "Um melhor diálogo de gerenciamento de modelos foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1031
msgid "Added loading spinner when sending message"
msgstr "Um spinner de carregamento ao mandar mensagens foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1032
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""
"Notificações caso o app não esteja ativo e o download de um modelo for "
"finalizado foram adicionadas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1033
msgid "Added new symbolic icon"
msgstr "Um novo ícone simbólico foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1034
msgid "Added frame to message textview widget"
msgstr "Quadro ao redor do textview do widget de mensagem foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1035
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr "Consertado \"blocos de código não deveriam ser editáveis\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1047
msgid "Added code highlighting"
msgstr "Highlighting de código foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1048
msgid "Added image recognition (llava model)"
msgstr "Reconhecimento de imagem foi adicionado (modelo llava)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1049
msgid "Added multiline prompt"
msgstr "Prompt de múltiplas linhas foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1050
msgid "Fixed some small bugs"
msgstr "Pequenos erros foram consertados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1051
msgid "General optimization"
msgstr "Otimização geral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1061
msgid "Fixes and features"
msgstr "Consertos e funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1063
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr "Tradução para Russo (obrigado, github/alexkdeveloper)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1064
msgid "Fixed: Cannot close app on first setup"
msgstr "Consertado: Não era possível fechar o app no setup inicial"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1065
msgid "Fixed: Brand colors for Flathub"
msgstr "Consertado: Cores de branding para o Flathub"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1066
msgid "Fixed: App description"
msgstr "Consertada: Descrição do app"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1067
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""
"Consertado: Somente exibir 'diálogo de salvamento de mudanças' quando "
"vocêrealmente mudar o URL"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1077
msgid "0.2.2 Bug fixes"
msgstr "0.2.2 Conserto de Bugs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1079
msgid "Toast messages appearing behind dialogs"
msgstr "Mensagens toast aparecendo atrás de diálogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1080
msgid "Local model list not updating when changing servers"
msgstr "Lista de modelos locais não é atualizada ao mudar de servidor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1081
msgid "Closing the setup dialog closes the whole app"
msgstr "Fechar o diálogo de primeira configuração fecha o app"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1091
msgid "0.2.1 Data saving fix"
msgstr "0.2.1 Conserto de Salvamento de Dados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1092
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""
"O app não salvava os arquivos de config. e o histórico de conversa para a "
"pasta correta, isso foi corrigido."

#: data/com.jeffser.Alpaca.metainfo.xml.in:1101
msgid "0.2.0"
msgstr "0.2.0"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1103
msgid "New Features"
msgstr "Novas Funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1105
msgid "Restore chat after closing the app"
msgstr "Restaura a conversa após fechar o app"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1106
msgid "A button to clear the chat"
msgstr "Um botão para limpar a conversa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1107
msgid "Fixed multiple bugs involving how messages are shown"
msgstr ""
"Múltiplos bugs envolvendo como mensagens são exibidas foram consertados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1108
msgid "Added welcome dialog"
msgstr "Um diálogo de boas-vindas foi adicionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1109
msgid "More stability"
msgstr "Maior estabilidade"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1119
msgid "0.1.2 Quick fixes"
msgstr "0.1.2 Consertos Rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1120
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""
"Este lançamento conserta parte dos metadados necessários para ter um app em "
"Flatpak corretamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1126
msgid "0.1.1 Stable Release"
msgstr "0.1.1 Lançamento Estável"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1127
msgid "This is the first public version of Alpaca"
msgstr "Essa é a primeira versão pública de Alpaca"

#: src/main.py:193
msgid "Documentation"
msgstr ""

#: src/main.py:194
msgid "Become a Sponsor"
msgstr ""

#: src/main.py:195
msgid "Discussions"
msgstr ""

#: src/window.py:185
msgid "Speech recognition model is being downloaded ({})"
msgstr ""

#: src/window.py:210 src/window.py:240
msgid "Speech Recognition Error"
msgstr ""

#: src/window.py:210
msgid "An error occurred while pulling speech recognition model"
msgstr ""

#: src/window.py:240
msgid "An error occurred while using speech recognition"
msgstr ""

#: src/window.py:275
msgid "Ollama Was Not Found"
msgstr ""

#: src/window.py:276
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""

#: src/window.py:278
msgid "Open Tutorial in Web Browser"
msgstr ""

#: src/window.py:284 src/window.py:291 src/window.ui:472 src/window.ui:482
#: src/window.ui:504
msgid "Add Instance"
msgstr ""

#: src/window.py:292
msgid "Select a type of instance to add"
msgstr ""

#: src/window.py:527
msgid "No tools enabled."
msgstr ""

#: src/window.py:527
msgid "Open Tool Manager"
msgstr ""

#: src/window.py:530
msgid "'{}' does not support tools."
msgstr ""

#: src/window.py:530
msgid "Open Model Manager"
msgstr "Abra o Gerenciador de Modelos"

#: src/window.py:533 src/window.py:1122
msgid "Please select a model before chatting"
msgstr "Por favor, selecione um modelo antes de conversar"

#: src/window.py:581 src/window.py:582 src/window.py:651 src/window.ui:288
msgid "Close"
msgstr "Fechar"

#: src/window.py:584 src/window.py:585 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "Próximo"

#: src/window.py:649 src/instance_manager.py:405 src/instance_manager.py:406
#: src/tool_manager.py:136 src/window.ui:968 src/window.ui:972
#: src/custom_widgets/message_widget.py:79
#: src/custom_widgets/message_widget.py:229
#: src/custom_widgets/model_manager_widget.py:422
#: src/custom_widgets/dialog_widget.py:148
#: src/custom_widgets/dialog_widget.py:160
#: src/custom_widgets/dialog_widget.py:172
msgid "Cancel"
msgstr "Cancelar"

#: src/window.py:650
msgid "Hide"
msgstr ""

#: src/window.py:654
msgid "Close Alpaca?"
msgstr ""

#: src/window.py:655
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr ""

#: src/window.py:899
msgid "Cannot open image"
msgstr "Não foi possível abrir a imagem"

#: src/window.py:978
msgid "Delete Chat?"
msgstr "Excluir conversa"

#: src/window.py:979
msgid "Are you sure you want to delete '{}'?"
msgstr "Tem certeza que deseja excluir '{}'?"

#: src/window.py:981 src/window.py:1450
msgid "Delete"
msgstr "Excluir"

#: src/window.py:988
msgid "Rename Chat?"
msgstr "Renomear conversa"

#: src/window.py:989
msgid "Renaming '{}'"
msgstr "Renomeando '{}'"

#: src/window.py:991
msgid "Chat name"
msgstr "Nome do conversa"

#: src/window.py:992
msgid "Rename"
msgstr "Renomear"

#: src/window.py:997
msgid "Importable (.db)"
msgstr ""

#: src/window.py:998
msgid "Markdown"
msgstr ""

#: src/window.py:999
msgid "Markdown (Obsidian Style)"
msgstr ""

#: src/window.py:1000
msgid "JSON"
msgstr ""

#: src/window.py:1001
msgid "JSON (Include Metadata)"
msgstr ""

#: src/window.py:1004 src/window.ui:1405 src/window.ui:1439
#, fuzzy
msgid "Export Chat"
msgstr "Importar conversa"

#: src/window.py:1005
msgid "Select a method to export the chat"
msgstr ""

#: src/window.py:1021
msgid "This video does not have any transcriptions"
msgstr "Este vídeo não possui transcrições"

#: src/window.py:1028
msgid "Attach YouTube Video?"
msgstr "Anexar vídeo do YouTube?"

#: src/window.py:1029
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"Selecione uma transcrição para incluir"

#: src/window.py:1035
msgid "Error attaching video, please try again"
msgstr "Erro ao anexar vídeo, tente novamente"

#: src/window.py:1056 src/window.py:1444
msgid "Attach Website? (Experimental)"
msgstr "Anexar site? (Experimental)"

#: src/window.py:1057
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"Tem certeza de que deseja anexar\n"
"'{}'?"

#: src/window.py:1075 src/window.py:1087 src/window.py:1443
#: src/generic_actions.py:105
#, fuzzy
msgid "Image recognition is only available on specific models"
msgstr "Reconhecimento de imagem (Disponível apenas com o modelo LLaVA)"

#: src/window.py:1106 src/window.ui:1189
msgid "Quick Ask"
msgstr "Pergunta rápida"

#: src/window.py:1276
msgid "Attachment failed, screenshot might be too big"
msgstr ""

#: src/window.py:1290
msgid "Any compatible Alpaca attachment"
msgstr ""

#: src/window.py:1419
msgid "Attach Screenshot"
msgstr ""

#: src/window.py:1444
msgid "Please enter a website URL"
msgstr ""

#: src/window.py:1445
msgid "Attach YouTube Captions?"
msgstr ""

#: src/window.py:1445
msgid "Please enter a YouTube video URL"
msgstr ""

#: src/window.py:1448
msgid "Download Model?"
msgstr ""

#: src/window.py:1448
msgid "Please enter the model name following this template: name:tag"
msgstr ""

#: src/window.py:1450
msgid "Delete All Chats?"
msgstr ""

#: src/window.py:1450
msgid "Are you sure you want to delete all chats?"
msgstr ""

#: src/window.py:1461
msgid "Remove Attachment?"
msgstr "Remover anexo?"

#: src/window.py:1461
msgid "Are you sure you want to remove attachment?"
msgstr "Tem certeza de que deseja remover o anexo?"

#: src/window.py:1461 src/instance_manager.py:885
#: src/custom_widgets/model_manager_widget.py:423
#: src/custom_widgets/model_manager_widget.py:463
msgid "Remove"
msgstr "Remover"

#: src/window.py:1476
msgid "Already Installed!"
msgstr ""

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""

#: src/available_models_descriptions.py:3
msgid "QwQ is the reasoning model of the Qwen series."
msgstr ""

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision é uma coleção de modelos generativos de raciocínio de "
"imagem ajustados por instruções em tamanhos 11B e 90B."

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "O Llama 3.2 da Meta fica pequeno com os modelos 1B e 3B."

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 é um novo modelo de última geração da Meta disponível em tamanhos "
"de parâmetros 8B, 70B e 405B."

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: O LLM disponível abertamente mais capaz até o momento"

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "O modelo 7B lançado pela Mistral AI, atualizado para a versão 0.3."

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Um modelo de incorporação aberta de alto desempenho com uma grande janela de "
"contexto de token."

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma é uma família de modelos abertos leves e de última geração "
"desenvolvidos pelo Google DeepMind. Atualizado para a versão 1.1"

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 é uma série de grandes modelos de linguagem da Alibaba Cloud que "
"abrangem parâmetros de 0,5B a 110B"

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr ""
"Qwen2 é uma nova série de grandes modelos de linguagem do grupo Alibaba"

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 é uma família de modelos abertos de última geração leves 3B (Mini) e "
"14B (Médio) da Microsoft."

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 é uma coleção de modelos de linguagem básicos que variam de "
"parâmetros de 7B a 70B."

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Os modelos Qwen2.5 são pré-treinados no mais recente conjunto de dados em "
"grande escala do Alibaba, abrangendo até 18 trilhões de tokens. O modelo "
"suporta até 128 mil tokens e possui suporte multilíngue."

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 é um modelo eficiente e de alto desempenho disponível em três "
"tamanhos: 2B, 9B e 27B."

#: src/available_models_descriptions.py:17
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA é um novo modelo multimodal grande e treinado de ponta a ponta que "
"combina um codificador de visão e Vicuna para compreensão visual e de "
"linguagem de uso geral. Atualizado para a versão 1.6."

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr ""
"Um grande modelo de linguagem que pode usar prompts de texto para gerar e "
"discutir código."

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"A mais recente série de modelos Qwen específicos de código, com melhorias "
"significativas na geração de código, raciocínio de código e correção de "
"código."

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Um modelo 12B de última geração com comprimento de contexto de 128k, "
"desenvolvido pela Mistral AI em colaboração com a NVIDIA."

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"O projeto TinyLlama é um esforço aberto para treinar um modelo compacto de "
"1,1B Llama em 3 trilhões de tokens."

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "Modelo de incorporação grande de última geração de mixedbread.ai"

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 é a próxima geração de LLMs de código aberto treinados de forma "
"transparente que vem em três tamanhos: parâmetros 3B, 7B e 15B."

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Um modelo de linguagem de código Mixture-of-Experts de código aberto que "
"atinge desempenho comparável ao GPT4-Turbo em tarefas específicas de código."

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Modelos sem censura, 8x7b e 8x22b ajustados com base na mistura Mixtral de "
"modelos especialistas que se destacam em tarefas de codificação. Criado por "
"Eric Hartford."

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma é uma coleção de modelos leves e poderosos que podem executar uma "
"variedade de tarefas de codificação, como preenchimento de código "
"intermediário,geração de código, compreensão de linguagem natural, "
"raciocínio matemático e acompanhamento de instruções."

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Um modelo de linguagem de código Mixture-of-Experts de código aberto que "
"atinge desempenho comparável ao GPT4-Turbo em tarefas específicas de código."

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: um modelo de linguagem 2,7B da Microsoft Research que demonstra "
"excelentes capacidades de raciocínio e compreensão de linguagem."

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Modelo Uncensored Llama 2 de George Sung e Jarrad Hope."

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder é um modelo de codificação capaz treinado em dois trilhões de "
"códigos e tokens de linguagem natural."

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Um conjunto de modelos de incorporação de texto da Snowflake, otimizados "
"para desempenho."

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Modelo de linguagem grande de última geração da Microsoft AI com desempenho "
"aprimorado em casos de uso complexos de chat, multilíngue, raciocínio e "
"agente."

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"O modelo Dolphin sem censura baseado em Mistral que se destaca em tarefas de "
"codificação. Atualizado para a versão 2.8."

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 é um novo modelo com tamanhos 8B e 70B de Eric Hartford baseado "
"no Llama 3 que possui uma variedade de habilidades de instrução, conversação "
"e codificação."

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 é um modelo de linguagem bilíngue de alto desempenho."

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R é um modelo de linguagem grande otimizado para interação "
"conversacional e tarefas de contexto longo."

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Um modelo de uso geral que varia de 3 bilhões a 70 bilhões de parâmetros, "
"adequado para hardware básico."

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Um modelo LLaVA ajustado do Llama 3 Instruct com melhores pontuações em "
"vários benchmarks."

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr é uma série de versões aprimoradas dos modelos Mistral e Mixtral que "
"são treinados para atuar como assistentes úteis."

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Um modelo de IA leve com 3,8 bilhões de parâmetros com desempenho "
"ultrapassando modelos de tamanho semelhante e maiores."

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Incorporação de modelos em conjuntos de dados de nível de frase muito "
"grandes."

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral é o primeiro modelo de código da Mistral AI projetado para tarefas "
"de geração de código."

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder é um modelo de geração de código treinado em mais de 80 linguagens "
"de programação."

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Modelo de chat de uso geral baseado em Llama e Llama 2 com tamanhos de "
"contexto de 2K a 16K."

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "Uma família de modelos de base aberta da IBM para Code Intelligence"

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca é um modelo de 7 bilhões de parâmetros, ajustado com base "
"no modelo Mistral 7B usando o conjunto de dados OpenOrca."

#: src/available_models_descriptions.py:47
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 Uma família de modelos pequenos com parâmetros 135M, 360M e 1,7B, "
"treinados em um novo conjunto de dados de alta qualidade."

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored é um modelo de parâmetros 7B, 13B e 30B baseado no "
"Llama 2 sem censura de Eric Hartford."

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Modelo baseado em Llama 2 ajustado para melhorar a capacidade de diálogo "
"chinês."

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 é um novo modelo da BAAI que se distingue pela sua versatilidade em "
"Multifuncionalidade, Multilingualidade e Multigranulação."

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Um modelo versátil para cenários de desenvolvimento de software de IA, "
"incluindo conclusão de código."

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Uma família de modelos de código aberto treinados em uma ampla variedade de "
"dados, superando o ChatGPT em vários benchmarks. Atualizado para a versão "
"3.5-0106."

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, lançado pela Cohere, é uma nova família de modelos multilíngues de "
"última geração que suporta 23 idiomas."

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 é um grande modelo de linguagem pré-treinado em uma grande "
"quantidade de dados de código."

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"A poderosa família de modelos da Nous Research que se destaca em discussões "
"científicas e tarefas de codificação."

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ é um modelo de linguagem grande, poderoso e escalável, "
"desenvolvido especificamente para se destacar em casos de uso corporativo do "
"mundo real."

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "Modelo de geração de código de última geração"

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B é um modelo de codificação com variantes de instrução e "
"conclusão de código equivalente a modelos como o Code Llama 7B, que são 2,5x "
"maiores."

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Um modelo experimental de parâmetros 1.1B treinado no novo conjunto de dados "
"Dolphin 2.8 por Eric Hartford e baseado em TinyLlama."

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 é um modelo 7B ajustado pela Teknium no Mistral com conjuntos "
"de dados totalmente abertos."

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 é o novo modelo carro-chefe da Mistral que é "
"significativamente mais capaz em geração de código, matemática e raciocínio "
"com janela de contexto de 128k e suporte para dezenas de idiomas."

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math é uma série de modelos de linguagem matemática especializados "
"construídos com base nos LLMs Qwen2, que supera significativamente as "
"capacidades matemáticas de modelos de código aberto e até mesmo de modelos "
"de código fechado (por exemplo, GPT4o)."

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Um forte modelo de linguagem geral multilíngue com desempenho competitivo "
"para o Llama 3."

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 é um modelo de linguagem de parâmetros 1.6B e 12B de última "
"geração treinado em dados multilíngues em inglês, espanhol, alemão, "
"italiano, francês, português e holandês."

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA é um modelo multimodal que consiste no modelo básico Mistral 7B "
"aumentado com a arquitetura LLaVA."

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Um modelo de alto desempenho treinado com uma nova técnica chamada ajuste de "
"reflexão que ensina um LLM a detectar erros em seu raciocínio e corrigir o "
"curso."

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Um modelo de linguagem avançado criado com 2 trilhões de tokens bilíngues."

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Este modelo estende o comprimento de contexto do LLama-3 8B de 8k para mais "
"de 1 milhão de tokens."

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "Modelo focado em problemas de matemática e lógica"

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 é um modelo de linguagem de visão pequena projetado para "
"funcionar com eficiência em dispositivos de ponta."

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Um modelo ajustado baseado em Mistral com boa cobertura de domínio e idioma."

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Um modelo da NVIDIA baseado no Llama 3 que se destaca em resposta a "
"perguntas conversacionais (QA) e geração aumentada de recuperação (RAG)."

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Modelo conversacional baseado no Llama 2 que apresenta desempenho "
"competitivo em diversos benchmarks."

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder é um modelo de conclusão de código ajustado no StarCoder para "
"tarefas de geração de SQL"

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Modelos de uso geral baseados em Llama e Llama 2 da Nous Research."

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "Modelo de geração de código baseado em Code Llama."

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Uma extensão do Llama 2 que suporta um contexto de até 128 mil tokens."

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Uma variante sem censura 7B e 15B da família de modelos Dolphin que se "
"destaca na codificação, baseada no StarCoder2."

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "Modelo de uso geral baseado no Llama 2."

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Um modelo de linguagem de mistura de especialistas forte, econômico e "
"eficiente."

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling é um grande modelo de linguagem treinado por reforço de "
"aprendizagem a partir de feedback de IA focado em melhorar a utilidade do "
"chatbot."

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Um assistente companheiro treinado em filosofia, psicologia e "
"relacionamentos pessoais. Baseado em Mistral."

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 é a versão mais recente da principal série Hermes de LLMs da Nous "
"Research"

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder é uma série de modelos de linguagem de código-fonte aberto que "
"oferece desempenho de codificação de última geração com menos de 10 bilhões "
"de parâmetros."

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Um grande modelo de linguagem criado pelo Technology Innovation Institute "
"(TII) para uso em resumos, geração de texto e bots de bate-papo."

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 é um modelo de parâmetros 7B adaptado para cenários práticos com "
"excelente capacidade de raciocínio."

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Um modelo de linguagem grande de 10,7B compacto, mas poderoso, projetado "
"para conversas em um único turno."

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 é um modelo de parâmetro 72B que se destaca em tarefas de "
"conclusão de código, matemática e extração de log."

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Um novo modelo LLaVA pequeno ajustado do Phi 3 Mini."

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"O Orca 2 foi desenvolvido por pesquisas da Microsoft e é uma versão "
"aprimorada dos modelos Llama 2 da Meta. O modelo foi projetado para se "
"destacar particularmente no raciocínio."

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Uma série de LLMs multimodais (MLLMs) projetados para compreensão da "
"linguagem visual."

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Modelo baseado em Llama 2 ajustado em um conjunto de dados estilo Orca. "
"Originalmente chamado de Free Willy."

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Modelo Dolphin 2.7B sem censura de Eric Hartford, baseado no modelo de "
"linguagem Phi da Microsoft Research."

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 é uma família de modelos de linguagem compactos disponíveis em três "
"tamanhos: Parâmetros 135M, 360M e 1,7B."

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "Versão sem censura do modelo Wizard LM"

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Um modelo de linguagem pequena comercial da NVIDIA otimizado para roleplay, "
"RAG QA e chamada de função."

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Uma extensão do Mistral para suportar janelas de contexto de 64K ou 128K."

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Uma expansão do Llama 2 especializada em integrar a compreensão geral da "
"linguagem e o conhecimento de domínios específicos, especialmente em "
"programação e matemática."

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Modelo Llama 2 ajustado para responder a perguntas médicas com base em um "
"conjunto de dados médicos de código aberto."

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Modelo de linguagem médica de código aberto adaptado do Llama 2 para o "
"domínio médico."

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Uma série de modelos da Groq que representam um avanço significativo nos "
"recursos de IA de código aberto para uso de ferramentas/chamada de funções."

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct é um grande modelo de linguagem "
"personalizado pela NVIDIA para melhorar a utilidade das respostas geradas "
"por LLM para consultas de usuários."

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven é um modelo ajustado de instrução 13B para tarefas de chamada de "
"função."

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr "O modelo Nous Hermes 2 da Nous Research, agora treinado no Mixtral."

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "Ótimo modelo de geração de código baseado em Llama2."

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Modelo baseado em Llama2 sem censura com suporte para uma janela de contexto "
"de 16K."

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Os modelos IBM Granite 2B e 8B foram projetados para oferecer suporte a "
"casos de uso baseados em ferramentas e suporte para geração aumentada de "
"recuperação (RAG), simplificando a geração de código, tradução e correção de "
"bugs."

#: src/available_models_descriptions.py:109
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder é uma família de modelos de parâmetros de 7B treinados em dados "
"de instruções sintéticas de 75K usando OSS-Instruct, uma nova abordagem para "
"esclarecer LLMs com trechos de código-fonte aberto."

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Um modelo de chat leve que permite resultados precisos e responsivos sem a "
"necessidade de hardware de última geração."

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Um modelo de instrução de código de alto desempenho criado pela fusão de "
"dois modelos de código existentes."

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 é um modelo apenas de decodificador causal de parâmetros 11B "
"construído pela TII e treinado em tokens 5T."

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna é um modelo de parâmetros 13B baseado no Llama 2 treinado por "
"MelodysDreamj."

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite é um modelo ajustado baseado em Mistral com capacidades "
"aprimoradas de processamento de contextos longos."

#: src/available_models_descriptions.py:115
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: um modelo 7B projetado para raciocínio matemático e descoberta "
"científica pela Mistral AI."

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Modelo de texto para SQL de parâmetro 7B feito por MotherDuck e Numbers "
"Station."

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b é uma transformação do Dolphin-2.2-70b criada "
"intercalando o modelo consigo mesmo."

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro Preview: um modelo avançado de linguagem grande (LLM) com 22 "
"bilhões de parâmetros projetados para caber em uma única GPU"

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Uma série de modelos que convertem conteúdo HTML em conteúdo Markdown, o que "
"é útil para tarefas de conversão de conteúdo."

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Uma mistura de modelo de especialistas de alto desempenho, ajustada com "
"dados de alta qualidade."

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Um modelo de chat 7B ajustado com dados de alta qualidade e baseado em "
"Zephyr."

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Fusão do modelo Open Orca OpenChat e do modelo Garage-bAInd Platypus 2. "
"Projetado para chat e geração de código."

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Um modelo de linguagem criado pela combinação de dois modelos Llama 2 70B "
"ajustados em um."

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Os modelos IBM Granite 1B e 3B são a primeira mistura de especialistas "
"(MoE)Modelos Granite da IBM projetados para uso de baixa latência."

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Um modelo 3,8B ajustado em um conjunto de dados sintéticos privados de alta "
"qualidade para extração de informações, baseado em Phi-3."

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Os modelos de linguagem da Cohere For AI foram treinados para ter um bom "
"desempenho em 23 idiomas diferentes."

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX é um LLM aberto e de uso geral criado pela Databricks."

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Um modelo de raciocínio aberto e amplo para soluções do mundo real pelo "
"AlibabaInternational Digital Commerce Group (AIDC-AI)."

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Incorporação de modelo de BAAI mapeando textos em vetores."

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Um modelo de chamada de função de pesos abertos baseado no Llama 3, "
"competitivo com os recursos de chamada de função GPT-4o."

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Um modelo de conversação robusto projetado para ser usado em casos de uso de "
"chat e instrução."

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Uma versão atualizada do DeekSeek-V2 que integra as habilidades gerais e de "
"codificação do DeepSeek-V2-Chat e do DeepSeek-Coder-V2-Instruct."

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma é um conjunto de modelos de instruções ajustadas para avaliar a "
"segurança de respostas de entrada e saída de texto de prompt de texto em "
"relação a um conjunto de políticas de segurança definidas."

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Um modelo de verificação de fatos de última geração desenvolvido pela "
"Bespoke Labs."

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 é uma série de modelos ajustados para classificação de "
"segurança de conteúdo de entradas e respostas LLM."

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Modelo de transformadores de frases que pode ser usado para tarefas como "
"clustering ou pesquisa semântica."

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder é uma família LLM de código aberto e reproduzível que inclui "
"modelos 1.5B e 8B, com suporte para chat em inglês e chinês."

#: src/available_models_descriptions.py:138
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 é uma família líder de modelos de instruções, oferecendo dados, "
"códigos e receitas totalmentede código aberto pelo The Allen Institute for "
"AI."

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Modelo de incorporação de fronteira do Snowflake. O Arctic Embed 2.0 "
"adiciona suporte multilíngue sem sacrificar o desempenho ou a escalabilidade "
"do inglês."

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Os modelos IBM Granite Guardian 3.0 2B e 8B são projetados para detectar "
"riscos em prompts e/ou respostas."

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 é uma coleção de modelos generativos bilíngues (inglês e coreano) "
"ajustados por instruções, variando de 2,4B a 32B parâmetros, desenvolvidos e "
"lançados pela LG AI Research."

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 são modelos de linguagem multilíngues feitos para o Sudeste "
"Asiático. Disponíveis em tamanhos de parâmetros 1B, 8B e 20B."

#: src/available_models_descriptions.py:143
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""

#: src/available_models_descriptions.py:144
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""

#: src/available_models_descriptions.py:145
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""

#: src/available_models_descriptions.py:146
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""

#: src/available_models_descriptions.py:147
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""

#: src/available_models_descriptions.py:148
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""

#: src/available_models_descriptions.py:149
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""

#: src/available_models_descriptions.py:150
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""

#: src/available_models_descriptions.py:151
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""

#: src/available_models_descriptions.py:152
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""

#: src/available_models_descriptions.py:153
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""

#: src/available_models_descriptions.py:154
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""

#: src/available_models_descriptions.py:155
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""

#: src/available_models_descriptions.py:156
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""

#: src/available_models_descriptions.py:157
msgid "The current, most capable model that runs on a single GPU."
msgstr ""

#: src/available_models_descriptions.py:158
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""

#: src/available_models_descriptions.py:159
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""

#: src/available_models_descriptions.py:160
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""

#: src/available_models_descriptions.py:161
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""

#: src/available_models_descriptions.py:162
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""

#: src/available_models_descriptions.py:163
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""

#: src/available_models_descriptions.py:164
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""

#: src/available_models_descriptions.py:165
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""

#: src/available_models_descriptions.py:166
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""

#: src/instance_manager.py:30 src/instance_manager.py:366
msgid "Instance"
msgstr ""

#: src/instance_manager.py:60 src/instance_manager.py:69 src/window.ui:154
#: src/custom_widgets/chat_widget.py:423
msgid "New Chat"
msgstr "Nova Conversa"

#: src/instance_manager.py:76
msgid "Selecting tool to use..."
msgstr ""

#: src/instance_manager.py:85
msgid "Using {}"
msgstr ""

#: src/instance_manager.py:111
msgid "Tool Error"
msgstr ""

#: src/instance_manager.py:111
msgid "An error occurred while running tool"
msgstr ""

#: src/instance_manager.py:114
msgid "Generating message..."
msgstr ""

#: src/instance_manager.py:162 src/instance_manager.py:462
#: src/instance_manager.py:472 src/instance_manager.py:616
#: src/instance_manager.py:688 src/instance_manager.py:730
#: src/instance_manager.py:759 src/instance_manager.py:802
#: src/instance_manager.py:822 src/instance_manager.py:843
msgid "Instance Error"
msgstr ""

#: src/instance_manager.py:162
msgid "Message generation failed"
msgstr ""

#: src/instance_manager.py:218 src/window.ui:885
msgid "Name"
msgstr "Nome"

#: src/instance_manager.py:226
msgid "Port"
msgstr ""

#: src/instance_manager.py:227
msgid "Which network port will '{}' use"
msgstr ""

#: src/instance_manager.py:241
msgid "Instance URL"
msgstr ""

#: src/instance_manager.py:244 src/instance_manager.py:254
#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key (Unchanged)"
msgstr ""

#: src/instance_manager.py:244 src/instance_manager.py:254
msgid "API Key (Optional)"
msgstr ""

#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key"
msgstr ""

#: src/instance_manager.py:267
msgid "Max Tokens"
msgstr ""

#: src/instance_manager.py:268
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""

#: src/instance_manager.py:283
#, fuzzy
msgid "Temperature"
msgstr "Funcionalidades"

#: src/instance_manager.py:284
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""

#: src/instance_manager.py:299
msgid "Seed"
msgstr "Semente"

#: src/instance_manager.py:300
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""

#: src/instance_manager.py:315
msgid "Overrides"
msgstr ""

#: src/instance_manager.py:315
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""

#: src/instance_manager.py:333
msgid "Model Directory"
msgstr "Diretório de modelos"

#: src/instance_manager.py:335
msgid "Select Directory"
msgstr ""

#: src/instance_manager.py:346
msgid "Default Model"
msgstr "Modelo Padrão"

#: src/instance_manager.py:346
msgid "Model to select when starting a new chat."
msgstr ""

#: src/instance_manager.py:348
msgid "Title Model"
msgstr ""

#: src/instance_manager.py:348
msgid "Model to use when generating a chat title."
msgstr ""

#: src/instance_manager.py:412 src/instance_manager.py:413
#: src/custom_widgets/message_widget.py:233
msgid "Save"
msgstr "Salvar"

#: src/instance_manager.py:462 src/instance_manager.py:688
#: src/instance_manager.py:730 src/instance_manager.py:759
msgid "Could not retrieve added models"
msgstr ""

#: src/instance_manager.py:472
msgid "Could not retrieve available models"
msgstr ""

#: src/instance_manager.py:539
msgid "Ollama (Managed)"
msgstr ""

#: src/instance_manager.py:547
msgid "Local AI instance managed directly by Alpaca"
msgstr ""

#: src/instance_manager.py:570
msgid "Alpaca Support"
msgstr "Suporte Alpaca"

#: src/instance_manager.py:577
msgid "Model request too large for system"
msgstr "Solicitação de modelo muito grande para o sistema"

#: src/instance_manager.py:580
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr "GPU AMD detectada, mas falta a extensão, Ollama usará CPU."

#: src/instance_manager.py:582
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "GPU AMD detectada, mas ROCm está faltando, Ollama usará CPU."

#: src/instance_manager.py:584
msgid "Using AMD GPU type '{}'"
msgstr "Usando tipo de GPU AMD '{}'"

#: src/instance_manager.py:594
msgid "Integrated Ollama instance is not running"
msgstr "A instância integrada do Ollama não está em execução"

#: src/instance_manager.py:616
msgid "Managed Ollama instance failed to start"
msgstr ""

#: src/instance_manager.py:619
msgid "Integrated Ollama instance is running"
msgstr "A instância integrada do Ollama está em execução"

#: src/instance_manager.py:624 src/instance_manager.py:625
msgid "Ollama Log"
msgstr ""

#: src/instance_manager.py:637
msgid "Local or remote AI instance not managed by Alpaca"
msgstr ""

#: src/instance_manager.py:802 src/instance_manager.py:822
#: src/instance_manager.py:843
msgid "Could not retrieve models"
msgstr ""

#: src/instance_manager.py:811
msgid "Fireworks AI inference platform"
msgstr ""

#: src/instance_manager.py:831
msgid "Lambda Labs cloud inference API"
msgstr ""

#: src/instance_manager.py:852
msgid "Cerebras AI cloud inference API"
msgstr ""

#: src/instance_manager.py:858
msgid "Kluster AI cloud inference API"
msgstr ""

#: src/instance_manager.py:862
msgid "OpenAI Compatible Instance"
msgstr ""

#: src/instance_manager.py:863
msgid "AI instance compatible with OpenAI library"
msgstr ""

#: src/instance_manager.py:885
msgid "Remove Instance?"
msgstr ""

#: src/instance_manager.py:885
msgid "Are you sure you want to remove this instance?"
msgstr ""

#: src/instance_manager.py:900
msgid "Edit Instance"
msgstr ""

#: src/tool_manager.py:71
msgid "AI Description"
msgstr ""

#: src/tool_manager.py:72
msgid "The description the AI model will use to understand what the tool does."
msgstr ""

#: src/tool_manager.py:83
msgid "Arguments"
msgstr ""

#: src/tool_manager.py:84
msgid "Variables that are filled by the AI."
msgstr ""

#: src/tool_manager.py:97
msgid "Variables"
msgstr ""

#: src/tool_manager.py:98
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""

#: src/tool_manager.py:140 src/custom_widgets/dialog_widget.py:146
#: src/custom_widgets/dialog_widget.py:158
#: src/custom_widgets/dialog_widget.py:170
msgid "Accept"
msgstr "Aceitar"

#: src/tool_manager.py:177
msgid "Gets the current date and/or time."
msgstr ""

#: src/tool_manager.py:211
msgid "Gets a recipe by the meal's name"
msgstr ""

#: src/tool_manager.py:224 src/tool_manager.py:281
msgid "YouTube Video"
msgstr ""

#: src/tool_manager.py:227 src/tool_manager.py:284
msgid "Source"
msgstr ""

#: src/tool_manager.py:262
msgid "Gets a list of food recipes by a specified category"
msgstr ""

#: src/tool_manager.py:307
msgid "Extracts an article from Wikipedia by it's title"
msgstr ""

#: src/tool_manager.py:349
msgid "Search for a term online using DuckDuckGo"
msgstr ""

#: src/tool_manager.py:365
msgid "Abstract Source"
msgstr ""

#: src/tool_manager.py:384
msgid "Official Website"
msgstr ""

#: src/tool_manager.py:432
msgid "Request to run a command using SSH to connect to the device"
msgstr ""

#: src/tool_manager.py:435
msgid "IP Address"
msgstr ""

#: src/tool_manager.py:440
msgid "Username"
msgstr ""

#: src/tool_manager.py:445
msgid "Network Port"
msgstr ""

#: src/tool_manager.py:462
msgid "Model Requested to Run Command"
msgstr ""

#: src/tool_manager.py:463
msgid "Command"
msgstr ""

#: src/tool_manager.py:465
msgid "Explanation"
msgstr ""

#: src/tool_manager.py:466
msgid "No explanation was provided"
msgstr ""

#: src/tool_manager.py:467
msgid "Make sure you understand what the command does before running it."
msgstr ""

#: src/window.ui:34
msgid "Welcome"
msgstr ""

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "Anterior"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "Bem-vindo(a) a Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr ""

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr ""

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""

#: src/window.ui:107
msgid "Private by Design"
msgstr ""

#: src/window.ui:108
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""

#: src/window.ui:114
msgid "Local AI"
msgstr ""

#: src/window.ui:115
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""

#: src/window.ui:120 src/window.ui:121
msgid "Install Ollama"
msgstr ""

#: src/window.ui:165
msgid "Menu"
msgstr "Menu"

#: src/window.ui:187
msgid "Toggle Sidebar"
msgstr "Alternar barra lateral"

#: src/window.ui:194
msgid "Search Messages"
msgstr "Pesquisar mensagens"

#: src/window.ui:211 src/window.ui:236 src/window.ui:1371
#, fuzzy
msgid "Manage Models"
msgstr "Gerenciar modelos"

#: src/window.ui:232
msgid "Add Models"
msgstr ""

#: src/window.ui:249
#, fuzzy
msgid "Chat Menu"
msgstr "Menu"

#: src/window.ui:262
msgid "Message search bar"
msgstr "Barra de pesquisa de mensagens"

#: src/window.ui:271 src/window.ui:273
msgid "Search messages"
msgstr "Pesquisar mensagens"

#: src/window.ui:289
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""
"Aviso: O modo de economia de energia está ativado, isso tornará a geração de "
"mensagens mais lenta"

#: src/window.ui:336 src/window.ui:1469
msgid "Attach File"
msgstr "Anexar arquivo"

#: src/window.ui:369 src/window.ui:1238
msgid "Use Speech Recognition"
msgstr ""

#: src/window.ui:404
msgid "Send Message"
msgstr "Enviar Mensagem"

#: src/window.ui:423
msgid "Stop Message"
msgstr ""

#: src/window.ui:453
msgid "Instance Manager"
msgstr ""

#: src/window.ui:468
msgid "No Instances Found"
msgstr ""

#: src/window.ui:469
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr ""

#: src/window.ui:498
msgid "Added Instances"
msgstr ""

#: src/window.ui:499
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""

#: src/window.ui:535
msgid "Tool Manager"
msgstr ""

#: src/window.ui:546
msgid "Available Tools"
msgstr ""

#: src/window.ui:547
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""

#: src/window.ui:566
msgid "Model Manager"
msgstr ""

#: src/window.ui:604
#, fuzzy
msgid "Search Model"
msgstr "Funcionalidades"

#: src/window.ui:618
msgid "Model Manager Menu"
msgstr ""

#: src/window.ui:631
msgid "Model search bar"
msgstr "Barra de pesquisa de modelo"

#: src/window.ui:643 src/window.ui:645
msgid "Search models"
msgstr "Pesquisar modelos"

#: src/window.ui:652
msgid "Filter Models"
msgstr ""

#: src/window.ui:668
msgid "Added"
msgstr ""

#: src/window.ui:678 src/window.ui:739 src/window.ui:793
msgid "No Models Found"
msgstr "Nenhum modelo encontrado"

#: src/window.ui:679
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""

#: src/window.ui:682 src/window.ui:692 src/window.ui:1367
msgid "Manage Instances"
msgstr ""

#: src/window.ui:740 src/window.ui:794
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""

#: src/window.ui:752
msgid "Available"
msgstr ""

#: src/window.ui:806
msgid "Creator"
msgstr ""

#: src/window.ui:817
msgid "Model Creator"
msgstr ""

#: src/window.ui:818
msgid "Select a method of importing a model to continue"
msgstr ""

#: src/window.ui:830
msgid "GGUF File"
msgstr ""

#: src/window.ui:841
msgid "Existing Model"
msgstr ""

#: src/window.ui:859
msgid "Identity"
msgstr ""

#: src/window.ui:862
msgid "Base"
msgstr "Base"

#: src/window.ui:869
msgid "Profile Picture"
msgstr ""

#: src/window.ui:874
msgid "Open File"
msgstr ""

#: src/window.ui:890 src/custom_widgets/model_manager_widget.py:257
msgid "Tag"
msgstr ""

#: src/window.ui:897 src/custom_widgets/model_manager_widget.py:274
msgid "Context"
msgstr "Contexto"

#: src/window.ui:898
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""

#: src/window.ui:926
msgid "Behavior"
msgstr "Comportamento"

#: src/window.ui:929
msgid "Imagination"
msgstr ""

#: src/window.ui:930
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr ""

#: src/window.ui:944
msgid "Focus"
msgstr ""

#: src/window.ui:945
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr ""

#: src/window.ui:978 src/window.ui:986
msgid "Add Model"
msgstr ""

#: src/window.ui:1020 src/window.ui:1381
msgid "Preferences"
msgstr "Preferências"

#: src/window.ui:1028
#, fuzzy
msgid "Run Alpaca In Background"
msgstr "Executar em segundo plano"

#: src/window.ui:1034
msgid "Show Power Saver Warning"
msgstr "Mostrar aviso de economia de energia"

#: src/window.ui:1035
msgid "When running a managed Ollama instance"
msgstr ""

#: src/window.ui:1041
msgid "Zoom"
msgstr ""

#: src/window.ui:1058
msgid "Auto Send Message After Talking"
msgstr ""

#: src/window.ui:1064
msgid "Speech Recognition Language"
msgstr ""

#: src/window.ui:1074
msgid "Text to Speech Voice"
msgstr ""

#: src/window.ui:1086
msgid "Delete All Chats"
msgstr ""

#: src/window.ui:1098
msgid "Notice"
msgstr ""

#: src/window.ui:1118
msgid ""
"Hey Alpaca users! We're so excited to bring you a fresh update packed with "
"awesome new features to explore! Get ready to experience Alpaca in a whole "
"new way!"
msgstr ""

#: src/window.ui:1125
msgid "Smart Tools"
msgstr ""

#: src/window.ui:1126
msgid ""
"Supported AI models can use handy tools to grab information both locally and "
"online. Head over to the brand new \"Tool Manager\" to toggle them on or off."
msgstr ""

#: src/window.ui:1133
msgid "Talk to Models"
msgstr ""

#: src/window.ui:1134
msgid ""
"You can now dictate your messages using local speech recognition. It's super "
"convenient! You can even customize your language and other settings in the "
"Preferences dialog."
msgstr ""

#: src/window.ui:1141
msgid "Find Models Faster"
msgstr ""

#: src/window.ui:1142
msgid ""
"Browsing through your Ollama models just got easier! We've added the ability "
"to filter models by their categories in the Model Manager. Now you can "
"quickly find exactly the model you're looking for."
msgstr ""

#: src/window.ui:1149
msgid "Math Rendering"
msgstr ""

#: src/window.ui:1150
msgid ""
"We've improved how LaTeX equations are rendered in messages, making them "
"look cleaner and more consistent. Your mathematical discussions will be "
"clearer than ever!"
msgstr ""

#: src/window.ui:1157
msgid "More Instances"
msgstr ""

#: src/window.ui:1158
msgid ""
"Get ready to connect Alpaca to a whole universe of AI providers! We've added "
"support for over 5 new AI instance providers, including Anthropic, "
"OpenRouter, and Fireworks. The possibilities are endless!"
msgstr ""

#: src/window.ui:1165
msgid "Attachment Enhancement"
msgstr ""

#: src/window.ui:1166
msgid ""
"You can now attach and ask questions about even more file types, "
"including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
"you'll see it with rich text styling, making it easier to understand the "
"content before you send it."
msgstr ""

#: src/window.ui:1187
msgid "Quick ask dialog"
msgstr "Caixa de diálogo de pergunta rápida"

#: src/window.ui:1199
msgid "Save Conversation to Alpaca"
msgstr "Salvar conversa no Alpaca"

#: src/window.ui:1268
msgid "Terminal dialog"
msgstr ""

#: src/window.ui:1271
msgid "Terminal"
msgstr "Terminal"

#: src/window.ui:1285
msgid "Open Environment Directory"
msgstr ""

#: src/window.ui:1306
msgid "File preview dialog"
msgstr "Caixa de diálogo de visualização de arquivo"

#: src/window.ui:1317
msgid "Open With Default App"
msgstr "Abrir com aplicativo padrão"

#: src/window.ui:1325
msgid "Remove Attachment"
msgstr "Remover anexo"

#: src/window.ui:1359
msgid "Start Quick Ask"
msgstr ""

#: src/window.ui:1363
#, fuzzy
msgid "Import Chat"
msgstr "Importar conversa"

#: src/window.ui:1375
msgid "Manage Tools"
msgstr ""

#: src/window.ui:1385
msgid "Keyboard Shortcuts"
msgstr "Atalhos de Teclado"

#: src/window.ui:1389
msgid "About Alpaca"
msgstr "Sobre Alpaca"

#: src/window.ui:1397 src/window.ui:1431
msgid "Rename Chat"
msgstr "Renomear Conversa"

#: src/window.ui:1401 src/window.ui:1435
msgid "Duplicate Chat"
msgstr "Conversa duplicada"

#: src/window.ui:1411 src/window.ui:1445
msgid "Delete Chat"
msgstr "Excluir Conversa"

#: src/window.ui:1419
msgid "Reload Added Models"
msgstr ""

#: src/window.ui:1423
msgid "Download Model From Name"
msgstr ""

#: src/window.ui:1453
msgid "Send as User"
msgstr "Enviar como usuário"

#: src/window.ui:1457
msgid "Send as System"
msgstr "Enviar como sistema"

#: src/window.ui:1461 src/gtk/help-overlay.ui:133
msgid "Use Tools"
msgstr ""

#: src/window.ui:1473
msgid "Attach Website"
msgstr ""

#: src/window.ui:1477
msgid "Attach YouTube Captions"
msgstr ""

#: src/alpaca_search_provider.py.in:43
msgid "Open chat"
msgstr "Abrir conversa"

#: src/alpaca_search_provider.py.in:44
msgid "Quick ask"
msgstr "Pergunta rápida"

#: src/generic_actions.py:79
msgid "An error occurred while extracting text from the website"
msgstr "Ocorreu um erro ao extrair texto do site"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr ""

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr ""

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr ""

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr ""

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr ""

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr ""

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr ""

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr ""

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr ""

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr ""

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr ""

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr ""

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr ""

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr ""

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr ""

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr ""

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "Copiar"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "Colar"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr ""

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "Inserir nova linha"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr ""

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr ""

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr ""

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr ""

#: src/custom_widgets/chat_widget.py:92
msgid "Try one of these prompts"
msgstr "Experimente um destes prompts"

#: src/custom_widgets/chat_widget.py:121
msgid "Send prompt: '{}'"
msgstr "Enviar prompt: '{}'"

#: src/custom_widgets/chat_widget.py:127
msgid "Refresh Prompts"
msgstr ""

#: src/custom_widgets/chat_widget.py:185
#, fuzzy
msgid "Chat exported successfully"
msgstr "Conversa exportada com sucesso"

#: src/custom_widgets/chat_widget.py:205
msgid "User"
msgstr "Usuário"

#: src/custom_widgets/chat_widget.py:209
#: src/custom_widgets/message_widget.py:680
msgid "System"
msgstr "Sistema"

#: src/custom_widgets/chat_widget.py:297
msgid "Regenerate Response"
msgstr "Regenerar resposta"

#: src/custom_widgets/chat_widget.py:461
msgid "Copy of {}"
msgstr "Cópia de {}"

#: src/custom_widgets/chat_widget.py:474
#, fuzzy
msgid "Chat imported successfully"
msgstr "Conversa importada com sucesso"

#: src/custom_widgets/message_widget.py:88
msgid "Save Message"
msgstr "Salvar mensagem"

#: src/custom_widgets/message_widget.py:129
#: src/custom_widgets/message_widget.py:268
#, fuzzy
msgid "Message edited successfully"
msgstr "Modelo excluído com sucesso"

#: src/custom_widgets/message_widget.py:155
msgid "Response message"
msgstr "Mensagem de resposta"

#: src/custom_widgets/message_widget.py:157
msgid "System message"
msgstr "Mensagem do sistema"

#: src/custom_widgets/message_widget.py:159
msgid "User message"
msgstr "Mensagem do usuário"

#: src/custom_widgets/message_widget.py:218
msgid "{}Code Block"
msgstr "{}Bloco de código"

#: src/custom_widgets/message_widget.py:220
msgid "Code Block"
msgstr "Bloco de código"

#: src/custom_widgets/message_widget.py:221
#: src/custom_widgets/message_widget.py:530
#, fuzzy
msgid "Copy Message"
msgstr "Enviar Mensagem"

#: src/custom_widgets/message_widget.py:225
msgid "Edit Code Block"
msgstr ""

#: src/custom_widgets/message_widget.py:237
#: src/custom_widgets/message_widget.py:313
msgid "Run Script"
msgstr "Executar script"

#: src/custom_widgets/message_widget.py:277
msgid "Code copied to the clipboard"
msgstr "Código copiado para a área de transferência"

#: src/custom_widgets/message_widget.py:314
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""
"Certifique-se de entender o que este script faz antes de executá-lo, a "
"Alpaca não é responsável por quaisquer danos ao seu dispositivo ou dados"

#: src/custom_widgets/message_widget.py:316
msgid "Execute"
msgstr "Executar"

#: src/custom_widgets/message_widget.py:395
#: src/custom_widgets/message_widget.py:397
msgid "Image"
msgstr "Imagem"

#: src/custom_widgets/message_widget.py:406
#: src/custom_widgets/message_widget.py:418
msgid "Missing Image"
msgstr "Imagem ausente"

#: src/custom_widgets/message_widget.py:420
msgid "Missing image"
msgstr "Imagem ausente"

#: src/custom_widgets/message_widget.py:493
msgid "Copy Equation"
msgstr ""

#: src/custom_widgets/message_widget.py:500
msgid "Equation copied to the clipboard"
msgstr ""

#: src/custom_widgets/message_widget.py:520
#, fuzzy
msgid "Remove Message"
msgstr "Remover Imagem"

#: src/custom_widgets/message_widget.py:540
#, fuzzy
msgid "Edit Message"
msgstr "Enviar Mensagem"

#: src/custom_widgets/message_widget.py:551
msgid "Regenerate Message"
msgstr "Regenerar mensagem"

#: src/custom_widgets/message_widget.py:563
msgid "Dictate Message"
msgstr ""

#: src/custom_widgets/message_widget.py:583
msgid "Message copied to the clipboard"
msgstr "Mensagem copiada para a área de transferência"

#: src/custom_widgets/message_widget.py:648
msgid "Message cannot be regenerated while receiving a response"
msgstr "A mensagem não pode ser regenerada ao receber uma resposta"

#: src/custom_widgets/message_widget.py:957
msgid "Thought"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:67
#: src/custom_widgets/model_manager_widget.py:69
msgid "Stop Download"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:74
msgid "Stop Download?"
msgstr "Parar o download?"

#: src/custom_widgets/model_manager_widget.py:75
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "Tem certeza que deseja parar o download de '{}'?"

#: src/custom_widgets/model_manager_widget.py:77
msgid "Stop"
msgstr "Parar"

#: src/custom_widgets/model_manager_widget.py:147
msgid "Model Manager Error"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:147
msgid "An error occurred whilst pulling '{}'"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:172
msgid "Download Completed"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:172
msgid "Model '{}' downloaded successfully."
msgstr ""

#: src/custom_widgets/model_manager_widget.py:235
msgid "Change Profile Picture"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:258
msgid "Family"
msgstr "Família"

#: src/custom_widgets/model_manager_widget.py:259
msgid "Parameter Size"
msgstr "Tamanho do parâmetro"

#: src/custom_widgets/model_manager_widget.py:260
msgid "Quantization Level"
msgstr "Nível de quantização"

#: src/custom_widgets/model_manager_widget.py:263
msgid "Parent Model"
msgstr "Modelo pai"

#: src/custom_widgets/model_manager_widget.py:266
#: src/custom_widgets/model_manager_widget.py:268
msgid "Modified At"
msgstr "Modificado em"

#: src/custom_widgets/model_manager_widget.py:276
msgid "Description"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:424
msgid "Change"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:427
msgid "Model Profile Picture"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:427
msgid "What do you want to do with the model's profile picture?"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:449
msgid "Create Child"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:457
msgid "Remove Model"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:460
msgid "Remove Model?"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:461
msgid "Are you sure you want to remove '{}'?"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:475
msgid "Multilingual"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:476
msgid "Code"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:477
msgid "Math"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:478
msgid "Vision"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:479
msgid "Embedding"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:480
msgid "Tools"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:481
msgid "Small"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:482
msgid "Medium"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:483
msgid "Big"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:484
msgid "Huge"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:573
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""

#: src/custom_widgets/terminal_widget.py:80
msgid "Setting up Python environment..."
msgstr "Configurando o ambiente Python..."

#: src/custom_widgets/terminal_widget.py:98
msgid "Compiling C++ script..."
msgstr ""

#: src/custom_widgets/terminal_widget.py:111
msgid "Running local web server"
msgstr ""

#: src/custom_widgets/terminal_widget.py:136
msgid "Using Flatpak contained shell"
msgstr ""

#: src/custom_widgets/terminal_widget.py:136
msgid "Using SSH to run command"
msgstr ""

#: src/custom_widgets/terminal_widget.py:142
msgid "Script Exited"
msgstr ""

#~ msgid "Clear Chat?"
#~ msgstr "Limpar conversa"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "Tem certeza de que deseja limpar a conversa?"

#~ msgid "Clear"
#~ msgstr "Limpar"

#~ msgid "Clear Chat"
#~ msgstr "Limpar Conversa"

#, fuzzy
#~ msgid "Built in Ollama instance"
#~ msgstr "Um cliente Ollama"

#~ msgid ""
#~ "QwQ is an experimental research model focused on advancing AI reasoning "
#~ "capabilities."
#~ msgstr ""
#~ "QwQ é um modelo de pesquisa experimental focado no avanço das capacidades "
#~ "de raciocínio da IA."

#~ msgid ""
#~ "It looks like you don't have any models downloaded yet. Download models "
#~ "to get started!"
#~ msgstr ""
#~ "Parece que você ainda não tem nenhum modelo baixado. Baixe os modelos "
#~ "para começar!"

#~ msgid ""
#~ "Mistral Small is a lightweight model designed for cost-effective use in "
#~ "tasks like translation and summarization."
#~ msgstr ""
#~ "Mistral Small é um modelo leve projetado para uso econômico em tarefas "
#~ "como tradução e resumo."

#~ msgid "Loading Instance"
#~ msgstr "Carregando instância"

#~ msgid "General"
#~ msgstr "Geral"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Token do portador (opcional)"

#, fuzzy
#~ msgid "Chat with local AI models"
#~ msgstr "Converse com modelos de IA locais"

#~ msgid "An Ollama client"
#~ msgstr "Um cliente Ollama"

#~ msgid "Connect"
#~ msgstr "Conectar"

#~ msgid "Server URL"
#~ msgstr "URL do servidor"

#~ msgid "Connect Remote Instance"
#~ msgstr "Conectar instância remota"

#~ msgid "Enter instance information to continue"
#~ msgstr "Insira as informações da instância para continuar"

#, fuzzy
#~ msgid "Close Alpaca"
#~ msgstr "Bem-vindo(a) a Alpaca"

#~ msgid "Use Local Instance"
#~ msgstr "Usar instância local"

#, fuzzy
#~ msgid "Connection Error"
#~ msgstr "Conexão Remota"

#~ msgid "The remote instance has disconnected"
#~ msgstr "A instância remota foi desconectada"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Houve um erro com a instância local Ollama, a mesma foi desconfigurada"

#~ msgid "An error occurred: {}"
#~ msgstr "Ocorreu um erro: {}"

#~ msgid "Ollama instance was shut down due to inactivity"
#~ msgstr "A instância do Ollama foi encerrada devido à inatividade"

#, fuzzy
#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Gerencia uma conexão remota com Ollama"

#~ msgid "Change Ollama Instance"
#~ msgstr "Alterar instância do Ollama"

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "A temperatura do modelo. Aumentar a temperatura fará com que o "
#~ "modeloresponda de maneira mais criativa. (Padrão: 0,8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Defina a semente de número aleatório a ser usado para a geração. "
#~ "Definindo isso como umnúmero específico fará o modelo gerar o mesmo texto "
#~ "para o mesmoprompt. (Padrão: 0 (aleatório))"

#~ msgid "Keep Alive Time"
#~ msgstr "Mantenha vivo"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Controla quanto tempo o modelo permanecerá carregado na memória seguindo "
#~ "osolicitação em minutos (padrão: 5)"

#, fuzzy
#~ msgid "Ollama Instance"
#~ msgstr "Um cliente Ollama"

#, fuzzy
#~ msgid "Ollama Overrides"
#~ msgstr "Site do Ollama"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Gerenciar os argumentos usados ​​no Ollama, quaisquer alterações nesta "
#~ "página apenas se aplicapara a instância integrada, a instância será "
#~ "reiniciada se você fizer alterações."

#~ msgid "Idle Timer"
#~ msgstr "Tempo de inatividade"

#~ msgid ""
#~ "Number of minutes the instance should remain idle before it is shut down "
#~ "(0 means it won't be shut down)"
#~ msgstr ""
#~ "Número de minutos, a instância deve permanecer ociosa antes de ser "
#~ "fechada (0significa que não será fechado)"

#~ msgid "Change Model Directory"
#~ msgstr "Alterar diretório de modelo"

#~ msgid "Powered by Ollama"
#~ msgstr "Com tecnologia Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Site do Ollama"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca e seus desenvolvedores não são responsáveis por quaisquer danos "
#~ "causados a dispositivos ou software resultante da execução de código "
#~ "gerado por um modelo de IA. Por favor, tenha cuidado e revise o código "
#~ "com cuidado antes de executá-lo."

#~ msgid "From Existing Model"
#~ msgstr "Do modelo existente"

#~ msgid "From GGUF File"
#~ msgstr "Do arquivo GGUF"

#~ msgid "From Name"
#~ msgstr "Do nome"

#, fuzzy
#~ msgid "image"
#~ msgstr "Imagem"

#~ msgid "Select Model"
#~ msgstr "Selecione o modelo"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Este modelo será usado como base para o novo modelo"

#~ msgid "Pull Model"
#~ msgstr "Baixar Modelo"

#~ msgid ""
#~ "Input the name of the model in this format\n"
#~ "name:tag"
#~ msgstr "Remover anexo?"

#~ msgid ""
#~ "The default model to use on new chats and when Alpaca is launched with "
#~ "the option --ask \"message\""
#~ msgstr ""
#~ "O modelo padrão a ser usado em novos chats e quando o Alpaca é iniciado "
#~ "com a opção --ask \"message\""

#~ msgid "Manage models dialog"
#~ msgstr "Gerenciar diálogo de modelos"

#, fuzzy
#~ msgid "Create Model"
#~ msgstr "Criar"

#~ msgid "Refresh Local Models"
#~ msgstr "Atualizar modelos locais"

#~ msgid "Try a different search or pull an unlisted model from it's name"
#~ msgstr ""
#~ "Tente uma pesquisa diferente ou extraia um modelo não listado de seu nome"

#~ msgid "Pull Model From Name"
#~ msgstr "Extrair modelo do nome"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "Ao baixar este modelo, você aceita o contrato de licença disponível no "
#~ "site do modelo."

#~ msgid "Model Details"
#~ msgstr "Detalhes do modelo"

#~ msgid ""
#~ "Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
#~ "instructions automatically. Please visit the model's website or Ollama "
#~ "documentation for more information if you're unsure."
#~ msgstr ""
#~ "Alguns modelos exigem um modelfile, o Alpaca preenche as instruções FROM "
#~ "e SYSTEM (contexto) automaticamente. Visite a documentação do modelo ou "
#~ "do Ollama para obter mais informações se não tiver certeza."

#~ msgid "Create"
#~ msgstr "Criar"

#~ msgid "Stop Pulling '{}'"
#~ msgstr "Pare de puxar '{}'"

#~ msgid "Details"
#~ msgstr "Detalhes"

#~ msgid "Remove '{}'"
#~ msgstr "Remover '{}'"

#~ msgid "Delete Model?"
#~ msgstr "Excluir modelo?"

#~ msgid "Create Model Based on '{}'"
#~ msgstr "Criar modelo baseado em '{}'"

#~ msgid "Format"
#~ msgstr "Formatar"

#~ msgid "Enter download menu for {}"
#~ msgstr "Entre no menu de download de {}"

#~ msgid "Download"
#~ msgstr "Baixar"

#~ msgid "Large Model"
#~ msgstr "Modelo Grande"

#~ msgid "Download {}:{}"
#~ msgstr "Download {}:{}"

#~ msgid "Model deleted successfully"
#~ msgstr "Modelo excluído com sucesso"

#~ msgid "Task Complete"
#~ msgstr "Tarefa Concluída"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "O modelo '{}' foi baixado com sucesso"

#~ msgid "Pull Model Error"
#~ msgstr "Erro ao Baixar Modelo"

#~ msgid "Failed to pull model '{}': {}"
#~ msgstr "Falha ao extrair o modelo '{}': {}"

#~ msgid "Error pulling '{}': {}"
#~ msgstr "Erro ao extrair '{}': {}"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr "Não foi possível baixar o modelo '{}' devido a um erro de rede."

#~ msgid "Error pulling '{}'"
#~ msgstr "Erro ao extrair '{}'"

#~ msgid ""
#~ "New state of the art 70B model. Llama 3.3 70B offers similar performance "
#~ "compared to Llama 3.1 405B model."
#~ msgstr ""
#~ "Novo modelo 70B de última geração. O Llama 3.3 70B oferece desempenho "
#~ "similar em comparação ao modelo Llama 3.1 405B."

#~ msgid "Script exited"
#~ msgstr "Script encerrado"

#~ msgid "The script is contained inside Flatpak"
#~ msgstr "O script está contido dentro do Flatpak"

#~ msgid "Close application"
#~ msgstr "Fechar aplicativo"

#~ msgid "Import chat"
#~ msgstr "Importar conversa"

#~ msgid "Clear chat"
#~ msgstr "Limpar chat"

#~ msgid "New chat"
#~ msgstr "Nova conversa"

#~ msgid "Show shortcuts window"
#~ msgstr "Mostrar janela de atalhos"

#~ msgid "Manage models"
#~ msgstr "Gerenciar modelos"

#~ msgid "Toggle sidebar"
#~ msgstr "Alternar barra lateral"

#~ msgid "Rename chat"
#~ msgstr "Renomear conversa"

#~ msgid "Editor"
#~ msgstr "Editor"

#~ msgid "Message text box"
#~ msgstr "Caixa de texto de mensagem"

#~ msgid "Missing file"
#~ msgstr "Arquivo ausente"

#~ msgid "Image Recognition"
#~ msgstr "Reconhecimento de imagem"

#~ msgid ""
#~ "Your system's available RAM suggests that this model might be too large "
#~ "to run optimally. Are you sure you want to download it anyway?"
#~ msgstr ""
#~ "A RAM disponível no seu sistema sugere que este modelo pode ser muito "
#~ "grande para rodar de forma otimizada. Tem certeza de que deseja baixá-lo "
#~ "mesmo assim?"

#~ msgid "This video is not available"
#~ msgstr "Este vídeo não está disponível"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr "A conversa não pode ser limpa enquanto gera uma mensagem"

#, fuzzy
#~ msgid "Use local instance"
#~ msgstr "URL da instância remota"

#, fuzzy
#~ msgid "URL of Remote Instance"
#~ msgstr "URL da instância remota"

#~ msgid "Failed to connect to server"
#~ msgstr "Falha ao conectar com o servidor"

#, fuzzy
#~ msgid "Pulling in the background..."
#~ msgstr "Executar em segundo plano"

#, fuzzy
#~ msgid "Featured Models"
#~ msgstr "Funcionalidades"

#, fuzzy
#~ msgid "Template"
#~ msgstr "Funcionalidades"

#, fuzzy
#~ msgid "A conversation showing code highlight"
#~ msgstr "Uma conversa exibindo highlighting de código"

#~ msgid "A conversation involving multiple models"
#~ msgstr "Uma conversa envolvendo múltiplos modelos"

#~ msgid "Managing models"
#~ msgstr "Gerenciando modelos"

#~ msgid "An error occurred"
#~ msgstr "Ocorreu um erro"

#~ msgid "Could not list local models"
#~ msgstr "Não foi possível listar modelos locais"

#~ msgid "Could not delete model"
#~ msgstr "Não foi possível excluir o modelo"

#~ msgid "Could not pull model"
#~ msgstr "Não foi possível baixar o modelo"

#~ msgid "Cannot delete chat because it's the only one left"
#~ msgstr "Não foi possível excluir a conversa por ser a única restante"

#, fuzzy
#~ msgid "That tag is already being pulled"
#~ msgstr "Esta tag já está sendo baixada"

#, fuzzy
#~ msgid "That tag has been pulled already"
#~ msgstr "Esta tag já foi baixada"

#~ msgid "Model pulled successfully"
#~ msgstr "Modelo baixado com sucesso"

#, fuzzy
#~ msgid "Model"
#~ msgstr "Parar Modelo"

#, fuzzy
#~ msgid "Send message"
#~ msgstr "Enviar Mensagem"

#~ msgid "Remote Connection"
#~ msgstr "Conexão Remota"

#~ msgid "Use remote connection"
#~ msgstr "Usar conexão remota"

#~ msgid "Manage Alpaca's Behavior"
#~ msgstr "Gerencia o Comportamento de Alpaca"

#, fuzzy
#~ msgid "Export current chat"
#~ msgstr "Exportar conversa"

#~ msgid "Upload image"
#~ msgstr "Enviar Imagem"

#~ msgid "Only available on selected models"
#~ msgstr "Disponível apenas em modelos selecionados"

#~ msgid "Send"
#~ msgstr "Enviar"

#~ msgid "Delete Model"
#~ msgstr "Excluir Modelo"

#~ msgid "Please select a tag to pull '{}'"
#~ msgstr "Por favor, selecione uma tag para baixar '{}'"

#~ msgid "Pull"
#~ msgstr "Baixar"

#~ msgid "Are you sure you want to remove image?"
#~ msgstr "Tem certeza que quer remover a imagem?"

#~ msgid "The name '{}' is already in use"
#~ msgstr "O nome '{}' já está em uso"

#~ msgid "Create Chat"
#~ msgstr "Criar Conversa"

#~ msgid "Welcome dialog"
#~ msgstr "Diálogo de Boas-vindas"

#~ msgid "Chats"
#~ msgstr "Conversas"

#~ msgid "Requires model 'llava' to be selected"
#~ msgstr "Requer que um modelo 'llava' esteja selecionado"

#~ msgid "Save Changes"
#~ msgstr "Salvar Mudanças"

#~ msgid "Do you want to save the URL change?"
#~ msgstr "Deseja salvar as mudanças na URL?"

#~ msgid "Discard"
#~ msgstr "Descartar"

#~ msgid ""
#~ "To get started, please ensure you have an Ollama instance set up. You can "
#~ "either run Ollama locally on your machine or connect to a remote instance."
#~ msgstr ""
#~ "Para iniciar, por favor assegure-se que você tem uma insância Ollama "
#~ "configurada e funcional. Você pode rodar Ollama localmente em sua máquina "
#~ "ou através de uma instância remota."

#~ msgid "Setup"
#~ msgstr "Setup"

#~ msgid ""
#~ "If you are running an Ollama instance locally and haven't modified the "
#~ "default ports, you can use the default URL. Otherwise, please enter the "
#~ "URL of your Ollama instance."
#~ msgstr ""
#~ "Caso esteja rodando uma instância Ollama localmente e não modificou as "
#~ "portas padrão, você pode usar a URL padrão. Caso contrário, por favor, "
#~ "insira a URL da sua instância Ollama."

#~ msgid "Change Server"
#~ msgstr "Mudar Servidor"

#~ msgid "Change server"
#~ msgstr "Mudar servidor"
