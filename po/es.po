# Spanish translations for Alpaca package.
# Copyright (C) 2024 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# Jeffry Samuel Eduarte Rojas <jeffrysamuer@gmail.com>, 2024.
#
msgid ""
msgstr ""
"Project-Id-Version: 2.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-12 13:12-0600\n"
"PO-Revision-Date: 2024-05-19 19:44-0600\n"
"Last-Translator: Jeffry Samuel Eduarte Rojas <jeffrysamuer@gmail.com>\n"
"Language-Team: Spanish\n"
"Language: es\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ai;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "Chatea con modelos de IA"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "Un cliente de IA privado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1128
msgid "Features"
msgstr "Funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1130
msgid "Talk to multiple models in the same conversation"
msgstr "Habla con multiples modelos en la misma conversación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1131
msgid "Pull and delete models from the app"
msgstr "Descarga y elimina modelos desde la app"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "Multiples conversaciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "Reconocimiento de imagenes (Solo disponible con modelos compatibles)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "Reconocimiento de documentos de texto plano"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "Importa y exporta chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "Agrega transcripciones de YouTube a los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "Agrega texto de un sitio web a los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "Reconocimiento de PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/window.ui:90
msgid "Disclaimer"
msgstr "Aviso Legal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"Este proyecto no está afiliado del todo con Ollama, no soy responsable por "
"cualquier daño a tu dispositivo o software causado por correr codigo "
"proveido por cualquier modelo."

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "Una conversación normal con un modelo AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "Una conversación que incluye reconocimiento de imagenes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "Una conversación con un modelo personalizado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "Una conversación mostrando highlighting de codigo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "Un script de Python corriendo dentro de la terminal integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation involving a YouTube video transcript"
msgstr "Una conversación que incluye una transcripción de un video de YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "Multiples modelos siendo descargados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "Model creator screen"
msgstr "Pantalla de creación de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:104
#: data/com.jeffser.Alpaca.metainfo.xml.in:152
#: data/com.jeffser.Alpaca.metainfo.xml.in:170
#: data/com.jeffser.Alpaca.metainfo.xml.in:186
#: data/com.jeffser.Alpaca.metainfo.xml.in:198
#: data/com.jeffser.Alpaca.metainfo.xml.in:248
#: data/com.jeffser.Alpaca.metainfo.xml.in:294
#: data/com.jeffser.Alpaca.metainfo.xml.in:325
#: data/com.jeffser.Alpaca.metainfo.xml.in:334
#: data/com.jeffser.Alpaca.metainfo.xml.in:397
#: data/com.jeffser.Alpaca.metainfo.xml.in:425
#: data/com.jeffser.Alpaca.metainfo.xml.in:439
#: data/com.jeffser.Alpaca.metainfo.xml.in:456
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:476
#: data/com.jeffser.Alpaca.metainfo.xml.in:493
#: data/com.jeffser.Alpaca.metainfo.xml.in:503
#: data/com.jeffser.Alpaca.metainfo.xml.in:520
#: data/com.jeffser.Alpaca.metainfo.xml.in:530
#: data/com.jeffser.Alpaca.metainfo.xml.in:577
#: data/com.jeffser.Alpaca.metainfo.xml.in:602
#: data/com.jeffser.Alpaca.metainfo.xml.in:627
#: data/com.jeffser.Alpaca.metainfo.xml.in:649
#: data/com.jeffser.Alpaca.metainfo.xml.in:667
#: data/com.jeffser.Alpaca.metainfo.xml.in:685
#: data/com.jeffser.Alpaca.metainfo.xml.in:697
#: data/com.jeffser.Alpaca.metainfo.xml.in:713
msgid "Fixes"
msgstr "Arreglos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Fixed Ollama (Manged) instance not being able to be created"
msgstr "Se solucionó el problema de que no se podía crear una instancia de "
"Ollama (Administrada)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:106
msgid "Instance manager now follows default model"
msgstr "El gestor de instancias ahora sigue el modelo predeterminado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:107
msgid "English text-to-speech voices not working"
msgstr "Las voces de texto a voz en inglés no funcionan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:108
msgid "Instance manager sometimes not saving instances"
msgstr "El gestor de instancias a veces no guarda las instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:109
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""
"Se corrigieron las instancias de Gorq y Deepseek que no generaban texto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
#: data/com.jeffser.Alpaca.metainfo.xml.in:163
#: data/com.jeffser.Alpaca.metainfo.xml.in:180
#: data/com.jeffser.Alpaca.metainfo.xml.in:210
#: data/com.jeffser.Alpaca.metainfo.xml.in:220
#: data/com.jeffser.Alpaca.metainfo.xml.in:231
#: data/com.jeffser.Alpaca.metainfo.xml.in:258
#: data/com.jeffser.Alpaca.metainfo.xml.in:278
#: data/com.jeffser.Alpaca.metainfo.xml.in:304
#: data/com.jeffser.Alpaca.metainfo.xml.in:319
#: data/com.jeffser.Alpaca.metainfo.xml.in:344
#: data/com.jeffser.Alpaca.metainfo.xml.in:372
#: data/com.jeffser.Alpaca.metainfo.xml.in:382
#: data/com.jeffser.Alpaca.metainfo.xml.in:393
#: data/com.jeffser.Alpaca.metainfo.xml.in:407
#: data/com.jeffser.Alpaca.metainfo.xml.in:419
#: data/com.jeffser.Alpaca.metainfo.xml.in:435
#: data/com.jeffser.Alpaca.metainfo.xml.in:450
#: data/com.jeffser.Alpaca.metainfo.xml.in:485
#: data/com.jeffser.Alpaca.metainfo.xml.in:510
#: data/com.jeffser.Alpaca.metainfo.xml.in:541
#: data/com.jeffser.Alpaca.metainfo.xml.in:567
#: data/com.jeffser.Alpaca.metainfo.xml.in:589
#: data/com.jeffser.Alpaca.metainfo.xml.in:620
#: data/com.jeffser.Alpaca.metainfo.xml.in:642
#: data/com.jeffser.Alpaca.metainfo.xml.in:663
#: data/com.jeffser.Alpaca.metainfo.xml.in:678
#: data/com.jeffser.Alpaca.metainfo.xml.in:703
msgid "New"
msgstr "Nuevo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:118
msgid "Smart tools for models"
msgstr "Herramientas inteligentes para modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:119
msgid "Speech recognition (message dictation)"
msgstr "Reconocimiento de voz (dictado de mensajes)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:120
msgid "Text to Speech"
msgstr "Texto a Voz"

#: data/com.jeffser.Alpaca.metainfo.xml.in:121
msgid "New Quick Chat system"
msgstr "Nuevo Sistema de Pregunta Rápida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "Filter Ollama models by categories"
msgstr "Filtrar modelos de Ollama por categorías"

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Better math Latex rendering in messages"
msgstr "Mejor renderización matemática de Latex en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Rich text rendering in attachment preview"
msgstr "Mejor renderización de texto en la vista previa de archivos adjuntos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Matplotlib is now included in Python code runner"
msgstr "Matplotlib ahora está incluido en el ejecutor de código Python"

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Styling for messages being generated"
msgstr "Estilización para los mensajes que siendo generados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
#: data/com.jeffser.Alpaca.metainfo.xml.in:236
msgid "New Instances"
msgstr "Nuevas Instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:130
msgid "Deepseek"
msgstr "Deepseek"

#: data/com.jeffser.Alpaca.metainfo.xml.in:131
msgid "OpenRouter AI"
msgstr "OpenRouter AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:132
msgid "Anthropic"
msgstr "Anthropic"

#: data/com.jeffser.Alpaca.metainfo.xml.in:133
msgid "Groq Cloud"
msgstr "Groq Cloud"

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "Fireworks AI"
msgstr "Fireworks AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:135
msgid "Lambda Labs"
msgstr "Lambda Labs"

#: data/com.jeffser.Alpaca.metainfo.xml.in:137
msgid "New Attachment Types"
msgstr "Nuevos Tipos de Archivos Adjuntos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:139
msgid "Microsoft Word Document (docx)"
msgstr "Documento de Microsoft Word (docx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:140
msgid "Microsoft PowerPoint Document (pptx)"
msgstr "Documento de Microsoft PowerPoint (pptx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:141
msgid "Microsoft Excel Document (xlsx)"
msgstr "Documento de Microsoft Excel (xlsx)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:143
msgid "New Tools"
msgstr "Nuevas Herramientas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:145 src/tool_manager.py:431
msgid "Run Command (Testing)"
msgstr "Ejecutar Comando (Prueba)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:146 src/tool_manager.py:348
msgid "Online Search"
msgstr "Búsqueda en Línea"

#: data/com.jeffser.Alpaca.metainfo.xml.in:147 src/tool_manager.py:306
msgid "Extract Wikipedia Article"
msgstr "Extracción de Artículos de Wikipedia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:148 src/tool_manager.py:210
msgid "Get Recipe by Name"
msgstr "Obtener Receta por Nombre"

#: data/com.jeffser.Alpaca.metainfo.xml.in:149 src/tool_manager.py:261
msgid "Get Recipes by Category"
msgstr "Obtenga Recetas por Categoría"

#: data/com.jeffser.Alpaca.metainfo.xml.in:150 src/tool_manager.py:176
msgid "Get Current Datetime"
msgstr "Obtener Fecha y Hora Actual"

#: data/com.jeffser.Alpaca.metainfo.xml.in:154
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""
"Se solucionó el problema de que la pantalla de bienvenida fija no se "
"mostraba a veces al eliminar un mensaje."

#: data/com.jeffser.Alpaca.metainfo.xml.in:155
msgid "Fixed bold text not rendering correctly in tables"
msgstr ""
"Se solucionó el problema del texto en negrita que no se representaba "
"correctamente en las tablas."

#: data/com.jeffser.Alpaca.metainfo.xml.in:156
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr ""
"Se corrigieron los botones de solicitud de muestra que se desbordaban en "
"pantallas pequeñas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:165
msgid "Updated runtime to Gnome 48"
msgstr "Runtime actualizado a Gnome 48"

#: data/com.jeffser.Alpaca.metainfo.xml.in:166
msgid "Added back 'category pills' to model manager"
msgstr ""
"Se agregaron nuevamente las 'pastillas de categoría' al gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:167
msgid "Better appearance for model manager sidebar"
msgstr "Mejor apariencia para la barra lateral del gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:168
#: data/com.jeffser.Alpaca.metainfo.xml.in:184
msgid "New models"
msgstr "Nuevos modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:172
msgid "Fixed bad title generation with chain-of-thought models"
msgstr ""
"Se corrigió la generación incorrecta de títulos con modelos de cadena de "
"pensamiento."

#: data/com.jeffser.Alpaca.metainfo.xml.in:173
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""
"Ocultar el selector de páginas en el administrador de modelos si solo hay "
"una página (instancias en línea)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Option to delete all chats"
msgstr "Opción para eliminar todos los chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:183
msgid "Button to refresh sample prompts"
msgstr "Botón para actualizar los mensajes de muestra"

#: data/com.jeffser.Alpaca.metainfo.xml.in:188
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr ""
"Se solucionó el problema de guardar una instancia de Ollama (administrada) "
"que podría bloquearla."

#: data/com.jeffser.Alpaca.metainfo.xml.in:189
msgid "Fixed stop button"
msgstr "Se arregló el botón de parada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:190
msgid "Fixed model search not working if there are only pulling models"
msgstr "La búsqueda de modelo no funciona si solo hay modelos descargandose"

#: data/com.jeffser.Alpaca.metainfo.xml.in:191
msgid "Fixed sample prompts sometimes not appearing"
msgstr "Se corrigieron los mensajes de muestra que a veces no aparecían."

#: data/com.jeffser.Alpaca.metainfo.xml.in:200
msgid "Don't clear the building output of C++ scripts"
msgstr "No borre la salida de compilación de scripts de C++"

#: data/com.jeffser.Alpaca.metainfo.xml.in:201
msgid "Better handling of attachments"
msgstr "Mejor manejo de los archivos adjuntos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:202
msgid "Handle remote Ollama instance's API Key better"
msgstr "Manejar mejor la clave API de la instancia remota de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Remove '\\n' characters in instance edit page"
msgstr "Eliminar caracteres '\\n' en la página de edición de instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:212
msgid "Dynamic chat loading"
msgstr "Cargado de chat dinamico"

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Updated Ollama instance"
msgstr "Actualización de instancia de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:222
msgid "Tweaked appearance of models in model manager"
msgstr "Se modificó la apariencia de los modelos en el gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:223
msgid "Updated Ollama instance to 0.5.11"
msgstr "Se actualizó la instancia de Ollama a la versión 0.5.11"

#: data/com.jeffser.Alpaca.metainfo.xml.in:224
msgid "Added new models"
msgstr "Se agregaron nuevos modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:233
msgid "New instance manager"
msgstr "Nuevo gestor de instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:234
msgid "New welcome screen"
msgstr "Nueva pantalla de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:238
msgid "OpenAI ChatGPT"
msgstr "OpenAI ChatGPT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "Google Gemini"
msgstr "Google Gemini"

#: data/com.jeffser.Alpaca.metainfo.xml.in:240
msgid "Together AI"
msgstr "Together AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
msgid "Venice"
msgstr "Venice"

#: data/com.jeffser.Alpaca.metainfo.xml.in:250
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""
"Se solucionó el problema de exportación de chats con el archivo adjunto "
"'pensamientos'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "Fixed attachment filters"
msgstr "Filtros de archivos adjuntos arreglados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "New model manager"
msgstr "Nuevo gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Changed GtkSpinner to AdwSpinner"
msgstr "Cambiado GTKSpinner a AdwSpinner"

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Better handling of launch process"
msgstr "Mejor manejo del proceso de lanzamiento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid "New loading screen at launch"
msgstr "Nueva pantalla de carga en el lanzamiento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:264
msgid "Better handling of file types"
msgstr "Mejor manejo de los tipos de archivos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:265
msgid "Better regex expression for LaTeX equations"
msgstr "Mejor expresión regular para ecuaciones LaTeX"

#: data/com.jeffser.Alpaca.metainfo.xml.in:266
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""
"Cuadro de diálogo de confirmación si el usuario cierra Alpaca mientras se "
"descarga un modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:267
msgid "Better handling of think tags in messages"
msgstr "Mejor manejo de las etiquetas de pensamiento en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:268
msgid "Default model is now in charge of generating titles"
msgstr "El modelo predeterminado ahora se encarga de generar título"

#: data/com.jeffser.Alpaca.metainfo.xml.in:269
msgid "Message header is now shown whilst the message is being generated"
msgstr "Encabezado del mensaje ahora se muestra mientras se genera el mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:270
msgid "Better handling of model profile pictures"
msgstr "Mejor manejo de las fotos de perfil de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:271
msgid "New models in 'available models' list"
msgstr "Nuevos modelos en la lista de 'modelos disponibles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:280
msgid "Added option for attaching screenshots"
msgstr "Añadida opción para adjuntar capturas de pantalla"

#: data/com.jeffser.Alpaca.metainfo.xml.in:281
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr "Ecuaciones básicas de LaTeX ahora son renderizadas en mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:282
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr "Scripts de C++ y HTML ahora pueden ser ejecutados dentro de Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:283
msgid "Added option to open the environment directory from the terminal"
msgstr "Añadida opción para abrir el directorio del ambiente en la terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:284
msgid "Added option to edit code blocks directly"
msgstr "Añadida opción para editar bloques de código directamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:285
msgid "Complete keyboard shortcut list"
msgstr "Lista de atajos de teclado completa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Images are now attached in 640p resolution"
msgstr "Imagenes ahora son adjuntadas en resolución 640p"

#: data/com.jeffser.Alpaca.metainfo.xml.in:287
msgid "Website attachments now use extracted titles"
msgstr "Sitios web adjuntados ahora extraen titulos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:288
msgid "Better chat title generation"
msgstr "Mejor generación de titulos de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:289
msgid "Added option to attach any plain text files"
msgstr "Añadida opción para adjuntar cualquier archivo de texto plano"

#: data/com.jeffser.Alpaca.metainfo.xml.in:290
msgid "Added spellchecker to message entry"
msgstr "Añadido corrector ortográfico a la entrada de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:291
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr "Los parametros de Alpaca ahora son almacenados en SQLite3"

#: data/com.jeffser.Alpaca.metainfo.xml.in:292
msgid "Small appearance changes in text entries"
msgstr "Cambios de apariencia pequeños en entradas de texto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:296
msgid "Alpaca's launch process is more reliable"
msgstr "El proceso de lanzamiento de Alpaca ahora es más confiable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Closing the terminal now kills the script subprocess"
msgstr "Cerrar la terminal ahora detiene el suproceso del script"

#: data/com.jeffser.Alpaca.metainfo.xml.in:306
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr "Backend de chat transicionada de JSON a SQLite"

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Changed appearance of messages"
msgstr "Cambiada la apariencia de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid "Added the option to add profile pictures to models"
msgstr "Opción añadida para agregar fotos de perfil a modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:310
#: data/com.jeffser.Alpaca.metainfo.xml.in:782
#: data/com.jeffser.Alpaca.metainfo.xml.in:831
msgid "Fix"
msgstr "Arreglo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr "Cambiados override de HIP_VISIBLE_DEVICES a ROCR_VISIBLE_DEVICES"

#: data/com.jeffser.Alpaca.metainfo.xml.in:321
msgid "Added categories to models"
msgstr "Añadidas categorias a modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:322
msgid "Specified model's languages"
msgstr "Especificar lenguajes de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Added warning when downloading embedding models"
msgstr "Añadida advertencia cuando se descargan modelos de incrustación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:327
msgid "Replaced low ram warning with big model warning"
msgstr ""
"Se reemplazó la advertencia de RAM baja con una advertencia de modelo grande"

#: data/com.jeffser.Alpaca.metainfo.xml.in:336
msgid "Correctly escape markup before rendering message"
msgstr "Correctamente escapa markup antes de renderizar mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:337
msgid "Fixed about dialog not working if log file was missing"
msgstr ""
"Arreglado dialogo 'sobre Alpaca' no funcionando si archivo log no existe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:346
msgid "System messages can now be sent directly from Alpaca"
msgstr ""
"Mensajes de sistema ahora pueden ser enviados directamente desde Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:347
msgid "New redesign for messages and smaller minimum size"
msgstr "Nuevo rediseño para mensajes y menor tamaño minimo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:348
msgid "New models included in 'available models list'"
msgstr "Nuevos modelos incluidos en la 'lista de modelos disponibles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:349
msgid "Added symbolic icon when attaching code files"
msgstr "Añadido icono simbolico cuando se adjuntan archivos de codigos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:350
msgid "When exporting a chat it now includes a markdown file"
msgstr "Cuando se exporta un chat ahora se incluye un archivo Markdown"

#: data/com.jeffser.Alpaca.metainfo.xml.in:351
msgid "Refresh button in model manager when using a remote instance"
msgstr ""
"Botón de recarga en el gestor de modelos cuando se usa instancia remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:352
msgid "Assistant messages are now editable"
msgstr "Mensajes de asistente ahora son editables"

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "Updated Ollama to v0.5.2"
msgstr "Ollama actualizado a v0.5.2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "New option to change model directory"
msgstr "Nueva opción para cambiar el directorio de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "File previewer now resizes dynamically to content"
msgstr "Previsualizador de archivos ahora ajusta su tamaño dinamicamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr "Alpaca ha sido adaptado para funcionar sin instancia de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
msgid "Compatibility added with ODT files"
msgstr "Compatibilidad añadida con archivos ODT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:360
msgid "Restored ROCm compatibility"
msgstr "Capabilidad ROCm restaurada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Se agregó un gesto de pulsación prolongada a las filas de chat para que se "
"puedan realizar acciones en pantallas táctiles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:362
msgid "Fixed edit button not saving changes"
msgstr "Arreglado boton de editado no guardando cambios"

#: data/com.jeffser.Alpaca.metainfo.xml.in:363
msgid "Changed max temperature value to 2"
msgstr "Cambiado el valor temperatura maxima a 2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:364
msgid "Made seed 0 actually random"
msgstr "Semilla 0 ahora es aleatoria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:365
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""
"El proveedor de búsqueda de Gnome corregido no funcionaba fuera de las "
"instalaciones de Flatpak"

#: data/com.jeffser.Alpaca.metainfo.xml.in:374
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr "Nueva opción --ask MENSAJE para abrir una ventana 'Pregunta Rápida'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:375
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""
"Integración con busqueda de Gnome ahora funciona si Alpaca esta abierto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:384
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""
"Añadidos parametros de lanzamiento --ask MENSAJE, --new-chat CHAT, --select-"
"chat CHAT, --list-chats, --version"

#: data/com.jeffser.Alpaca.metainfo.xml.in:385
msgid "Added integration as Gnome Search Provider"
msgstr "Añadido integración como Proveedor de Busqueda de Gnome"

#: data/com.jeffser.Alpaca.metainfo.xml.in:386
msgid "Updated Ollama to v0.4.2 with new models"
msgstr "Actualizado Ollama a v0.4.2 con nuevos modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:395
msgid "User messages are now compacted into bubbles"
msgstr "Mensajes de usuario ahora son compactados en burbujas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:399
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""
"Dialogo de reconnexión arreglado: no funciona cuando 'usar instancia local' "
"es seleccionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""
"Arreglado gestor de modelos no adaptandose a fuentes de sistema grandes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:409
msgid "Details page for models"
msgstr "Pagina de detalles para modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""
"El selector de modelos se remplaza con un boton para el gestor de modelos "
"cuando no hay modelos descargados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:411
msgid "Added warning when model is too big for the device"
msgstr "Añadida advertencia cuando el modelo es muy grande para el dispositivo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "Added AMD GPU indicator in preferences"
msgstr "Añadido indicador para GPU de AMD en preferencias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:421
msgid "Better system for handling dialogs"
msgstr "Mejor sistema para manejar dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:422
msgid "Better system for handling instance switching"
msgstr "Mejor sistema para manejar el cambio de instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "Remote connection dialog"
msgstr "Dialogo de conexión remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:427
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""
"Arreglado: Modelos se duplican cuando se cambia entre instancia remota y "
"local"

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "Better internal instance manager"
msgstr "Mejor gestor de instancias interno"

#: data/com.jeffser.Alpaca.metainfo.xml.in:437
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr "Añadido botones 'Cancelar' y 'Guardar' cuando se edita un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:441
msgid "Better handling of image recognition"
msgstr "Mejor manejo de reconocimiento de imagenes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:442
msgid "Remove unused files when canceling a model download"
msgstr "Remover archivos no usados cuando se cancela una descarga de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:443
msgid "Better message blocks rendering"
msgstr "Mejor renderizado de bloques de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:452
msgid "Run bash and python scripts straight from chat"
msgstr "Ejecutar scripts de Bash y Python directamente desde el chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:453
msgid "Updated Ollama to 0.3.12"
msgstr "Ollama actualizado a 0.3.12"

#: data/com.jeffser.Alpaca.metainfo.xml.in:454
msgid "New models!"
msgstr "Nuevos modelos!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Fixed and made faster the launch sequence"
msgstr "Arreglado y optimizado el proceso de lanzamiento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Better detection of code blocks in messages"
msgstr "Mejor detección de bloques de código en mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr "Arreglado: Aplicación no abre en ciertos equipos con GPUs Nvidia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""
"Arreglado: Notificaciones de mensajes a veces congelan la aplicación debido "
"a que corrían en diferentes hilos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Fixed message generation sometimes failing"
msgstr "Arreglado: Generación de mensajes a veces fallaba"

#: data/com.jeffser.Alpaca.metainfo.xml.in:487
msgid "Sidebar resizes with the window"
msgstr "Barra lateral cambia su tamaño con respecto a la ventana"

#: data/com.jeffser.Alpaca.metainfo.xml.in:488
msgid "New welcome dialog"
msgstr "Nuevo dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:489
msgid "Message search"
msgstr "Busqueda de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:490
msgid "Updated Ollama to v0.3.11"
msgstr "Actualizado Ollama a v0.3.11"

#: data/com.jeffser.Alpaca.metainfo.xml.in:491
msgid "A lot of new models provided by Ollama repository"
msgstr "Muchos modelos nuevos proveidos por el repositorio de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""
"Arreglado: Texto dentro del gestionador de modelos cuando la opción de "
"accesibilidad 'texto grande' esta activa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Fixed image recognition on unsupported models"
msgstr "Arreglado reconocimiento de imagenes en modelos no soportados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:505
msgid "Fixed spinner not hiding if the back end fails"
msgstr "Arreglado, spinner no se esconde si la instancia falla"

#: data/com.jeffser.Alpaca.metainfo.xml.in:506
msgid "Fixed image recognition with local images"
msgstr "Arreglado reconocimiento de imagenes locales"

#: data/com.jeffser.Alpaca.metainfo.xml.in:507
msgid "Changed appearance of delete / stop model buttons"
msgstr "Apariencia de botones de eliminar y parar modelos cambiada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:508
msgid "Fixed stop button crashing the app"
msgstr "Arreglado, botón de parar generacion congela la aplicacion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:512
msgid "Made sidebar resize a little when the window is smaller"
msgstr "Barra lateral cambia su tamaño un poco cuando la ventana es pequeña"

#: data/com.jeffser.Alpaca.metainfo.xml.in:513
msgid "Instant launch"
msgstr "Lanzamiento instantaneo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:522
msgid "Fixed error on first run (welcome dialog)"
msgstr "Arreglado error en el primer lanzamiento (dialogo de bienvenida)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:523
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""
"Arreglado verificador de instancia de Ollama (usado en paquetes de sistema)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:532
msgid "Fixed 'clear chat' option"
msgstr "Arreglada opción de 'Limpiar Chat'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:533
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr "Arreglado dialogo de bienvenida causando que la instancia no inicie"

#: data/com.jeffser.Alpaca.metainfo.xml.in:534
msgid "Fixed support for AMD GPUs"
msgstr "Arreglado soporte para GPUs de AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:543
msgid "Model, message and chat systems have been rewritten"
msgstr "Se han reescrito los sistemas de modelos, mensajes y chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:544
msgid "New models are available"
msgstr "Nuevos modelos disponibles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Ollama updated to v0.3.9"
msgstr "Actualizado Ollama a v0.3.9"

#: data/com.jeffser.Alpaca.metainfo.xml.in:546
msgid "Added support for multiple chat generations simultaneously"
msgstr "Se agregó soporte para múltiples generaciones de chat simultáneamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:547
msgid "Added experimental AMD GPU support"
msgstr "Se agregó soporte experimental con GPU AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:548
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""
"Se agregó un indicador de carga de mensajes y un indicador de mensajes "
"nuevos a la pestaña de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "Added animations"
msgstr "Se agregaron animaciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid "Changed model manager / model selector appearance"
msgstr "Se modificó la apariencia del gestor de modelos / selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Changed message appearance"
msgstr "Se modificó la apariencia de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:552
msgid "Added markdown and code blocks to user messages"
msgstr "Añadido markdown y bloques de código para mensajes de usuario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:553
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""
"Se agregó un diálogo de carga al inicio para que la aplicación se abra más "
"rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:554
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""
"Se agregó una advertencia cuando el dispositivo está en modo de 'ahorro de "
"batería'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:555
msgid "Added inactivity timer to integrated instance"
msgstr "Se agregó un temporizador de inactividad a la instancia integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:558
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr "El chat ahora se desplaza hasta la parte inferior cuando se cambia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:559
msgid "Better handling of focus on messages"
msgstr "Mejor manejo de focus en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "Better general performance on the app"
msgstr "Mejor rendimiento general en la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:569
msgid "New duplicate chat option"
msgstr "Nueva opción de duplicado de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:570
msgid "Changed model selector appearance"
msgstr "Apariencia del selector de modelos cambiada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:571
msgid "Message entry is focused on launch and chat change"
msgstr "La entrada de mensaje tiene focus al abrir el app o al cambiar chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:572
msgid "Message is focused when it's being edited"
msgstr "El mensaje tiene focus al ser editado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:573
msgid "Added loading spinner when regenerating a message"
msgstr "Añadido spinner de carga cuando se regenera un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:574
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr "Añadido debugging de Ollama al dialogo 'Sobre Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:575
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""
"Cambiada apariencia y comportamiento del dialogo de transcripciones de "
"YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:579
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr "CTRL+W y CTRL+Q paran la instancia local antes de cerrar la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:580
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""
"Cambiada apariencia del botón 'Abrir Gestor de Modelos' en la pantalla de "
"bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Fixed message generation not working consistently"
msgstr "Arreglado generación de mensajes no funcionando consistentemente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:582
msgid "Fixed message edition not working consistently"
msgstr "Arreglado edición de mesnajes no funcionando consistentemente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:591
msgid "Model manager opens faster"
msgstr "Gestor de modelos abre más rapidamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:592
msgid "Delete chat option in secondary menu"
msgstr "Opción de eliminar chat en el menu secundario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:593
msgid "New model selector popup"
msgstr "Nuevo selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:594
msgid "Standard shortcuts"
msgstr "Atajos de teclado estandares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Model manager is navigable with keyboard"
msgstr "El gestor de modelos es navegable con el teclado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Changed sidebar collapsing behavior"
msgstr "Cambiado comportamiento de colapso de la barra lateral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:597
msgid "Focus indicators on messages"
msgstr "Indicadores de focus en mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Welcome screen"
msgstr "Pantalla de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid "Give message entry focus at launch"
msgstr "Dado focus a la entrada de texto de mensaje al abrir la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:600
msgid "Generally better code"
msgstr "Mejor código en general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Better width for dialogs"
msgstr "Mejor medida de largo para dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Better compatibility with screen readers"
msgstr "Mejor compatibilidad con lectores de pantalla"

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Fixed message regenerator"
msgstr "Arreglado regenerador de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:607
msgid "Removed 'Featured models' from welcome dialog"
msgstr "'Modelos destacados' removido del dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:608
msgid "Added default buttons to dialogs"
msgstr "Añadidos botones por defecto a dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:609
msgid "Fixed import / export of chats"
msgstr "Arreglado importación / exportación de chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:610
msgid "Changed Python2 title to Python on code blocks"
msgstr "Cambiado titulo Python2 a Python en bloques de código"

#: data/com.jeffser.Alpaca.metainfo.xml.in:611
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""
"Prevenir regeneración de titulos cuando el usuario escribio un titulo "
"personalizado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:612
msgid "Show date on stopped messages"
msgstr "Mostrar fecha en mensajes interrumpidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Fix clear chat error"
msgstr "Arreglado error al limpiar chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Changed shortcuts to standards"
msgstr "Cambiado los atajos de teclado a estandares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Moved 'Manage Models' button to primary menu"
msgstr "Movido botón 'Gestión de Modelos' al menu primario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "Stable support for GGUF model files"
msgstr "Soporte estable para archivos de modelo GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
#: data/com.jeffser.Alpaca.metainfo.xml.in:900
msgid "General optimizations"
msgstr "Optimización general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:629
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""
"Mejor manejo de la tecla de enter (importante para escritura en Japones)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:630
msgid "Removed sponsor dialog"
msgstr "Removido dialogo de patrocinio"

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "Added sponsor link in about dialog"
msgstr "Añadido link de patrocinio en el dialogo 'sobre'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Changed window and elements dimensions"
msgstr "Cambiadas las dimensiones de ventana y elementos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:633
msgid "Selected model changes when entering model manager"
msgstr "Selección de modelo cambia cuando se entra al gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:634
msgid "Better image tooltips"
msgstr "Mejor tooltips para imagenes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:635
msgid "GGUF Support"
msgstr "Soporte para GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Regenerate any response, even if they are incomplete"
msgstr "Regenerar cualquier respuesta, inclusive si están incompletas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Support for pulling models by name:tag"
msgstr "Soporte para la descargas de modelos por nombre:etiqueta"

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Restored sidebar toggle button"
msgstr "Restaurado botón de barra lateral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:651
msgid "Reverted back to standard styles"
msgstr "Revertido a estilos estandares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:652
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr "Titulos de chat generados teniendo \"'S\" por algún motivo, arreglado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:653
msgid "Changed min width for model dropdown"
msgstr "Cambiado largo minimo para el selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Changed message entry shadow"
msgstr "Cambiada la sombra en el campo de texto para mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "The last model used is now restored when the user changes chat"
msgstr ""
"El ultimo modelo usado ahora es restaurado cuando el usuario cambia el chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:656
msgid "Better check for message finishing"
msgstr "Mejor chequeo de mensaje terminando"

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
msgid "Added table rendering (Thanks Nokse)"
msgstr "Renderizado de tablas añadido (Gracias Nokse)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:669
msgid "Made support dialog more common"
msgstr "Hizo que el diálogo de soporte sea más común"

#: data/com.jeffser.Alpaca.metainfo.xml.in:670
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""
"El título del diálogo en el selector de etiquetas al descargar modelos no se "
"mostraba correctamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""
"Prevenir que la generación de chats cree un título con múltiples líneas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Bearer Token entry on connection error dialog"
msgstr "Entrada de Token de Portador en el diálogo de error de conexión"

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Small appearance changes"
msgstr "Pequeños cambios en la apariencia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:682
msgid "Compatibility with code blocks without explicit language"
msgstr "Compatibilidad con bloques de código sin lenguaje explícito"

#: data/com.jeffser.Alpaca.metainfo.xml.in:683
msgid "Rare, optional and dismissible support dialog"
msgstr "Diálogo de soporte raro, opcional y descartable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:687
msgid "Date format for Simplified Chinese translation"
msgstr "Formato de fecha para la traducción al chino simplificado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:688
msgid "Bug with unsupported localizations"
msgstr "Error con localizaciones no soportadas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:689
msgid "Min height being too large to be used on mobile"
msgstr "Altura mínima demasiado grande para ser usada en móviles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:690
msgid "Remote connection checker bug"
msgstr "Error en el comprobador de conexión remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:699
msgid "Models with capital letters on their tag don't work"
msgstr "Los modelos con letras mayúsculas en su etiqueta no funcionan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:700
msgid "Ollama fails to launch on some systems"
msgstr "Ollama no se inicia en algunos sistemas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:701
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""
"Las transcripciones de YouTube no se están guardando en el directorio TMP "
"correcto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:705
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""
"Los mensajes de depuración ahora se muestran en el diálogo 'Acerca de Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr "Actualizado Ollama a la versión 0.3.0 (nuevos modelos)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:715
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""
"Los modelos con '-' en sus nombres no funcionaban correctamente, esto ya "
"está solucionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:716
msgid "Better connection check for Ollama"
msgstr "Mejor comprobación de conexión para Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Stable Release"
msgstr "Lanzamiento Estable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""
"El nuevo ícono fue creado por Tobias Bernard en Gnome Gitlab, ¡gracias por "
"el gran ícono!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Features and fixes"
msgstr "Características y correcciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid "Updated Ollama instance to 0.2.8"
msgstr "Instancia de Ollama actualizada a la 0.2.8"

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid "Better model selector"
msgstr "Mejor selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Model manager redesign"
msgstr "Rediseño del gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:730
msgid "Better tag selector when pulling a model"
msgstr "Mejor selector de etiquetas al seleccionar un modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:731
msgid "Model search"
msgstr "Búsqueda de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:732
msgid "Added support for bearer tokens on remote instances"
msgstr "Añadido soporte para tokens de portador en instancias remotas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:733
msgid "Preferences dialog redesign"
msgstr "Rediseño del diálogo de preferencias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:734
msgid "Added context menus to interact with a chat"
msgstr "Añadidos menús contextuales para interactuar con un chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:735
msgid "Redesigned primary and secondary menus"
msgstr "Rediseño de los menús primario y secundario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:736
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""
"Integración de YouTube: Pega la URL de un video con una transcripción y se "
"añadirá al mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:737
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""
"Integración de sitios web (Experimental): Extrae el texto del cuerpo de un "
"sitio web agregando su URL al mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Chat title generation"
msgstr "Generación de título de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:739
msgid "Auto resizing of message entry"
msgstr "Redimensionado automático de la entrada de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Chat notifications"
msgstr "Notificaciones de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:741
msgid "Added indicator when an image is missing"
msgstr "Añadido indicador cuando falta una imagen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""
"Reordenar automáticamente el orden de los chats cuando se recibe un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Redesigned file preview dialog"
msgstr "Rediseño del diálogo de vista previa de archivos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Credited new contributors"
msgstr "Agradecimientos a los nuevos colaboradores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:745
msgid "Better stability and optimization"
msgstr "Mejor estabilidad y optimización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:746
msgid "Edit messages to change the context of a conversation"
msgstr "Editar mensajes para cambiar el contexto de una conversación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "Added disclaimers when pulling models"
msgstr "Añadidos descargos de responsabilidad al seleccionar modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:748
msgid "Preview files before sending a message"
msgstr "Previsualizar archivos antes de enviar un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:749
msgid "Better format for date and time on messages"
msgstr "Mejor formato para la fecha y hora en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:750
msgid "Error and debug logging on terminal"
msgstr "Registro de errores y depuración en la terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Auto-hiding sidebar button"
msgstr "Botón de barra lateral que se oculta automáticamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:752
msgid "Various UI tweaks"
msgstr "Diversos ajustes en la interfaz de usuario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "New Models"
msgstr "Nuevos Modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:756
msgid "Gemma2"
msgstr "Gemma2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:757
msgid "GLM4"
msgstr "GLM4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:758
msgid "Codegeex4"
msgstr "Codegeex4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:759
msgid "InternLM2"
msgstr "InternLM2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Llama3-groq-tool-use"
msgstr "Llama3-groq-tool-use"

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Mathstral"
msgstr "Mathstral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Mistral-nemo"
msgstr "Mistral-nemo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "Firefunction-v2"
msgstr "Firefunction-v2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "Nuextract"
msgstr "Nuextract"

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Translations"
msgstr "Traducciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:767
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""
"Estas son todas las traducciones disponibles en la versión 1.0.0, ¡gracias a "
"todos los colaboradores!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:769
msgid "Russian: Alex K"
msgstr "Ruso: Alex K"

#: data/com.jeffser.Alpaca.metainfo.xml.in:770
msgid "Spanish: Jeffser"
msgstr "Español: Jeffser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:771
msgid "Brazilian Portuguese: Daimar Stein"
msgstr "Portugués brasileño: Daimar Stein"

#: data/com.jeffser.Alpaca.metainfo.xml.in:772
msgid "French: Louis Chauvet-Villaret"
msgstr "Francés: Louis Chauvet-Villaret"

#: data/com.jeffser.Alpaca.metainfo.xml.in:773
msgid "Norwegian: CounterFlow64"
msgstr "Noruego: CounterFlow64"

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid "Bengali: Aritra Saha"
msgstr "Bengalí: Aritra Saha"

#: data/com.jeffser.Alpaca.metainfo.xml.in:775
msgid "Simplified Chinese: Yuehao Sui"
msgstr "Chino simplificado: Yuehao Sui"

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""
"Removida compatibilidad con DOCX temporalmente debido a un error con la "
"dependencia python-lxml"

#: data/com.jeffser.Alpaca.metainfo.xml.in:789
#: data/com.jeffser.Alpaca.metainfo.xml.in:819
#: data/com.jeffser.Alpaca.metainfo.xml.in:840
#: data/com.jeffser.Alpaca.metainfo.xml.in:1045
#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
msgid "Big Update"
msgstr "Gran Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:791
msgid "Added compatibility for PDF"
msgstr "Añadida compatibilidad para PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:792
msgid "Added compatibility for DOCX"
msgstr "Añadida compatibilidad para DOCX"

#: data/com.jeffser.Alpaca.metainfo.xml.in:793
msgid "Merged 'file attachment' menu into one button"
msgstr "Combinado menu 'subir archivos' en un botón"

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
#: data/com.jeffser.Alpaca.metainfo.xml.in:993
msgid "Quick Fix"
msgstr "Arreglo rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""
"Hubieron unos errores mientras los chats transicionaban a la nueva versión. "
"Pido disculpas si eso causo alguna corrupción en to historial de chats. Esta "
"debería de ser la única vez que una transición es necesaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:807
#: data/com.jeffser.Alpaca.metainfo.xml.in:959
msgid "Huge Update"
msgstr "Gran Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:809
msgid "Added: Support for plain text files"
msgstr "Añadido: Soporte para archivos de texto plano"

#: data/com.jeffser.Alpaca.metainfo.xml.in:810
msgid "Added: New backend system for storing messages"
msgstr "Añadido: Nuevo sistema en el backend para guardar mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:811
msgid "Added: Support for changing Ollama's overrides"
msgstr "Añadido: Soporte para cambiar overrides de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "General Optimization"
msgstr "Optimización general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Added: Support for GGUF models (experimental)"
msgstr "Añadido: Soporte de modelos GGUF (experimental)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Added: Support for customization and creation of models"
msgstr "Añadido: Soporte para personalización y creración de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr "Arreglado: Iconos no se mostraban en sistemas que no usan Gnome"

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Update Ollama to v0.1.39"
msgstr "Ollama actualizado a v0.1.39"

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""
"Arreglado: La aplicación no abre si 'models tweaks' no esta presente en los "
"archivos de configuración"

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""
"Multiples iconos cambiados (avion de papel para el boton de enviar mensaje)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Combined export / import chat buttons into a menu"
msgstr "Botones importar / exportar chat combinados en un menu"

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr "Añadidos ajustes de modelo (temperatura, semilla, mantener vivo)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:845
msgid "Fixed send / stop button"
msgstr "Arreglado boton enviar / parar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""
"Arreglado: Aplicación no chequea si la conexión remota funciona cuando inicia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:853
msgid "Daily Update"
msgstr "Actulización Diaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:855
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""
"Añadido elipsis a el nombre del chat para que no afecte el largo del boton"

#: data/com.jeffser.Alpaca.metainfo.xml.in:856
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr "Nuevo atajo de teclado para crear chat (CTRL+N)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:857
msgid "New message entry design"
msgstr "Nuevo diseño para el entry de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:858
msgid "Fixed: Can't rename the same chat multiple times"
msgstr "Arreglado: No se puede renombrar el mismo chat multiples veces"

#: data/com.jeffser.Alpaca.metainfo.xml.in:865
msgid "The fix"
msgstr "Arreglos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:867
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""
"Arreglado: Instancia de Ollama sigue siendo ejecutada en el fondo aunque sea "
"desactivada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:868
msgid "Fixed: Can't pull models on the integrated instance"
msgstr "Arreglado: No se puede descargar modelos en la instancia integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:875
msgid "Quick tweaks"
msgstr "Arreglos rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Added progress bar to models that are being pulled"
msgstr "Añadida barra de progreso a modelos que estan siendo descargados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:878
msgid "Added size to tags when pulling a model"
msgstr "Añadido tamaño de tags cuando se descarga un modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "General optimizations on the background"
msgstr "Optimizaciones general en el fondo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:886
msgid "Quick fixes"
msgstr "Arreglos rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:888
msgid "Fixed: Scroll when message is received"
msgstr "Arreglado: Desplazamiento automatico cuando un mensaje es recibido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:889
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr "Arreglad: Contenido no cambia cuando se crea un nuevo chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:890
msgid "Added 'Featured Models' page on welcome dialog"
msgstr "Añadida sección 'Modelos Destacados' en el dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:897
msgid "Nice Update"
msgstr "Buena Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:899
msgid "UI tweaks (Thanks Nokse22)"
msgstr "Mejor UI en general (Gracias Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:901
msgid "Metadata fixes"
msgstr "Correciones de metadata"

#: data/com.jeffser.Alpaca.metainfo.xml.in:908
msgid "Quick fix"
msgstr "Arreglo rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:910
msgid "Updated Spanish translation"
msgstr "Actualización a la traducción a Español"

#: data/com.jeffser.Alpaca.metainfo.xml.in:911
msgid "Added compatibility for PNG"
msgstr "Añadida compatibilidad para PNG"

#: data/com.jeffser.Alpaca.metainfo.xml.in:918
msgid "New Update"
msgstr "Nueva Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:920
msgid "Updated model list"
msgstr "Lista de modelos actualizada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:921
msgid "Added image recognition to more models"
msgstr "Añadido reconocimiento de imagenes a más modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:922
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr "Añadida tradución a Portugues Brasileño (Gracias Daimaar Stein)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:923
msgid "Refined the general UI (Thanks Nokse22)"
msgstr "Mejor UI en general (Gracias Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "Added 'delete message' feature"
msgstr "Añadida función 'eliminar mensaje'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:925
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""
"Añadida metadata para que distribuidores de software puedan saber que la "
"aplicación es compatible con celulares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""
"Cambiado el atajo para enviar mensaje a solo la tecla enter (para hacer "
"salto de linea usa shift+enter)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:933
msgid "Bug Fixes"
msgstr "Arreglo de errores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:935
msgid "Fixed: Minor spelling mistake"
msgstr "Arregalada falta de ortografía"

#: data/com.jeffser.Alpaca.metainfo.xml.in:936
msgid "Added 'mobile' as a supported form factor"
msgstr "Añadido soporte para celulares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:937
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr "Arreglado: Dialogo 'Error de conexión' no funcionando correctamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:938
msgid "Fixed: App might freeze randomly on startup"
msgstr "Arreglado: Aplicación se congela al azar cuando inicia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:939
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr "Cambiado label 'chats' en la barra lateral por 'Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:946
msgid "Cool Update"
msgstr "Actualización Potente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:948
msgid "Better design for chat window"
msgstr "Mejor diseño para la ventana de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:949
msgid "Better design for chat sidebar"
msgstr "Mejor interfaz para la barra lateral de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Fixed remote connections"
msgstr "Conexión remota arreglada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:951
msgid "Fixed Ollama restarting in loop"
msgstr "Arreglado, Ollama reiniciandose en bucle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "Other cool backend stuff"
msgstr "Otras cosas geniales en el backend"

#: data/com.jeffser.Alpaca.metainfo.xml.in:961
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr "Añadido Ollama como parte de Alpaca, Ollama se ejecutara en un sandbox"

#: data/com.jeffser.Alpaca.metainfo.xml.in:962
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""
"Añadida la opcion de conectarse a instancias remotas (como funcionaba) antes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:963
msgid "Added option to import and export chats"
msgstr "Añadida la opcion de importar y exportar chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:964
msgid "Added option to run Alpaca with Ollama in the background"
msgstr "Añadida la opcion de ejecutar Alpaca y Ollama en el fondo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:965
msgid "Added preferences dialog"
msgstr "Añadido dialogo de preferencias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:966
msgid "Changed the welcome dialog"
msgstr "Nuevo dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:968
#: data/com.jeffser.Alpaca.metainfo.xml.in:985
#: data/com.jeffser.Alpaca.metainfo.xml.in:997
#: data/com.jeffser.Alpaca.metainfo.xml.in:1016
#: data/com.jeffser.Alpaca.metainfo.xml.in:1037
#: data/com.jeffser.Alpaca.metainfo.xml.in:1053
#: data/com.jeffser.Alpaca.metainfo.xml.in:1069
#: data/com.jeffser.Alpaca.metainfo.xml.in:1083
#: data/com.jeffser.Alpaca.metainfo.xml.in:1093
#: data/com.jeffser.Alpaca.metainfo.xml.in:1111
#: data/com.jeffser.Alpaca.metainfo.xml.in:1133
msgid "Please report any errors to the issues page, thank you."
msgstr "Por favor reporta cualquier error a la página de problemas, gracias."

#: data/com.jeffser.Alpaca.metainfo.xml.in:976
msgid "Yet Another Daily Update"
msgstr "Otra Actulización Diaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:978
msgid "Added better UI for 'Manage Models' dialog"
msgstr "Añadida mejor interfaz para el dialogo 'gestión de modelos'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:979
msgid "Added better UI for the chat sidebar"
msgstr "Añadida mejor interfaz para la barra lateral de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:980
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""
"Remplazada la descripción de modelo por un botón para abrir la página web de "
"Ollama para el modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:981
msgid "Added myself to the credits as the spanish translator"
msgstr "Agregue mi nombre en los creditos como el traductor a Español"

#: data/com.jeffser.Alpaca.metainfo.xml.in:982
msgid "Using XDG properly to get config folder"
msgstr "Usando XDG apropiadamente para obtener el folder de configuración"

#: data/com.jeffser.Alpaca.metainfo.xml.in:983
msgid "Update for translations"
msgstr "Actualización para traducciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:995
msgid "The last update had some mistakes in the description of the update"
msgstr ""
"La última actualización tenía unos errores en la descripción de la "
"actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1005
msgid "Another Daily Update"
msgstr "Otra Actulización Diaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1007
msgid "Added full Spanish translation"
msgstr "Añadida traducción completa a Español"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1008
msgid "Added support for background pulling of multiple models"
msgstr "Añadido soporte para descargar multiples modelos en el fondo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1009
msgid "Added interrupt button"
msgstr "Añadido botón de interrupción"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1010
msgid "Added basic shortcuts"
msgstr "Añadidos atajos de teclado basicos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1011
msgid "Better translation support"
msgstr "Mejor soporte para traducciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1012
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""
"El usuario ahora puede dejar el nombre del chat vacio durante la creación, "
"la aplicación añadira un placeholder"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1013
msgid "Better scalling for different window sizes"
msgstr "Mejor escalado para distintos tamaños de ventana"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1014
msgid "Fixed: Can't close app if first time setup fails"
msgstr "Arreglado: No se puede cerrar la aplicación en el primer setup"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "Really Big Update"
msgstr "Actualización Bastante Grande"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1026
msgid "Added multiple chats support!"
msgstr "Añadido soporte para multiples chats!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1027
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""
"Añadido soporte para Pango Markup (negrita, lista, titulo, subtitulo, "
"monoespaciado)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1028
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""
"Añadido autoscroll si el usuario se encuentra en la parte inferior del chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1029
msgid "Added support for multiple tags on a single model"
msgstr "Añadido soporte para multiples etiquetas con un solo modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1030
msgid "Added better model management dialog"
msgstr "Añadido mejor gestión de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1031
msgid "Added loading spinner when sending message"
msgstr "Añadido spinner de carga cuando se envia un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1032
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""
"Añadidas notificaciones si la aplicación no está activa y la descarga de un "
"modelo finaliza"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1033
msgid "Added new symbolic icon"
msgstr "Añadido nuevo icono simbolico"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1034
msgid "Added frame to message textview widget"
msgstr "Añadido borde al objeto textview del mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1035
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr "Arreglado \"bloques de codigo no deberían de ser editables\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1047
msgid "Added code highlighting"
msgstr "Añadido resaltado de código"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1048
msgid "Added image recognition (llava model)"
msgstr "Añadido reconocimiento de imagenes (modelo llava)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1049
msgid "Added multiline prompt"
msgstr "Añadido caja de texto de multiples lineas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1050
msgid "Fixed some small bugs"
msgstr "Arreglados unos pequeños errores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1051
msgid "General optimization"
msgstr "Optimización general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1061
msgid "Fixes and features"
msgstr "Arreglos y funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1063
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr "Traducción a Ruso (gracias github/alexkdeveloper)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1064
msgid "Fixed: Cannot close app on first setup"
msgstr "Arreglado: No se puede cerrar la aplicación en el primer setup"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1065
msgid "Fixed: Brand colors for Flathub"
msgstr "Arreglado: Colores de marca para Flathub"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1066
msgid "Fixed: App description"
msgstr "Arreglado: Descripción de aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1067
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""
"Arreglado: Solo mostrar el dialogo 'guardar cambios' cuando se cambia el url"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1077
msgid "0.2.2 Bug fixes"
msgstr "0.2.2 Arreglo de errores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1079
msgid "Toast messages appearing behind dialogs"
msgstr "Mensajes toast apareciendo detrás de dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1080
msgid "Local model list not updating when changing servers"
msgstr ""
"Lista de modelos locales no es actualizada cuando se cambia el servidor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1081
msgid "Closing the setup dialog closes the whole app"
msgstr "Cerrar el dialogo de setup cierra toda la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1091
msgid "0.2.1 Data saving fix"
msgstr "0.2.1 Arreglo en el guardado de datos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1092
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""
"La aplicación no guardaba los archivos de configuración o los chats en el "
"directorio correcto, esto ahora ha sido arreglado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1101
msgid "0.2.0"
msgstr "0.2.0"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1103
msgid "New Features"
msgstr "Nuevas funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1105
msgid "Restore chat after closing the app"
msgstr "Restaurar chat despues de cerrar la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1106
msgid "A button to clear the chat"
msgstr "Un botón para limpiar el chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1107
msgid "Fixed multiple bugs involving how messages are shown"
msgstr "Arreglados multiples errores acerca de como los mensajes son mostrados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1108
msgid "Added welcome dialog"
msgstr "Añadido dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1109
msgid "More stability"
msgstr "Más estabilidad"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1119
msgid "0.1.2 Quick fixes"
msgstr "0.1.2 Arreglos rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1120
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""
"Esta versión arregla metadatos necesarios para tener un aplicación de "
"Flatpak justa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1126
msgid "0.1.1 Stable Release"
msgstr "0.1.1"

#: data/com.jeffser.Alpaca.metainfo.xml.in:1127
msgid "This is the first public version of Alpaca"
msgstr "Esta es la primera versión publica de Alpaca"

#: src/main.py:193
msgid "Documentation"
msgstr "Documentación"

#: src/main.py:194
msgid "Become a Sponsor"
msgstr "Conviértete en un Patrocinador"

#: src/main.py:195
msgid "Discussions"
msgstr "Discusiones"

#: src/window.py:185
msgid "Speech recognition model is being downloaded ({})"
msgstr "Se está descargando el modelo de reconocimiento de voz ({})"

#: src/window.py:210 src/window.py:240
msgid "Speech Recognition Error"
msgstr "Error de Reconocimiento de Voz"

#: src/window.py:210
msgid "An error occurred while pulling speech recognition model"
msgstr "Se produjo un error al descargar el modelo de reconocimiento de voz"

#: src/window.py:240
msgid "An error occurred while using speech recognition"
msgstr "Se produjo un error al utilizar el reconocimiento de voz"

#: src/window.py:275
msgid "Ollama Was Not Found"
msgstr "Ollama No Fue Encontrado"

#: src/window.py:276
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""
"Para agregar una instancia de Ollama administrada, debe tener Ollama "
"instalado localmente en su dispositivo, este es un proceso simple y no "
"debería tomar más de 5 minutos."

#: src/window.py:278
msgid "Open Tutorial in Web Browser"
msgstr "Abrir Tutorial en Navegador Web"

#: src/window.py:284 src/window.py:291 src/window.ui:472 src/window.ui:482
#: src/window.ui:504
msgid "Add Instance"
msgstr "Agregar instancia"

#: src/window.py:292
msgid "Select a type of instance to add"
msgstr "Seleccione un tipo de instancia para agregar"

#: src/window.py:527
msgid "No tools enabled."
msgstr "No hay herramientas habilitadas."

#: src/window.py:527
msgid "Open Tool Manager"
msgstr "Abrir el Gestor de herramientas"

#: src/window.py:530
msgid "'{}' does not support tools."
msgstr "'{}' no admite herramientas."

#: src/window.py:530
msgid "Open Model Manager"
msgstr "Abrir Gestor de Modelos"

#: src/window.py:533 src/window.py:1122
msgid "Please select a model before chatting"
msgstr "Por favor selecciona un modelo antes de enviar un mensaje"

#: src/window.py:581 src/window.py:582 src/window.py:651 src/window.ui:288
msgid "Close"
msgstr "Cerrar"

#: src/window.py:584 src/window.py:585 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "Siguiente"

#: src/window.py:649 src/instance_manager.py:405 src/instance_manager.py:406
#: src/tool_manager.py:136 src/window.ui:968 src/window.ui:972
#: src/custom_widgets/message_widget.py:79
#: src/custom_widgets/message_widget.py:229
#: src/custom_widgets/model_manager_widget.py:422
#: src/custom_widgets/dialog_widget.py:148
#: src/custom_widgets/dialog_widget.py:160
#: src/custom_widgets/dialog_widget.py:172
msgid "Cancel"
msgstr "Cancelar"

#: src/window.py:650
msgid "Hide"
msgstr "Esconder"

#: src/window.py:654
msgid "Close Alpaca?"
msgstr "¿Cerrar Alpaca?"

#: src/window.py:655
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr "Hay una tarea en curso. ¿Estás seguro de que deseas cerrar Alpaca?"

#: src/window.py:899
msgid "Cannot open image"
msgstr "No se pudo abrir la imagen"

#: src/window.py:978
msgid "Delete Chat?"
msgstr "¿Eliminar Chat?"

#: src/window.py:979
msgid "Are you sure you want to delete '{}'?"
msgstr "¿Estás seguro de que quieres eliminar '{}'?"

#: src/window.py:981 src/window.py:1450
msgid "Delete"
msgstr "Eliminar"

#: src/window.py:988
msgid "Rename Chat?"
msgstr "¿Renombrar Chat?"

#: src/window.py:989
msgid "Renaming '{}'"
msgstr "Renombrando '{}'"

#: src/window.py:991
msgid "Chat name"
msgstr "Nombre de Chat"

#: src/window.py:992
msgid "Rename"
msgstr "Renombrar"

#: src/window.py:997
msgid "Importable (.db)"
msgstr "Importable (.db)"

#: src/window.py:998
msgid "Markdown"
msgstr "Markdown"

#: src/window.py:999
msgid "Markdown (Obsidian Style)"
msgstr "Markdown (Estilo Obsidian)"

#: src/window.py:1000
msgid "JSON"
msgstr "JSON"

#: src/window.py:1001
msgid "JSON (Include Metadata)"
msgstr "JSON (Incluir Metadata)"

#: src/window.py:1004 src/window.ui:1405 src/window.ui:1439
msgid "Export Chat"
msgstr "Exportar chat"

#: src/window.py:1005
msgid "Select a method to export the chat"
msgstr "Seleccione un método para exportar el chat"

#: src/window.py:1021
msgid "This video does not have any transcriptions"
msgstr "Este video no tiene transcripciones"

#: src/window.py:1028
msgid "Attach YouTube Video?"
msgstr "¿Adjuntar Video de YouTube?"

#: src/window.py:1029
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"Por favor selecciona la transcripción ha incluir"

#: src/window.py:1035
msgid "Error attaching video, please try again"
msgstr "Error adjuntando video, por favor intenta denuevo"

#: src/window.py:1056 src/window.py:1444
msgid "Attach Website? (Experimental)"
msgstr "¿Adjuntar Sitio Web? (Experimental)"

#: src/window.py:1057
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"¿Estás seguro de que quieres adjuntar\n"
"'{}'?"

#: src/window.py:1075 src/window.py:1087 src/window.py:1443
#: src/generic_actions.py:105
msgid "Image recognition is only available on specific models"
msgstr ""
"Reconocimiento de imagenes esta disponible solamente en modelos compatibles"

#: src/window.py:1106 src/window.ui:1189
msgid "Quick Ask"
msgstr "Pregunta Rápida"

#: src/window.py:1276
msgid "Attachment failed, screenshot might be too big"
msgstr "Adjuntado fallo, captura de pantalla puede ser muy grande"

#: src/window.py:1290
msgid "Any compatible Alpaca attachment"
msgstr "Cualquier archivo compatible con Alpaca"

#: src/window.py:1419
msgid "Attach Screenshot"
msgstr "Adjuntar Captura de Pantalla"

#: src/window.py:1444
msgid "Please enter a website URL"
msgstr "Por favor, introduzca la URL de un sitio web"

#: src/window.py:1445
msgid "Attach YouTube Captions?"
msgstr "¿Adjuntar subtítulos de YouTube?"

#: src/window.py:1445
msgid "Please enter a YouTube video URL"
msgstr "Por favor, introduzca la URL de un vídeo de YouTube"

#: src/window.py:1448
msgid "Download Model?"
msgstr "¿Descargar modelo?"

#: src/window.py:1448
msgid "Please enter the model name following this template: name:tag"
msgstr ""
"Por favor, introduzca el nombre del modelo siguiendo esta plantilla: "
"nombre:etiqueta"

#: src/window.py:1450
msgid "Delete All Chats?"
msgstr "¿Borrar Todos Los Chats?"

#: src/window.py:1450
msgid "Are you sure you want to delete all chats?"
msgstr "¿Estás seguro de que quieres eliminar todos los chats?"

#: src/window.py:1461
msgid "Remove Attachment?"
msgstr "¿Remover Adjunto?"

#: src/window.py:1461
msgid "Are you sure you want to remove attachment?"
msgstr "¿Estás seguro de que quieres remover el adjunto?"

#: src/window.py:1461 src/instance_manager.py:885
#: src/custom_widgets/model_manager_widget.py:423
#: src/custom_widgets/model_manager_widget.py:463
msgid "Remove"
msgstr "Remover"

#: src/window.py:1476
msgid "Already Installed!"
msgstr "¡Ya instalado!"

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"Nuevo modelo 70B de última generación. Llama 3.3 70B ofrece un rendimiento "
"similar al modelo Llama 3.1 405B."

#: src/available_models_descriptions.py:3
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ es el modelo de razonamiento de la serie Qwen."

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision es una colección de modelos generativos de razonamiento de "
"imágenes ajustados por instrucciones en tamaños 11B y 90B."

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Llama 3.2 de Meta es pequeño con modelos 1B y 3B."

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 es un nuevo modelo de vanguardia de Meta disponible en tamaños de "
"8B, 70B y 405B."

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: El LLM abierto más capaz a esta fecha."

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "El modelo 7B lanzado por Mistral AI, actualizado a la versión 0.3."

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Un modelo de integración abierto de alto rendimiento con una gran ventana de "
"contexto de token."

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma es una familia de nuevos modelos abiertos livianos construidos por "
"Google DeepMind. Actualizado a la versión 1.1."

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 es una serie de LLM por Alibaba Cloud que cubren parametros entre "
"0.5B hasta 110B."

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 es una nueva serie de LLM del grupo Alibaba."

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 es una familia de los ultimos modelos livianos de Microsoft, 3B (Mini) "
"y 14B (Medium)."

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 es una colección de modelos bases que cubren parametros entre 7B y "
"70B."

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Los modelos Qwen2.5 están entrenados previamente con el último conjunto de "
"datos a gran escala de Alibaba, que abarca hasta 18 billones de tokens. El "
"modelo admite hasta 128 000 tokens y tiene soporte multilingüe."

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 es un modelo de alto rendimiento y eficiente disponible en "
"tres tamaños: 2B, 9B y 27B."

#: src/available_models_descriptions.py:17
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA es un nuevo LLM entrenado en end-to-end que combina un "
"encodificador visual y Vicuna para entendimiento general en lenguaje y "
"visión. Acutalizado a la versión 1.6."

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr "Un LLM que puede usar texto para generar y discutir sobre codigo."

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"La última serie de modelos Qwen específicos de código, con mejoras "
"significativas en la generación de código, el razonamiento de código y la "
"corrección de código."

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Un modelo de vanguardia de 12B con una longitud de contexto de 128k, "
"construido por Mistral AI en colaboración con NVIDIA."

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"El proyecto TinyLlama es un esfuerzo abierto para entrenar un modelo "
"compacto de Llama de 1.1B en 3 billones de tokens."

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "Modelo de integración grande de última generación de Mixedbread.ai"

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 es la próxima generación de modelos de lenguaje abiertos "
"entrenados de manera transparente, que vienen en tres tamaños: 3B, 7B y 15B "
"parámetros."

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Un set de modelos Mixture-of-Experts (MoE) con pesos abiertos por Mistral AI "
"dispnible en tamaños de parametros 8x7b y 8x22b."

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Descensurado, 8x7b y 8x22b, modelos afinados basados enn una mezcla de "
"modelos expertos de Mixtral especializados en tareas de codigo. Creado por "
"Eric Hartford."

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma es una colección de poderosos, modelos livianos que pueden hacer "
"una variedad de tareas de codigo como fill-in-the-middle completación de "
"codigo, generación de codigo, comprensión de lenguaje natural, razonamiento "
"matematico y seguimiento de instrucciones."

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Un modelo de lenguaje Mixturer-of-Experts abierto que consigue un "
"rendimiento comparable a GPT4-Turbo en tareas especificas a codigo."

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: un modelo de lenguaje de 2.700 millones de Microsoft Research que "
"demuestra excelentes capacidades de razonamiento y comprensión del lenguaje."

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Modelo Llama 2 descensurado por George Sung y Jarrad Hope."

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder en un modelo especializado en codigo, entrenado en 2 "
"trillones de tokens de codigo y lenguaje natural."

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Un conjunto de modelos de incrustación de texto por Snowflake, optimizados "
"para el rendimiento."

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Modelo de lenguaje grande de vanguardia de Microsoft AI con rendimiento "
"mejorado en chat complejo, multilingüe, razonamiento y casos de uso de "
"agentes."

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"El modelo descensurado Dolphin, basado en Mistral que sobresale en tareas de "
"codigo. Actualizado a la versión 2.8."

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 es un modelo nuevo con tamaños de 8B y 70B hecho por Eric "
"Hartford basado en Llama 3, tiene una variedad de instrucciones "
"conversacionales y habilidades en código"

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 es un modelo de lenguaje bilingüe de alto rendimiento."

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R es un LLM optimizado para interacciones conversacionales y tareas "
"que requieren un contexto largo."

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Un modelo de uso general oscilando entre 3 billones hasta 70 billones de "
"parametros, adecuado para hardware básico."

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Un modelo LLaVA ajustado a partir de Llama 3 Instruct con mejores "
"puntuaciones en varios benchmarks."

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr es una serie de versiones ajustadas de los modelos Mistral y Mixtral "
"que están entrenados para actuar como asistentes útiles."

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Un modelo de IA liviano con 3.8 mil millones de parámetros con un "
"rendimiento que supera a modelos similares y de mayor tamaño."

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Modelos de incrustación en conjuntos de datos de nivel de oración muy "
"grandes."

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral es el primer modelo de código de Mistral AI diseñado para tareas "
"de generación de código."

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder es un modelo de generación de código entrenado en más de 80 "
"lenguajes de programación."

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Modelo de chat de uso general basado en Llama y Llama 2 con tamaños de "
"contexto de 2K a 16K."

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr ""
"Una familia de modelos de base abiertos por IBM para Code Intelligence."

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca es un modelo de 7 billones de parametros, afinado con base "
"en el modelo Mistral 7B usando el dataset de OpenOrca."

#: src/available_models_descriptions.py:47
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 Una familia de modelos pequeños con 135M, 360M y 1.7B de parámetros, "
"entrenados en un nuevo conjunto de datos de alta calidad."

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored es un modelo de 7B, 13B y 30B parámetros basado en "
"Llama 2 sin censura por Eric Hartford."

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Modelo basado en Llama 2 ajustado para mejorar la capacidad de diálogo en "
"chino."

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 es un nuevo modelo de BAAI que se distingue por su versatilidad en "
"multifuncionalidad, multilingüismo y multigranularidad."

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Un modelo versátil para escenarios de desarrollo de software de IA, "
"incluyendo la finalización de código."

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Una familia de modelos de código abierto entrenados en una amplia variedad "
"de datos, superando a ChatGPT en varios benchmarks. Actualizado a la versión "
"3.5-0106."

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, lanzado por Cohere, es una familia de los ultimos modelos "
"multilingües que soportan 23 lenguajes."

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 es un modelo de lenguaje grande preentrenado con una gran "
"cantidad de datos de código."

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"La poderosa familia de modelos de Nous Research que sobresale en discusiones "
"científicas y tareas de programación."

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ es un poderoso, escalable LLM construido con el proposito de "
"sobresalir en usos profesionales del mundo real."

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "Modelo de generación de código de vanguardia."

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B es un modelo de codificación con variantes de instrucción y "
"completado de código a la par con modelos como Code Llama 7B que son 2.5 "
"veces más grandes."

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Un modelo experimental de 1.1B parámetros entrenado en el nuevo conjunto de "
"datos Dolphin 2.8 por Eric Hartford y basado en TinyLlama."

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 es un modelo de 7B ajustado por Teknium en Mistral con "
"conjuntos de datos completamente abiertos."

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 es el nuevo modelo insignia de Mistral que es "
"significativamente más capaz en generación de código, matemáticas y "
"razonamiento, con una ventana de contexto de 128k y soporte para docenas de "
"idiomas."

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math es una serie de modelos de lenguaje matemático especializados "
"creados sobre la base de los LLM de Qwen2, que superan significativamente "
"las capacidades matemáticas de los modelos de código abierto e incluso de "
"los modelos de código cerrado (por ejemplo, GPT4o)."

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Un modelo de lenguaje general multilingüe con un rendimiento competitivo con "
"respecto a Llama 3."

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 es un modelo de lenguaje de vanguardia de 1.6B y 12B parámetros "
"entrenado en datos multilingües en inglés, español, alemán, italiano, "
"francés, portugués y neerlandés."

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA es un modelo multimodal que consiste en el modelo base Mistral 7B "
"aumentado con la arquitectura LLaVA."

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Un modelo de alto rendimiento entrenado con una nueva técnica llamada "
"Reflection-tuning que enseña a un LLM a detectar errores en su razonamiento "
"y corregir el rumbo."

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Un modelo de lenguaje avanzado creado con 2 billones de tokens bilingües."

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Este modelo extiende la longitud del contexto de LLama-3 8B de 8k a más de "
"1m tokens."

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "Modelo enfocado en problemas de matemáticas y lógica."

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 es un pequeño modelo de lenguaje de visión diseñado para "
"funcionar eficientemente en dispositivos periféricos."

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Un modelo ajustado basado en Mistral con buena cobertura de dominio y "
"lenguaje."

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Un modelo de NVIDIA basado en Llama 3 que sobresale en respuesta a preguntas "
"conversacionales (QA) y generación aumentada por recuperación (RAG)."

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Modelo conversacional basado en Llama 2 que tiene un rendimiento competitivo "
"en varios benchmarks."

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder es un modelo de completado de código ajustado en StarCoder para "
"tareas de generación de SQL."

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Modelos de uso general basados en Llama y Llama 2 de Nous Research."

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "Modelo de generación de código basado en Code Llama."

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Una extensión de Llama 2 que soporta un contexto de hasta 128k tokens."

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Una variante sin censura de 7B y 15B de la familia de modelos Dolphin que "
"sobresale en codificación, basada en StarCoder2."

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "Modelo de uso general basado en Llama 2."

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Un modelo de lenguaje Mixture-of-Experts fuerte, económico y eficiente."

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling es un modelo de lenguaje grande entrenado mediante aprendizaje por "
"refuerzo a partir de retroalimentación de IA enfocado en mejorar la utilidad "
"de los chatbots."

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Un asistente compañero entrenado en filosofía, psicología y relaciones "
"personales. Basado en Mistral."

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 es la última versión de la serie insignia de LLM Hermes de Nous "
"Research"

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder es una serie de modelos de lenguaje de código de código abierto que "
"ofrece un rendimiento de codificación de última generación con menos de 10 "
"mil millones de parámetros."

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Un modelo de lenguaje grande creado por el Instituto de Innovación "
"Tecnológica (TII) para su uso en resúmenes, generación de texto y chat bots."

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 es un modelo de 7B parámetros adaptado para escenarios prácticos "
"con una capacidad de razonamiento excepcional."

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Un modelo de lenguaje grande compacto pero poderoso de 10.7B diseñado para "
"conversación de un solo turno."

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 es un modelo de parámetros 72B que se destaca en tareas de "
"finalización de código, matemáticas y extracción de registros."

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Un nuevo pequeño modelo LLaVA ajustado a partir de Phi 3 Mini."

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 es construido por Microsoft Research, y es una versión ajustada de "
"los modelos Llama 2 de Meta. El modelo está diseñado para sobresalir "
"particularmente en razonamiento."

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Una serie de LLM multimodales (MLLM) diseñados para la comprensión entre "
"visión y lenguaje."

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Modelo basado en Llama 2 ajustado en un conjunto de datos estilo Orca. "
"Originalmente llamado Free Willy."

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr ""
"Mistral Small 3 establece un nuevo punto de referencia en la categoría de "
"modelos de lenguaje grandes “pequeños” por debajo de 70B."

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Modelo Dolphin sin censura de 2.7B por Eric Hartford, basado en el modelo de "
"lenguaje Phi por Microsoft Research."

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 es una familia de modelos de lenguaje compactos disponibles en tres "
"tamaños: 135M, 360M y 1.7B de parámetros."

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "Versión sin censura del modelo Wizard LM."

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Un modelo de lenguaje pequeño comercialmente amigable de NVIDIA optimizado "
"para juegos de roles, control de calidad de RAG y llamada de funciones."

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Una extensión de Mistral para soportar ventanas de contexto de 64K o 128K."

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Una expansión de Llama 2 que se especializa en integrar tanto la comprensión "
"general del lenguaje como el conocimiento específico del dominio, "
"particularmente en programación y matemáticas."

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Modelo Llama 2 ajustado para responder preguntas médicas basado en un "
"conjunto de datos médicos de código abierto."

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Modelo de lenguaje grande médico de código abierto adaptado de Llama 2 al "
"dominio médico."

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Una serie de modelos de Groq que representan un avance significativo en las "
"capacidades de IA de código abierto para el uso de herramientas/llamadas a "
"funciones."

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct es un modelo de lenguaje grande "
"personalizado por NVIDIA para mejorar la utilidad de las respuestas "
"generadas por LLM a las consultas de los usuarios."

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven es un modelo ajustado de 13B para tareas de llamada de funciones."

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"El modelo Nous Hermes 2 de Nous Research, ahora entrenado sobre Mixtral."

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "Gran modelo de generación de código basado en Llama2."

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Modelo sin censura basado en Llama2 con soporte para una ventana de contexto "
"de 16K."

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Los modelos IBM Granite 2B y 8B están diseñados para soportar casos de uso "
"basados ​​en herramientas y soporte para generación aumentada de recuperación "
"(RAG), agilizando la generación de código, la traducción y la corrección de "
"errores."

#: src/available_models_descriptions.py:109
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder es una familia de modelos de 7B parámetros entrenados en 75K "
"datos de instrucción sintética utilizando OSS-Instruct, un enfoque novedoso "
"para iluminar a los LLMs con fragmentos de código de código abierto."

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Un modelo de chat ligero que permite una salida precisa y receptiva sin "
"requerir hardware de alta gama."

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Un modelo de instrucción de código de alto rendimiento creado mediante la "
"fusión de dos modelos de código existentes."

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 es un modelo causal de 11B parámetros solo decodificador construido "
"por TII y entrenado en más de 5T tokens."

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna es un modelo de 13B parámetros basado en Llama 2 entrenado por "
"MelodysDreamj."

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite es un modelo ajustado basado en Mistral con capacidades "
"mejoradas de procesamiento de contextos largos."

#: src/available_models_descriptions.py:115
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: un modelo de 7B diseñado para razonamiento matemático y "
"descubrimiento científico por Mistral AI."

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Modelo de texto a SQL de 7B parámetros hecho por MotherDuck y Numbers "
"Station."

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b es una transformación de Dolphin-2.2-70b creada al "
"entrelazar el modelo consigo mismo."

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Vista previa de Solar Pro: un modelo de lenguaje grande (LLM) avanzado con "
"22 mil millones de parámetros diseñado para caber en una sola GPU"

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Una serie de modelos que convierten contenido HTML en contenido Markdown, lo "
"cual resulta útil para tareas de conversión de contenido."

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Un modelo de mezcla de expertos de alto rendimiento, ajustado con datos de "
"alta calidad."

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Un modelo de chat de 7B ajustado con datos de alta calidad y basado en "
"Zephyr."

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Fusión del modelo Open Orca OpenChat y el modelo Garage-bAInd Platypus 2. "
"Diseñado para chat y generación de código."

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Un modelo de lenguaje creado combinando dos modelos ajustados de Llama 2 70B "
"en uno."

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Los modelos IBM Granite 1B y 3B son la primera mezcla de modelos Granite de "
"expertos (MoE) de IBM diseñados para un uso de baja latencia."

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Un modelo de 3.8B ajustado con un conjunto de datos sintéticos de alta "
"calidad para extracción de información, basado en Phi-3."

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Cohere Para modelos de lenguaje de IA entrenados para funcionar bien en 23 "
"idiomas diferentes."

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX es un LLM abierto de propósito general creado por Databricks."

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Un modelo de razonamiento abierto a gran escala para soluciones del mundo "
"real del Alibaba International Digital Commerce Group (AIDC-AI)."

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Modelo de incrustación de BAAI que mapea textos a vectores."

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Un modelo de llamadas a funciones con pesos abiertos basado en Llama 3, "
"competitivo con las capacidades de llamadas a funciones de GPT-4o."

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Un modelo conversacional robusto diseñado para ser utilizado tanto en casos "
"de uso de chat como de instrucción."

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Una versión mejorada de DeepSeek-V2 que integra las capacidades generales y "
"de codificación de DeepSeek-V2-Chat y DeepSeek-Coder-V2-Instruct."

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma es un conjunto de modelos de instrucciones optimizados para "
"evaluar la seguridad de las respuestas de entrada y salida de texto frente a "
"un conjunto de políticas de seguridad definidas."

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Un modelo de verificación de datos de última generación desarrollado por "
"Bespoke Labs."

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 es una serie de modelos optimizados para la clasificación de "
"seguridad de contenido de entradas y respuestas LLM."

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Modelo de transformadores de oraciones que puede utilizarse para tareas como "
"agrupamiento o búsqueda semántica."

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder es una familia LLM de código abierto y reproducible que incluye "
"modelos 1.5B y 8B y admite chat en los idiomas inglés y chino."

#: src/available_models_descriptions.py:138
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 es una familia de modelos de seguimiento de instrucciones líder que "
"ofrece datos, códigos y recetas de código totalmente abierto del Instituto "
"Allen para IA."

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Modelo de integración de vanguardia de Snowflake. Arctic Embed 2.0 agrega "
"compatibilidad multilingüe sin sacrificar el rendimiento ni la escalabilidad "
"en inglés."

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Los modelos IBM Granite Guardian 3.0 2B y 8B están diseñados para detectar "
"riesgos en indicaciones y/o respuestas."

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 es una colección de modelos generativos bilingües (inglés y "
"coreano) optimizados para instrucciones que van desde 2.4B a 32B parámetros, "
"desarrollados y lanzados por LG AI Research."

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 son modelos de lenguaje multilingües diseñados para el sudeste "
"asiático. Disponibles en tamaños de parámetros 1B, 8B y 20B."

#: src/available_models_descriptions.py:143
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Una familia de modelos de IA eficientes con un rendimiento de 10B de "
"parámetros en ciencias, matemáticas y codificación a través de técnicas de "
"entrenamiento innovadoras."

#: src/available_models_descriptions.py:144
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."

#: src/available_models_descriptions.py:145
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Los modelos IBM Granite 1B y 3B son modelos Granite de mezcla de contexto "
"largo de expertos (MoE) de IBM diseñados para un uso de baja latencia."

#: src/available_models_descriptions.py:146
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"Los modelos IBM Granite Embedding 30M y 278M son modelos de incrustación de "
"biencoder densos de solo texto, con 30M disponible solo en inglés y 278M "
"para casos de uso multilingües."

#: src/available_models_descriptions.py:147
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4 es un modelo abierto de última generación con 14B parámetros de "
"Microsoft."

#: src/available_models_descriptions.py:148
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Un nuevo modelo de razonamiento pequeño perfeccionado a partir del modelo "
"Instruct 3B de Qwen 2.5."

#: src/available_models_descriptions.py:149
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 es la próxima generación de la serie Dolphin de "
"modelos optimizados por instrucciones, diseñados para ser el mejor modelo "
"local de propósito general, que permite codificación, matemáticas, agentes, "
"llamadas de funciones y casos de uso general."

#: src/available_models_descriptions.py:150
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"Primera generación de modelos de razonamiento de DeepSeek con un rendimiento "
"comparable a OpenAI-o1, incluidos seis modelos densos extraídos de DeepSeek-"
"R1 basados ​​en Llama y Qwen."

#: src/available_models_descriptions.py:151
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Un sólido modelo de lenguaje de mezcla de expertos (MoE) con 671B de "
"parámetros totales con 37B activados para cada token."

#: src/available_models_descriptions.py:152
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 es una nueva familia de modelos 7B y 13B entrenados con tokens de "
"hasta 5T. Estos modelos están a la par o son mejores que los modelos "
"completamente abiertos de tamaño equivalente y son competitivos con modelos "
"de peso abierto como Llama 3.1 en los puntos de referencia académicos de "
"inglés."

#: src/available_models_descriptions.py:153
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"El modelo más pequeño de la serie R de Cohere ofrece velocidad, eficiencia y "
"calidad de primer nivel para crear potentes aplicaciones de IA en GPU "
"comerciales y dispositivos de edge."

#: src/available_models_descriptions.py:154
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"Una familia de modelos de razonamiento de código completamente abierto "
"creada utilizando un conjunto de datos derivado de la destilación de "
"DeepSeek-R1."

#: src/available_models_descriptions.py:155
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"Una versión optimizada de Deepseek-R1-Distilled-Qwen-1.5B que supera el "
"rendimiento de o1-preview de OpenAI con solo 1.500 millones de parámetros en "
"evaluaciones matemáticas populares."

#: src/available_models_descriptions.py:156
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"Una versión del modelo DeepSeek-R1 que ha sido entrenado posteriormente para "
"proporcionar información imparcial, precisa y objetiva de Perplexity."

#: src/available_models_descriptions.py:157
msgid "The current, most capable model that runs on a single GPU."
msgstr "El modelo actual más capaz que funciona con una sola GPU."

#: src/available_models_descriptions.py:158
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini aporta mejoras significativas en soporte multilingüe, "
"razonamiento y matemáticas, y ahora, la tan esperada función de llamada de "
"funciones finalmente es compatible."

#: src/available_models_descriptions.py:159
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"Un modelo de lenguaje de visión compacto y eficiente, diseñado "
"específicamente para la comprensión visual de documentos, que permite la "
"extracción automatizada de contenido de tablas, gráficos, infografías, "
"gráficos, diagramas y más."

#: src/available_models_descriptions.py:160
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 es una familia de modelos de IA de contexto largo de IBM Granite "
"optimizados para capacidades de pensamiento."

#: src/available_models_descriptions.py:161
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"Una nueva versión de última generación del modelo liviano Command R7B que se "
"destaca por sus capacidades avanzadas en idioma árabe para empresas en Medio "
"Oriente y el norte de África."

#: src/available_models_descriptions.py:162
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr ""
"Modelo de 111 mil millones de parámetros optimizado para empresas exigentes "
"que requieren IA rápida, segura y de alta calidad"

#: src/available_models_descriptions.py:163
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"EXAONE Deep exhibe capacidades superiores en varias tareas de razonamiento, "
"incluidos puntos de referencia de matemáticas y codificación, que van desde "
"2.4B a 32B de parámetros desarrollados y publicados por LG AI Research."

#: src/available_models_descriptions.py:164
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"Basado en Mistral Small 3, Mistral Small 3.1 (2503) agrega comprensión de "
"visión de última generación y mejora las capacidades de contexto largo hasta "
"128k tokens sin comprometer el rendimiento del texto."

#: src/available_models_descriptions.py:165
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"Cogito v1 Preview es una familia de modelos de razonamiento híbrido de Deep "
"Cogito que superan a los mejores modelos abiertos disponibles del mismo "
"tamaño, incluidos sus homólogos de LLaMA, DeepSeek y Qwen en la mayoría de "
"los puntos de referencia estándar."

#: src/available_models_descriptions.py:166
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"DeepCoder es un modelo codificador 14B de código abierto a nivel O3-mini, "
"con una versión 1.5B también disponible."

#: src/instance_manager.py:30 src/instance_manager.py:366
msgid "Instance"
msgstr "Instancia"

#: src/instance_manager.py:60 src/instance_manager.py:69 src/window.ui:154
#: src/custom_widgets/chat_widget.py:423
msgid "New Chat"
msgstr "Nuevo Chat"

#: src/instance_manager.py:76
msgid "Selecting tool to use..."
msgstr "Seleccionando la herramienta a utilizar..."

#: src/instance_manager.py:85
msgid "Using {}"
msgstr "Usando {}"

#: src/instance_manager.py:111
msgid "Tool Error"
msgstr "Error de Herramienta"

#: src/instance_manager.py:111
msgid "An error occurred while running tool"
msgstr "Se produjo un error al ejecutar la herramienta"

#: src/instance_manager.py:114
msgid "Generating message..."
msgstr "Generando mensaje..."

#: src/instance_manager.py:162 src/instance_manager.py:462
#: src/instance_manager.py:472 src/instance_manager.py:616
#: src/instance_manager.py:688 src/instance_manager.py:730
#: src/instance_manager.py:759 src/instance_manager.py:802
#: src/instance_manager.py:822 src/instance_manager.py:843
msgid "Instance Error"
msgstr "Error de Instancia"

#: src/instance_manager.py:162
msgid "Message generation failed"
msgstr "Error en la generación del mensaje"

#: src/instance_manager.py:218 src/window.ui:885
msgid "Name"
msgstr "Nombre"

#: src/instance_manager.py:226
msgid "Port"
msgstr "Puerto"

#: src/instance_manager.py:227
msgid "Which network port will '{}' use"
msgstr "Qué puerto de red utilizará '{}'"

#: src/instance_manager.py:241
msgid "Instance URL"
msgstr "URL de instancia"

#: src/instance_manager.py:244 src/instance_manager.py:254
#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key (Unchanged)"
msgstr "Clave API (Sin Cambios)"

#: src/instance_manager.py:244 src/instance_manager.py:254
msgid "API Key (Optional)"
msgstr "Clave API (Opcional)"

#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key"
msgstr "Clave API"

#: src/instance_manager.py:267
msgid "Max Tokens"
msgstr "Tokens Maximos"

#: src/instance_manager.py:268
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"Define la cantidad máxima de tokens (palabras + espacios) que la IA puede "
"generar en una respuesta. Más tokens permiten respuestas más largas, pero "
"pueden llevar más tiempo y costar más."

#: src/instance_manager.py:283
msgid "Temperature"
msgstr "Temperatura"

#: src/instance_manager.py:284
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""
"Aumentar la temperatura hará que los modelos respondan de forma más creativa."

#: src/instance_manager.py:299
msgid "Seed"
msgstr "Semilla"

#: src/instance_manager.py:300
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""
"Si se establece esto en un número específico distinto de 0, el modelo "
"generará el mismo texto para el mismo mensaje."

#: src/instance_manager.py:315
msgid "Overrides"
msgstr "Overrides"

#: src/instance_manager.py:315
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""
"Estas entradas son opcionales y se utilizan para solucionar problemas "
"relacionados con la GPU con Ollama."

#: src/instance_manager.py:333
msgid "Model Directory"
msgstr "Directorio de Modelos"

#: src/instance_manager.py:335
msgid "Select Directory"
msgstr "Seleccionar Directorio"

#: src/instance_manager.py:346
msgid "Default Model"
msgstr "Modelo por Defecto"

#: src/instance_manager.py:346
msgid "Model to select when starting a new chat."
msgstr "Modelo a seleccionar al iniciar un nuevo chat."

#: src/instance_manager.py:348
msgid "Title Model"
msgstr "Modelo de Título"

#: src/instance_manager.py:348
msgid "Model to use when generating a chat title."
msgstr "Modelo a utilizar al generar un título de chat."

#: src/instance_manager.py:412 src/instance_manager.py:413
#: src/custom_widgets/message_widget.py:233
msgid "Save"
msgstr "Guardar"

#: src/instance_manager.py:462 src/instance_manager.py:688
#: src/instance_manager.py:730 src/instance_manager.py:759
msgid "Could not retrieve added models"
msgstr "No se pudieron recuperar los modelos agregados"

#: src/instance_manager.py:472
msgid "Could not retrieve available models"
msgstr "No se pudieron recuperar los modelos disponibles"

#: src/instance_manager.py:539
msgid "Ollama (Managed)"
msgstr "Ollama (Administrado)"

#: src/instance_manager.py:547
msgid "Local AI instance managed directly by Alpaca"
msgstr "Instancia de IA local administrada directamente por Alpaca"

#: src/instance_manager.py:570
msgid "Alpaca Support"
msgstr "Soporte de Alpaca"

#: src/instance_manager.py:577
msgid "Model request too large for system"
msgstr "Solicitud de modelo muy grande para el sistema"

#: src/instance_manager.py:580
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""
"GPU AMD detectada pero la extensión no está instalada, Ollama usará CPU."

#: src/instance_manager.py:582
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "GPU AMD detectada pero ROCm no está instalado, Ollama usará CPU."

#: src/instance_manager.py:584
msgid "Using AMD GPU type '{}'"
msgstr "Usando GPU AMD tipo '{}'"

#: src/instance_manager.py:594
msgid "Integrated Ollama instance is not running"
msgstr "Instancia integrada de Ollama no está corriendo"

#: src/instance_manager.py:616
msgid "Managed Ollama instance failed to start"
msgstr "La instancia de Ollama administrada no pudo iniciar"

#: src/instance_manager.py:619
msgid "Integrated Ollama instance is running"
msgstr "Instancia integrada de Ollama está corriendo"

#: src/instance_manager.py:624 src/instance_manager.py:625
msgid "Ollama Log"
msgstr "Registro de Ollama"

#: src/instance_manager.py:637
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "Instancia de IA local o remota no administrada por Alpaca"

#: src/instance_manager.py:802 src/instance_manager.py:822
#: src/instance_manager.py:843
msgid "Could not retrieve models"
msgstr "No se pudieron recuperar los modelos"

#: src/instance_manager.py:811
msgid "Fireworks AI inference platform"
msgstr "Plataforma de inferencia de IA de Fireworks"

#: src/instance_manager.py:831
msgid "Lambda Labs cloud inference API"
msgstr "API de inferencia en la nube de Lambda Labs"

#: src/instance_manager.py:852
msgid "Cerebras AI cloud inference API"
msgstr "API de inferencia en la nube de Cerebras AI"

#: src/instance_manager.py:858
msgid "Kluster AI cloud inference API"
msgstr "API de inferencia en la nube de Kluster AI"

#: src/instance_manager.py:862
msgid "OpenAI Compatible Instance"
msgstr "Instancia Compatible con OpenAI"

#: src/instance_manager.py:863
msgid "AI instance compatible with OpenAI library"
msgstr "Instancia de IA compatible con la biblioteca OpenAI"

#: src/instance_manager.py:885
msgid "Remove Instance?"
msgstr "¿Eliminar instancia?"

#: src/instance_manager.py:885
msgid "Are you sure you want to remove this instance?"
msgstr "¿Estás seguro de que quieres eliminar esta instancia?"

#: src/instance_manager.py:900
msgid "Edit Instance"
msgstr "Editar Instancia"

#: src/tool_manager.py:71
msgid "AI Description"
msgstr "Descripción de IA"

#: src/tool_manager.py:72
msgid "The description the AI model will use to understand what the tool does."
msgstr ""
"La descripción que utilizará el modelo de IA para comprender qué hace la "
"herramienta."

#: src/tool_manager.py:83
msgid "Arguments"
msgstr "Argumentos"

#: src/tool_manager.py:84
msgid "Variables that are filled by the AI."
msgstr "Variables que son rellenadas por la IA."

#: src/tool_manager.py:97
msgid "Variables"
msgstr "Variables"

#: src/tool_manager.py:98
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""
"Valores rellenados por el usuario que la herramienta utiliza para funcionar, "
"la IA no tiene acceso a estas variables en absoluto."

#: src/tool_manager.py:140 src/custom_widgets/dialog_widget.py:146
#: src/custom_widgets/dialog_widget.py:158
#: src/custom_widgets/dialog_widget.py:170
msgid "Accept"
msgstr "Aceptar"

#: src/tool_manager.py:177
msgid "Gets the current date and/or time."
msgstr "Obtiene la fecha y/o hora actual."

#: src/tool_manager.py:211
msgid "Gets a recipe by the meal's name"
msgstr "Obtiene una receta por el nombre de la comida."

#: src/tool_manager.py:224 src/tool_manager.py:281
msgid "YouTube Video"
msgstr "Vídeo de YouTube"

#: src/tool_manager.py:227 src/tool_manager.py:284
msgid "Source"
msgstr "Fuente"

#: src/tool_manager.py:262
msgid "Gets a list of food recipes by a specified category"
msgstr "Obtiene una lista de recetas de comida por una categoría específica"

#: src/tool_manager.py:307
msgid "Extracts an article from Wikipedia by it's title"
msgstr "Extrae un artículo de Wikipedia por su título."

#: src/tool_manager.py:349
msgid "Search for a term online using DuckDuckGo"
msgstr "Busca un término en línea usando DuckDuckGo"

#: src/tool_manager.py:365
msgid "Abstract Source"
msgstr "Fuente de Abstracto"

#: src/tool_manager.py:384
msgid "Official Website"
msgstr "Sitio Web Oficial"

#: src/tool_manager.py:432
msgid "Request to run a command using SSH to connect to the device"
msgstr ""
"Solicitud para ejecutar un comando mediante SSH para conectarse al "
"dispositivo"

#: src/tool_manager.py:435
msgid "IP Address"
msgstr "Dirección IP"

#: src/tool_manager.py:440
msgid "Username"
msgstr "Nombre de Usuario"

#: src/tool_manager.py:445
msgid "Network Port"
msgstr "Puerto de Red"

#: src/tool_manager.py:462
msgid "Model Requested to Run Command"
msgstr "Modelo Solicita Ejecutar Comando"

#: src/tool_manager.py:463
msgid "Command"
msgstr "Comando"

#: src/tool_manager.py:465
msgid "Explanation"
msgstr "Explicación"

#: src/tool_manager.py:466
msgid "No explanation was provided"
msgstr "No se proporcionó ninguna explicación"

#: src/tool_manager.py:467
msgid "Make sure you understand what the command does before running it."
msgstr "Asegúrese de comprender lo que hace el comando antes de ejecutarlo."

#: src/window.ui:34
msgid "Welcome"
msgstr "Bienvenida"

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "Anterior"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "Bienvenido a Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr "Impulsando tu potencial"

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""
"Alpaca y sus desarrolladores no son responsables de ningún daño a los "
"dispositivos o al software que resulte de la ejecución del código generado "
"por un modelo de IA. Tenga cuidado y revise el código con atención antes de "
"ejecutarlo.\n"
"\n"
"Alpaca se distribuye bajo la licencia GPL v3.0, este software no tiene "
"garantía."

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr "Ejecución de Código Sin Esfuerzo"

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""
"Alpaca puede ejecutar Python, C++ e incluso HTML (con un servidor en vivo) "
"directamente desde tus conversaciones. ¡Pruébalo!"

#: src/window.ui:107
msgid "Private by Design"
msgstr "Privado por Diseño"

#: src/window.ui:108
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""
"Con Alpaca, tus conversaciones se guardan localmente en tu dispositivo, por "
"lo que puedes estar seguro de que tus datos siempre están seguros y privados."

#: src/window.ui:114
msgid "Local AI"
msgstr "AI Local"

#: src/window.ui:115
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""
"Alpaca trabaja con proveedores de IA como Gemini y ChatGPT. Para ejecutar "
"modelos de IA localmente en tu dispositivo, necesitas instalar Ollama en "
"Alpaca. ¡Lo hemos simplificado muchísimo para que puedas empezar rápidamente!"

#: src/window.ui:120 src/window.ui:121
msgid "Install Ollama"
msgstr "Instalar Ollama"

#: src/window.ui:165
msgid "Menu"
msgstr "Menu"

#: src/window.ui:187
msgid "Toggle Sidebar"
msgstr "Alternar Barra Lateral"

#: src/window.ui:194
msgid "Search Messages"
msgstr "Buscar Mensajes"

#: src/window.ui:211 src/window.ui:236 src/window.ui:1371
msgid "Manage Models"
msgstr "Gestionar Modelos"

#: src/window.ui:232
msgid "Add Models"
msgstr "Agregar Modelos"

#: src/window.ui:249
msgid "Chat Menu"
msgstr "Menu de Chat"

#: src/window.ui:262
msgid "Message search bar"
msgstr "Barra de búsqueda de mensajes"

#: src/window.ui:271 src/window.ui:273
msgid "Search messages"
msgstr "Buscar mensajes"

#: src/window.ui:289
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""
"Advertencia: el modo de ahorro de energía está habilitado, esto ralentizará "
"la generación de mensajes."

#: src/window.ui:336 src/window.ui:1469
msgid "Attach File"
msgstr "Adjuntar Archivo"

#: src/window.ui:369 src/window.ui:1238
msgid "Use Speech Recognition"
msgstr "Usar Reconocimiento de Voz"

#: src/window.ui:404
msgid "Send Message"
msgstr "Enviar Mensaje"

#: src/window.ui:423
msgid "Stop Message"
msgstr "Detener el Mensaje"

#: src/window.ui:453
msgid "Instance Manager"
msgstr "Gestor de Instancias"

#: src/window.ui:468
msgid "No Instances Found"
msgstr "Ningún Instancia Encontrada"

#: src/window.ui:469
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr "Parece un poco vacío aquí. ¡Agrega una instancia para empezar!"

#: src/window.ui:498
msgid "Added Instances"
msgstr "Instancias Agregadas"

#: src/window.ui:499
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""
"Administra tus instancias de IA, los chats y los mensajes se comparten entre "
"instancias al generar respuestas."

#: src/window.ui:535
msgid "Tool Manager"
msgstr "Gestor de Herramientas"

#: src/window.ui:546
msgid "Available Tools"
msgstr "Herramientas Disponibles"

#: src/window.ui:547
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""
"Funciones que los modelos de IA pueden utilizar al enviar un mensaje "
"seleccionando \"Usar Herramientas\" en el menú contextual del botón de envío."

#: src/window.ui:566
msgid "Model Manager"
msgstr "Gestor de Modelos"

#: src/window.ui:604
msgid "Search Model"
msgstr "Buscar Modelo"

#: src/window.ui:618
msgid "Model Manager Menu"
msgstr "Menu del Gestor de Modelos"

#: src/window.ui:631
msgid "Model search bar"
msgstr "Barra de busqueda de modelos"

#: src/window.ui:643 src/window.ui:645
msgid "Search models"
msgstr "Buscar Modelos"

#: src/window.ui:652
msgid "Filter Models"
msgstr "Filtrar Modelos"

#: src/window.ui:668
msgid "Added"
msgstr "Agregado"

#: src/window.ui:678 src/window.ui:739 src/window.ui:793
msgid "No Models Found"
msgstr "Ningún Modelo Encontrado"

#: src/window.ui:679
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""
"Parece un poco vacío aquí. ¡Prueba a descargar algunos modelos o cambia tu "
"instancia de IA para comenzar!"

#: src/window.ui:682 src/window.ui:692 src/window.ui:1367
msgid "Manage Instances"
msgstr "Gestionar Instancias"

#: src/window.ui:740 src/window.ui:794
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"Parece que nos hemos quedado sin modelos para esa búsqueda. ¡Intenta "
"modificar tus palabras clave o explora algo nuevo!"

#: src/window.ui:752
msgid "Available"
msgstr "Disponibles"

#: src/window.ui:806
msgid "Creator"
msgstr "Creador"

#: src/window.ui:817
msgid "Model Creator"
msgstr "Creador de Modelos"

#: src/window.ui:818
msgid "Select a method of importing a model to continue"
msgstr "Seleccione un método para importar un modelo para continuar"

#: src/window.ui:830
msgid "GGUF File"
msgstr "Archivo GGUF"

#: src/window.ui:841
msgid "Existing Model"
msgstr "Modelo Existente"

#: src/window.ui:859
msgid "Identity"
msgstr "Identidad"

#: src/window.ui:862
msgid "Base"
msgstr "Base"

#: src/window.ui:869
msgid "Profile Picture"
msgstr "Foto de Perfil"

#: src/window.ui:874
msgid "Open File"
msgstr "Abrir Archivo"

#: src/window.ui:890 src/custom_widgets/model_manager_widget.py:257
msgid "Tag"
msgstr "Etiqueta"

#: src/window.ui:897 src/custom_widgets/model_manager_widget.py:274
msgid "Context"
msgstr "Contexto"

#: src/window.ui:898
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""
"Describe el comportamiento deseado del modelo en su idioma principal "
"(normalmente inglés)."

#: src/window.ui:926
msgid "Behavior"
msgstr "Comportamiento"

#: src/window.ui:929
msgid "Imagination"
msgstr "Imaginación"

#: src/window.ui:930
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr ""
"Un número mayor da como resultado respuestas más diversas del modelo. (top_k)"

#: src/window.ui:944
msgid "Focus"
msgstr "Concentración"

#: src/window.ui:945
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "Un número mayor amplía la cantidad de respuestas posibles. (top_p)"

#: src/window.ui:978 src/window.ui:986
msgid "Add Model"
msgstr "Agregar modelo"

#: src/window.ui:1020 src/window.ui:1381
msgid "Preferences"
msgstr "Preferencias"

#: src/window.ui:1028
msgid "Run Alpaca In Background"
msgstr "Ejecutar Alpaca en el fondo"

#: src/window.ui:1034
msgid "Show Power Saver Warning"
msgstr "Mostrar Advertencia de Ahorro de Energía"

#: src/window.ui:1035
msgid "When running a managed Ollama instance"
msgstr "Al ejecutar una instancia de Ollama administrada"

#: src/window.ui:1041
msgid "Zoom"
msgstr "Zoom"

#: src/window.ui:1058
msgid "Auto Send Message After Talking"
msgstr "Enviar Mensaje Automáticamente Después de Hablar"

#: src/window.ui:1064
msgid "Speech Recognition Language"
msgstr "Lenguaje de Reconocimiento de Voz"

#: src/window.ui:1074
msgid "Text to Speech Voice"
msgstr "Voz a usar en texto a voz"

#: src/window.ui:1086
msgid "Delete All Chats"
msgstr "Eliminar Todos Los Chats"

#: src/window.ui:1098
msgid "Notice"
msgstr "Aviso"

#: src/window.ui:1118
msgid ""
"Hey Alpaca users! We're so excited to bring you a fresh update packed with "
"awesome new features to explore! Get ready to experience Alpaca in a whole "
"new way!"
msgstr ""
"¡Hola, usuarios de Alpaca! ¡Nos emociona traerles una nueva actualización "
"repleta de increíbles funciones nuevas para explorar! ¡Prepárense para "
"experimentar Alpaca de una manera completamente nueva!"

#: src/window.ui:1125
msgid "Smart Tools"
msgstr "Herramientas Inteligentes"

#: src/window.ui:1126
msgid ""
"Supported AI models can use handy tools to grab information both locally and "
"online. Head over to the brand new \"Tool Manager\" to toggle them on or off."
msgstr ""
"Los modelos de IA compatibles pueden usar herramientas útiles para recopilar "
"información tanto localmente como en línea. Accede al nuevo \"Administrador "
"de Herramientas\" para activarlas o desactivarlas."

#: src/window.ui:1133
msgid "Talk to Models"
msgstr "Habla con Modelos"

#: src/window.ui:1134
msgid ""
"You can now dictate your messages using local speech recognition. It's super "
"convenient! You can even customize your language and other settings in the "
"Preferences dialog."
msgstr ""
"Ahora puedes dictar tus mensajes con reconocimiento de voz local. ¡Es súper "
"práctico! Incluso puedes personalizar el idioma y otras opciones en el "
"cuadro de diálogo Preferencias."

#: src/window.ui:1141
msgid "Find Models Faster"
msgstr "Encuentra Modelos Más Rápido"

#: src/window.ui:1142
msgid ""
"Browsing through your Ollama models just got easier! We've added the ability "
"to filter models by their categories in the Model Manager. Now you can "
"quickly find exactly the model you're looking for."
msgstr ""
"¡Explorar tus modelos de Ollama ahora es más fácil! Hemos añadido la "
"posibilidad de filtrarlos por categorías en el Administrador de Modelos. "
"Ahora puedes encontrar rápidamente el modelo que buscas."

#: src/window.ui:1149
msgid "Math Rendering"
msgstr "Renderización Matemática"

#: src/window.ui:1150
msgid ""
"We've improved how LaTeX equations are rendered in messages, making them "
"look cleaner and more consistent. Your mathematical discussions will be "
"clearer than ever!"
msgstr ""
"Hemos mejorado la representación de las ecuaciones LaTeX en los mensajes, "
"haciéndolos más claros y consistentes. ¡Tus discusiones matemáticas serán "
"más claras que nunca!"

#: src/window.ui:1157
msgid "More Instances"
msgstr "Más Instancias"

#: src/window.ui:1158
msgid ""
"Get ready to connect Alpaca to a whole universe of AI providers! We've added "
"support for over 5 new AI instance providers, including Anthropic, "
"OpenRouter, and Fireworks. The possibilities are endless!"
msgstr ""
"¡Prepárate para conectar Alpaca con un universo completo de proveedores de "
"IA! Hemos añadido compatibilidad con más de 5 nuevos proveedores de "
"instancias de IA, como Anthropic, OpenRouter y Fireworks. ¡Las posibilidades "
"son infinitas!"

#: src/window.ui:1165
msgid "Attachment Enhancement"
msgstr "Mejora de Archivos Adjuntos"

#: src/window.ui:1166
msgid ""
"You can now attach and ask questions about even more file types, "
"including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
"you'll see it with rich text styling, making it easier to understand the "
"content before you send it."
msgstr ""
"Ahora puedes adjuntar y hacer preguntas sobre más tipos de archivos, "
"como .docx, .pptx y .xlsx. Además, al previsualizar un archivo adjunto, lo "
"verás con texto enriquecido, lo que facilita la comprensión del contenido "
"antes de enviarlo."

#: src/window.ui:1187
msgid "Quick ask dialog"
msgstr "Dialogo de pregunta rápida"

#: src/window.ui:1199
msgid "Save Conversation to Alpaca"
msgstr "Guardar Conversación a Alpaca"

#: src/window.ui:1268
msgid "Terminal dialog"
msgstr "Diálogo de terminal"

#: src/window.ui:1271
msgid "Terminal"
msgstr "Terminal"

#: src/window.ui:1285
msgid "Open Environment Directory"
msgstr "Abrir Directorio del Ambiente"

#: src/window.ui:1306
msgid "File preview dialog"
msgstr "Dialogo de vista previa de archivos"

#: src/window.ui:1317
msgid "Open With Default App"
msgstr "Abrir con aplicación predeterminada"

#: src/window.ui:1325
msgid "Remove Attachment"
msgstr "Remover Adjunto"

#: src/window.ui:1359
msgid "Start Quick Ask"
msgstr "Iniciar Pregunta Rápida"

#: src/window.ui:1363
msgid "Import Chat"
msgstr "Importar chat"

#: src/window.ui:1375
msgid "Manage Tools"
msgstr "Gestionar Herramientas"

#: src/window.ui:1385
msgid "Keyboard Shortcuts"
msgstr "Atajos de Teclado"

#: src/window.ui:1389
msgid "About Alpaca"
msgstr "Sobre Alpaca"

#: src/window.ui:1397 src/window.ui:1431
msgid "Rename Chat"
msgstr "Renombrar Chat"

#: src/window.ui:1401 src/window.ui:1435
msgid "Duplicate Chat"
msgstr "Duplicar Chat"

#: src/window.ui:1411 src/window.ui:1445
msgid "Delete Chat"
msgstr "Eliminar Chat"

#: src/window.ui:1419
msgid "Reload Added Models"
msgstr "Recargar Modelos Agregados"

#: src/window.ui:1423
msgid "Download Model From Name"
msgstr "Descargar Modelo Usando Nombre"

#: src/window.ui:1453
msgid "Send as User"
msgstr "Enviar Como Usuario"

#: src/window.ui:1457
msgid "Send as System"
msgstr "Enviar Como Sistema"

#: src/window.ui:1461 src/gtk/help-overlay.ui:133
msgid "Use Tools"
msgstr "Usar Herramientas"

#: src/window.ui:1473
msgid "Attach Website"
msgstr "Adjuntar Sitio Web"

#: src/window.ui:1477
msgid "Attach YouTube Captions"
msgstr "Adjuntar Subtitulos de YouTube"

#: src/alpaca_search_provider.py.in:43
msgid "Open chat"
msgstr "Abrir chat"

#: src/alpaca_search_provider.py.in:44
msgid "Quick ask"
msgstr "Pregunta rápida"

#: src/generic_actions.py:79
msgid "An error occurred while extracting text from the website"
msgstr "Ha ocurrido un error mientras se extraía texto del sitio web"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "General"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "Mostrar Atajos"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "Preferencias"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr "Pregunta Rápida"

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "Gestor de Modelos"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "Gestor de Instancias"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr "Gestor de Acciones"

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "Alternar Barra Lateral"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr "Abandonar"

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "Gestión de chat"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "Crear Chat"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "Eliminar Chat"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "Limpiar Chat"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "Renombrar Chat"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr "Alternar las Barras de Búsqueda"

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "Entrada de mensaje"

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "Copiar"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "Pegar"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr "Abrir el Menú de Emojis"

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "Saltar línea"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr "Enviar Mensaje Como Sistema"

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr ""
"Los mensajes del sistema son tomados como instrucciones literales por los "
"modelos"

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr "Pidele al modelo que utilice herramientas para generar un mensaje"

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr "Enviar Mensaje Como Usuario"

#: src/custom_widgets/chat_widget.py:92
msgid "Try one of these prompts"
msgstr "Prueba uno de estos mensajes"

#: src/custom_widgets/chat_widget.py:121
msgid "Send prompt: '{}'"
msgstr "Enviar mensaje: '{}'"

#: src/custom_widgets/chat_widget.py:127
msgid "Refresh Prompts"
msgstr "Refrescar Mensajes de Prueba"

#: src/custom_widgets/chat_widget.py:185
msgid "Chat exported successfully"
msgstr "Chat exportado exitosamente"

#: src/custom_widgets/chat_widget.py:205
msgid "User"
msgstr "Usuario"

#: src/custom_widgets/chat_widget.py:209
#: src/custom_widgets/message_widget.py:680
msgid "System"
msgstr "Sistema"

#: src/custom_widgets/chat_widget.py:297
msgid "Regenerate Response"
msgstr "Regenerar Respuesta"

#: src/custom_widgets/chat_widget.py:461
msgid "Copy of {}"
msgstr "Copia de {}"

#: src/custom_widgets/chat_widget.py:474
msgid "Chat imported successfully"
msgstr "Chat importado exitosamente"

#: src/custom_widgets/message_widget.py:88
msgid "Save Message"
msgstr "Guardar Mensaje"

#: src/custom_widgets/message_widget.py:129
#: src/custom_widgets/message_widget.py:268
msgid "Message edited successfully"
msgstr "Mensaje eliminado exitosamente"

#: src/custom_widgets/message_widget.py:155
msgid "Response message"
msgstr "Mensaje de respuesta"

#: src/custom_widgets/message_widget.py:157
msgid "System message"
msgstr "Mensaje de sistema"

#: src/custom_widgets/message_widget.py:159
msgid "User message"
msgstr "Mensaje de usuario"

#: src/custom_widgets/message_widget.py:218
msgid "{}Code Block"
msgstr "{}Bloque de Código"

#: src/custom_widgets/message_widget.py:220
msgid "Code Block"
msgstr "Bloque de Código"

#: src/custom_widgets/message_widget.py:221
#: src/custom_widgets/message_widget.py:530
msgid "Copy Message"
msgstr "Copiar Mensaje"

#: src/custom_widgets/message_widget.py:225
msgid "Edit Code Block"
msgstr "Editar Bloque de Código"

#: src/custom_widgets/message_widget.py:237
#: src/custom_widgets/message_widget.py:313
msgid "Run Script"
msgstr "Ejecutar Script"

#: src/custom_widgets/message_widget.py:277
msgid "Code copied to the clipboard"
msgstr "Codigo copiado"

#: src/custom_widgets/message_widget.py:314
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""
"Asegúrese de comprender lo que hace este script antes de ejecutarlo. Alpaca "
"no es responsable de ningún daño a su dispositivo o datos."

#: src/custom_widgets/message_widget.py:316
msgid "Execute"
msgstr "Ejecutar"

#: src/custom_widgets/message_widget.py:395
#: src/custom_widgets/message_widget.py:397
msgid "Image"
msgstr "Imagen"

#: src/custom_widgets/message_widget.py:406
#: src/custom_widgets/message_widget.py:418
msgid "Missing Image"
msgstr "Imagen no Encontrada"

#: src/custom_widgets/message_widget.py:420
msgid "Missing image"
msgstr "Imagen no Encontrada"

#: src/custom_widgets/message_widget.py:493
msgid "Copy Equation"
msgstr "Copiar Ecuación"

#: src/custom_widgets/message_widget.py:500
msgid "Equation copied to the clipboard"
msgstr "Ecuación copiada al portapapeles"

#: src/custom_widgets/message_widget.py:520
msgid "Remove Message"
msgstr "Remover Mensaje"

#: src/custom_widgets/message_widget.py:540
msgid "Edit Message"
msgstr "Editar Mensaje"

#: src/custom_widgets/message_widget.py:551
msgid "Regenerate Message"
msgstr "Regenerar Mensaje"

#: src/custom_widgets/message_widget.py:563
msgid "Dictate Message"
msgstr "Dictar Mensaje"

#: src/custom_widgets/message_widget.py:583
msgid "Message copied to the clipboard"
msgstr "Mensaje copiado"

#: src/custom_widgets/message_widget.py:648
msgid "Message cannot be regenerated while receiving a response"
msgstr "Mensaje no puede ser regenerado mientras se recibe una respuesta"

#: src/custom_widgets/message_widget.py:957
msgid "Thought"
msgstr "Pensamiento"

#: src/custom_widgets/model_manager_widget.py:67
#: src/custom_widgets/model_manager_widget.py:69
msgid "Stop Download"
msgstr "Detener la descarga"

#: src/custom_widgets/model_manager_widget.py:74
msgid "Stop Download?"
msgstr "¿Detener Descarga?"

#: src/custom_widgets/model_manager_widget.py:75
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "¿Estás seguro de que quieres dejar de descargar '{}'?"

#: src/custom_widgets/model_manager_widget.py:77
msgid "Stop"
msgstr "Parar"

#: src/custom_widgets/model_manager_widget.py:147
msgid "Model Manager Error"
msgstr "Error del Gestor de Modelos"

#: src/custom_widgets/model_manager_widget.py:147
msgid "An error occurred whilst pulling '{}'"
msgstr "Se produjo un error al descargar '{}'"

#: src/custom_widgets/model_manager_widget.py:172
msgid "Download Completed"
msgstr "Descarga Completada"

#: src/custom_widgets/model_manager_widget.py:172
msgid "Model '{}' downloaded successfully."
msgstr "El modelo '{}' se descargó correctamente."

#: src/custom_widgets/model_manager_widget.py:235
msgid "Change Profile Picture"
msgstr "Cambiar Foto de Perfil"

#: src/custom_widgets/model_manager_widget.py:258
msgid "Family"
msgstr "Familia"

#: src/custom_widgets/model_manager_widget.py:259
msgid "Parameter Size"
msgstr "Tamaño de Parametro"

#: src/custom_widgets/model_manager_widget.py:260
msgid "Quantization Level"
msgstr "Nivel de Cuantificación"

#: src/custom_widgets/model_manager_widget.py:263
msgid "Parent Model"
msgstr "Modelo Padre"

#: src/custom_widgets/model_manager_widget.py:266
#: src/custom_widgets/model_manager_widget.py:268
msgid "Modified At"
msgstr "Modificado en"

#: src/custom_widgets/model_manager_widget.py:276
msgid "Description"
msgstr "Descripción"

#: src/custom_widgets/model_manager_widget.py:424
msgid "Change"
msgstr "Cambiar"

#: src/custom_widgets/model_manager_widget.py:427
msgid "Model Profile Picture"
msgstr "Foto de Perfil de Modelo"

#: src/custom_widgets/model_manager_widget.py:427
msgid "What do you want to do with the model's profile picture?"
msgstr "¿Qué quieres hacer con la foto de perfil del modelo?"

#: src/custom_widgets/model_manager_widget.py:449
msgid "Create Child"
msgstr "Crear Descendiente"

#: src/custom_widgets/model_manager_widget.py:457
msgid "Remove Model"
msgstr "Remover Modelo"

#: src/custom_widgets/model_manager_widget.py:460
msgid "Remove Model?"
msgstr "¿Remover Modelo?"

#: src/custom_widgets/model_manager_widget.py:461
msgid "Are you sure you want to remove '{}'?"
msgstr "¿Estás seguro de que quieres eliminar '{}'?"

#: src/custom_widgets/model_manager_widget.py:475
msgid "Multilingual"
msgstr "Plurilingüe"

#: src/custom_widgets/model_manager_widget.py:476
msgid "Code"
msgstr "Código"

#: src/custom_widgets/model_manager_widget.py:477
msgid "Math"
msgstr "Matemáticas"

#: src/custom_widgets/model_manager_widget.py:478
msgid "Vision"
msgstr "Visión"

#: src/custom_widgets/model_manager_widget.py:479
msgid "Embedding"
msgstr "Incrustación"

#: src/custom_widgets/model_manager_widget.py:480
msgid "Tools"
msgstr "Herramientas"

#: src/custom_widgets/model_manager_widget.py:481
msgid "Small"
msgstr "Pequeño"

#: src/custom_widgets/model_manager_widget.py:482
msgid "Medium"
msgstr "Mediano"

#: src/custom_widgets/model_manager_widget.py:483
msgid "Big"
msgstr "Grande"

#: src/custom_widgets/model_manager_widget.py:484
msgid "Huge"
msgstr "Enorme"

#: src/custom_widgets/model_manager_widget.py:573
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""
"Al descargar este modelo, acepta el acuerdo de licencia disponible en el "
"sitio web del modelo."

#: src/custom_widgets/terminal_widget.py:80
msgid "Setting up Python environment..."
msgstr "Iniciando ambiente de Python"

#: src/custom_widgets/terminal_widget.py:98
msgid "Compiling C++ script..."
msgstr "Compilando script C++..."

#: src/custom_widgets/terminal_widget.py:111
msgid "Running local web server"
msgstr "Ejecutar servidor web local"

#: src/custom_widgets/terminal_widget.py:136
msgid "Using Flatpak contained shell"
msgstr "Usando el shell contenido de Flatpak"

#: src/custom_widgets/terminal_widget.py:136
msgid "Using SSH to run command"
msgstr "Usando SSH para ejecutar comando"

#: src/custom_widgets/terminal_widget.py:142
msgid "Script Exited"
msgstr "El Script ha Terminado"

#~ msgid "Clear Chat?"
#~ msgstr "¿Limpiar Chat?"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "¿Estás seguro de que quieres limpiar el chat?"

#~ msgid "Clear"
#~ msgstr "Limpiar"

#~ msgid "Clear Chat"
#~ msgstr "Limpiar Chat"

#~ msgid "Removal of Ollama"
#~ msgstr "Eliminación de Ollama"

#~ msgid ""
#~ "Hey there! With Alpaca 5.1.0, we're making some changes. To keep using "
#~ "Ollama directly within Alpaca, you'll just need to install our new Ollama "
#~ "extension. Don't worry, your models remain untouched!"
#~ msgstr ""
#~ "¡Hola! Con Alpaca 5.1.0, estamos implementando algunos cambios. Para "
#~ "seguir usando Ollama directamente desde Alpaca, solo necesitas instalar "
#~ "nuestra nueva extensión. ¡No te preocupes, tus modelos no se verán "
#~ "afectados!"

#~ msgid "Regenerate Equation"
#~ msgstr "Regenerar Ecuación"

#~ msgid "LaTeX Equation"
#~ msgstr "Ecuación LaTeX"

#~ msgid "Actions"
#~ msgstr "Acciones"

#~ msgid "Which network port will Ollama use"
#~ msgstr "El puerto de red que Ollama utilizará"

#~ msgid "Built in Ollama instance"
#~ msgstr "Instancia de Ollama incluida"

#~ msgid "'{}' does not support actions."
#~ msgstr "'{}' no admite acciones."

#~ msgid "Action Error"
#~ msgstr "Error de Acción"

#~ msgid "An error occurred while running action"
#~ msgstr "Se produjo un error al ejecutar la acción"

#~ msgid "Action Manager"
#~ msgstr "Gestor de Acciones"

#~ msgid "Available Actions"
#~ msgstr "Acciones Disponibles"

#~ msgid ""
#~ "Functions that AI models might use when sending a message by selecting "
#~ "\"Use Actions\" in the send button context menu."
#~ msgstr ""
#~ "Funciones que los modelos de IA pueden utilizar al enviar un mensaje "
#~ "seleccionando \"Usar acciones\" en el menú contextual del botón de envío."

#~ msgid "Action"
#~ msgstr "Acción"

#~ msgid "The current strongest model that fits on a single GPU."
#~ msgstr "El modelo más potente actual que se adapta a una sola GPU."

#~ msgid "Visit Website"
#~ msgstr "Visitar Sitio Web"

#~ msgid ""
#~ "QwQ is an experimental research model focused on advancing AI reasoning "
#~ "capabilities."
#~ msgstr ""
#~ "QwQ es un modelo de investigación experimental centrado en mejorar las "
#~ "capacidades de razonamiento de la IA."

#~ msgid "Your AI, Your Choice"
#~ msgstr "Tu IA, Tu Elección"

#~ msgid ""
#~ "Alpaca includes Ollama by default, giving you instant access to AI. "
#~ "Customize your experience further by connecting to Google Gemini, OpenAI "
#~ "ChatGPT, Together.AI, and more."
#~ msgstr ""
#~ "Alpaca incluye Ollama de forma predeterminada, lo que te da acceso "
#~ "instantáneo a la IA. Personaliza aún más tu experiencia conectándote a "
#~ "Google Gemini, OpenAI ChatGPT, Together.AI y más."

#~ msgid ""
#~ "It looks like you don't have any models downloaded yet. Download models "
#~ "to get started!"
#~ msgstr ""
#~ "Parece que aún no has descargado ningún modelo. ¡Descarga modelos para "
#~ "empezar!"

#~ msgid "Loading"
#~ msgstr "Cargando"

#~ msgid "Chat with local and online AI models"
#~ msgstr "Chatea con modelos de IA locales y en línea"

#~ msgid ""
#~ "Mistral Small is a lightweight model designed for cost-effective use in "
#~ "tasks like translation and summarization."
#~ msgstr ""
#~ "Mistral Small es un modelo liviano diseñado para un uso rentable en "
#~ "tareas como traducción y resumen."

#~ msgid ""
#~ "DeepSeek's first generation reasoning models with comparable performance "
#~ "to OpenAI-o1."
#~ msgstr ""
#~ "Modelos de razonamiento de primera generación de DeepSeek con un "
#~ "rendimiento comparable a OpenAI-o1."

#~ msgid "Loading Instance"
#~ msgstr "Cargando Instancia"

#~ msgid "General"
#~ msgstr "General"

#~ msgctxt "shortcut window"
#~ msgid "Search Messages"
#~ msgstr "Buscar Mensajes"

#~ msgid "Not Available"
#~ msgstr "No Disponible"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Bearer Token (Opcional)"

#~ msgid "Chat with local AI models"
#~ msgstr "Chatea con modelos de IA"

#~ msgid "An Ollama client"
#~ msgstr "Un cliente de Ollama"

#~ msgid "Connect"
#~ msgstr "Conectar"

#~ msgid "Server URL"
#~ msgstr "URL del Server"

#~ msgid "Connect Remote Instance"
#~ msgstr "Conectar Instancia Remota"

#~ msgid "Enter instance information to continue"
#~ msgstr "Ingresa información de la instancia para continuar"

#~ msgid "Close Alpaca"
#~ msgstr "Cerrar Alpaca"

#~ msgid "Use Local Instance"
#~ msgstr "Usar Instancia Local"

#~ msgid "Connection Error"
#~ msgstr "Error de conexión"

#~ msgid "The remote instance has disconnected"
#~ msgstr "La instancia remota se ha desconectado"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Ha ocurrido un error con la instancia local de Ollama, ha sido reinicida"

#~ msgid "An error occurred: {}"
#~ msgstr "Un error ocurrió: {}"

#~ msgid "Ollama instance was shut down due to inactivity"
#~ msgstr "La instancia de Ollama se apagó debido a inactividad"

#~ msgid "Local Models"
#~ msgstr "Modelos Locales"

#~ msgid ""
#~ "It looks a bit empty in here. Try downloading some models to get started!"
#~ msgstr ""
#~ "Parece un poco vacío aquí. ¡Prueba a descargar algunos modelos para "
#~ "comenzar!"

#~ msgid "Available Models"
#~ msgstr "Modelos Disponibles"

#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Usa una conección remota a Ollama"

#~ msgid "Change Ollama Instance"
#~ msgstr "Cambiar Instancia de Ollama"

#~ msgid ""
#~ "The default model to use on new chats and when generating chat titles"
#~ msgstr ""
#~ "El modelo predeterminado que se utilizará en los chats nuevos y al "
#~ "generar títulos de chat"

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "La temperatura del modelo. Incrementando la temparatura hará que el "
#~ "modelo responda más creativamente (Por defecto: 0.8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Aplica el numero al azar que se usa como semilla para generación. Aplicar "
#~ "un numero especifico hará que el modelo genere el mismo texto a la misma "
#~ "pregunta del usuario (Por defecto: 0 (Al azar))"

#~ msgid "Keep Alive Time"
#~ msgstr "Tiempo Para Mantener Vivo"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Controla por cuanto tiempo el modelo permanecera cargado en la memoria "
#~ "despues de la ultima petición en minutos (Por defecto: 5)"

#~ msgid "Ollama Instance"
#~ msgstr "Instancia de Ollama"

#~ msgid "Ollama Overrides"
#~ msgstr "Overrides de Ollama"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Administra los argumentos usados en Ollama, cualquier cambio en esta "
#~ "página solo aplica a la instancia integrada, la instancia se reiniciará "
#~ "si haces algún cambio"

#~ msgid "Idle Timer"
#~ msgstr "Temporizador de inactividad"

#~ msgid ""
#~ "Number of minutes the instance should remain idle before it is shut down "
#~ "(0 means it won't be shut down)"
#~ msgstr ""
#~ "Número de minutos que la instancia debe permanecer inactiva antes de "
#~ "apagarse (0 significa que no se apagará)"

#~ msgid "Change Model Directory"
#~ msgstr "Cambiar Directorio de Modelos"

#~ msgid "Powered by Ollama"
#~ msgstr "Impulsado por Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Sitio Web de Ollama"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca y sus desarrolladores no son responsables por cualquier daño a "
#~ "dispositivos o software resultados por la ejecución de codigo generado "
#~ "por un modelo de IA. Por favor sea precavido y revise el codigo "
#~ "cuidadosamente antes de correrlo"

#~ msgid "Reload Local Models"
#~ msgstr "Recargar Modelos Locales"

#~ msgctxt "shortcut window"
#~ msgid "Import Chat"
#~ msgstr "Importar Chat"

#~ msgid "(No system message available)"
#~ msgstr "(No hay ningún mensaje del sistema disponible)"

#~ msgid "From Existing Model"
#~ msgstr "Desde Modelo Existente"

#~ msgid "From GGUF File"
#~ msgstr "Desde Archivo GGUF"

#~ msgid "From Name"
#~ msgstr "Desde Nombre"

#~ msgid "image"
#~ msgstr "Imagen"

#~ msgid "Select Model"
#~ msgstr "Selecciona el Modelo"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Este modelo será usado como base para el nuevo modelo"

#~ msgid "Pull Model"
#~ msgstr "Descargar Modelo"

#~ msgid ""
#~ "Input the name of the model in this format\n"
#~ "name:tag"
#~ msgstr ""
#~ "Ingresa el nombre del modelo en este formato\n"
#~ "nombre:etiqueta"

#~ msgid ""
#~ "Phi 4 is a 14B parameter, state-of-the-art open model from Microsoft."
#~ msgstr ""
#~ "Phi 4 es un modelo abierto de última generación con 14B parámetros de "
#~ "Microsoft."

#~ msgid "Sponsor Alpaca"
#~ msgstr "Patrocina Alpaca"

#~ msgid ""
#~ "The default model to use on new chats and when Alpaca is launched with "
#~ "the option --ask \"message\""
#~ msgstr ""
#~ "El modelo por defecto a usar en chats nuevos y cuando Alpaca es lanzado "
#~ "con la opción --ask \"mensaje\""

#~ msgid "Manage models dialog"
#~ msgstr "Dialogo de gestión de modelos"

#~ msgid "Create Model"
#~ msgstr "Crear Modelo"

#~ msgid "Refresh Local Models"
#~ msgstr "Recargar Modelos Locales"

#~ msgid "Try a different search or pull an unlisted model from it's name"
#~ msgstr ""
#~ "Prueba una búsqueda diferente o descarga un modelo que no esté en el "
#~ "listado a partir de su nombre."

#~ msgid "Pull Model From Name"
#~ msgstr "Descargar Modelo a Partir del Nombre"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "Al descargar este modelo aceptas la licencia disponible en el sitio web "
#~ "del modelo"

#~ msgid "Model Details"
#~ msgstr "Detalles de Modelo"

#~ msgid ""
#~ "Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
#~ "instructions automatically. Please visit the model's website or Ollama "
#~ "documentation for more information if you're unsure."
#~ msgstr ""
#~ "Algunos modelos requieren un archivo de modelo, Alpaca completa "
#~ "automáticamente las instrucciones FROM y SYSTEM (contexto). Por favor, "
#~ "visita el sitio web del modelo o la documentación de Ollama para más "
#~ "información si tienes dudas."

#~ msgid "Create"
#~ msgstr "Crear"

#~ msgid "Stop Pulling '{}'"
#~ msgstr "Parar Descarga de '{}'"

#~ msgid "Details"
#~ msgstr "Detalles"

#~ msgid "Remove '{}'"
#~ msgstr "Remover '{}'"

#~ msgid "Delete Model?"
#~ msgstr "¿Eliminar Modelo?"

#~ msgid "Create Model Based on '{}'"
#~ msgstr "Crear Modelo Basado en '{}'"

#~ msgid "Change Model Picture"
#~ msgstr "Cambiar Foto de Perfil"

#~ msgid "Format"
#~ msgstr "Formato"

#~ msgid "Enter download menu for {}"
#~ msgstr "Entrar menu de descarga para {}"

#~ msgid "Embedding Model"
#~ msgstr "Modelo de incrustación"

#~ msgid ""
#~ "This model is meant to be used in the training of other models and won't "
#~ "work directly with Alpaca. Are you sure you want to download it anyway?"
#~ msgstr ""
#~ "Este modelo está pensado para usarse en el entrenamiento de otros modelos "
#~ "y no funcionará directamente con Alpaca. ¿Estás seguro de que quieres "
#~ "descargarlo de todas formas?"

#~ msgid "Download"
#~ msgstr "Descargar"

#~ msgid "Large Model"
#~ msgstr "Modelo Largo"

#~ msgid ""
#~ "This model might be too large to run optimally. Are you sure you want to "
#~ "download it anyway?"
#~ msgstr ""
#~ "Es posible que este modelo sea demasiado grande para funcionar de forma "
#~ "óptima. ¿Estás seguro de que deseas descargarlo de todas formas?"

#~ msgid "Others..."
#~ msgstr "Otros..."

#~ msgid "Download {}:{}"
#~ msgstr "Descargar {}:{}"

#~ msgid "Model deleted successfully"
#~ msgstr "Modelo eliminado exitosamente"

#~ msgid "Task Complete"
#~ msgstr "Tarea completada"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "El modelo '{}' fue descargado exitosamente"

#~ msgid "Pull Model Error"
#~ msgstr "Error Descargando Modelo"

#~ msgid "Failed to pull model '{}': {}"
#~ msgstr "Fallo descarga de modelo '{}': {}"

#~ msgid "Error pulling '{}': {}"
#~ msgstr "Error descargando '{}': {}"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr "No se pudo descargar el modelo '{}' debido a un error de red"

#~ msgid "Error pulling '{}'"
#~ msgstr "Error descargando '{}'"

#~ msgid ""
#~ "New state of the art 70B model. Llama 3.3 70B offers similar performance "
#~ "compared to Llama 3.1 405B model."
#~ msgstr ""
#~ "Nuevo modelo 70B de última generación. Llama 3.3 70B ofrece un "
#~ "rendimiento similar al modelo Llama 3.1 405B."

#~ msgid "Script exited"
#~ msgstr "El script salió"

#~ msgid "The script is contained inside Flatpak"
#~ msgstr "El script está contenido dentro de Flatpak"

#~ msgid "Close application"
#~ msgstr "Cerrar aplicación"

#~ msgid "Import chat"
#~ msgstr "Importar chat"

#~ msgid "Clear chat"
#~ msgstr "Limpiar chat"

#~ msgid "New chat"
#~ msgstr "Nuevo chat"

#~ msgid "Show shortcuts window"
#~ msgstr "Mostrar ventana de atajos"

#~ msgid "Manage models"
#~ msgstr "Gestionar modelos"

#~ msgid "Toggle sidebar"
#~ msgstr "Alternar barra lateral"

#~ msgid "Rename chat"
#~ msgstr "Renombrar chat"

#~ msgid "Editor"
#~ msgstr "Editor"

#~ msgid "Message text box"
#~ msgstr "Caja de texto para mensaje"

#~ msgid "Missing file"
#~ msgstr "Archivo faltante"

#~ msgid "Image Recognition"
#~ msgstr "Reconocimiento de Imagenes"

#~ msgid ""
#~ "Your system's available RAM suggests that this model might be too large "
#~ "to run optimally. Are you sure you want to download it anyway?"
#~ msgstr ""
#~ "La memoria RAM disponible en tu sistema sugiere que este modelo podría "
#~ "ser demasiado grande para funcionar de manera óptima. ¿Estás seguro de "
#~ "que deseas descargarlo de todos modos?"

#~ msgid "Create chat"
#~ msgstr "Crear chat"

#~ msgid "Create chat and send message"
#~ msgstr "Crear chat y enviar mensaje"

#~ msgid "This video is not available"
#~ msgstr "Este video no está disponible"

#~ msgid "AMD GPU detected but the extension is missing, Ollama will use CPU"
#~ msgstr ""
#~ "GPU AMD detectada pero la extensión no está instalada, Ollama usará el CPU"

#~ msgid "Select a Model"
#~ msgstr "Selecciona un Modelo"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr "El chat no puede ser limpiado mientras se recibe un mensaje"

#~ msgid "Create Chat?"
#~ msgstr "¿Crear Chat?"

#~ msgid "Enter name for new chat"
#~ msgstr "Ingrese el nombre para el nuevo chat"

#~ msgid "Use local instance"
#~ msgstr "Usar instancia local"

#~ msgid "An error occurred while creating the model"
#~ msgstr "Ha ocurrido un error mientras se creaba el modelo"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL de la Instancia Remota"

#~ msgid "Press Enter to close..."
#~ msgstr "Presione Enter para cerrar..."

#~ msgid "No compatible terminal was found in the system"
#~ msgstr "No se encontró ningún terminal compatible en el sistema"

#~ msgid ""
#~ "Google Gemma 2 is a high-performing and efficient model by now available "
#~ "in three sizes: 2B, 9B, and 27B."
#~ msgstr ""
#~ "Google Gemma 2 es un modelo de alto rendimiento y eficiente que ahora "
#~ "está disponible en tres tamaños: 2B, 9B y 27B."

#~ msgid "Loading instance"
#~ msgstr "Cargando instancia"

#~ msgid "Applying user preferences"
#~ msgstr "Aplicando preferencias de usuario"

#~ msgid "Updating list of local models"
#~ msgstr "Actualizando lista de modelos locales"

#~ msgid "Updating list of available models"
#~ msgstr "Actualizando lista de modelos disponibles"

#~ msgid "Loading chats"
#~ msgstr "Cargando chats"

#~ msgid "Loading Alpaca dialog"
#~ msgstr "Dialogo de carga de Alpaca"

#~ msgid "Loading Alpaca..."
#~ msgstr "Cargando Alpaca..."

#~ msgid "Failed to connect to server"
#~ msgstr "No se pudo conectar al servidor"

#~ msgid "Stop Creating '{}'"
#~ msgstr "Parar la creación de '{}'"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 ahora está disponible en 2 tamaños, 9B y 27B."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr "¿Estás seguro de que quieres parar la descarga de '{} ({})'?"

#~ msgid "Try a different search"
#~ msgstr "Intenta una busqueda distinta"

#~ msgid "Pulling in the background..."
#~ msgstr "Descargando en el fondo..."

#~ msgid "Featured Models"
#~ msgstr "Modelos Destacados"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later.\n"
#~ "\n"
#~ "By downloading any model you accept their license agreement available on "
#~ "the model's website.\n"
#~ "                  "
#~ msgstr ""
#~ "Alpaca funciona localmente en tu dispositivo, para empezar a conversar "
#~ "necesitaras un modelo de AI, puedes descargar un modelo de esta página o "
#~ "en el menu 'Gestionar Modelos' despues.\n"
#~ "\n"
#~ "Al descargar cualquier modelo aceptas su acuerdo de licencia disponible "
#~ "en el sitio web del modelo.\n"
#~ "                  "

#~ msgid "Built by Meta"
#~ msgstr "Construido por Meta"

#~ msgid "Built by Google DeepMind"
#~ msgstr "Construido por Google DeepMind"

#~ msgid "Built by Microsoft"
#~ msgstr "Construido por Microsoft"

#~ msgid "Multimodal AI with image recognition"
#~ msgstr "IA multimodal con reconocimiento de imagenes"

#~ msgid "Remove '{} ({})'"
#~ msgstr "Remover '{} ({})'"

#~ msgid "Stop Pulling '{} ({})'"
#~ msgstr "Parar Descarga de '{} ({})'"

#~ msgid "Template"
#~ msgstr "Plantilla"

#~ msgid ""
#~ "Some models require a specific template. Please visit the model's website "
#~ "for more information if you're unsure."
#~ msgstr ""
#~ "Algunos modelos requieren de una plantilla especifica. Por favor visita "
#~ "el sitio web del modelo para más información en caso de que no estés "
#~ "seguro"

#~ msgid "From GGUF File (Experimental)"
#~ msgstr "Usar archivo GGUF (Experimental)"

#~ msgid "A conversation showing code highlight"
#~ msgstr "Una conversación mostrando highlight de codigo"

#~ msgid "A conversation involving multiple models"
#~ msgstr "Una conversación incluyendo multiples modelos"

#~ msgid "Managing models"
#~ msgstr "Gestionando modelos"

#~ msgid "Open with Default App"
#~ msgstr "Abrir con Aplicación Predeterminada"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later."
#~ msgstr ""
#~ "Alpaca funciona localmente en tu dispositivo, para empezar a chatear "
#~ "necesitas un modelo IA, puedes descargar modelos de esta lista o usando "
#~ "el menu 'Gestionar Modelos' despues"

#~ msgid "An error occurred"
#~ msgstr "Ha ocurrio un error"

#~ msgid "Could not list local models"
#~ msgstr "No se pudieron listar los modelos locales"

#~ msgid "Could not delete model"
#~ msgstr "No se pudo eliminar el modelo"

#~ msgid "Could not pull model"
#~ msgstr "No se pudo descargar el modelo"

#~ msgid "Cannot delete chat because it's the only one left"
#~ msgstr "No se pudo eliminar el chat por que es el único que queda"

#~ msgid "That tag is already being pulled"
#~ msgstr "Esa etiqueta ya se está descargando"

#~ msgid "That tag has been pulled already"
#~ msgstr "Esa etiqueta ya ha sido descargada"

#~ msgid "Model pulled successfully"
#~ msgstr "Modelo descargado exitosamente"
