# Spanish translations for Alpaca package.
# Copyright (C) 2024 Jeffry Samuel Eduarte Rojas
# This file is distributed under the same license as the Alpaca package.
# Jeffry Samuel Eduarte Rojas <jeffrysamuer@gmail.com>, 2024.
#
msgid ""
msgstr ""
"Project-Id-Version: 2.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-02-17 14:06-0600\n"
"PO-Revision-Date: 2024-05-19 19:44-0600\n"
"Last-Translator: Jeffry Samuel Eduarte Rojas <jeffrysamuer@gmail.com>\n"
"Language-Team: Spanish\n"
"Language: es\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ai;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with local and online AI models"
msgstr "Chatea con modelos de IA locales y en línea"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "Un cliente de IA privado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:993
msgid "Features"
msgstr "Funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
msgid "Built in Ollama instance"
msgstr "Instancia de Ollama incluida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:995
msgid "Talk to multiple models in the same conversation"
msgstr "Habla con multiples modelos en la misma conversación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
#: data/com.jeffser.Alpaca.metainfo.xml.in:996
msgid "Pull and delete models from the app"
msgstr "Descarga y elimina modelos desde la app"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Have multiple conversations"
msgstr "Multiples conversaciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Image recognition (Only available with compatible models)"
msgstr "Reconocimiento de imagenes (Solo disponible con modelos compatibles)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Plain text documents recognition"
msgstr "Reconocimiento de documentos de texto plano"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Import and export chats"
msgstr "Importa y exporta chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append YouTube transcripts to the prompt"
msgstr "Agrega transcripciones de YouTube a los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "Append text from a website to the prompt"
msgstr "Agrega texto de un sitio web a los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:22
msgid "PDF recognition"
msgstr "Reconocimiento de PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24 src/window.ui:110
msgid "Disclaimer"
msgstr "Aviso Legal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:25
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"Este proyecto no está afiliado del todo con Ollama, no soy responsable por "
"cualquier daño a tu dispositivo o software causado por correr codigo "
"proveido por cualquier modelo."

#: data/com.jeffser.Alpaca.metainfo.xml.in:54
msgid "A normal conversation with an AI Model"
msgstr "Una conversación normal con un modelo AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:58
msgid "A conversation involving image recognition"
msgstr "Una conversación que incluye reconocimiento de imagenes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:62
msgid "A conversation involving a custom model"
msgstr "Una conversación con un modelo personalizado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:66
msgid "A conversation showing code highlighting"
msgstr "Una conversación mostrando highlighting de codigo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:70
msgid "A Python script running inside integrated terminal"
msgstr "Un script de Python corriendo dentro de la terminal integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:74
msgid "A conversation involving a YouTube video transcript"
msgstr "Una conversación que incluye una transcripción de un video de YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:78
msgid "Multiple models being downloaded"
msgstr "Multiples modelos siendo descargados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:82
msgid "Model creator screen"
msgstr "Pantalla de creación de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:96
#: data/com.jeffser.Alpaca.metainfo.xml.in:123
#: data/com.jeffser.Alpaca.metainfo.xml.in:143
#: data/com.jeffser.Alpaca.metainfo.xml.in:169
#: data/com.jeffser.Alpaca.metainfo.xml.in:184
#: data/com.jeffser.Alpaca.metainfo.xml.in:209
#: data/com.jeffser.Alpaca.metainfo.xml.in:237
#: data/com.jeffser.Alpaca.metainfo.xml.in:247
#: data/com.jeffser.Alpaca.metainfo.xml.in:258
#: data/com.jeffser.Alpaca.metainfo.xml.in:272
#: data/com.jeffser.Alpaca.metainfo.xml.in:284
#: data/com.jeffser.Alpaca.metainfo.xml.in:300
#: data/com.jeffser.Alpaca.metainfo.xml.in:315
#: data/com.jeffser.Alpaca.metainfo.xml.in:350
#: data/com.jeffser.Alpaca.metainfo.xml.in:375
#: data/com.jeffser.Alpaca.metainfo.xml.in:406
#: data/com.jeffser.Alpaca.metainfo.xml.in:432
#: data/com.jeffser.Alpaca.metainfo.xml.in:454
#: data/com.jeffser.Alpaca.metainfo.xml.in:485
#: data/com.jeffser.Alpaca.metainfo.xml.in:507
#: data/com.jeffser.Alpaca.metainfo.xml.in:528
#: data/com.jeffser.Alpaca.metainfo.xml.in:543
#: data/com.jeffser.Alpaca.metainfo.xml.in:568
msgid "New"
msgstr "Nuevo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:98
msgid "New instance manager"
msgstr "Nuevo gestor de instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
msgid "New welcome screen"
msgstr "Nueva pantalla de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "New Instances"
msgstr "Nuevas Instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:103
msgid "OpenAI ChatGPT"
msgstr "OpenAI ChatGPT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:104
msgid "Google Gemini"
msgstr "Google Gemini"

#: data/com.jeffser.Alpaca.metainfo.xml.in:105
msgid "Together AI"
msgstr "Together AI"

#: data/com.jeffser.Alpaca.metainfo.xml.in:106
msgid "Venice"
msgstr "Venice"

#: data/com.jeffser.Alpaca.metainfo.xml.in:113
#: data/com.jeffser.Alpaca.metainfo.xml.in:159
#: data/com.jeffser.Alpaca.metainfo.xml.in:190
#: data/com.jeffser.Alpaca.metainfo.xml.in:199
#: data/com.jeffser.Alpaca.metainfo.xml.in:262
#: data/com.jeffser.Alpaca.metainfo.xml.in:290
#: data/com.jeffser.Alpaca.metainfo.xml.in:304
#: data/com.jeffser.Alpaca.metainfo.xml.in:321
#: data/com.jeffser.Alpaca.metainfo.xml.in:332
#: data/com.jeffser.Alpaca.metainfo.xml.in:341
#: data/com.jeffser.Alpaca.metainfo.xml.in:358
#: data/com.jeffser.Alpaca.metainfo.xml.in:368
#: data/com.jeffser.Alpaca.metainfo.xml.in:385
#: data/com.jeffser.Alpaca.metainfo.xml.in:395
#: data/com.jeffser.Alpaca.metainfo.xml.in:442
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:492
#: data/com.jeffser.Alpaca.metainfo.xml.in:514
#: data/com.jeffser.Alpaca.metainfo.xml.in:532
#: data/com.jeffser.Alpaca.metainfo.xml.in:550
#: data/com.jeffser.Alpaca.metainfo.xml.in:562
#: data/com.jeffser.Alpaca.metainfo.xml.in:578
msgid "Fixes"
msgstr "Arreglos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:115
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""
"Se solucionó el problema de exportación de chats con el archivo adjunto "
"'pensamientos'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
msgid "Fixed attachment filters"
msgstr "Filtros de archivos adjuntos arreglados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "New model manager"
msgstr "Nuevo gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Changed GtkSpinner to AdwSpinner"
msgstr "Cambiado GTKSpinner a AdwSpinner"

#: data/com.jeffser.Alpaca.metainfo.xml.in:127
msgid "Better handling of launch process"
msgstr "Mejor manejo del proceso de lanzamiento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
msgid "New loading screen at launch"
msgstr "Nueva pantalla de carga en el lanzamiento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:129
msgid "Better handling of file types"
msgstr "Mejor manejo de los tipos de archivos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:130
msgid "Better regex expression for LaTeX equations"
msgstr "Mejor expresión regular para ecuaciones LaTeX"

#: data/com.jeffser.Alpaca.metainfo.xml.in:131
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""
"Cuadro de diálogo de confirmación si el usuario cierra Alpaca mientras se "
"descarga un modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:132
msgid "Better handling of think tags in messages"
msgstr "Mejor manejo de las etiquetas de pensamiento en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:133
msgid "Default model is now in charge of generating titles"
msgstr "El modelo predeterminado ahora se encarga de generar título"

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "Message header is now shown whilst the message is being generated"
msgstr "Encabezado del mensaje ahora se muestra mientras se genera el mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:135
msgid "Better handling of model profile pictures"
msgstr "Mejor manejo de las fotos de perfil de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:136
msgid "New models in 'available models' list"
msgstr "Nuevos modelos en la lista de 'modelos disponibles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:145
msgid "Added option for attaching screenshots"
msgstr "Añadida opción para adjuntar capturas de pantalla"

#: data/com.jeffser.Alpaca.metainfo.xml.in:146
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr "Ecuaciones básicas de LaTeX ahora son renderizadas en mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:147
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr "Scripts de C++ y HTML ahora pueden ser ejecutados dentro de Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:148
msgid "Added option to open the environment directory from the terminal"
msgstr "Añadida opción para abrir el directorio del ambiente en la terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:149
msgid "Added option to edit code blocks directly"
msgstr "Añadida opción para editar bloques de código directamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:150
msgid "Complete keyboard shortcut list"
msgstr "Lista de atajos de teclado completa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:151
msgid "Images are now attached in 640p resolution"
msgstr "Imagenes ahora son adjuntadas en resolución 640p"

#: data/com.jeffser.Alpaca.metainfo.xml.in:152
msgid "Website attachments now use extracted titles"
msgstr "Sitios web adjuntados ahora extraen titulos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:153
msgid "Better chat title generation"
msgstr "Mejor generación de titulos de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:154
msgid "Added option to attach any plain text files"
msgstr "Añadida opción para adjuntar cualquier archivo de texto plano"

#: data/com.jeffser.Alpaca.metainfo.xml.in:155
msgid "Added spellchecker to message entry"
msgstr "Añadido corrector ortográfico a la entrada de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:156
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr "Los parametros de Alpaca ahora son almacenados en SQLite3"

#: data/com.jeffser.Alpaca.metainfo.xml.in:157
msgid "Small appearance changes in text entries"
msgstr "Cambios de apariencia pequeños en entradas de texto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:161
msgid "Alpaca's launch process is more reliable"
msgstr "El proceso de lanzamiento de Alpaca ahora es más confiable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:162
msgid "Closing the terminal now kills the script subprocess"
msgstr "Cerrar la terminal ahora detiene el suproceso del script"

#: data/com.jeffser.Alpaca.metainfo.xml.in:171
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr "Backend de chat transicionada de JSON a SQLite"

#: data/com.jeffser.Alpaca.metainfo.xml.in:172
msgid "Changed appearance of messages"
msgstr "Cambiada la apariencia de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:173
msgid "Added the option to add profile pictures to models"
msgstr "Opción añadida para agregar fotos de perfil a modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:175
#: data/com.jeffser.Alpaca.metainfo.xml.in:647
#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Fix"
msgstr "Arreglo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:177
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr "Cambiados override de HIP_VISIBLE_DEVICES a ROCR_VISIBLE_DEVICES"

#: data/com.jeffser.Alpaca.metainfo.xml.in:186
msgid "Added categories to models"
msgstr "Añadidas categorias a modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:187
msgid "Specified model's languages"
msgstr "Especificar lenguajes de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:188
msgid "Added warning when downloading embedding models"
msgstr "Añadida advertencia cuando se descargan modelos de incrustación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:192
msgid "Replaced low ram warning with big model warning"
msgstr ""
"Se reemplazó la advertencia de RAM baja con una advertencia de modelo grande"

#: data/com.jeffser.Alpaca.metainfo.xml.in:201
msgid "Correctly escape markup before rendering message"
msgstr "Correctamente escapa markup antes de renderizar mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:202
msgid "Fixed about dialog not working if log file was missing"
msgstr ""
"Arreglado dialogo 'sobre Alpaca' no funcionando si archivo log no existe"

#: data/com.jeffser.Alpaca.metainfo.xml.in:211
msgid "System messages can now be sent directly from Alpaca"
msgstr ""
"Mensajes de sistema ahora pueden ser enviados directamente desde Alpaca"

#: data/com.jeffser.Alpaca.metainfo.xml.in:212
msgid "New redesign for messages and smaller minimum size"
msgstr "Nuevo rediseño para mensajes y menor tamaño minimo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "New models included in 'available models list'"
msgstr "Nuevos modelos incluidos en la 'lista de modelos disponibles'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:214
msgid "Added symbolic icon when attaching code files"
msgstr "Añadido icono simbolico cuando se adjuntan archivos de codigos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:215
msgid "When exporting a chat it now includes a markdown file"
msgstr "Cuando se exporta un chat ahora se incluye un archivo Markdown"

#: data/com.jeffser.Alpaca.metainfo.xml.in:216
msgid "Refresh button in model manager when using a remote instance"
msgstr ""
"Botón de recarga en el gestor de modelos cuando se usa instancia remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:217
msgid "Assistant messages are now editable"
msgstr "Mensajes de asistente ahora son editables"

#: data/com.jeffser.Alpaca.metainfo.xml.in:218
msgid "Updated Ollama to v0.5.2"
msgstr "Ollama actualizado a v0.5.2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:219
msgid "New option to change model directory"
msgstr "Nueva opción para cambiar el directorio de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:220
msgid "File previewer now resizes dynamically to content"
msgstr "Previsualizador de archivos ahora ajusta su tamaño dinamicamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:221
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr "Alpaca ha sido adaptado para funcionar sin instancia de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:222
msgid "Compatibility added with ODT files"
msgstr "Compatibilidad añadida con archivos ODT"

#: data/com.jeffser.Alpaca.metainfo.xml.in:225
msgid "Restored ROCm compatibility"
msgstr "Capabilidad ROCm restaurada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:226
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""
"Se agregó un gesto de pulsación prolongada a las filas de chat para que se "
"puedan realizar acciones en pantallas táctiles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:227
msgid "Fixed edit button not saving changes"
msgstr "Arreglado boton de editado no guardando cambios"

#: data/com.jeffser.Alpaca.metainfo.xml.in:228
msgid "Changed max temperature value to 2"
msgstr "Cambiado el valor temperatura maxima a 2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "Made seed 0 actually random"
msgstr "Semilla 0 ahora es aleatoria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:230
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""
"El proveedor de búsqueda de Gnome corregido no funcionaba fuera de las "
"instalaciones de Flatpak"

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr "Nueva opción --ask MENSAJE para abrir una ventana 'Pregunta Rápida'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:240
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""
"Integración con busqueda de Gnome ahora funciona si Alpaca esta abierto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:249
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""
"Añadidos parametros de lanzamiento --ask MENSAJE, --new-chat CHAT, --select-"
"chat CHAT, --list-chats, --version"

#: data/com.jeffser.Alpaca.metainfo.xml.in:250
msgid "Added integration as Gnome Search Provider"
msgstr "Añadido integración como Proveedor de Busqueda de Gnome"

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "Updated Ollama to v0.4.2 with new models"
msgstr "Actualizado Ollama a v0.4.2 con nuevos modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "User messages are now compacted into bubbles"
msgstr "Mensajes de usuario ahora son compactados en burbujas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:264
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""
"Dialogo de reconnexión arreglado: no funciona cuando 'usar instancia local' "
"es seleccionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:265
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""
"Arreglado gestor de modelos no adaptandose a fuentes de sistema grandes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:274
msgid "Details page for models"
msgstr "Pagina de detalles para modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""
"El selector de modelos se remplaza con un boton para el gestor de modelos "
"cuando no hay modelos descargados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Added warning when model is too big for the device"
msgstr "Añadida advertencia cuando el modelo es muy grande para el dispositivo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:277
msgid "Added AMD GPU indicator in preferences"
msgstr "Añadido indicador para GPU de AMD en preferencias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Better system for handling dialogs"
msgstr "Mejor sistema para manejar dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:287
msgid "Better system for handling instance switching"
msgstr "Mejor sistema para manejar el cambio de instancias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:288
msgid "Remote connection dialog"
msgstr "Dialogo de conexión remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:292
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""
"Arreglado: Modelos se duplican cuando se cambia entre instancia remota y "
"local"

#: data/com.jeffser.Alpaca.metainfo.xml.in:293
msgid "Better internal instance manager"
msgstr "Mejor gestor de instancias interno"

#: data/com.jeffser.Alpaca.metainfo.xml.in:302
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr "Añadido botones 'Cancelar' y 'Guardar' cuando se edita un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:306
msgid "Better handling of image recognition"
msgstr "Mejor manejo de reconocimiento de imagenes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Remove unused files when canceling a model download"
msgstr "Remover archivos no usados cuando se cancela una descarga de modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid "Better message blocks rendering"
msgstr "Mejor renderizado de bloques de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:317
msgid "Run bash and python scripts straight from chat"
msgstr "Ejecutar scripts de Bash y Python directamente desde el chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:318
msgid "Updated Ollama to 0.3.12"
msgstr "Ollama actualizado a 0.3.12"

#: data/com.jeffser.Alpaca.metainfo.xml.in:319
msgid "New models!"
msgstr "Nuevos modelos!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Fixed and made faster the launch sequence"
msgstr "Arreglado y optimizado el proceso de lanzamiento"

#: data/com.jeffser.Alpaca.metainfo.xml.in:324
msgid "Better detection of code blocks in messages"
msgstr "Mejor detección de bloques de código en mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:325
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr "Arreglado: Aplicación no abre en ciertos equipos con GPUs Nvidia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:334
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""
"Arreglado: Notificaciones de mensajes a veces congelan la aplicación debido "
"a que corrían en diferentes hilos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:343
msgid "Fixed message generation sometimes failing"
msgstr "Arreglado: Generación de mensajes a veces fallaba"

#: data/com.jeffser.Alpaca.metainfo.xml.in:352
msgid "Sidebar resizes with the window"
msgstr "Barra lateral cambia su tamaño con respecto a la ventana"

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "New welcome dialog"
msgstr "Nuevo dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "Message search"
msgstr "Busqueda de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "Updated Ollama to v0.3.11"
msgstr "Actualizado Ollama a v0.3.11"

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "A lot of new models provided by Ollama repository"
msgstr "Muchos modelos nuevos proveidos por el repositorio de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:360
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""
"Arreglado: Texto dentro del gestionador de modelos cuando la opción de "
"accesibilidad 'texto grande' esta activa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid "Fixed image recognition on unsupported models"
msgstr "Arreglado reconocimiento de imagenes en modelos no soportados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:370
msgid "Fixed spinner not hiding if the back end fails"
msgstr "Arreglado, spinner no se esconde si la instancia falla"

#: data/com.jeffser.Alpaca.metainfo.xml.in:371
msgid "Fixed image recognition with local images"
msgstr "Arreglado reconocimiento de imagenes locales"

#: data/com.jeffser.Alpaca.metainfo.xml.in:372
msgid "Changed appearance of delete / stop model buttons"
msgstr "Apariencia de botones de eliminar y parar modelos cambiada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:373
msgid "Fixed stop button crashing the app"
msgstr "Arreglado, botón de parar generacion congela la aplicacion"

#: data/com.jeffser.Alpaca.metainfo.xml.in:377
msgid "Made sidebar resize a little when the window is smaller"
msgstr "Barra lateral cambia su tamaño un poco cuando la ventana es pequeña"

#: data/com.jeffser.Alpaca.metainfo.xml.in:378
msgid "Instant launch"
msgstr "Lanzamiento instantaneo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:387
msgid "Fixed error on first run (welcome dialog)"
msgstr "Arreglado error en el primer lanzamiento (dialogo de bienvenida)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:388
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""
"Arreglado verificador de instancia de Ollama (usado en paquetes de sistema)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:397
msgid "Fixed 'clear chat' option"
msgstr "Arreglada opción de 'Limpiar Chat'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:398
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr "Arreglado dialogo de bienvenida causando que la instancia no inicie"

#: data/com.jeffser.Alpaca.metainfo.xml.in:399
msgid "Fixed support for AMD GPUs"
msgstr "Arreglado soporte para GPUs de AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:408
msgid "Model, message and chat systems have been rewritten"
msgstr "Se han reescrito los sistemas de modelos, mensajes y chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:409
msgid "New models are available"
msgstr "Nuevos modelos disponibles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid "Ollama updated to v0.3.9"
msgstr "Actualizado Ollama a v0.3.9"

#: data/com.jeffser.Alpaca.metainfo.xml.in:411
msgid "Added support for multiple chat generations simultaneously"
msgstr "Se agregó soporte para múltiples generaciones de chat simultáneamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "Added experimental AMD GPU support"
msgstr "Se agregó soporte experimental con GPU AMD"

#: data/com.jeffser.Alpaca.metainfo.xml.in:413
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""
"Se agregó un indicador de carga de mensajes y un indicador de mensajes "
"nuevos a la pestaña de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:414
msgid "Added animations"
msgstr "Se agregaron animaciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:415
msgid "Changed model manager / model selector appearance"
msgstr "Se modificó la apariencia del gestor de modelos / selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:416
msgid "Changed message appearance"
msgstr "Se modificó la apariencia de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:417
msgid "Added markdown and code blocks to user messages"
msgstr "Añadido markdown y bloques de código para mensajes de usuario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:418
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""
"Se agregó un diálogo de carga al inicio para que la aplicación se abra más "
"rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:419
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""
"Se agregó una advertencia cuando el dispositivo está en modo de 'ahorro de "
"batería'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:420
msgid "Added inactivity timer to integrated instance"
msgstr "Se agregó un temporizador de inactividad a la instancia integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr "El chat ahora se desplaza hasta la parte inferior cuando se cambia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:424
msgid "Better handling of focus on messages"
msgstr "Mejor manejo de focus en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:425
msgid "Better general performance on the app"
msgstr "Mejor rendimiento general en la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:434
msgid "New duplicate chat option"
msgstr "Nueva opción de duplicado de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:435
msgid "Changed model selector appearance"
msgstr "Apariencia del selector de modelos cambiada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:436
msgid "Message entry is focused on launch and chat change"
msgstr "La entrada de mensaje tiene focus al abrir el app o al cambiar chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:437
msgid "Message is focused when it's being edited"
msgstr "El mensaje tiene focus al ser editado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:438
msgid "Added loading spinner when regenerating a message"
msgstr "Añadido spinner de carga cuando se regenera un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:439
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr "Añadido debugging de Ollama al dialogo 'Sobre Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:440
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""
"Cambiada apariencia y comportamiento del dialogo de transcripciones de "
"YouTube"

#: data/com.jeffser.Alpaca.metainfo.xml.in:444
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr "CTRL+W y CTRL+Q paran la instancia local antes de cerrar la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:445
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""
"Cambiada apariencia del botón 'Abrir Gestor de Modelos' en la pantalla de "
"bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:446
msgid "Fixed message generation not working consistently"
msgstr "Arreglado generación de mensajes no funcionando consistentemente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:447
msgid "Fixed message edition not working consistently"
msgstr "Arreglado edición de mesnajes no funcionando consistentemente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:456
msgid "Model manager opens faster"
msgstr "Gestor de modelos abre más rapidamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid "Delete chat option in secondary menu"
msgstr "Opción de eliminar chat en el menu secundario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "New model selector popup"
msgstr "Nuevo selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Standard shortcuts"
msgstr "Atajos de teclado estandares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid "Model manager is navigable with keyboard"
msgstr "El gestor de modelos es navegable con el teclado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:461
msgid "Changed sidebar collapsing behavior"
msgstr "Cambiado comportamiento de colapso de la barra lateral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:462
msgid "Focus indicators on messages"
msgstr "Indicadores de focus en mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:463
msgid "Welcome screen"
msgstr "Pantalla de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:464
msgid "Give message entry focus at launch"
msgstr "Dado focus a la entrada de texto de mensaje al abrir la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:465
msgid "Generally better code"
msgstr "Mejor código en general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid "Better width for dialogs"
msgstr "Mejor medida de largo para dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:470
msgid "Better compatibility with screen readers"
msgstr "Mejor compatibilidad con lectores de pantalla"

#: data/com.jeffser.Alpaca.metainfo.xml.in:471
msgid "Fixed message regenerator"
msgstr "Arreglado regenerador de mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid "Removed 'Featured models' from welcome dialog"
msgstr "'Modelos destacados' removido del dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:473
msgid "Added default buttons to dialogs"
msgstr "Añadidos botones por defecto a dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:474
msgid "Fixed import / export of chats"
msgstr "Arreglado importación / exportación de chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:475
msgid "Changed Python2 title to Python on code blocks"
msgstr "Cambiado titulo Python2 a Python en bloques de código"

#: data/com.jeffser.Alpaca.metainfo.xml.in:476
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""
"Prevenir regeneración de titulos cuando el usuario escribio un titulo "
"personalizado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:477
msgid "Show date on stopped messages"
msgstr "Mostrar fecha en mensajes interrumpidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Fix clear chat error"
msgstr "Arreglado error al limpiar chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:487
msgid "Changed shortcuts to standards"
msgstr "Cambiado los atajos de teclado a estandares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:488
msgid "Moved 'Manage Models' button to primary menu"
msgstr "Movido botón 'Gestión de Modelos' al menu primario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:489
#: data/com.jeffser.Alpaca.metainfo.xml.in:511
msgid "Stable support for GGUF model files"
msgstr "Soporte estable para archivos de modelo GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:490
#: data/com.jeffser.Alpaca.metainfo.xml.in:765
msgid "General optimizations"
msgstr "Optimización general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:494
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""
"Mejor manejo de la tecla de enter (importante para escritura en Japones)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid "Removed sponsor dialog"
msgstr "Removido dialogo de patrocinio"

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Added sponsor link in about dialog"
msgstr "Añadido link de patrocinio en el dialogo 'sobre'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:497
msgid "Changed window and elements dimensions"
msgstr "Cambiadas las dimensiones de ventana y elementos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:498
msgid "Selected model changes when entering model manager"
msgstr "Selección de modelo cambia cuando se entra al gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:499
msgid "Better image tooltips"
msgstr "Mejor tooltips para imagenes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:500
msgid "GGUF Support"
msgstr "Soporte para GGUF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:509
msgid "Regenerate any response, even if they are incomplete"
msgstr "Regenerar cualquier respuesta, inclusive si están incompletas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:510
msgid "Support for pulling models by name:tag"
msgstr "Soporte para la descargas de modelos por nombre:etiqueta"

#: data/com.jeffser.Alpaca.metainfo.xml.in:512
msgid "Restored sidebar toggle button"
msgstr "Restaurado botón de barra lateral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:516
msgid "Reverted back to standard styles"
msgstr "Revertido a estilos estandares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:517
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr "Titulos de chat generados teniendo \"'S\" por algún motivo, arreglado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:518
msgid "Changed min width for model dropdown"
msgstr "Cambiado largo minimo para el selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:519
msgid "Changed message entry shadow"
msgstr "Cambiada la sombra en el campo de texto para mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:520
msgid "The last model used is now restored when the user changes chat"
msgstr ""
"El ultimo modelo usado ahora es restaurado cuando el usuario cambia el chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:521
msgid "Better check for message finishing"
msgstr "Mejor chequeo de mensaje terminando"

#: data/com.jeffser.Alpaca.metainfo.xml.in:530
msgid "Added table rendering (Thanks Nokse)"
msgstr "Renderizado de tablas añadido (Gracias Nokse)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:534
msgid "Made support dialog more common"
msgstr "Hizo que el diálogo de soporte sea más común"

#: data/com.jeffser.Alpaca.metainfo.xml.in:535
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""
"El título del diálogo en el selector de etiquetas al descargar modelos no se "
"mostraba correctamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:536
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""
"Prevenir que la generación de chats cree un título con múltiples líneas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Bearer Token entry on connection error dialog"
msgstr "Entrada de Token de Portador en el diálogo de error de conexión"

#: data/com.jeffser.Alpaca.metainfo.xml.in:546
msgid "Small appearance changes"
msgstr "Pequeños cambios en la apariencia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:547
msgid "Compatibility with code blocks without explicit language"
msgstr "Compatibilidad con bloques de código sin lenguaje explícito"

#: data/com.jeffser.Alpaca.metainfo.xml.in:548
msgid "Rare, optional and dismissible support dialog"
msgstr "Diálogo de soporte raro, opcional y descartable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:552
msgid "Date format for Simplified Chinese translation"
msgstr "Formato de fecha para la traducción al chino simplificado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:553
msgid "Bug with unsupported localizations"
msgstr "Error con localizaciones no soportadas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:554
msgid "Min height being too large to be used on mobile"
msgstr "Altura mínima demasiado grande para ser usada en móviles"

#: data/com.jeffser.Alpaca.metainfo.xml.in:555
msgid "Remote connection checker bug"
msgstr "Error en el comprobador de conexión remota"

#: data/com.jeffser.Alpaca.metainfo.xml.in:564
msgid "Models with capital letters on their tag don't work"
msgstr "Los modelos con letras mayúsculas en su etiqueta no funcionan"

#: data/com.jeffser.Alpaca.metainfo.xml.in:565
msgid "Ollama fails to launch on some systems"
msgstr "Ollama no se inicia en algunos sistemas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:566
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""
"Las transcripciones de YouTube no se están guardando en el directorio TMP "
"correcto"

#: data/com.jeffser.Alpaca.metainfo.xml.in:570
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""
"Los mensajes de depuración ahora se muestran en el diálogo 'Acerca de Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:571
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr "Actualizado Ollama a la versión 0.3.0 (nuevos modelos)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:580
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""
"Los modelos con '-' en sus nombres no funcionaban correctamente, esto ya "
"está solucionado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Better connection check for Ollama"
msgstr "Mejor comprobación de conexión para Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:588
msgid "Stable Release"
msgstr "Lanzamiento Estable"

#: data/com.jeffser.Alpaca.metainfo.xml.in:589
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""
"El nuevo ícono fue creado por Tobias Bernard en Gnome Gitlab, ¡gracias por "
"el gran ícono!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:590
msgid "Features and fixes"
msgstr "Características y correcciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:592
msgid "Updated Ollama instance to 0.2.8"
msgstr "Instancia de Ollama actualizada a la 0.2.8"

#: data/com.jeffser.Alpaca.metainfo.xml.in:593
msgid "Better model selector"
msgstr "Mejor selector de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:594
msgid "Model manager redesign"
msgstr "Rediseño del gestor de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Better tag selector when pulling a model"
msgstr "Mejor selector de etiquetas al seleccionar un modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Model search"
msgstr "Búsqueda de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:597
msgid "Added support for bearer tokens on remote instances"
msgstr "Añadido soporte para tokens de portador en instancias remotas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Preferences dialog redesign"
msgstr "Rediseño del diálogo de preferencias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid "Added context menus to interact with a chat"
msgstr "Añadidos menús contextuales para interactuar con un chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:600
msgid "Redesigned primary and secondary menus"
msgstr "Rediseño de los menús primario y secundario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:601
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""
"Integración de YouTube: Pega la URL de un video con una transcripción y se "
"añadirá al mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:602
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""
"Integración de sitios web (Experimental): Extrae el texto del cuerpo de un "
"sitio web agregando su URL al mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:603
msgid "Chat title generation"
msgstr "Generación de título de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Auto resizing of message entry"
msgstr "Redimensionado automático de la entrada de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Chat notifications"
msgstr "Notificaciones de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Added indicator when an image is missing"
msgstr "Añadido indicador cuando falta una imagen"

#: data/com.jeffser.Alpaca.metainfo.xml.in:607
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""
"Reordenar automáticamente el orden de los chats cuando se recibe un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:608
msgid "Redesigned file preview dialog"
msgstr "Rediseño del diálogo de vista previa de archivos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:609
msgid "Credited new contributors"
msgstr "Agradecimientos a los nuevos colaboradores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:610
msgid "Better stability and optimization"
msgstr "Mejor estabilidad y optimización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:611
msgid "Edit messages to change the context of a conversation"
msgstr "Editar mensajes para cambiar el contexto de una conversación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:612
msgid "Added disclaimers when pulling models"
msgstr "Añadidos descargos de responsabilidad al seleccionar modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Preview files before sending a message"
msgstr "Previsualizar archivos antes de enviar un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:614
msgid "Better format for date and time on messages"
msgstr "Mejor formato para la fecha y hora en los mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:615
msgid "Error and debug logging on terminal"
msgstr "Registro de errores y depuración en la terminal"

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
msgid "Auto-hiding sidebar button"
msgstr "Botón de barra lateral que se oculta automáticamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:617
msgid "Various UI tweaks"
msgstr "Diversos ajustes en la interfaz de usuario"

#: data/com.jeffser.Alpaca.metainfo.xml.in:619
msgid "New Models"
msgstr "Nuevos Modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Gemma2"
msgstr "Gemma2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "GLM4"
msgstr "GLM4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Codegeex4"
msgstr "Codegeex4"

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "InternLM2"
msgstr "InternLM2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Llama3-groq-tool-use"
msgstr "Llama3-groq-tool-use"

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Mathstral"
msgstr "Mathstral"

#: data/com.jeffser.Alpaca.metainfo.xml.in:627
msgid "Mistral-nemo"
msgstr "Mistral-nemo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:628
msgid "Firefunction-v2"
msgstr "Firefunction-v2"

#: data/com.jeffser.Alpaca.metainfo.xml.in:629
msgid "Nuextract"
msgstr "Nuextract"

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "Translations"
msgstr "Traducciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""
"Estas son todas las traducciones disponibles en la versión 1.0.0, ¡gracias a "
"todos los colaboradores!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:634
msgid "Russian: Alex K"
msgstr "Ruso: Alex K"

#: data/com.jeffser.Alpaca.metainfo.xml.in:635
msgid "Spanish: Jeffser"
msgstr "Español: Jeffser"

#: data/com.jeffser.Alpaca.metainfo.xml.in:636
msgid "Brazilian Portuguese: Daimar Stein"
msgstr "Portugués brasileño: Daimar Stein"

#: data/com.jeffser.Alpaca.metainfo.xml.in:637
msgid "French: Louis Chauvet-Villaret"
msgstr "Francés: Louis Chauvet-Villaret"

#: data/com.jeffser.Alpaca.metainfo.xml.in:638
msgid "Norwegian: CounterFlow64"
msgstr "Noruego: CounterFlow64"

#: data/com.jeffser.Alpaca.metainfo.xml.in:639
msgid "Bengali: Aritra Saha"
msgstr "Bengalí: Aritra Saha"

#: data/com.jeffser.Alpaca.metainfo.xml.in:640
msgid "Simplified Chinese: Yuehao Sui"
msgstr "Chino simplificado: Yuehao Sui"

#: data/com.jeffser.Alpaca.metainfo.xml.in:648
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""
"Removida compatibilidad con DOCX temporalmente debido a un error con la "
"dependencia python-lxml"

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
#: data/com.jeffser.Alpaca.metainfo.xml.in:684
#: data/com.jeffser.Alpaca.metainfo.xml.in:705
#: data/com.jeffser.Alpaca.metainfo.xml.in:910
#: data/com.jeffser.Alpaca.metainfo.xml.in:967
msgid "Big Update"
msgstr "Gran Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:656
msgid "Added compatibility for PDF"
msgstr "Añadida compatibilidad para PDF"

#: data/com.jeffser.Alpaca.metainfo.xml.in:657
msgid "Added compatibility for DOCX"
msgstr "Añadida compatibilidad para DOCX"

#: data/com.jeffser.Alpaca.metainfo.xml.in:658
msgid "Merged 'file attachment' menu into one button"
msgstr "Combinado menu 'subir archivos' en un botón"

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
#: data/com.jeffser.Alpaca.metainfo.xml.in:858
msgid "Quick Fix"
msgstr "Arreglo rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:666
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""
"Hubieron unos errores mientras los chats transicionaban a la nueva versión. "
"Pido disculpas si eso causo alguna corrupción en to historial de chats. Esta "
"debería de ser la única vez que una transición es necesaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:672
#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Huge Update"
msgstr "Gran Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:674
msgid "Added: Support for plain text files"
msgstr "Añadido: Soporte para archivos de texto plano"

#: data/com.jeffser.Alpaca.metainfo.xml.in:675
msgid "Added: New backend system for storing messages"
msgstr "Añadido: Nuevo sistema en el backend para guardar mensajes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:676
msgid "Added: Support for changing Ollama's overrides"
msgstr "Añadido: Soporte para cambiar overrides de Ollama"

#: data/com.jeffser.Alpaca.metainfo.xml.in:677
msgid "General Optimization"
msgstr "Optimización general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:686
msgid "Added: Support for GGUF models (experimental)"
msgstr "Añadido: Soporte de modelos GGUF (experimental)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:687
msgid "Added: Support for customization and creation of models"
msgstr "Añadido: Soporte para personalización y creración de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:688
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr "Arreglado: Iconos no se mostraban en sistemas que no usan Gnome"

#: data/com.jeffser.Alpaca.metainfo.xml.in:689
msgid "Update Ollama to v0.1.39"
msgstr "Ollama actualizado a v0.1.39"

#: data/com.jeffser.Alpaca.metainfo.xml.in:698
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""
"Arreglado: La aplicación no abre si 'models tweaks' no esta presente en los "
"archivos de configuración"

#: data/com.jeffser.Alpaca.metainfo.xml.in:707
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""
"Multiples iconos cambiados (avion de papel para el boton de enviar mensaje)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:708
msgid "Combined export / import chat buttons into a menu"
msgstr "Botones importar / exportar chat combinados en un menu"

#: data/com.jeffser.Alpaca.metainfo.xml.in:709
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr "Añadidos ajustes de modelo (temperatura, semilla, mantener vivo)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:710
msgid "Fixed send / stop button"
msgstr "Arreglado boton enviar / parar"

#: data/com.jeffser.Alpaca.metainfo.xml.in:711
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""
"Arreglado: Aplicación no chequea si la conexión remota funciona cuando inicia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:718
msgid "Daily Update"
msgstr "Actulización Diaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:720
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""
"Añadido elipsis a el nombre del chat para que no afecte el largo del boton"

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr "Nuevo atajo de teclado para crear chat (CTRL+N)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:722
msgid "New message entry design"
msgstr "Nuevo diseño para el entry de mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Fixed: Can't rename the same chat multiple times"
msgstr "Arreglado: No se puede renombrar el mismo chat multiples veces"

#: data/com.jeffser.Alpaca.metainfo.xml.in:730
msgid "The fix"
msgstr "Arreglos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:732
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""
"Arreglado: Instancia de Ollama sigue siendo ejecutada en el fondo aunque sea "
"desactivada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:733
msgid "Fixed: Can't pull models on the integrated instance"
msgstr "Arreglado: No se puede descargar modelos en la instancia integrada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Quick tweaks"
msgstr "Arreglos rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Added progress bar to models that are being pulled"
msgstr "Añadida barra de progreso a modelos que estan siendo descargados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Added size to tags when pulling a model"
msgstr "Añadido tamaño de tags cuando se descarga un modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "General optimizations on the background"
msgstr "Optimizaciones general en el fondo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Quick fixes"
msgstr "Arreglos rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:753
msgid "Fixed: Scroll when message is received"
msgstr "Arreglado: Desplazamiento automatico cuando un mensaje es recibido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr "Arreglad: Contenido no cambia cuando se crea un nuevo chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:755
msgid "Added 'Featured Models' page on welcome dialog"
msgstr "Añadida sección 'Modelos Destacados' en el dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Nice Update"
msgstr "Buena Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "UI tweaks (Thanks Nokse22)"
msgstr "Mejor UI en general (Gracias Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Metadata fixes"
msgstr "Correciones de metadata"

#: data/com.jeffser.Alpaca.metainfo.xml.in:773
msgid "Quick fix"
msgstr "Arreglo rápido"

#: data/com.jeffser.Alpaca.metainfo.xml.in:775
msgid "Updated Spanish translation"
msgstr "Actualización a la traducción a Español"

#: data/com.jeffser.Alpaca.metainfo.xml.in:776
msgid "Added compatibility for PNG"
msgstr "Añadida compatibilidad para PNG"

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid "New Update"
msgstr "Nueva Actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:785
msgid "Updated model list"
msgstr "Lista de modelos actualizada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:786
msgid "Added image recognition to more models"
msgstr "Añadido reconocimiento de imagenes a más modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:787
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr "Añadida tradución a Portugues Brasileño (Gracias Daimaar Stein)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:788
msgid "Refined the general UI (Thanks Nokse22)"
msgstr "Mejor UI en general (Gracias Nokse22)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:789
msgid "Added 'delete message' feature"
msgstr "Añadida función 'eliminar mensaje'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:790
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""
"Añadida metadata para que distribuidores de software puedan saber que la "
"aplicación es compatible con celulares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:791
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""
"Cambiado el atajo para enviar mensaje a solo la tecla enter (para hacer "
"salto de linea usa shift+enter)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:798
msgid "Bug Fixes"
msgstr "Arreglo de errores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
msgid "Fixed: Minor spelling mistake"
msgstr "Arregalada falta de ortografía"

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Added 'mobile' as a supported form factor"
msgstr "Añadido soporte para celulares"

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr "Arreglado: Dialogo 'Error de conexión' no funcionando correctamente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:803
msgid "Fixed: App might freeze randomly on startup"
msgstr "Arreglado: Aplicación se congela al azar cuando inicia"

#: data/com.jeffser.Alpaca.metainfo.xml.in:804
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr "Cambiado label 'chats' en la barra lateral por 'Alpaca'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:811
msgid "Cool Update"
msgstr "Actualización Potente"

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
msgid "Better design for chat window"
msgstr "Mejor diseño para la ventana de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
msgid "Better design for chat sidebar"
msgstr "Mejor interfaz para la barra lateral de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:815
msgid "Fixed remote connections"
msgstr "Conexión remota arreglada"

#: data/com.jeffser.Alpaca.metainfo.xml.in:816
msgid "Fixed Ollama restarting in loop"
msgstr "Arreglado, Ollama reiniciandose en bucle"

#: data/com.jeffser.Alpaca.metainfo.xml.in:817
msgid "Other cool backend stuff"
msgstr "Otras cosas geniales en el backend"

#: data/com.jeffser.Alpaca.metainfo.xml.in:826
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr "Añadido Ollama como parte de Alpaca, Ollama se ejecutara en un sandbox"

#: data/com.jeffser.Alpaca.metainfo.xml.in:827
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""
"Añadida la opcion de conectarse a instancias remotas (como funcionaba) antes"

#: data/com.jeffser.Alpaca.metainfo.xml.in:828
msgid "Added option to import and export chats"
msgstr "Añadida la opcion de importar y exportar chats"

#: data/com.jeffser.Alpaca.metainfo.xml.in:829
msgid "Added option to run Alpaca with Ollama in the background"
msgstr "Añadida la opcion de ejecutar Alpaca y Ollama en el fondo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:830
msgid "Added preferences dialog"
msgstr "Añadido dialogo de preferencias"

#: data/com.jeffser.Alpaca.metainfo.xml.in:831
msgid "Changed the welcome dialog"
msgstr "Nuevo dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
#: data/com.jeffser.Alpaca.metainfo.xml.in:850
#: data/com.jeffser.Alpaca.metainfo.xml.in:862
#: data/com.jeffser.Alpaca.metainfo.xml.in:881
#: data/com.jeffser.Alpaca.metainfo.xml.in:902
#: data/com.jeffser.Alpaca.metainfo.xml.in:918
#: data/com.jeffser.Alpaca.metainfo.xml.in:934
#: data/com.jeffser.Alpaca.metainfo.xml.in:948
#: data/com.jeffser.Alpaca.metainfo.xml.in:958
#: data/com.jeffser.Alpaca.metainfo.xml.in:976
#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid "Please report any errors to the issues page, thank you."
msgstr "Por favor reporta cualquier error a la página de problemas, gracias."

#: data/com.jeffser.Alpaca.metainfo.xml.in:841
msgid "Yet Another Daily Update"
msgstr "Otra Actulización Diaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Added better UI for 'Manage Models' dialog"
msgstr "Añadida mejor interfaz para el dialogo 'gestión de modelos'"

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Added better UI for the chat sidebar"
msgstr "Añadida mejor interfaz para la barra lateral de chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:845
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""
"Remplazada la descripción de modelo por un botón para abrir la página web de "
"Ollama para el modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Added myself to the credits as the spanish translator"
msgstr "Agregue mi nombre en los creditos como el traductor a Español"

#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "Using XDG properly to get config folder"
msgstr "Usando XDG apropiadamente para obtener el folder de configuración"

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "Update for translations"
msgstr "Actualización para traducciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:860
msgid "The last update had some mistakes in the description of the update"
msgstr ""
"La última actualización tenía unos errores en la descripción de la "
"actualización"

#: data/com.jeffser.Alpaca.metainfo.xml.in:870
msgid "Another Daily Update"
msgstr "Otra Actulización Diaria"

#: data/com.jeffser.Alpaca.metainfo.xml.in:872
msgid "Added full Spanish translation"
msgstr "Añadida traducción completa a Español"

#: data/com.jeffser.Alpaca.metainfo.xml.in:873
msgid "Added support for background pulling of multiple models"
msgstr "Añadido soporte para descargar multiples modelos en el fondo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:874
msgid "Added interrupt button"
msgstr "Añadido botón de interrupción"

#: data/com.jeffser.Alpaca.metainfo.xml.in:875
msgid "Added basic shortcuts"
msgstr "Añadidos atajos de teclado basicos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:876
msgid "Better translation support"
msgstr "Mejor soporte para traducciones"

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""
"El usuario ahora puede dejar el nombre del chat vacio durante la creación, "
"la aplicación añadira un placeholder"

#: data/com.jeffser.Alpaca.metainfo.xml.in:878
msgid "Better scalling for different window sizes"
msgstr "Mejor escalado para distintos tamaños de ventana"

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "Fixed: Can't close app if first time setup fails"
msgstr "Arreglado: No se puede cerrar la aplicación en el primer setup"

#: data/com.jeffser.Alpaca.metainfo.xml.in:889
msgid "Really Big Update"
msgstr "Actualización Bastante Grande"

#: data/com.jeffser.Alpaca.metainfo.xml.in:891
msgid "Added multiple chats support!"
msgstr "Añadido soporte para multiples chats!"

#: data/com.jeffser.Alpaca.metainfo.xml.in:892
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""
"Añadido soporte para Pango Markup (negrita, lista, titulo, subtitulo, "
"monoespaciado)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:893
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""
"Añadido autoscroll si el usuario se encuentra en la parte inferior del chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:894
msgid "Added support for multiple tags on a single model"
msgstr "Añadido soporte para multiples etiquetas con un solo modelo"

#: data/com.jeffser.Alpaca.metainfo.xml.in:895
msgid "Added better model management dialog"
msgstr "Añadido mejor gestión de modelos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:896
msgid "Added loading spinner when sending message"
msgstr "Añadido spinner de carga cuando se envia un mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:897
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""
"Añadidas notificaciones si la aplicación no está activa y la descarga de un "
"modelo finaliza"

#: data/com.jeffser.Alpaca.metainfo.xml.in:898
msgid "Added new symbolic icon"
msgstr "Añadido nuevo icono simbolico"

#: data/com.jeffser.Alpaca.metainfo.xml.in:899
msgid "Added frame to message textview widget"
msgstr "Añadido borde al objeto textview del mensaje"

#: data/com.jeffser.Alpaca.metainfo.xml.in:900
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr "Arreglado \"bloques de codigo no deberían de ser editables\""

#: data/com.jeffser.Alpaca.metainfo.xml.in:912
msgid "Added code highlighting"
msgstr "Añadido resaltado de código"

#: data/com.jeffser.Alpaca.metainfo.xml.in:913
msgid "Added image recognition (llava model)"
msgstr "Añadido reconocimiento de imagenes (modelo llava)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:914
msgid "Added multiline prompt"
msgstr "Añadido caja de texto de multiples lineas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:915
msgid "Fixed some small bugs"
msgstr "Arreglados unos pequeños errores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid "General optimization"
msgstr "Optimización general"

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid "Fixes and features"
msgstr "Arreglos y funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr "Traducción a Ruso (gracias github/alexkdeveloper)"

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "Fixed: Cannot close app on first setup"
msgstr "Arreglado: No se puede cerrar la aplicación en el primer setup"

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "Fixed: Brand colors for Flathub"
msgstr "Arreglado: Colores de marca para Flathub"

#: data/com.jeffser.Alpaca.metainfo.xml.in:931
msgid "Fixed: App description"
msgstr "Arreglado: Descripción de aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:932
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""
"Arreglado: Solo mostrar el dialogo 'guardar cambios' cuando se cambia el url"

#: data/com.jeffser.Alpaca.metainfo.xml.in:942
msgid "0.2.2 Bug fixes"
msgstr "0.2.2 Arreglo de errores"

#: data/com.jeffser.Alpaca.metainfo.xml.in:944
msgid "Toast messages appearing behind dialogs"
msgstr "Mensajes toast apareciendo detrás de dialogos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:945
msgid "Local model list not updating when changing servers"
msgstr ""
"Lista de modelos locales no es actualizada cuando se cambia el servidor"

#: data/com.jeffser.Alpaca.metainfo.xml.in:946
msgid "Closing the setup dialog closes the whole app"
msgstr "Cerrar el dialogo de setup cierra toda la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:956
msgid "0.2.1 Data saving fix"
msgstr "0.2.1 Arreglo en el guardado de datos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:957
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""
"La aplicación no guardaba los archivos de configuración o los chats en el "
"directorio correcto, esto ahora ha sido arreglado"

#: data/com.jeffser.Alpaca.metainfo.xml.in:966
msgid "0.2.0"
msgstr "0.2.0"

#: data/com.jeffser.Alpaca.metainfo.xml.in:968
msgid "New Features"
msgstr "Nuevas funcionalidades"

#: data/com.jeffser.Alpaca.metainfo.xml.in:970
msgid "Restore chat after closing the app"
msgstr "Restaurar chat despues de cerrar la aplicación"

#: data/com.jeffser.Alpaca.metainfo.xml.in:971
msgid "A button to clear the chat"
msgstr "Un botón para limpiar el chat"

#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid "Fixed multiple bugs involving how messages are shown"
msgstr "Arreglados multiples errores acerca de como los mensajes son mostrados"

#: data/com.jeffser.Alpaca.metainfo.xml.in:973
msgid "Added welcome dialog"
msgstr "Añadido dialogo de bienvenida"

#: data/com.jeffser.Alpaca.metainfo.xml.in:974
msgid "More stability"
msgstr "Más estabilidad"

#: data/com.jeffser.Alpaca.metainfo.xml.in:984
msgid "0.1.2 Quick fixes"
msgstr "0.1.2 Arreglos rápidos"

#: data/com.jeffser.Alpaca.metainfo.xml.in:985
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""
"Esta versión arregla metadatos necesarios para tener un aplicación de "
"Flatpak justa"

#: data/com.jeffser.Alpaca.metainfo.xml.in:991
msgid "0.1.1 Stable Release"
msgstr "0.1.1"

#: data/com.jeffser.Alpaca.metainfo.xml.in:992
msgid "This is the first public version of Alpaca"
msgstr "Esta es la primera versión publica de Alpaca"

#: src/window.py:143 src/window.py:150 src/window.ui:467 src/window.ui:477
#: src/window.ui:499
msgid "Add Instance"
msgstr "Agregar instancia"

#: src/window.py:151
msgid "Select a type of instance to add"
msgstr "Seleccione un tipo de instancia para agregar"

#: src/window.py:338 src/window.py:898
msgid "Please select a model before chatting"
msgstr "Por favor selecciona un modelo antes de enviar un mensaje"

#: src/window.py:377 src/window.py:378 src/window.py:431 src/window.ui:320
msgid "Close"
msgstr "Cerrar"

#: src/window.py:380 src/window.py:381 src/window.ui:82 src/window.ui:83
msgid "Next"
msgstr "Siguiente"

#: src/window.py:429 src/instance_manager.py:405 src/instance_manager.py:406
#: src/instance_manager.py:514 src/instance_manager.py:515
#: src/instance_manager.py:656 src/instance_manager.py:657 src/window.ui:916
#: src/window.ui:920 src/custom_widgets/message_widget.py:60
#: src/custom_widgets/message_widget.py:199
#: src/custom_widgets/model_manager_widget.py:380
#: src/custom_widgets/dialog_widget.py:149
#: src/custom_widgets/dialog_widget.py:161
#: src/custom_widgets/dialog_widget.py:173
msgid "Cancel"
msgstr "Cancelar"

#: src/window.py:430
msgid "Hide"
msgstr "Esconder"

#: src/window.py:434
msgid "Close Alpaca?"
msgstr "¿Cerrar Alpaca?"

#: src/window.py:435
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr "Hay una tarea en curso. ¿Estás seguro de que deseas cerrar Alpaca?"

#: src/window.py:665
msgid "Cannot open image"
msgstr "No se pudo abrir la imagen"

#: src/window.py:771
msgid "Delete Chat?"
msgstr "¿Eliminar Chat?"

#: src/window.py:772
msgid "Are you sure you want to delete '{}'?"
msgstr "¿Estás seguro de que quieres eliminar '{}'?"

#: src/window.py:774
msgid "Delete"
msgstr "Eliminar"

#: src/window.py:781
msgid "Rename Chat?"
msgstr "¿Renombrar Chat?"

#: src/window.py:782
msgid "Renaming '{}'"
msgstr "Renombrando '{}'"

#: src/window.py:784
msgid "Chat name"
msgstr "Nombre de Chat"

#: src/window.py:785
msgid "Rename"
msgstr "Renombrar"

#: src/window.py:790
msgid "Importable (.db)"
msgstr "Importable (.db)"

#: src/window.py:791
msgid "Markdown"
msgstr "Markdown"

#: src/window.py:792
msgid "Markdown (Obsidian Style)"
msgstr "Markdown (Estilo Obsidian)"

#: src/window.py:793
msgid "JSON"
msgstr "JSON"

#: src/window.py:794
msgid "JSON (Include Metadata)"
msgstr "JSON (Incluir Metadata)"

#: src/window.py:797 src/window.ui:1173 src/window.ui:1211
msgid "Export Chat"
msgstr "Exportar chat"

#: src/window.py:798
msgid "Select a method to export the chat"
msgstr "Seleccione un método para exportar el chat"

#: src/window.py:814
msgid "This video does not have any transcriptions"
msgstr "Este video no tiene transcripciones"

#: src/window.py:821
msgid "Attach YouTube Video?"
msgstr "¿Adjuntar Video de YouTube?"

#: src/window.py:822
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"Por favor selecciona la transcripción ha incluir"

#: src/window.py:828
msgid "Error attaching video, please try again"
msgstr "Error adjuntando video, por favor intenta denuevo"

#: src/window.py:849 src/window.py:1112
msgid "Attach Website? (Experimental)"
msgstr "¿Adjuntar Sitio Web? (Experimental)"

#: src/window.py:850
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"¿Estás seguro de que quieres adjuntar\n"
"'{}'?"

#: src/window.py:868 src/window.py:880 src/window.py:1111
#: src/generic_actions.py:99
msgid "Image recognition is only available on specific models"
msgstr ""
"Reconocimiento de imagenes esta disponible solamente en modelos compatibles"

#: src/window.py:900 src/window.ui:998
msgid "Quick Ask"
msgstr "Pregunta Rápida"

#: src/window.py:1022
msgid "Attachment failed, screenshot might be too big"
msgstr "Adjuntado fallo, captura de pantalla puede ser muy grande"

#: src/window.py:1036
msgid "Any compatible Alpaca attachment"
msgstr "Cualquier archivo compatible con Alpaca"

#: src/window.py:1096
msgid "Clear Chat?"
msgstr "¿Limpiar Chat?"

#: src/window.py:1096
msgid "Are you sure you want to clear the chat?"
msgstr "¿Estás seguro de que quieres limpiar el chat?"

#: src/window.py:1096
msgid "Clear"
msgstr "Limpiar"

#: src/window.py:1112
msgid "Please enter a website URL"
msgstr "Por favor, introduzca la URL de un sitio web"

#: src/window.py:1113
msgid "Attach YouTube Captions?"
msgstr "¿Adjuntar subtítulos de YouTube?"

#: src/window.py:1113
msgid "Please enter a YouTube video URL"
msgstr "Por favor, introduzca la URL de un vídeo de YouTube"

#: src/window.py:1116
msgid "Download Model?"
msgstr "¿Descargar modelo?"

#: src/window.py:1116
msgid "Please enter the model name following this template: name:tag"
msgstr ""
"Por favor, introduzca el nombre del modelo siguiendo esta plantilla: "
"nombre:etiqueta"

#: src/window.py:1127
msgid "Remove Attachment?"
msgstr "¿Remover Adjunto?"

#: src/window.py:1127
msgid "Are you sure you want to remove attachment?"
msgstr "¿Estás seguro de que quieres remover el adjunto?"

#: src/window.py:1127 src/instance_manager.py:773
#: src/custom_widgets/model_manager_widget.py:381
#: src/custom_widgets/model_manager_widget.py:423
msgid "Remove"
msgstr "Remover"

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"Nuevo modelo 70B de última generación. Llama 3.3 70B ofrece un rendimiento "
"similar al modelo Llama 3.1 405B."

#: src/available_models_descriptions.py:3
msgid ""
"QwQ is an experimental research model focused on advancing AI reasoning "
"capabilities."
msgstr ""
"QwQ es un modelo de investigación experimental centrado en mejorar las "
"capacidades de razonamiento de la IA."

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision es una colección de modelos generativos de razonamiento de "
"imágenes ajustados por instrucciones en tamaños 11B y 90B."

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Llama 3.2 de Meta es pequeño con modelos 1B y 3B."

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr ""
"Llama 3.1 es un nuevo modelo de vanguardia de Meta disponible en tamaños de "
"8B, 70B y 405B."

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3: El LLM abierto más capaz a esta fecha."

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "El modelo 7B lanzado por Mistral AI, actualizado a la versión 0.3."

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr ""
"Un modelo de integración abierto de alto rendimiento con una gran ventana de "
"contexto de token."

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr ""
"Gemma es una familia de nuevos modelos abiertos livianos construidos por "
"Google DeepMind. Actualizado a la versión 1.1."

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr ""
"Qwen 1.5 es una serie de LLM por Alibaba Cloud que cubren parametros entre "
"0.5B hasta 110B."

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 es una nueva serie de LLM del grupo Alibaba."

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 es una familia de los ultimos modelos livianos de Microsoft, 3B (Mini) "
"y 14B (Medium)."

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr ""
"Llama 2 es una colección de modelos bases que cubren parametros entre 7B y "
"70B."

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Los modelos Qwen2.5 están entrenados previamente con el último conjunto de "
"datos a gran escala de Alibaba, que abarca hasta 18 billones de tokens. El "
"modelo admite hasta 128 000 tokens y tiene soporte multilingüe."

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr ""
"Google Gemma 2 es un modelo de alto rendimiento y eficiente disponible en "
"tres tamaños: 2B, 9B y 27B."

#: src/available_models_descriptions.py:17
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA es un nuevo LLM entrenado en end-to-end que combina un "
"encodificador visual y Vicuna para entendimiento general en lenguaje y "
"visión. Acutalizado a la versión 1.6."

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr "Un LLM que puede usar texto para generar y discutir sobre codigo."

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"La última serie de modelos Qwen específicos de código, con mejoras "
"significativas en la generación de código, el razonamiento de código y la "
"corrección de código."

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr ""
"Un modelo de vanguardia de 12B con una longitud de contexto de 128k, "
"construido por Mistral AI en colaboración con NVIDIA."

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"El proyecto TinyLlama es un esfuerzo abierto para entrenar un modelo "
"compacto de Llama de 1.1B en 3 billones de tokens."

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "Modelo de integración grande de última generación de Mixedbread.ai"

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 es la próxima generación de modelos de lenguaje abiertos "
"entrenados de manera transparente, que vienen en tres tamaños: 3B, 7B y 15B "
"parámetros."

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Un set de modelos Mixture-of-Experts (MoE) con pesos abiertos por Mistral AI "
"dispnible en tamaños de parametros 8x7b y 8x22b."

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"Descensurado, 8x7b y 8x22b, modelos afinados basados enn una mezcla de "
"modelos expertos de Mixtral especializados en tareas de codigo. Creado por "
"Eric Hartford."

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma es una colección de poderosos, modelos livianos que pueden hacer "
"una variedad de tareas de codigo como fill-in-the-middle completación de "
"codigo, generación de codigo, comprensión de lenguaje natural, razonamiento "
"matematico y seguimiento de instrucciones."

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"Un modelo de lenguaje Mixturer-of-Experts abierto que consigue un "
"rendimiento comparable a GPT4-Turbo en tareas especificas a codigo."

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr ""
"Phi-2: un modelo de lenguaje de 2.700 millones de Microsoft Research que "
"demuestra excelentes capacidades de razonamiento y comprensión del lenguaje."

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "Modelo Llama 2 descensurado por George Sung y Jarrad Hope."

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder en un modelo especializado en codigo, entrenado en 2 "
"trillones de tokens de codigo y lenguaje natural."

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr ""
"Un conjunto de modelos de incrustación de texto por Snowflake, optimizados "
"para el rendimiento."

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"Modelo de lenguaje grande de vanguardia de Microsoft AI con rendimiento "
"mejorado en chat complejo, multilingüe, razonamiento y casos de uso de "
"agentes."

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr ""
"El modelo descensurado Dolphin, basado en Mistral que sobresale en tareas de "
"codigo. Actualizado a la versión 2.8."

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 es un modelo nuevo con tamaños de 8B y 70B hecho por Eric "
"Hartford basado en Llama 3, tiene una variedad de instrucciones "
"conversacionales y habilidades en código"

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 es un modelo de lenguaje bilingüe de alto rendimiento."

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr ""
"Command R es un LLM optimizado para interacciones conversacionales y tareas "
"que requieren un contexto largo."

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr ""
"Un modelo de uso general oscilando entre 3 billones hasta 70 billones de "
"parametros, adecuado para hardware básico."

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr ""
"Un modelo LLaVA ajustado a partir de Llama 3 Instruct con mejores "
"puntuaciones en varios benchmarks."

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr es una serie de versiones ajustadas de los modelos Mistral y Mixtral "
"que están entrenados para actuar como asistentes útiles."

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr ""
"Un modelo de IA liviano con 3.8 mil millones de parámetros con un "
"rendimiento que supera a modelos similares y de mayor tamaño."

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr ""
"Modelos de incrustación en conjuntos de datos de nivel de oración muy "
"grandes."

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr ""
"Codestral es el primer modelo de código de Mistral AI diseñado para tareas "
"de generación de código."

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr ""
"StarCoder es un modelo de generación de código entrenado en más de 80 "
"lenguajes de programación."

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr ""
"Modelo de chat de uso general basado en Llama y Llama 2 con tamaños de "
"contexto de 2K a 16K."

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr ""
"Una familia de modelos de base abiertos por IBM para Code Intelligence."

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca es un modelo de 7 billones de parametros, afinado con base "
"en el modelo Mistral 7B usando el dataset de OpenOrca."

#: src/available_models_descriptions.py:47
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 Una familia de modelos pequeños con 135M, 360M y 1.7B de parámetros, "
"entrenados en un nuevo conjunto de datos de alta calidad."

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored es un modelo de 7B, 13B y 30B parámetros basado en "
"Llama 2 sin censura por Eric Hartford."

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr ""
"Modelo basado en Llama 2 ajustado para mejorar la capacidad de diálogo en "
"chino."

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr ""
"BGE-M3 es un nuevo modelo de BAAI que se distingue por su versatilidad en "
"multifuncionalidad, multilingüismo y multigranularidad."

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr ""
"Un modelo versátil para escenarios de desarrollo de software de IA, "
"incluyendo la finalización de código."

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"Una familia de modelos de código abierto entrenados en una amplia variedad "
"de datos, superando a ChatGPT en varios benchmarks. Actualizado a la versión "
"3.5-0106."

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr ""
"Aya 23, lanzado por Cohere, es una familia de los ultimos modelos "
"multilingües que soportan 23 lenguajes."

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr ""
"CodeQwen1.5 es un modelo de lenguaje grande preentrenado con una gran "
"cantidad de datos de código."

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr ""
"La poderosa familia de modelos de Nous Research que sobresale en discusiones "
"científicas y tareas de programación."

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ es un poderoso, escalable LLM construido con el proposito de "
"sobresalir en usos profesionales del mundo real."

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "Modelo de generación de código de vanguardia."

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B es un modelo de codificación con variantes de instrucción y "
"completado de código a la par con modelos como Code Llama 7B que son 2.5 "
"veces más grandes."

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Un modelo experimental de 1.1B parámetros entrenado en el nuevo conjunto de "
"datos Dolphin 2.8 por Eric Hartford y basado en TinyLlama."

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 es un modelo de 7B ajustado por Teknium en Mistral con "
"conjuntos de datos completamente abiertos."

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 es el nuevo modelo insignia de Mistral que es "
"significativamente más capaz en generación de código, matemáticas y "
"razonamiento, con una ventana de contexto de 128k y soporte para docenas de "
"idiomas."

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math es una serie de modelos de lenguaje matemático especializados "
"creados sobre la base de los LLM de Qwen2, que superan significativamente "
"las capacidades matemáticas de los modelos de código abierto e incluso de "
"los modelos de código cerrado (por ejemplo, GPT4o)."

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr ""
"Un modelo de lenguaje general multilingüe con un rendimiento competitivo con "
"respecto a Llama 3."

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 es un modelo de lenguaje de vanguardia de 1.6B y 12B parámetros "
"entrenado en datos multilingües en inglés, español, alemán, italiano, "
"francés, portugués y neerlandés."

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr ""
"BakLLaVA es un modelo multimodal que consiste en el modelo base Mistral 7B "
"aumentado con la arquitectura LLaVA."

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"Un modelo de alto rendimiento entrenado con una nueva técnica llamada "
"Reflection-tuning que enseña a un LLM a detectar errores en su razonamiento "
"y corregir el rumbo."

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr ""
"Un modelo de lenguaje avanzado creado con 2 billones de tokens bilingües."

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr ""
"Este modelo extiende la longitud del contexto de LLama-3 8B de 8k a más de "
"1m tokens."

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "Modelo enfocado en problemas de matemáticas y lógica."

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr ""
"moondream2 es un pequeño modelo de lenguaje de visión diseñado para "
"funcionar eficientemente en dispositivos periféricos."

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr ""
"Un modelo ajustado basado en Mistral con buena cobertura de dominio y "
"lenguaje."

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"Un modelo de NVIDIA basado en Llama 3 que sobresale en respuesta a preguntas "
"conversacionales (QA) y generación aumentada por recuperación (RAG)."

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr ""
"Modelo conversacional basado en Llama 2 que tiene un rendimiento competitivo "
"en varios benchmarks."

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr ""
"SQLCoder es un modelo de completado de código ajustado en StarCoder para "
"tareas de generación de SQL."

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "Modelos de uso general basados en Llama y Llama 2 de Nous Research."

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "Modelo de generación de código basado en Code Llama."

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Una extensión de Llama 2 que soporta un contexto de hasta 128k tokens."

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr ""
"Una variante sin censura de 7B y 15B de la familia de modelos Dolphin que "
"sobresale en codificación, basada en StarCoder2."

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "Modelo de uso general basado en Llama 2."

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr ""
"Un modelo de lenguaje Mixture-of-Experts fuerte, económico y eficiente."

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling es un modelo de lenguaje grande entrenado mediante aprendizaje por "
"refuerzo a partir de retroalimentación de IA enfocado en mejorar la utilidad "
"de los chatbots."

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr ""
"Un asistente compañero entrenado en filosofía, psicología y relaciones "
"personales. Basado en Mistral."

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr ""
"Hermes 3 es la última versión de la serie insignia de LLM Hermes de Nous "
"Research"

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder es una serie de modelos de lenguaje de código de código abierto que "
"ofrece un rendimiento de codificación de última generación con menos de 10 "
"mil millones de parámetros."

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"Un modelo de lenguaje grande creado por el Instituto de Innovación "
"Tecnológica (TII) para su uso en resúmenes, generación de texto y chat bots."

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr ""
"InternLM2.5 es un modelo de 7B parámetros adaptado para escenarios prácticos "
"con una capacidad de razonamiento excepcional."

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr ""
"Un modelo de lenguaje grande compacto pero poderoso de 10.7B diseñado para "
"conversación de un solo turno."

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 es un modelo de parámetros 72B que se destaca en tareas de "
"finalización de código, matemáticas y extracción de registros."

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "Un nuevo pequeño modelo LLaVA ajustado a partir de Phi 3 Mini."

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 es construido por Microsoft Research, y es una versión ajustada de "
"los modelos Llama 2 de Meta. El modelo está diseñado para sobresalir "
"particularmente en razonamiento."

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr ""
"Una serie de LLM multimodales (MLLM) diseñados para la comprensión entre "
"visión y lenguaje."

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"Modelo basado en Llama 2 ajustado en un conjunto de datos estilo Orca. "
"Originalmente llamado Free Willy."

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small is a lightweight model designed for cost-effective use in "
"tasks like translation and summarization."
msgstr ""
"Mistral Small es un modelo liviano diseñado para un uso rentable en tareas "
"como traducción y resumen."

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Modelo Dolphin sin censura de 2.7B por Eric Hartford, basado en el modelo de "
"lenguaje Phi por Microsoft Research."

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 es una familia de modelos de lenguaje compactos disponibles en tres "
"tamaños: 135M, 360M y 1.7B de parámetros."

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "Versión sin censura del modelo Wizard LM."

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"Un modelo de lenguaje pequeño comercialmente amigable de NVIDIA optimizado "
"para juegos de roles, control de calidad de RAG y llamada de funciones."

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr ""
"Una extensión de Mistral para soportar ventanas de contexto de 64K o 128K."

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Una expansión de Llama 2 que se especializa en integrar tanto la comprensión "
"general del lenguaje como el conocimiento específico del dominio, "
"particularmente en programación y matemáticas."

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr ""
"Modelo Llama 2 ajustado para responder preguntas médicas basado en un "
"conjunto de datos médicos de código abierto."

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr ""
"Modelo de lenguaje grande médico de código abierto adaptado de Llama 2 al "
"dominio médico."

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"Una serie de modelos de Groq que representan un avance significativo en las "
"capacidades de IA de código abierto para el uso de herramientas/llamadas a "
"funciones."

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct es un modelo de lenguaje grande "
"personalizado por NVIDIA para mejorar la utilidad de las respuestas "
"generadas por LLM a las consultas de los usuarios."

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr ""
"Nexus Raven es un modelo ajustado de 13B para tareas de llamada de funciones."

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr ""
"El modelo Nous Hermes 2 de Nous Research, ahora entrenado sobre Mixtral."

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "Gran modelo de generación de código basado en Llama2."

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr ""
"Modelo sin censura basado en Llama2 con soporte para una ventana de contexto "
"de 16K."

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"Los modelos IBM Granite 2B y 8B están diseñados para soportar casos de uso "
"basados ​​en herramientas y soporte para generación aumentada de recuperación "
"(RAG), agilizando la generación de código, la traducción y la corrección de "
"errores."

#: src/available_models_descriptions.py:109
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder es una familia de modelos de 7B parámetros entrenados en 75K "
"datos de instrucción sintética utilizando OSS-Instruct, un enfoque novedoso "
"para iluminar a los LLMs con fragmentos de código de código abierto."

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr ""
"Un modelo de chat ligero que permite una salida precisa y receptiva sin "
"requerir hardware de alta gama."

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr ""
"Un modelo de instrucción de código de alto rendimiento creado mediante la "
"fusión de dos modelos de código existentes."

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 es un modelo causal de 11B parámetros solo decodificador construido "
"por TII y entrenado en más de 5T tokens."

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr ""
"Wizard Vicuna es un modelo de 13B parámetros basado en Llama 2 entrenado por "
"MelodysDreamj."

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr ""
"MistralLite es un modelo ajustado basado en Mistral con capacidades "
"mejoradas de procesamiento de contextos largos."

#: src/available_models_descriptions.py:115
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr ""
"MathΣtral: un modelo de 7B diseñado para razonamiento matemático y "
"descubrimiento científico por Mistral AI."

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr ""
"Modelo de texto a SQL de 7B parámetros hecho por MotherDuck y Numbers "
"Station."

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b es una transformación de Dolphin-2.2-70b creada al "
"entrelazar el modelo consigo mismo."

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Vista previa de Solar Pro: un modelo de lenguaje grande (LLM) avanzado con "
"22 mil millones de parámetros diseñado para caber en una sola GPU"

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"Una serie de modelos que convierten contenido HTML en contenido Markdown, lo "
"cual resulta útil para tareas de conversión de contenido."

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr ""
"Un modelo de mezcla de expertos de alto rendimiento, ajustado con datos de "
"alta calidad."

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr ""
"Un modelo de chat de 7B ajustado con datos de alta calidad y basado en "
"Zephyr."

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"Fusión del modelo Open Orca OpenChat y el modelo Garage-bAInd Platypus 2. "
"Diseñado para chat y generación de código."

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr ""
"Un modelo de lenguaje creado combinando dos modelos ajustados de Llama 2 70B "
"en uno."

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Los modelos IBM Granite 1B y 3B son la primera mezcla de modelos Granite de "
"expertos (MoE) de IBM diseñados para un uso de baja latencia."

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"Un modelo de 3.8B ajustado con un conjunto de datos sintéticos de alta "
"calidad para extracción de información, basado en Phi-3."

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr ""
"Cohere Para modelos de lenguaje de IA entrenados para funcionar bien en 23 "
"idiomas diferentes."

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX es un LLM abierto de propósito general creado por Databricks."

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"Un modelo de razonamiento abierto a gran escala para soluciones del mundo "
"real del Alibaba International Digital Commerce Group (AIDC-AI)."

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "Modelo de incrustación de BAAI que mapea textos a vectores."

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr ""
"Un modelo de llamadas a funciones con pesos abiertos basado en Llama 3, "
"competitivo con las capacidades de llamadas a funciones de GPT-4o."

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr ""
"Un modelo conversacional robusto diseñado para ser utilizado tanto en casos "
"de uso de chat como de instrucción."

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"Una versión mejorada de DeepSeek-V2 que integra las capacidades generales y "
"de codificación de DeepSeek-V2-Chat y DeepSeek-Coder-V2-Instruct."

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma es un conjunto de modelos de instrucciones optimizados para "
"evaluar la seguridad de las respuestas de entrada y salida de texto frente a "
"un conjunto de políticas de seguridad definidas."

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr ""
"Un modelo de verificación de datos de última generación desarrollado por "
"Bespoke Labs."

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 es una serie de modelos optimizados para la clasificación de "
"seguridad de contenido de entradas y respuestas LLM."

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr ""
"Modelo de transformadores de oraciones que puede utilizarse para tareas como "
"agrupamiento o búsqueda semántica."

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder es una familia LLM de código abierto y reproducible que incluye "
"modelos 1.5B y 8B y admite chat en los idiomas inglés y chino."

#: src/available_models_descriptions.py:138
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 es una familia de modelos de seguimiento de instrucciones líder que "
"ofrece datos, códigos y recetas de código totalmente abierto del Instituto "
"Allen para IA."

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Modelo de integración de vanguardia de Snowflake. Arctic Embed 2.0 agrega "
"compatibilidad multilingüe sin sacrificar el rendimiento ni la escalabilidad "
"en inglés."

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr ""
"Los modelos IBM Granite Guardian 3.0 2B y 8B están diseñados para detectar "
"riesgos en indicaciones y/o respuestas."

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 es una colección de modelos generativos bilingües (inglés y "
"coreano) optimizados para instrucciones que van desde 2.4B a 32B parámetros, "
"desarrollados y lanzados por LG AI Research."

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr ""
"Sailor2 son modelos de lenguaje multilingües diseñados para el sudeste "
"asiático. Disponibles en tamaños de parámetros 1B, 8B y 20B."

#: src/available_models_descriptions.py:143
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"Una familia de modelos de IA eficientes con un rendimiento de 10B de "
"parámetros en ciencias, matemáticas y codificación a través de técnicas de "
"entrenamiento innovadoras."

#: src/available_models_descriptions.py:144
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."

#: src/available_models_descriptions.py:145
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"Los modelos IBM Granite 1B y 3B son modelos Granite de mezcla de contexto "
"largo de expertos (MoE) de IBM diseñados para un uso de baja latencia."

#: src/available_models_descriptions.py:146
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"Los modelos IBM Granite Embedding 30M y 278M son modelos de incrustación de "
"biencoder densos de solo texto, con 30M disponible solo en inglés y 278M "
"para casos de uso multilingües."

#: src/available_models_descriptions.py:147
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr ""
"Phi-4 es un modelo abierto de última generación con 14B parámetros de "
"Microsoft."

#: src/available_models_descriptions.py:148
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr ""
"Un nuevo modelo de razonamiento pequeño perfeccionado a partir del modelo "
"Instruct 3B de Qwen 2.5."

#: src/available_models_descriptions.py:149
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 es la próxima generación de la serie Dolphin de "
"modelos optimizados por instrucciones, diseñados para ser el mejor modelo "
"local de propósito general, que permite codificación, matemáticas, agentes, "
"llamadas de funciones y casos de uso general."

#: src/available_models_descriptions.py:150
msgid ""
"DeepSeek's first generation reasoning models with comparable performance to "
"OpenAI-o1."
msgstr ""
"Modelos de razonamiento de primera generación de DeepSeek con un rendimiento "
"comparable a OpenAI-o1."

#: src/available_models_descriptions.py:151
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"Un sólido modelo de lenguaje de mezcla de expertos (MoE) con 671B de "
"parámetros totales con 37B activados para cada token."

#: src/available_models_descriptions.py:152
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 es una nueva familia de modelos 7B y 13B entrenados con tokens de "
"hasta 5T. Estos modelos están a la par o son mejores que los modelos "
"completamente abiertos de tamaño equivalente y son competitivos con modelos "
"de peso abierto como Llama 3.1 en los puntos de referencia académicos de "
"inglés."

#: src/available_models_descriptions.py:153
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"El modelo más pequeño de la serie R de Cohere ofrece velocidad, eficiencia y "
"calidad de primer nivel para crear potentes aplicaciones de IA en GPU "
"comerciales y dispositivos de edge."

#: src/instance_manager.py:28
msgid "Instance"
msgstr "Instancia"

#: src/instance_manager.py:57 src/window.ui:161
#: src/custom_widgets/chat_widget.py:397
msgid "New Chat"
msgstr "Nuevo Chat"

#: src/instance_manager.py:79 src/instance_manager.py:166
#: src/instance_manager.py:176 src/instance_manager.py:319
#: src/instance_manager.py:578 src/instance_manager.py:716
#: src/instance_manager.py:744
msgid "Instance Error"
msgstr "Error de Instancia"

#: src/instance_manager.py:79
msgid "Message generation failed"
msgstr "Error en la generación del mensaje"

#: src/instance_manager.py:166 src/instance_manager.py:578
#: src/instance_manager.py:716 src/instance_manager.py:744
msgid "Could not retrieve added models"
msgstr "No se pudieron recuperar los modelos agregados"

#: src/instance_manager.py:176
msgid "Could not retrieve available models"
msgstr "No se pudieron recuperar los modelos disponibles"

#: src/instance_manager.py:244
msgid "Ollama (Managed)"
msgstr "Ollama (Administrado)"

#: src/instance_manager.py:273
msgid "Alpaca Support"
msgstr "Soporte de Alpaca"

#: src/instance_manager.py:280
msgid "Model request too large for system"
msgstr "Solicitud de modelo muy grande para el sistema"

#: src/instance_manager.py:283
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr ""
"GPU AMD detectada pero la extensión no está instalada, Ollama usará CPU."

#: src/instance_manager.py:285
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "GPU AMD detectada pero ROCm no está instalado, Ollama usará CPU."

#: src/instance_manager.py:287
msgid "Using AMD GPU type '{}'"
msgstr "Usando GPU AMD tipo '{}'"

#: src/instance_manager.py:297
msgid "Integrated Ollama instance is not running"
msgstr "Instancia integrada de Ollama no está corriendo"

#: src/instance_manager.py:319
msgid "Managed Ollama instance failed to start"
msgstr "La instancia de Ollama administrada no pudo iniciar"

#: src/instance_manager.py:322
msgid "Integrated Ollama instance is running"
msgstr "Instancia integrada de Ollama está corriendo"

#: src/instance_manager.py:326
msgid "Local AI instance managed directly by Alpaca"
msgstr "Instancia de IA local administrada directamente por Alpaca"

#: src/instance_manager.py:329 src/instance_manager.py:330
msgid "Ollama Log"
msgstr "Registro de Ollama"

#: src/instance_manager.py:335 src/instance_manager.py:471
#: src/instance_manager.py:593 src/window.ui:833
msgid "Name"
msgstr "Nombre"

#: src/instance_manager.py:341
msgid "Port"
msgstr "Puerto"

#: src/instance_manager.py:341
msgid "Which network port will Ollama use"
msgstr "El puerto de red que Ollama utilizará"

#: src/instance_manager.py:346 src/instance_manager.py:483
#: src/instance_manager.py:624
msgid "Temperature"
msgstr "Temperatura"

#: src/instance_manager.py:346 src/instance_manager.py:483
#: src/instance_manager.py:624
msgid "Increasing the temperature will make the models answer more creatively."
msgstr ""
"Aumentar la temperatura hará que los modelos respondan de forma más creativa."

#: src/instance_manager.py:349 src/instance_manager.py:486
#: src/instance_manager.py:628
msgid "Seed"
msgstr "Semilla"

#: src/instance_manager.py:349 src/instance_manager.py:486
#: src/instance_manager.py:628
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr ""
"Si se establece esto en un número específico distinto de 0, el modelo "
"generará el mismo texto para el mismo mensaje."

#: src/instance_manager.py:354
msgid "Model Directory"
msgstr "Directorio de Modelos"

#: src/instance_manager.py:356
msgid "Select Directory"
msgstr "Seleccionar Directorio"

#: src/instance_manager.py:367 src/instance_manager.py:492
#: src/instance_manager.py:634
msgid "Default Model"
msgstr "Modelo por Defecto"

#: src/instance_manager.py:367 src/instance_manager.py:492
#: src/instance_manager.py:634
msgid "Model to select when starting a new chat."
msgstr "Modelo a seleccionar al iniciar un nuevo chat."

#: src/instance_manager.py:369 src/instance_manager.py:494
#: src/instance_manager.py:636
msgid "Title Model"
msgstr "Modelo de Título"

#: src/instance_manager.py:369 src/instance_manager.py:494
#: src/instance_manager.py:636
msgid "Model to use when generating a chat title."
msgstr "Modelo a utilizar al generar un título de chat."

#: src/instance_manager.py:385
msgid "Overrides"
msgstr "Overrides"

#: src/instance_manager.py:385
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr ""
"Estas entradas son opcionales y se utilizan para solucionar problemas "
"relacionados con la GPU con Ollama."

#: src/instance_manager.py:412 src/instance_manager.py:413
#: src/instance_manager.py:521 src/instance_manager.py:522
#: src/instance_manager.py:663 src/instance_manager.py:664
#: src/custom_widgets/message_widget.py:203
msgid "Save"
msgstr "Guardar"

#: src/instance_manager.py:468
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "Instancia de IA local o remota no administrada por Alpaca"

#: src/instance_manager.py:474 src/instance_manager.py:596
msgid "Instance URL"
msgstr "URL de instancia"

#: src/instance_manager.py:477
msgid "API Key (Optional)"
msgstr "Clave API (Opcional)"

#: src/instance_manager.py:598 src/instance_manager.py:600
msgid "API Key (Unchanged)"
msgstr "Clave API (Sin Cambios)"

#: src/instance_manager.py:598 src/instance_manager.py:600
msgid "API Key"
msgstr "Clave API"

#: src/instance_manager.py:606
msgid "Max Tokens"
msgstr "Tokens Maximos"

#: src/instance_manager.py:607
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"Define la cantidad máxima de tokens (palabras + espacios) que la IA puede "
"generar en una respuesta. Más tokens permiten respuestas más largas, pero "
"pueden llevar más tiempo y costar más."

#: src/instance_manager.py:755
msgid "OpenAI Compatible Instance"
msgstr "Instancia Compatible con OpenAI"

#: src/instance_manager.py:773
msgid "Remove Instance?"
msgstr "¿Eliminar instancia?"

#: src/instance_manager.py:773
msgid "Are you sure you want to remove this instance?"
msgstr "¿Estás seguro de que quieres eliminar esta instancia?"

#: src/instance_manager.py:788
msgid "Edit Instance"
msgstr "Editar Instancia"

#: src/window.ui:33
msgid "Loading"
msgstr "Cargando"

#: src/window.ui:54
msgid "Welcome"
msgstr "Bienvenida"

#: src/window.ui:66 src/window.ui:67
msgid "Previous"
msgstr "Anterior"

#: src/window.ui:102
msgid "Welcome to Alpaca"
msgstr "Bienvenido a Alpaca"

#: src/window.ui:103
msgid "Powering your potential"
msgstr "Impulsando tu potencial"

#: src/window.ui:111
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""
"Alpaca y sus desarrolladores no son responsables de ningún daño a los "
"dispositivos o al software que resulte de la ejecución del código generado "
"por un modelo de IA. Tenga cuidado y revise el código con atención antes de "
"ejecutarlo.\n"
"\n"
"Alpaca se distribuye bajo la licencia GPL v3.0, este software no tiene "
"garantía."

#: src/window.ui:120
msgid "Effortless Code Execution"
msgstr "Ejecución de Código Sin Esfuerzo"

#: src/window.ui:121
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""
"Alpaca puede ejecutar Python, C++ e incluso HTML (con un servidor en vivo) "
"directamente desde tus conversaciones. ¡Pruébalo!"

#: src/window.ui:127
msgid "Your AI, Your Choice"
msgstr "Tu IA, Tu Elección"

#: src/window.ui:128
msgid ""
"Alpaca includes Ollama by default, giving you instant access to AI. "
"Customize your experience further by connecting to Google Gemini, OpenAI "
"ChatGPT, Together.AI, and more."
msgstr ""
"Alpaca incluye Ollama de forma predeterminada, lo que te da acceso "
"instantáneo a la IA. Personaliza aún más tu experiencia conectándote a "
"Google Gemini, OpenAI ChatGPT, Together.AI y más."

#: src/window.ui:134
msgid "Private by Design"
msgstr "Privado por Diseño"

#: src/window.ui:135
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""
"Con Alpaca, tus conversaciones se guardan localmente en tu dispositivo, por "
"lo que puedes estar seguro de que tus datos siempre están seguros y privados."

#: src/window.ui:172
msgid "Menu"
msgstr "Menu"

#: src/window.ui:194
msgid "Toggle Sidebar"
msgstr "Alternar Barra Lateral"

#: src/window.ui:201
msgid "Search Messages"
msgstr "Buscar Mensajes"

#: src/window.ui:221
msgid "Loading Instance"
msgstr "Cargando Instancia"

#: src/window.ui:241 src/window.ui:263 src/window.ui:269 src/window.ui:1143
msgid "Manage Models"
msgstr "Gestionar Modelos"

#: src/window.ui:281
msgid "Chat Menu"
msgstr "Menu de Chat"

#: src/window.ui:294
msgid "Message search bar"
msgstr "Barra de búsqueda de mensajes"

#: src/window.ui:303 src/window.ui:305
msgid "Search messages"
msgstr "Buscar mensajes"

#: src/window.ui:321
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr ""
"Advertencia: el modo de ahorro de energía está habilitado, esto ralentizará "
"la generación de mensajes."

#: src/window.ui:369 src/window.ui:1237
msgid "Attach File"
msgstr "Adjuntar Archivo"

#: src/window.ui:399
msgid "Send Message"
msgstr "Enviar Mensaje"

#: src/window.ui:418
msgid "Stop Message"
msgstr "Detener el Mensaje"

#: src/window.ui:448
msgid "Instance Manager"
msgstr "Gestor de Instancias"

#: src/window.ui:463
msgid "No Instances Found"
msgstr "Ningún Instancia Encontrada"

#: src/window.ui:464
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr "Parece un poco vacío aquí. ¡Agrega una instancia para empezar!"

#: src/window.ui:493
msgid "Added Instances"
msgstr "Instancias Agregadas"

#: src/window.ui:494
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr ""
"Administra tus instancias de IA, los chats y los mensajes se comparten entre "
"instancias al generar respuestas."

#: src/window.ui:529
msgid "Model Manager"
msgstr "Gestor de Modelos"

#: src/window.ui:565
msgid "Search Model"
msgstr "Buscar Modelo"

#: src/window.ui:579
msgid "Model Manager Menu"
msgstr "Menu del Gestor de Modelos"

#: src/window.ui:592
msgid "Model search bar"
msgstr "Barra de busqueda de modelos"

#: src/window.ui:601 src/window.ui:603
msgid "Search models"
msgstr "Buscar Modelos"

#: src/window.ui:617
msgid "Added"
msgstr "Agregado"

#: src/window.ui:627 src/window.ui:687 src/window.ui:741
msgid "No Models Found"
msgstr "Ningún Modelo Encontrado"

#: src/window.ui:628
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr ""
"Parece un poco vacío aquí. ¡Prueba a descargar algunos modelos o cambia tu "
"instancia de IA para comenzar!"

#: src/window.ui:631 src/window.ui:641 src/window.ui:1139
msgid "Manage Instances"
msgstr "Gestionar Instancias"

#: src/window.ui:688 src/window.ui:742
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"Parece que nos hemos quedado sin modelos para esa búsqueda. ¡Intenta "
"modificar tus palabras clave o explora algo nuevo!"

#: src/window.ui:700
msgid "Available"
msgstr "Disponibles"

#: src/window.ui:754
msgid "Creator"
msgstr "Creador"

#: src/window.ui:765
msgid "Model Creator"
msgstr "Creador de Modelos"

#: src/window.ui:766
msgid "Select a method of importing a model to continue"
msgstr "Seleccione un método para importar un modelo para continuar"

#: src/window.ui:778
msgid "GGUF File"
msgstr "Archivo GGUF"

#: src/window.ui:789
msgid "Existing Model"
msgstr "Modelo Existente"

#: src/window.ui:807
msgid "Identity"
msgstr "Identidad"

#: src/window.ui:810
msgid "Base"
msgstr "Base"

#: src/window.ui:817
msgid "Profile Picture"
msgstr "Foto de Perfil"

#: src/window.ui:822
msgid "Open File"
msgstr "Abrir Archivo"

#: src/window.ui:838 src/custom_widgets/model_manager_widget.py:211
msgid "Tag"
msgstr "Etiqueta"

#: src/window.ui:845
msgid "Context"
msgstr "Contexto"

#: src/window.ui:846
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr ""
"Describe el comportamiento deseado del modelo en su idioma principal "
"(normalmente inglés)."

#: src/window.ui:874
msgid "Behavior"
msgstr "Comportamiento"

#: src/window.ui:877
msgid "Imagination"
msgstr "Imaginación"

#: src/window.ui:878
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr ""
"Un número mayor da como resultado respuestas más diversas del modelo. (top_k)"

#: src/window.ui:892
msgid "Focus"
msgstr "Concentración"

#: src/window.ui:893
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "Un número mayor amplía la cantidad de respuestas posibles. (top_p)"

#: src/window.ui:926 src/window.ui:934
msgid "Add Model"
msgstr "Agregar modelo"

#: src/window.ui:968 src/window.ui:1149
msgid "Preferences"
msgstr "Preferencias"

#: src/window.ui:971
msgid "General"
msgstr "General"

#: src/window.ui:978
msgid "Run Alpaca In Background"
msgstr "Ejecutar Alpaca en el fondo"

#: src/window.ui:984
msgid "Show Power Saver Warning"
msgstr "Mostrar Advertencia de Ahorro de Energía"

#: src/window.ui:996
msgid "Quick ask dialog"
msgstr "Dialogo de pregunta rápida"

#: src/window.ui:1008
msgid "Save Conversation to Alpaca"
msgstr "Guardar Conversación a Alpaca"

#: src/window.ui:1023
msgid "Terminal dialog"
msgstr "Diálogo de terminal"

#: src/window.ui:1026
msgid "Terminal"
msgstr "Terminal"

#: src/window.ui:1038
msgid "Open Environment Directory"
msgstr "Abrir Directorio del Ambiente"

#: src/window.ui:1059
msgid "File preview dialog"
msgstr "Dialogo de vista previa de archivos"

#: src/window.ui:1070
msgid "Open With Default App"
msgstr "Abrir con aplicación predeterminada"

#: src/window.ui:1078
msgid "Remove Attachment"
msgstr "Remover Adjunto"

#: src/window.ui:1135
msgid "Import Chat"
msgstr "Importar chat"

#: src/window.ui:1153
msgid "Keyboard Shortcuts"
msgstr "Atajos de Teclado"

#: src/window.ui:1157
msgid "About Alpaca"
msgstr "Sobre Alpaca"

#: src/window.ui:1165 src/window.ui:1203
msgid "Rename Chat"
msgstr "Renombrar Chat"

#: src/window.ui:1169 src/window.ui:1207
msgid "Duplicate Chat"
msgstr "Duplicar Chat"

#: src/window.ui:1177
msgid "Clear Chat"
msgstr "Limpiar Chat"

#: src/window.ui:1183 src/window.ui:1217
msgid "Delete Chat"
msgstr "Eliminar Chat"

#: src/window.ui:1191
msgid "Reload Added Models"
msgstr "Recargar Modelos Agregados"

#: src/window.ui:1195
msgid "Download Model From Name"
msgstr "Descargar Modelo Usando Nombre"

#: src/window.ui:1225
msgid "Send as User"
msgstr "Enviar Como Usuario"

#: src/window.ui:1229
msgid "Send as System"
msgstr "Enviar Como Sistema"

#: src/window.ui:1241
msgid "Attach Screenshot"
msgstr "Adjuntar Captura de Pantalla"

#: src/window.ui:1245
msgid "Attach Website"
msgstr "Adjuntar Sitio Web"

#: src/window.ui:1249
msgid "Attach YouTube Captions"
msgstr "Adjuntar Subtitulos de YouTube"

#: src/alpaca_search_provider.py.in:40
msgid "Open chat"
msgstr "Abrir chat"

#: src/alpaca_search_provider.py.in:41
msgid "Quick ask"
msgstr "Pregunta rápida"

#: src/generic_actions.py:76
msgid "An error occurred while extracting text from the website"
msgstr "Ha ocurrido un error mientras se extraía texto del sitio web"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "General"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "Mostrar Atajos"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "Preferencias"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "Gestor de Modelos"

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "Gestor de Instancias"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "Alternar Barra Lateral"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Quit"
msgstr "Abandonar"

#: src/gtk/help-overlay.ui:52
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "Gestión de chat"

#: src/gtk/help-overlay.ui:55
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "Crear Chat"

#: src/gtk/help-overlay.ui:61
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "Eliminar Chat"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "Limpiar Chat"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "Renombrar Chat"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Search Messages"
msgstr "Buscar Mensajes"

#: src/gtk/help-overlay.ui:87
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "Entrada de mensaje"

#: src/gtk/help-overlay.ui:90
msgid "Copy"
msgstr "Copiar"

#: src/gtk/help-overlay.ui:96
msgid "Paste"
msgstr "Pegar"

#: src/gtk/help-overlay.ui:102
msgid "Open Emoji Menu"
msgstr "Abrir el Menú de Emojis"

#: src/gtk/help-overlay.ui:108
msgid "Insert new line"
msgstr "Saltar línea"

#: src/gtk/help-overlay.ui:114
msgid "Send Message as System"
msgstr "Enviar Mensaje Como Sistema"

#: src/gtk/help-overlay.ui:115
msgid "System messages are taken as literal instructions by models"
msgstr ""
"Los mensajes del sistema son tomados como instrucciones literales por los "
"modelos"

#: src/gtk/help-overlay.ui:121
msgid "Send Message as User"
msgstr "Enviar Mensaje Como Usuario"

#: src/custom_widgets/chat_widget.py:83
msgid "Send prompt: '{}'"
msgstr "Enviar mensaje: '{}'"

#: src/custom_widgets/chat_widget.py:89 src/custom_widgets/chat_widget.py:90
msgid "Open Model Manager"
msgstr "Abrir Gestor de Modelos"

#: src/custom_widgets/chat_widget.py:99
msgid "Try one of these prompts"
msgstr "Prueba uno de estos mensajes"

#: src/custom_widgets/chat_widget.py:99
msgid ""
"It looks like you don't have any models downloaded yet. Download models to "
"get started!"
msgstr ""
"Parece que aún no has descargado ningún modelo. ¡Descarga modelos para "
"empezar!"

#: src/custom_widgets/chat_widget.py:152
msgid "Chat exported successfully"
msgstr "Chat exportado exitosamente"

#: src/custom_widgets/chat_widget.py:172
msgid "User"
msgstr "Usuario"

#: src/custom_widgets/chat_widget.py:176
#: src/custom_widgets/message_widget.py:625
msgid "System"
msgstr "Sistema"

#: src/custom_widgets/chat_widget.py:266
msgid "Regenerate Response"
msgstr "Regenerar Respuesta"

#: src/custom_widgets/chat_widget.py:435
msgid "Copy of {}"
msgstr "Copia de {}"

#: src/custom_widgets/chat_widget.py:450
msgid "Chat imported successfully"
msgstr "Chat importado exitosamente"

#: src/custom_widgets/message_widget.py:69
msgid "Save Message"
msgstr "Guardar Mensaje"

#: src/custom_widgets/message_widget.py:110
#: src/custom_widgets/message_widget.py:238
msgid "Message edited successfully"
msgstr "Mensaje eliminado exitosamente"

#: src/custom_widgets/message_widget.py:136
msgid "Response message"
msgstr "Mensaje de respuesta"

#: src/custom_widgets/message_widget.py:138
msgid "System message"
msgstr "Mensaje de sistema"

#: src/custom_widgets/message_widget.py:140
msgid "User message"
msgstr "Mensaje de usuario"

#: src/custom_widgets/message_widget.py:188
msgid "{}Code Block"
msgstr "{}Bloque de Código"

#: src/custom_widgets/message_widget.py:190
msgid "Code Block"
msgstr "Bloque de Código"

#: src/custom_widgets/message_widget.py:191
#: src/custom_widgets/message_widget.py:525
msgid "Copy Message"
msgstr "Copiar Mensaje"

#: src/custom_widgets/message_widget.py:195
msgid "Edit Code Block"
msgstr "Editar Bloque de Código"

#: src/custom_widgets/message_widget.py:207
#: src/custom_widgets/message_widget.py:283
msgid "Run Script"
msgstr "Ejecutar Script"

#: src/custom_widgets/message_widget.py:247
msgid "Code copied to the clipboard"
msgstr "Codigo copiado"

#: src/custom_widgets/message_widget.py:284
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""
"Asegúrese de comprender lo que hace este script antes de ejecutarlo. Alpaca "
"no es responsable de ningún daño a su dispositivo o datos."

#: src/custom_widgets/message_widget.py:286
msgid "Execute"
msgstr "Ejecutar"

#: src/custom_widgets/message_widget.py:361
#: src/custom_widgets/message_widget.py:363
msgid "Image"
msgstr "Imagen"

#: src/custom_widgets/message_widget.py:372
#: src/custom_widgets/message_widget.py:384
msgid "Missing Image"
msgstr "Imagen no Encontrada"

#: src/custom_widgets/message_widget.py:386
msgid "Missing image"
msgstr "Imagen no Encontrada"

#: src/custom_widgets/message_widget.py:419
msgid "Copy Equation"
msgstr "Copiar Ecuación"

#: src/custom_widgets/message_widget.py:425
msgid "Regenerate Equation"
msgstr "Regenerar Ecuación"

#: src/custom_widgets/message_widget.py:446
msgid "Equation copied to the clipboard"
msgstr "Ecuación copiada al portapapeles"

#: src/custom_widgets/message_widget.py:450
msgid "LaTeX Equation"
msgstr "Ecuación LaTeX"

#: src/custom_widgets/message_widget.py:515
msgid "Remove Message"
msgstr "Remover Mensaje"

#: src/custom_widgets/message_widget.py:535
msgid "Edit Message"
msgstr "Editar Mensaje"

#: src/custom_widgets/message_widget.py:546
msgid "Regenerate Message"
msgstr "Regenerar Mensaje"

#: src/custom_widgets/message_widget.py:565
msgid "Message copied to the clipboard"
msgstr "Mensaje copiado"

#: src/custom_widgets/message_widget.py:592
msgid "Message cannot be regenerated while receiving a response"
msgstr "Mensaje no puede ser regenerado mientras se recibe una respuesta"

#: src/custom_widgets/message_widget.py:878
msgid "Thought"
msgstr "Pensamiento"

#: src/custom_widgets/model_manager_widget.py:117
msgid "Model Manager Error"
msgstr "Error del Gestor de Modelos"

#: src/custom_widgets/model_manager_widget.py:117
msgid "An error occurred whilst pulling '{}'"
msgstr "Se produjo un error al descargar '{}'"

#: src/custom_widgets/model_manager_widget.py:142
msgid "Download Completed"
msgstr "Descarga Completada"

#: src/custom_widgets/model_manager_widget.py:142
msgid "Model '{}' downloaded successfully."
msgstr "El modelo '{}' se descargó correctamente."

#: src/custom_widgets/model_manager_widget.py:154
#: src/custom_widgets/model_manager_widget.py:156
msgid "Stop Download"
msgstr "Detener la descarga"

#: src/custom_widgets/model_manager_widget.py:160
msgid "Stop Download?"
msgstr "¿Detener Descarga?"

#: src/custom_widgets/model_manager_widget.py:161
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "¿Estás seguro de que quieres dejar de descargar '{}'?"

#: src/custom_widgets/model_manager_widget.py:163
msgid "Stop"
msgstr "Parar"

#: src/custom_widgets/model_manager_widget.py:192
msgid "Change Profile Picture"
msgstr "Cambiar Foto de Perfil"

#: src/custom_widgets/model_manager_widget.py:212
msgid "Family"
msgstr "Familia"

#: src/custom_widgets/model_manager_widget.py:213
msgid "Parameter Size"
msgstr "Tamaño de Parametro"

#: src/custom_widgets/model_manager_widget.py:214
msgid "Quantization Level"
msgstr "Nivel de Cuantificación"

#: src/custom_widgets/model_manager_widget.py:217
msgid "Parent Model"
msgstr "Modelo Padre"

#: src/custom_widgets/model_manager_widget.py:220
#: src/custom_widgets/model_manager_widget.py:222
msgid "Modified At"
msgstr "Modificado en"

#: src/custom_widgets/model_manager_widget.py:244
#: src/custom_widgets/model_manager_widget.py:251
msgid "Not Available"
msgstr "No Disponible"

#: src/custom_widgets/model_manager_widget.py:382
msgid "Change"
msgstr "Cambiar"

#: src/custom_widgets/model_manager_widget.py:385
msgid "Model Profile Picture"
msgstr "Foto de Perfil de Modelo"

#: src/custom_widgets/model_manager_widget.py:385
msgid "What do you want to do with the model's profile picture?"
msgstr "¿Qué quieres hacer con la foto de perfil del modelo?"

#: src/custom_widgets/model_manager_widget.py:407
msgid "Create Child"
msgstr "Crear Descendiente"

#: src/custom_widgets/model_manager_widget.py:416
msgid "Remove Model"
msgstr "Remover Modelo"

#: src/custom_widgets/model_manager_widget.py:420
msgid "Remove Model?"
msgstr "¿Remover Modelo?"

#: src/custom_widgets/model_manager_widget.py:421
msgid "Are you sure you want to remove '{}'?"
msgstr "¿Estás seguro de que quieres eliminar '{}'?"

#: src/custom_widgets/model_manager_widget.py:435
msgid "Multilingual"
msgstr "Plurilingüe"

#: src/custom_widgets/model_manager_widget.py:436
msgid "Code"
msgstr "Código"

#: src/custom_widgets/model_manager_widget.py:437
msgid "Math"
msgstr "Matemáticas"

#: src/custom_widgets/model_manager_widget.py:438
msgid "Vision"
msgstr "Visión"

#: src/custom_widgets/model_manager_widget.py:439
msgid "Embedding"
msgstr "Incrustación"

#: src/custom_widgets/model_manager_widget.py:440
msgid "Small"
msgstr "Pequeño"

#: src/custom_widgets/model_manager_widget.py:441
msgid "Medium"
msgstr "Mediano"

#: src/custom_widgets/model_manager_widget.py:442
msgid "Big"
msgstr "Grande"

#: src/custom_widgets/model_manager_widget.py:443
msgid "Huge"
msgstr "Enorme"

#: src/custom_widgets/model_manager_widget.py:524
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr ""
"Al descargar este modelo, acepta el acuerdo de licencia disponible en el "
"sitio web del modelo."

#: src/custom_widgets/model_manager_widget.py:571
msgid "Visit Website"
msgstr "Visitar Sitio Web"

#: src/custom_widgets/dialog_widget.py:147
#: src/custom_widgets/dialog_widget.py:159
#: src/custom_widgets/dialog_widget.py:171
msgid "Accept"
msgstr "Aceptar"

#: src/custom_widgets/terminal_widget.py:75
msgid "Setting up Python environment..."
msgstr "Iniciando ambiente de Python"

#: src/custom_widgets/terminal_widget.py:90
msgid "Compiling C++ script..."
msgstr "Compilando script C++..."

#: src/custom_widgets/terminal_widget.py:104
msgid "Running local web server"
msgstr "Ejecutar servidor web local"

#: src/custom_widgets/terminal_widget.py:129
msgid "Using Flatpak contained shell"
msgstr "Usando el shell contenido de Flatpak"

#~ msgid "Bearer Token (Optional)"
#~ msgstr "Bearer Token (Opcional)"

#~ msgid "Chat with local AI models"
#~ msgstr "Chatea con modelos de IA"

#~ msgid "An Ollama client"
#~ msgstr "Un cliente de Ollama"

#~ msgid "Connect"
#~ msgstr "Conectar"

#~ msgid "Server URL"
#~ msgstr "URL del Server"

#~ msgid "Connect Remote Instance"
#~ msgstr "Conectar Instancia Remota"

#~ msgid "Enter instance information to continue"
#~ msgstr "Ingresa información de la instancia para continuar"

#~ msgid "Close Alpaca"
#~ msgstr "Cerrar Alpaca"

#~ msgid "Use Local Instance"
#~ msgstr "Usar Instancia Local"

#~ msgid "Connection Error"
#~ msgstr "Error de conexión"

#~ msgid "The remote instance has disconnected"
#~ msgstr "La instancia remota se ha desconectado"

#~ msgid ""
#~ "There was an error with the local Ollama instance, so it has been reset"
#~ msgstr ""
#~ "Ha ocurrido un error con la instancia local de Ollama, ha sido reinicida"

#~ msgid "An error occurred: {}"
#~ msgstr "Un error ocurrió: {}"

#~ msgid "Ollama instance was shut down due to inactivity"
#~ msgstr "La instancia de Ollama se apagó debido a inactividad"

#~ msgid "Local Models"
#~ msgstr "Modelos Locales"

#~ msgid ""
#~ "It looks a bit empty in here. Try downloading some models to get started!"
#~ msgstr ""
#~ "Parece un poco vacío aquí. ¡Prueba a descargar algunos modelos para "
#~ "comenzar!"

#~ msgid "Available Models"
#~ msgstr "Modelos Disponibles"

#~ msgid "Use Remote Connection to Ollama"
#~ msgstr "Usa una conección remota a Ollama"

#~ msgid "Change Ollama Instance"
#~ msgstr "Cambiar Instancia de Ollama"

#~ msgid ""
#~ "The default model to use on new chats and when generating chat titles"
#~ msgstr ""
#~ "El modelo predeterminado que se utilizará en los chats nuevos y al "
#~ "generar títulos de chat"

#~ msgid ""
#~ "The temperature of the model. Increasing the temperature will make the "
#~ "model answer more creatively. (Default: 0.8)"
#~ msgstr ""
#~ "La temperatura del modelo. Incrementando la temparatura hará que el "
#~ "modelo responda más creativamente (Por defecto: 0.8)"

#~ msgid ""
#~ "Sets the random number seed to use for generation. Setting this to a "
#~ "specific number will make the model generate the same text for the same "
#~ "prompt. (Default: 0 (random))"
#~ msgstr ""
#~ "Aplica el numero al azar que se usa como semilla para generación. Aplicar "
#~ "un numero especifico hará que el modelo genere el mismo texto a la misma "
#~ "pregunta del usuario (Por defecto: 0 (Al azar))"

#~ msgid "Keep Alive Time"
#~ msgstr "Tiempo Para Mantener Vivo"

#~ msgid ""
#~ "Controls how long the model will stay loaded into memory following the "
#~ "request in minutes (Default: 5)"
#~ msgstr ""
#~ "Controla por cuanto tiempo el modelo permanecera cargado en la memoria "
#~ "despues de la ultima petición en minutos (Por defecto: 5)"

#~ msgid "Ollama Instance"
#~ msgstr "Instancia de Ollama"

#~ msgid "Ollama Overrides"
#~ msgstr "Overrides de Ollama"

#~ msgid ""
#~ "Manage the arguments used on Ollama, any changes on this page only "
#~ "applies to the integrated instance, the instance will restart if you make "
#~ "changes."
#~ msgstr ""
#~ "Administra los argumentos usados en Ollama, cualquier cambio en esta "
#~ "página solo aplica a la instancia integrada, la instancia se reiniciará "
#~ "si haces algún cambio"

#~ msgid "Idle Timer"
#~ msgstr "Temporizador de inactividad"

#~ msgid ""
#~ "Number of minutes the instance should remain idle before it is shut down "
#~ "(0 means it won't be shut down)"
#~ msgstr ""
#~ "Número de minutos que la instancia debe permanecer inactiva antes de "
#~ "apagarse (0 significa que no se apagará)"

#~ msgid "Change Model Directory"
#~ msgstr "Cambiar Directorio de Modelos"

#~ msgid "Powered by Ollama"
#~ msgstr "Impulsado por Ollama"

#~ msgid "Ollama Website"
#~ msgstr "Sitio Web de Ollama"

#~ msgid ""
#~ "Alpaca and its developers are not liable for any damages to devices or "
#~ "software resulting from the execution of code generated by an AI model. "
#~ "Please exercise caution and review the code carefully before running it."
#~ msgstr ""
#~ "Alpaca y sus desarrolladores no son responsables por cualquier daño a "
#~ "dispositivos o software resultados por la ejecución de codigo generado "
#~ "por un modelo de IA. Por favor sea precavido y revise el codigo "
#~ "cuidadosamente antes de correrlo"

#~ msgid "Reload Local Models"
#~ msgstr "Recargar Modelos Locales"

#~ msgctxt "shortcut window"
#~ msgid "Import Chat"
#~ msgstr "Importar Chat"

#~ msgid "(No system message available)"
#~ msgstr "(No hay ningún mensaje del sistema disponible)"

#~ msgid "From Existing Model"
#~ msgstr "Desde Modelo Existente"

#~ msgid "From GGUF File"
#~ msgstr "Desde Archivo GGUF"

#~ msgid "From Name"
#~ msgstr "Desde Nombre"

#~ msgid "image"
#~ msgstr "Imagen"

#~ msgid "Select Model"
#~ msgstr "Selecciona el Modelo"

#~ msgid "This model will be used as the base for the new model"
#~ msgstr "Este modelo será usado como base para el nuevo modelo"

#~ msgid "Pull Model"
#~ msgstr "Descargar Modelo"

#~ msgid ""
#~ "Input the name of the model in this format\n"
#~ "name:tag"
#~ msgstr ""
#~ "Ingresa el nombre del modelo en este formato\n"
#~ "nombre:etiqueta"

#~ msgid ""
#~ "Phi 4 is a 14B parameter, state-of-the-art open model from Microsoft."
#~ msgstr ""
#~ "Phi 4 es un modelo abierto de última generación con 14B parámetros de "
#~ "Microsoft."

#~ msgid "Sponsor Alpaca"
#~ msgstr "Patrocina Alpaca"

#~ msgid ""
#~ "The default model to use on new chats and when Alpaca is launched with "
#~ "the option --ask \"message\""
#~ msgstr ""
#~ "El modelo por defecto a usar en chats nuevos y cuando Alpaca es lanzado "
#~ "con la opción --ask \"mensaje\""

#~ msgid "Manage models dialog"
#~ msgstr "Dialogo de gestión de modelos"

#~ msgid "Create Model"
#~ msgstr "Crear Modelo"

#~ msgid "Refresh Local Models"
#~ msgstr "Recargar Modelos Locales"

#~ msgid "Try a different search or pull an unlisted model from it's name"
#~ msgstr ""
#~ "Prueba una búsqueda diferente o descarga un modelo que no esté en el "
#~ "listado a partir de su nombre."

#~ msgid "Pull Model From Name"
#~ msgstr "Descargar Modelo a Partir del Nombre"

#~ msgid ""
#~ "By downloading this model you accept the license agreement available on "
#~ "the model's website."
#~ msgstr ""
#~ "Al descargar este modelo aceptas la licencia disponible en el sitio web "
#~ "del modelo"

#~ msgid "Model Details"
#~ msgstr "Detalles de Modelo"

#~ msgid ""
#~ "Some models require a modelfile, Alpaca fills FROM and SYSTEM (context) "
#~ "instructions automatically. Please visit the model's website or Ollama "
#~ "documentation for more information if you're unsure."
#~ msgstr ""
#~ "Algunos modelos requieren un archivo de modelo, Alpaca completa "
#~ "automáticamente las instrucciones FROM y SYSTEM (contexto). Por favor, "
#~ "visita el sitio web del modelo o la documentación de Ollama para más "
#~ "información si tienes dudas."

#~ msgid "Create"
#~ msgstr "Crear"

#~ msgid "Stop Pulling '{}'"
#~ msgstr "Parar Descarga de '{}'"

#~ msgid "Details"
#~ msgstr "Detalles"

#~ msgid "Remove '{}'"
#~ msgstr "Remover '{}'"

#~ msgid "Delete Model?"
#~ msgstr "¿Eliminar Modelo?"

#~ msgid "Create Model Based on '{}'"
#~ msgstr "Crear Modelo Basado en '{}'"

#~ msgid "Change Model Picture"
#~ msgstr "Cambiar Foto de Perfil"

#~ msgid "Format"
#~ msgstr "Formato"

#~ msgid "Enter download menu for {}"
#~ msgstr "Entrar menu de descarga para {}"

#~ msgid "Embedding Model"
#~ msgstr "Modelo de incrustación"

#~ msgid ""
#~ "This model is meant to be used in the training of other models and won't "
#~ "work directly with Alpaca. Are you sure you want to download it anyway?"
#~ msgstr ""
#~ "Este modelo está pensado para usarse en el entrenamiento de otros modelos "
#~ "y no funcionará directamente con Alpaca. ¿Estás seguro de que quieres "
#~ "descargarlo de todas formas?"

#~ msgid "Download"
#~ msgstr "Descargar"

#~ msgid "Large Model"
#~ msgstr "Modelo Largo"

#~ msgid ""
#~ "This model might be too large to run optimally. Are you sure you want to "
#~ "download it anyway?"
#~ msgstr ""
#~ "Es posible que este modelo sea demasiado grande para funcionar de forma "
#~ "óptima. ¿Estás seguro de que deseas descargarlo de todas formas?"

#~ msgid "Others..."
#~ msgstr "Otros..."

#~ msgid "Download {}:{}"
#~ msgstr "Descargar {}:{}"

#~ msgid "Model deleted successfully"
#~ msgstr "Modelo eliminado exitosamente"

#~ msgid "Task Complete"
#~ msgstr "Tarea completada"

#~ msgid "Model '{}' pulled successfully."
#~ msgstr "El modelo '{}' fue descargado exitosamente"

#~ msgid "Pull Model Error"
#~ msgstr "Error Descargando Modelo"

#~ msgid "Failed to pull model '{}': {}"
#~ msgstr "Fallo descarga de modelo '{}': {}"

#~ msgid "Error pulling '{}': {}"
#~ msgstr "Error descargando '{}': {}"

#~ msgid "Failed to pull model '{}' due to network error."
#~ msgstr "No se pudo descargar el modelo '{}' debido a un error de red"

#~ msgid "Error pulling '{}'"
#~ msgstr "Error descargando '{}'"

#~ msgid ""
#~ "New state of the art 70B model. Llama 3.3 70B offers similar performance "
#~ "compared to Llama 3.1 405B model."
#~ msgstr ""
#~ "Nuevo modelo 70B de última generación. Llama 3.3 70B ofrece un "
#~ "rendimiento similar al modelo Llama 3.1 405B."

#~ msgid "Script exited"
#~ msgstr "El script salió"

#~ msgid "The script is contained inside Flatpak"
#~ msgstr "El script está contenido dentro de Flatpak"

#~ msgid "Close application"
#~ msgstr "Cerrar aplicación"

#~ msgid "Import chat"
#~ msgstr "Importar chat"

#~ msgid "Clear chat"
#~ msgstr "Limpiar chat"

#~ msgid "New chat"
#~ msgstr "Nuevo chat"

#~ msgid "Show shortcuts window"
#~ msgstr "Mostrar ventana de atajos"

#~ msgid "Manage models"
#~ msgstr "Gestionar modelos"

#~ msgid "Toggle sidebar"
#~ msgstr "Alternar barra lateral"

#~ msgid "Rename chat"
#~ msgstr "Renombrar chat"

#~ msgid "Editor"
#~ msgstr "Editor"

#~ msgid "Message text box"
#~ msgstr "Caja de texto para mensaje"

#~ msgid "Missing file"
#~ msgstr "Archivo faltante"

#~ msgid "Image Recognition"
#~ msgstr "Reconocimiento de Imagenes"

#~ msgid ""
#~ "Your system's available RAM suggests that this model might be too large "
#~ "to run optimally. Are you sure you want to download it anyway?"
#~ msgstr ""
#~ "La memoria RAM disponible en tu sistema sugiere que este modelo podría "
#~ "ser demasiado grande para funcionar de manera óptima. ¿Estás seguro de "
#~ "que deseas descargarlo de todos modos?"

#~ msgid "Jeffry Samuel Eduarte Rojas"
#~ msgstr "Jeffry Samuel Eduarte Rojas"

#~ msgid "Create chat"
#~ msgstr "Crear chat"

#~ msgid "Create chat and send message"
#~ msgstr "Crear chat y enviar mensaje"

#~ msgid "This video is not available"
#~ msgstr "Este video no está disponible"

#~ msgid "AMD GPU detected but the extension is missing, Ollama will use CPU"
#~ msgstr ""
#~ "GPU AMD detectada pero la extensión no está instalada, Ollama usará el CPU"

#~ msgid "Select a Model"
#~ msgstr "Selecciona un Modelo"

#~ msgid "Chat cannot be cleared while receiving a message"
#~ msgstr "El chat no puede ser limpiado mientras se recibe un mensaje"

#~ msgid "Create Chat?"
#~ msgstr "¿Crear Chat?"

#~ msgid "Enter name for new chat"
#~ msgstr "Ingrese el nombre para el nuevo chat"

#~ msgid "Use local instance"
#~ msgstr "Usar instancia local"

#~ msgid "An error occurred while creating the model"
#~ msgstr "Ha ocurrido un error mientras se creaba el modelo"

#~ msgid "URL of Remote Instance"
#~ msgstr "URL de la Instancia Remota"

#~ msgid "Press Enter to close..."
#~ msgstr "Presione Enter para cerrar..."

#~ msgid "No compatible terminal was found in the system"
#~ msgstr "No se encontró ningún terminal compatible en el sistema"

#~ msgid ""
#~ "Google Gemma 2 is a high-performing and efficient model by now available "
#~ "in three sizes: 2B, 9B, and 27B."
#~ msgstr ""
#~ "Google Gemma 2 es un modelo de alto rendimiento y eficiente que ahora "
#~ "está disponible en tres tamaños: 2B, 9B y 27B."

#~ msgid "Loading instance"
#~ msgstr "Cargando instancia"

#~ msgid "Applying user preferences"
#~ msgstr "Aplicando preferencias de usuario"

#~ msgid "Updating list of local models"
#~ msgstr "Actualizando lista de modelos locales"

#~ msgid "Updating list of available models"
#~ msgstr "Actualizando lista de modelos disponibles"

#~ msgid "Loading chats"
#~ msgstr "Cargando chats"

#~ msgid "Loading Alpaca dialog"
#~ msgstr "Dialogo de carga de Alpaca"

#~ msgid "Loading Alpaca..."
#~ msgstr "Cargando Alpaca..."

#~ msgid "Failed to connect to server"
#~ msgstr "No se pudo conectar al servidor"

#~ msgid "Stop Creating '{}'"
#~ msgstr "Parar la creación de '{}'"

#~ msgid "Google Gemma 2 is now available in 2 sizes, 9B and 27B."
#~ msgstr "Google Gemma 2 ahora está disponible en 2 tamaños, 9B y 27B."

#~ msgid "Are you sure you want to stop pulling '{} ({})'?"
#~ msgstr "¿Estás seguro de que quieres parar la descarga de '{} ({})'?"

#~ msgid "Try a different search"
#~ msgstr "Intenta una busqueda distinta"

#~ msgid "Pulling in the background..."
#~ msgstr "Descargando en el fondo..."

#~ msgid "Featured Models"
#~ msgstr "Modelos Destacados"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later.\n"
#~ "\n"
#~ "By downloading any model you accept their license agreement available on "
#~ "the model's website.\n"
#~ "                  "
#~ msgstr ""
#~ "Alpaca funciona localmente en tu dispositivo, para empezar a conversar "
#~ "necesitaras un modelo de AI, puedes descargar un modelo de esta página o "
#~ "en el menu 'Gestionar Modelos' despues.\n"
#~ "\n"
#~ "Al descargar cualquier modelo aceptas su acuerdo de licencia disponible "
#~ "en el sitio web del modelo.\n"
#~ "                  "

#~ msgid "Built by Meta"
#~ msgstr "Construido por Meta"

#~ msgid "Built by Google DeepMind"
#~ msgstr "Construido por Google DeepMind"

#~ msgid "Built by Microsoft"
#~ msgstr "Construido por Microsoft"

#~ msgid "Multimodal AI with image recognition"
#~ msgstr "IA multimodal con reconocimiento de imagenes"

#~ msgid "Remove '{} ({})'"
#~ msgstr "Remover '{} ({})'"

#~ msgid "Stop Pulling '{} ({})'"
#~ msgstr "Parar Descarga de '{} ({})'"

#~ msgid "Template"
#~ msgstr "Plantilla"

#~ msgid ""
#~ "Some models require a specific template. Please visit the model's website "
#~ "for more information if you're unsure."
#~ msgstr ""
#~ "Algunos modelos requieren de una plantilla especifica. Por favor visita "
#~ "el sitio web del modelo para más información en caso de que no estés "
#~ "seguro"

#~ msgid "From GGUF File (Experimental)"
#~ msgstr "Usar archivo GGUF (Experimental)"

#~ msgid "A conversation showing code highlight"
#~ msgstr "Una conversación mostrando highlight de codigo"

#~ msgid "A conversation involving multiple models"
#~ msgstr "Una conversación incluyendo multiples modelos"

#~ msgid "Managing models"
#~ msgstr "Gestionando modelos"

#~ msgid "Open with Default App"
#~ msgstr "Abrir con Aplicación Predeterminada"

#~ msgid ""
#~ "Alpaca works locally on your device, to start chatting you'll need an AI "
#~ "model, you can either pull models from this list or the 'Manage Models' "
#~ "menu later."
#~ msgstr ""
#~ "Alpaca funciona localmente en tu dispositivo, para empezar a chatear "
#~ "necesitas un modelo IA, puedes descargar modelos de esta lista o usando "
#~ "el menu 'Gestionar Modelos' despues"

#~ msgid "An error occurred"
#~ msgstr "Ha ocurrio un error"

#~ msgid "Could not list local models"
#~ msgstr "No se pudieron listar los modelos locales"

#~ msgid "Could not delete model"
#~ msgstr "No se pudo eliminar el modelo"

#~ msgid "Could not pull model"
#~ msgstr "No se pudo descargar el modelo"

#~ msgid "Cannot delete chat because it's the only one left"
#~ msgstr "No se pudo eliminar el chat por que es el único que queda"

#~ msgid "That tag is already being pulled"
#~ msgstr "Esa etiqueta ya se está descargando"

#~ msgid "That tag has been pulled already"
#~ msgstr "Esa etiqueta ya ha sido descargada"

#~ msgid "Model pulled successfully"
#~ msgstr "Modelo descargado exitosamente"
