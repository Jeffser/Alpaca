# Simplified Chinese Translation for Alpaca
# Copyright (C) 2024 Jeffser
# This file is distributed under the same license as the Alpaca package.
# Aleksana <me@aleksana.moe>, 2024.
# Yuehao Sui <8ar10der@amao.run>, 2024-2025.
#
msgid ""
msgstr ""
"Project-Id-Version: 6.1.5\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-06-04 01:32-0600\n"
"PO-Revision-Date: 2025-06-05 00:28+0200\n"
"Last-Translator: Yuehao Sui <8ar10der@amao.run>\n"
"Language-Team: Chinese (China)\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Gtranslator 48.0\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

# 建议不翻译
#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ai;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "与 AI 模型聊天"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "私人 AI 客户端"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1201
msgid "Features"
msgstr "功能特点"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1203
msgid "Talk to multiple models in the same conversation"
msgstr "在同一对话中与多个模型交谈"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1204
msgid "Pull and delete models from the app"
msgstr "在应用中拉取或删除模型"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "进行多重对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "图像识别（仅适用于兼容模型）"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "纯文本文档识别"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "导入导出对话记录"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "将 Youtube 的转录文本添加到提示中"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "将来自网站的文本添加到提示中"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "PDF 识别"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/window.ui:90
msgid "Disclaimer"
msgstr "免责声明"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"本项目与 Ollama 没有任何关联，对于运行任何模型所提供的代码而对您的设备或软件"
"造成的任何损害，我概不负责。"

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "一段与 AI 模型的普通对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "一段带有图像识别的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "一段涉及自定义模型的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "一段展示代码高亮的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "一段在内置终端中运行的 Python 脚本"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation involving a YouTube video transcript"
msgstr "一段含有 YouTube 转录文本的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "已下载的多个模型"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "Model creator screen"
msgstr "模型创建者界面"

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:109
#: data/com.jeffser.Alpaca.metainfo.xml.in:142
#: data/com.jeffser.Alpaca.metainfo.xml.in:189
#: data/com.jeffser.Alpaca.metainfo.xml.in:236
#: data/com.jeffser.Alpaca.metainfo.xml.in:253
#: data/com.jeffser.Alpaca.metainfo.xml.in:283
#: data/com.jeffser.Alpaca.metainfo.xml.in:293
#: data/com.jeffser.Alpaca.metainfo.xml.in:304
#: data/com.jeffser.Alpaca.metainfo.xml.in:331
#: data/com.jeffser.Alpaca.metainfo.xml.in:351
#: data/com.jeffser.Alpaca.metainfo.xml.in:377
#: data/com.jeffser.Alpaca.metainfo.xml.in:392
#: data/com.jeffser.Alpaca.metainfo.xml.in:417
#: data/com.jeffser.Alpaca.metainfo.xml.in:445
#: data/com.jeffser.Alpaca.metainfo.xml.in:455
#: data/com.jeffser.Alpaca.metainfo.xml.in:466
#: data/com.jeffser.Alpaca.metainfo.xml.in:480
#: data/com.jeffser.Alpaca.metainfo.xml.in:492
#: data/com.jeffser.Alpaca.metainfo.xml.in:508
#: data/com.jeffser.Alpaca.metainfo.xml.in:523
#: data/com.jeffser.Alpaca.metainfo.xml.in:558
#: data/com.jeffser.Alpaca.metainfo.xml.in:583
#: data/com.jeffser.Alpaca.metainfo.xml.in:614
#: data/com.jeffser.Alpaca.metainfo.xml.in:640
#: data/com.jeffser.Alpaca.metainfo.xml.in:662
#: data/com.jeffser.Alpaca.metainfo.xml.in:693
#: data/com.jeffser.Alpaca.metainfo.xml.in:715
#: data/com.jeffser.Alpaca.metainfo.xml.in:736
#: data/com.jeffser.Alpaca.metainfo.xml.in:751
#: data/com.jeffser.Alpaca.metainfo.xml.in:776
msgid "New"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Multiple QuickAsk window rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
#: data/com.jeffser.Alpaca.metainfo.xml.in:120
#: data/com.jeffser.Alpaca.metainfo.xml.in:133
#: data/com.jeffser.Alpaca.metainfo.xml.in:148
#: data/com.jeffser.Alpaca.metainfo.xml.in:157
#: data/com.jeffser.Alpaca.metainfo.xml.in:168
#: data/com.jeffser.Alpaca.metainfo.xml.in:177
#: data/com.jeffser.Alpaca.metainfo.xml.in:225
#: data/com.jeffser.Alpaca.metainfo.xml.in:243
#: data/com.jeffser.Alpaca.metainfo.xml.in:259
#: data/com.jeffser.Alpaca.metainfo.xml.in:271
#: data/com.jeffser.Alpaca.metainfo.xml.in:321
#: data/com.jeffser.Alpaca.metainfo.xml.in:367
#: data/com.jeffser.Alpaca.metainfo.xml.in:398
#: data/com.jeffser.Alpaca.metainfo.xml.in:407
#: data/com.jeffser.Alpaca.metainfo.xml.in:470
#: data/com.jeffser.Alpaca.metainfo.xml.in:498
#: data/com.jeffser.Alpaca.metainfo.xml.in:512
#: data/com.jeffser.Alpaca.metainfo.xml.in:529
#: data/com.jeffser.Alpaca.metainfo.xml.in:540
#: data/com.jeffser.Alpaca.metainfo.xml.in:549
#: data/com.jeffser.Alpaca.metainfo.xml.in:566
#: data/com.jeffser.Alpaca.metainfo.xml.in:576
#: data/com.jeffser.Alpaca.metainfo.xml.in:593
#: data/com.jeffser.Alpaca.metainfo.xml.in:603
#: data/com.jeffser.Alpaca.metainfo.xml.in:650
#: data/com.jeffser.Alpaca.metainfo.xml.in:675
#: data/com.jeffser.Alpaca.metainfo.xml.in:700
#: data/com.jeffser.Alpaca.metainfo.xml.in:722
#: data/com.jeffser.Alpaca.metainfo.xml.in:740
#: data/com.jeffser.Alpaca.metainfo.xml.in:758
#: data/com.jeffser.Alpaca.metainfo.xml.in:770
#: data/com.jeffser.Alpaca.metainfo.xml.in:786
msgid "Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "Better stability for QuickAsk"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:102
msgid "Creating a new chat now selects it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "Chat Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:112
msgid "Hide \"latest\" and \"custom\" tags from model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:113
msgid "Hide model's languages behind popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:114
msgid "New models listed for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:115
msgid "Added option to autodictate new mesages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
msgid "Added Meta Llama API to list of instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:117
msgid ""
"Added new env variables options (\"24H hour formatting\" and \"only Ollama "
"mode\")"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:118
msgid "Made Mermaid scripts executable using Python HTTP server"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "Better stability when switching instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Better performance when navigating menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Fixed some dialogs not appearing in Quick Ask window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Faster message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Faster message rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:135
msgid "Fixed whisper directory not existing causing error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:144
#: data/com.jeffser.Alpaca.metainfo.xml.in:993
msgid "Updated model list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:145
msgid "Alpaca now remembers it's size"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:146
msgid "Added reasoning category for Ollama models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:150
msgid "Improvements in sample prompts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:159
msgid "Fixed auto creation of Ollama (Managed) instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:160
msgid "Removed legacy JSON to SQLite3 migration code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:161
msgid "Fixed power saving mode appearing whilst using online instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:170
msgid "Fixed Ollama (Manged) instance not being able to be created"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:179
msgid "Instance manager now follows default model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:180
msgid "English text-to-speech voices not working"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Instance manager sometimes not saving instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:191
msgid "Smart tools for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:192
msgid "Speech recognition (message dictation)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:193 src/widgets/model_manager.py:66
msgid "Text to Speech"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:194
msgid "New Quick Chat system"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:195
msgid "Filter Ollama models by categories"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:196
msgid "Better math Latex rendering in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:197
msgid "Rich text rendering in attachment preview"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:198
msgid "Matplotlib is now included in Python code runner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:199
msgid "Styling for messages being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:201
#: data/com.jeffser.Alpaca.metainfo.xml.in:309
msgid "New Instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Deepseek"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "OpenRouter AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:205
msgid "Anthropic"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:206
msgid "Groq Cloud"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:207
msgid "Fireworks AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:208
msgid "Lambda Labs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:210
msgid "New Attachment Types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:212
msgid "Microsoft Word Document (docx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Microsoft PowerPoint Document (pptx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:214
msgid "Microsoft Excel Document (xlsx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:216
msgid "New Tools"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:218 src/widgets/tools/tools.py:467
msgid "Run Command (Testing)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:219 src/widgets/tools/tools.py:374
msgid "Online Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:220 src/widgets/tools/tools.py:332
msgid "Extract Wikipedia Article"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:221 src/widgets/tools/tools.py:214
msgid "Get Recipe by Name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:222 src/widgets/tools/tools.py:275
msgid "Get Recipes by Category"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:223 src/widgets/tools/tools.py:181
msgid "Get Current Datetime"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:227
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:228
msgid "Fixed bold text not rendering correctly in tables"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:238
msgid "Updated runtime to Gnome 48"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:239
msgid "Added back 'category pills' to model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:240
msgid "Better appearance for model manager sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
#: data/com.jeffser.Alpaca.metainfo.xml.in:257
msgid "New models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:245
msgid "Fixed bad title generation with chain-of-thought models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:246
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:255
msgid "Option to delete all chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:256
msgid "Button to refresh sample prompts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Fixed stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid "Fixed model search not working if there are only pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:264
msgid "Fixed sample prompts sometimes not appearing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:273
msgid "Don't clear the building output of C++ scripts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:274
msgid "Better handling of attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid "Handle remote Ollama instance's API Key better"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Remove '\\n' characters in instance edit page"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:285
msgid "Dynamic chat loading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:286
msgid "Updated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:295
msgid "Tweaked appearance of models in model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:296
msgid "Updated Ollama instance to 0.5.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Added new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:306
msgid "New instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "New welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:311
msgid "OpenAI ChatGPT"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Google Gemini"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid "Together AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Venice"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:323
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:324
msgid "Fixed attachment filters"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:333
msgid "New model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:334
msgid "Changed GtkSpinner to AdwSpinner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:335
msgid "Better handling of launch process"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:336
msgid "New loading screen at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:337
msgid "Better handling of file types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:338
msgid "Better regex expression for LaTeX equations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:339
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
msgid "Better handling of think tags in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
msgid "Default model is now in charge of generating titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:342
msgid "Message header is now shown whilst the message is being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:343
msgid "Better handling of model profile pictures"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:344
msgid "New models in 'available models' list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "Added option for attaching screenshots"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Added option to open the environment directory from the terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
msgid "Added option to edit code blocks directly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:358
msgid "Complete keyboard shortcut list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:359
msgid "Images are now attached in 640p resolution"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:360
msgid "Website attachments now use extracted titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:361
msgid "Better chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:362
msgid "Added option to attach any plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:363
msgid "Added spellchecker to message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:364
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:365
msgid "Small appearance changes in text entries"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:369
msgid "Alpaca's launch process is more reliable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:370
msgid "Closing the terminal now kills the script subprocess"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:379
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:380
msgid "Changed appearance of messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:381
msgid "Added the option to add profile pictures to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:383
#: data/com.jeffser.Alpaca.metainfo.xml.in:855
#: data/com.jeffser.Alpaca.metainfo.xml.in:904
msgid "Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:385
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:394
msgid "Added categories to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:395
msgid "Specified model's languages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:396
msgid "Added warning when downloading embedding models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "Replaced low ram warning with big model warning"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:409
msgid "Correctly escape markup before rendering message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid "Fixed about dialog not working if log file was missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:419
msgid "System messages can now be sent directly from Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:420
msgid "New redesign for messages and smaller minimum size"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:421
msgid "New models included in 'available models list'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:422
msgid "Added symbolic icon when attaching code files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:423
msgid "When exporting a chat it now includes a markdown file"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:424
msgid "Refresh button in model manager when using a remote instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:425
msgid "Assistant messages are now editable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:426
msgid "Updated Ollama to v0.5.2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:427
msgid "New option to change model directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "File previewer now resizes dynamically to content"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:429
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:430
msgid "Compatibility added with ODT files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:433
msgid "Restored ROCm compatibility"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:434
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:435
msgid "Fixed edit button not saving changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:436
msgid "Changed max temperature value to 2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:437
msgid "Made seed 0 actually random"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:438
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:447
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:448
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Added integration as Gnome Search Provider"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:459
msgid "Updated Ollama to v0.4.2 with new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:468
msgid "User messages are now compacted into bubbles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:473
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:482
msgid "Details page for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:483
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:484
msgid "Added warning when model is too big for the device"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:485
msgid "Added AMD GPU indicator in preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:494
msgid "Better system for handling dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid "Better system for handling instance switching"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Remote connection dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:500
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:501
msgid "Better internal instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:510
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:514
msgid "Better handling of image recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:515
msgid "Remove unused files when canceling a model download"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:516
msgid "Better message blocks rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:525
msgid "Run bash and python scripts straight from chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:526
msgid "Updated Ollama to 0.3.12"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:527
msgid "New models!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:531
msgid "Fixed and made faster the launch sequence"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:532
msgid "Better detection of code blocks in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:533
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:542
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Fixed message generation sometimes failing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "Sidebar resizes with the window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:561
msgid "New welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:562
msgid "Message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:563
msgid "Updated Ollama to v0.3.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:564
msgid "A lot of new models provided by Ollama repository"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:568
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:569
msgid "Fixed image recognition on unsupported models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:578
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:579
msgid "Fixed image recognition with local images"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:580
msgid "Changed appearance of delete / stop model buttons"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Fixed stop button crashing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:585
msgid "Made sidebar resize a little when the window is smaller"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:586
msgid "Instant launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Fixed error on first run (welcome dialog)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:605
msgid "Fixed 'clear chat' option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:606
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:607
msgid "Fixed support for AMD GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
msgid "Model, message and chat systems have been rewritten"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:617
msgid "New models are available"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:618
msgid "Ollama updated to v0.3.9"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:619
msgid "Added support for multiple chat generations simultaneously"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:620
msgid "Added experimental AMD GPU support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Added animations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Changed model manager / model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "Changed message appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Added markdown and code blocks to user messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:627
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:628
msgid "Added inactivity timer to integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Better handling of focus on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:633
msgid "Better general performance on the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid "New duplicate chat option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "Changed model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Message entry is focused on launch and chat change"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Message is focused when it's being edited"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "Added loading spinner when regenerating a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:648
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:652
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:653
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Fixed message generation not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "Fixed message edition not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:664
msgid "Model manager opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
msgid "Delete chat option in secondary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:666
msgid "New model selector popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:667
msgid "Standard shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:668
msgid "Model manager is navigable with keyboard"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:669
msgid "Changed sidebar collapsing behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:670
msgid "Focus indicators on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:672
msgid "Give message entry focus at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:673
msgid "Generally better code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:677
msgid "Better width for dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Better compatibility with screen readers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid "Fixed message regenerator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Removed 'Featured models' from welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Added default buttons to dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:682
msgid "Fixed import / export of chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:683
msgid "Changed Python2 title to Python on code blocks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:684
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:685
msgid "Show date on stopped messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:686
msgid "Fix clear chat error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:695
msgid "Changed shortcuts to standards"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Moved 'Manage Models' button to primary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
#: data/com.jeffser.Alpaca.metainfo.xml.in:719
msgid "Stable support for GGUF model files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:698
#: data/com.jeffser.Alpaca.metainfo.xml.in:973
msgid "General optimizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:702
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:703
msgid "Removed sponsor dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:704
msgid "Added sponsor link in about dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:705
msgid "Changed window and elements dimensions"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Selected model changes when entering model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:707
msgid "Better image tooltips"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:708
msgid "GGUF Support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:717
msgid "Regenerate any response, even if they are incomplete"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:718
msgid "Support for pulling models by name:tag"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:720
msgid "Restored sidebar toggle button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid "Reverted back to standard styles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:726
msgid "Changed min width for model dropdown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid "Changed message entry shadow"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid "The last model used is now restored when the user changes chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Better check for message finishing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Added table rendering (Thanks Nokse)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Made support dialog more common"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:753
msgid "Bearer Token entry on connection error dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "Small appearance changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:755
msgid "Compatibility with code blocks without explicit language"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:756
msgid "Rare, optional and dismissible support dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Date format for Simplified Chinese translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Bug with unsupported localizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Min height being too large to be used on mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "Remote connection checker bug"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:772
msgid "Models with capital letters on their tag don't work"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:773
msgid "Ollama fails to launch on some systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:778
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:779
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:788
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:789
msgid "Better connection check for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:796
msgid "Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:797
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:798
msgid "Features and fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
msgid "Updated Ollama instance to 0.2.8"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Better model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Model manager redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:803
msgid "Better tag selector when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:804
msgid "Model search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:805
msgid "Added support for bearer tokens on remote instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:806
msgid "Preferences dialog redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:807
msgid "Added context menus to interact with a chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:808
msgid "Redesigned primary and secondary menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:809
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:810
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:811
msgid "Chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "Auto resizing of message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
msgid "Chat notifications"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
msgid "Added indicator when an image is missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:815
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:816
msgid "Redesigned file preview dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:817
msgid "Credited new contributors"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:818
msgid "Better stability and optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:819
msgid "Edit messages to change the context of a conversation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:820
msgid "Added disclaimers when pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Preview files before sending a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Better format for date and time on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid "Error and debug logging on terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid "Auto-hiding sidebar button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:825
msgid "Various UI tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:827
msgid "New Models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:829
msgid "Gemma2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:830
msgid "GLM4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:831
msgid "Codegeex4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:832
msgid "InternLM2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid "Llama3-groq-tool-use"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:834
msgid "Mathstral"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "Mistral-nemo"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid "Firefunction-v2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:837
msgid "Nuextract"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:839
msgid "Translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:840
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:842
msgid "Russian: Alex K"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:843
msgid "Spanish: Jeffser"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Brazilian Portuguese: Daimar Stein"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:845
msgid "French: Louis Chauvet-Villaret"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Norwegian: CounterFlow64"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "Bengali: Aritra Saha"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "Simplified Chinese: Yuehao Sui"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:856
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:862
#: data/com.jeffser.Alpaca.metainfo.xml.in:892
#: data/com.jeffser.Alpaca.metainfo.xml.in:913
#: data/com.jeffser.Alpaca.metainfo.xml.in:1118
#: data/com.jeffser.Alpaca.metainfo.xml.in:1175
msgid "Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:864
msgid "Added compatibility for PDF"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:865
msgid "Added compatibility for DOCX"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:866
msgid "Merged 'file attachment' menu into one button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:873
#: data/com.jeffser.Alpaca.metainfo.xml.in:1066
msgid "Quick Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:874
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:880
#: data/com.jeffser.Alpaca.metainfo.xml.in:1032
msgid "Huge Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:882
msgid "Added: Support for plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:883
msgid "Added: New backend system for storing messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:884
msgid "Added: Support for changing Ollama's overrides"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:885
msgid "General Optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:894
msgid "Added: Support for GGUF models (experimental)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:895
msgid "Added: Support for customization and creation of models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:896
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:897
msgid "Update Ollama to v0.1.39"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:906
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:915
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid "Combined export / import chat buttons into a menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:917
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:918
msgid "Fixed send / stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:919
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid "Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "New message entry design"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:931
msgid "Fixed: Can't rename the same chat multiple times"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:938
msgid "The fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:940
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:941
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:948
msgid "Quick tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Added progress bar to models that are being pulled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:951
msgid "Added size to tags when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "General optimizations on the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
msgid "Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:961
msgid "Fixed: Scroll when message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:962
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:963
msgid "Added 'Featured Models' page on welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:970
msgid "Nice Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid "UI tweaks (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:974
msgid "Metadata fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:981
msgid "Quick fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:983
msgid "Updated Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:984
msgid "Added compatibility for PNG"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:991
msgid "New Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:994
msgid "Added image recognition to more models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:995
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:996
msgid "Refined the general UI (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:997
msgid "Added 'delete message' feature"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1006
msgid "Bug Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1008
msgid "Fixed: Minor spelling mistake"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1009
msgid "Added 'mobile' as a supported form factor"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1010
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1011
msgid "Fixed: App might freeze randomly on startup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1012
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1019
msgid "Cool Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1021
msgid "Better design for chat window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1022
msgid "Better design for chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1023
msgid "Fixed remote connections"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "Fixed Ollama restarting in loop"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1025
msgid "Other cool backend stuff"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1034
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1035
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1036
msgid "Added option to import and export chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1037
msgid "Added option to run Alpaca with Ollama in the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1038
msgid "Added preferences dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1039
msgid "Changed the welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1041
#: data/com.jeffser.Alpaca.metainfo.xml.in:1058
#: data/com.jeffser.Alpaca.metainfo.xml.in:1070
#: data/com.jeffser.Alpaca.metainfo.xml.in:1089
#: data/com.jeffser.Alpaca.metainfo.xml.in:1110
#: data/com.jeffser.Alpaca.metainfo.xml.in:1126
#: data/com.jeffser.Alpaca.metainfo.xml.in:1142
#: data/com.jeffser.Alpaca.metainfo.xml.in:1156
#: data/com.jeffser.Alpaca.metainfo.xml.in:1166
#: data/com.jeffser.Alpaca.metainfo.xml.in:1184
#: data/com.jeffser.Alpaca.metainfo.xml.in:1206
msgid "Please report any errors to the issues page, thank you."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1049
msgid "Yet Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1051
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1052
msgid "Added better UI for the chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1053
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1054
msgid "Added myself to the credits as the spanish translator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1055
msgid "Using XDG properly to get config folder"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1056
msgid "Update for translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1068
msgid "The last update had some mistakes in the description of the update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1078
msgid "Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1080
msgid "Added full Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1081
msgid "Added support for background pulling of multiple models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1082
msgid "Added interrupt button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1083
msgid "Added basic shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1084
msgid "Better translation support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1085
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1086
msgid "Better scalling for different window sizes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1087
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1097
msgid "Really Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1099
msgid "Added multiple chats support!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1100
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1101
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
msgid "Added support for multiple tags on a single model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1103
msgid "Added better model management dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1104
msgid "Added loading spinner when sending message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1105
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1106
msgid "Added new symbolic icon"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1107
msgid "Added frame to message textview widget"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1108
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1120
msgid "Added code highlighting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1121
msgid "Added image recognition (llava model)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1122
msgid "Added multiline prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1123
msgid "Fixed some small bugs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1124
msgid "General optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1134
msgid "Fixes and features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1136
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1137
msgid "Fixed: Cannot close app on first setup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1138
msgid "Fixed: Brand colors for Flathub"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1139
msgid "Fixed: App description"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1140
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1150
msgid "0.2.2 Bug fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1152
msgid "Toast messages appearing behind dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1153
msgid "Local model list not updating when changing servers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1154
msgid "Closing the setup dialog closes the whole app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1164
msgid "0.2.1 Data saving fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1165
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1174
msgid "0.2.0"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1176
msgid "New Features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1178
msgid "Restore chat after closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1179
msgid "A button to clear the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1180
msgid "Fixed multiple bugs involving how messages are shown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1181
msgid "Added welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1182
msgid "More stability"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1192
msgid "0.1.2 Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1193
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1199
msgid "0.1.1 Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1200
msgid "This is the first public version of Alpaca"
msgstr ""

#: src/alpaca_search_provider.py.in:41
msgid "Open chat"
msgstr "打开对话"

#: src/alpaca_search_provider.py.in:42
msgid "Quick ask"
msgstr "快速问答"

#: src/constants.py:95
msgid "Never"
msgstr "从不"

#: src/constants.py:96
msgid "When Alpaca is Focused"
msgstr "当 Alpaca 是焦点窗口时"

#: src/constants.py:97
msgid "Always"
msgstr "总是"

#: src/main.py:204
msgid "Documentation"
msgstr "文档"

#: src/main.py:205
msgid "Become a Sponsor"
msgstr "成为赞助人"

#: src/main.py:206
msgid "Discussions"
msgstr "讨论"

#: src/ollama_models.py:33
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"最新一代的70B参数模型。Llama 3.3 70B 与 Llama 3.1 405B 模型相比提供了相似的性"
"能。"

#: src/ollama_models.py:56
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ 是Qwen系列模型的推理模型。"

#: src/ollama_models.py:84
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision 是一套经过指令调整的图像推理生成模型，有 11B 和 90B 大小。"

#: src/ollama_models.py:120
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Meta 的 Llama 3.2 采用小型 1B 和 3B 模型。"

#: src/ollama_models.py:155
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr "Llama 3.1 是新的来自 Meta 的先进模型，提供 8B, 70B, 和 405B 参数量。"

#: src/ollama_models.py:182
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3：迄今能力最强的开源大模型"

#: src/ollama_models.py:205
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "Mistral AI 发布的 7B 模型，已更新至 0.3 版。"

#: src/ollama_models.py:229
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr "具有大型标记上下文窗口的高性能开放式嵌入模型。"

#: src/ollama_models.py:258
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr "Gemma 是由 Google DeepMind 构建的轻量级先进开放模型系列。更新至 1.1 版"

#: src/ollama_models.py:314
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr "Qwen 1.5 是阿里云推出的一系列大型语言模型，参数从 0.5B 到 110B 不等"

#: src/ollama_models.py:378
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 是阿里巴巴推出的新的大语言模型系列"

#: src/ollama_models.py:407
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 是微软公司推出的一系列轻型 3B（迷你）和 14B（中型）先进开源模型。"

#: src/ollama_models.py:439
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr "Llama 2 是一组基础语言模型，参数从 7B 到 70B 不等。"

#: src/ollama_models.py:501
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Qwen2.5 模型在阿里巴巴最新的大规模数据集上进行了预训练，该数据集包含多达 18 "
"万亿个token。该模型最大支持 128K token，并支持多种语言。"

#: src/ollama_models.py:533
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr "Google Gemma 2 是一款高性能、高效率的模型，有三种规格：2B、9B 和 27B。"

#: src/ollama_models.py:567
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA 是一种新颖的端到端训练型大型多模态模型，它将视觉编码器和 Vicuna 结合"
"在一起，用于通用视觉和语言理解。已更新至 1.6 版。"

#: src/ollama_models.py:604
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr "大语言模型，可使用文本提示生成和讨论代码。"

#: src/ollama_models.py:650
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"最新系列的代码专用 Qwen 模型，在代码生成、代码推理和代码修复方面都有显著改"
"进。"

#: src/ollama_models.py:674
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr "一个具有 128k 上下文长度的先进模型，由 Mistral AI 与 NVIDIA 合作开发。"

#: src/ollama_models.py:696
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"TinyLlama 项目是一个开源的项目，旨在用 3 万亿标记训练一个 1.1B 的紧凑型 "
"Llama 模型。"

#: src/ollama_models.py:719
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "来自 mixedbread.ai 的最先进的大型嵌入模型"

#: src/ollama_models.py:752
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 是新一代透明训练的开放代码 LLM，有三种大小： 3B、7B 和 15B 参数。"

#: src/ollama_models.py:778
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Mistral AI 在 8x7b 和 8x22b 两种参数大小下建立的一套权重开放的专家混合模型"
"（MoE）。"

#: src/ollama_models.py:804
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"基于 Mixtral 混合专家模型的无审查、8x7b 和 8x22b 的微调模型，擅长编码任务。"
"由 Eric Hartford 创建。"

#: src/ollama_models.py:833
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma 是一系列功能强大的轻量级模型，可执行各种代码任务，如中间代码补全、"
"代码生成、自然语言理解、数学推理和指令跟踪。"

#: src/ollama_models.py:861
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"开源的 Mixture-of-Experts 代码语言模型在特定代码任务中的性能可与 GPT4-Turbo "
"相媲美。"

#: src/ollama_models.py:883
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr "Phi-2：微软研究院开发的 27 亿语言模型，具有出色的推理和语言理解能力。"

#: src/ollama_models.py:910
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "George Sung 和 Jarrad Hope 制作的无审查的 Llama 2 模型。"

#: src/ollama_models.py:945
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder 是一个基于两万亿个代码和自然语言标记训练而成的代码模型。"

#: src/ollama_models.py:986
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr "一套由 Snowflake 提供的文本嵌入模型，并对性能进行了优化。"

#: src/ollama_models.py:1014
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"来自 Microsoft AI 的最先进的大型语言模型，在复杂的对话、多语言、推理和代理用"
"例中性能更佳。"

#: src/ollama_models.py:1037
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr "基于 Mistral 的审查 Dolphin 模型，擅长代码任务。已更新至 2.8 版。"

#: src/ollama_models.py:1065
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 是 Eric Hartford 在 Llama 3 的基础上开发的新模型，有 8B 和 70B 大"
"小，具有各种教学、会话和代码技能。"

#: src/ollama_models.py:1099
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 是一个高性能的双语语言模型。"

#: src/ollama_models.py:1122
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr "Command R 是一种大语言模型，针对对话交互和长语境任务进行了优化。"

#: src/ollama_models.py:1159
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr "通用模型，参数范围从 30 亿到 700 亿，适合入门级硬件。"

#: src/ollama_models.py:1182
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr "根据 Llama 3 进行微调的 LLaVA 模型在多个基准测试中取得了更好的成绩。"

#: src/ollama_models.py:1209
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr 是一系列经过微调的 Mistral 和 Mixtral 模型，经过训练后可充当得力助手。"

#: src/ollama_models.py:1231
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr "拥有 38 亿个参数的轻量人工智能模型，性能超越同类和更大规模的模型。"

#: src/ollama_models.py:1259
msgid "Embedding models on very large sentence level datasets."
msgstr "在超大型语句级数据集上嵌入模型。"

#: src/ollama_models.py:1282
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr "Codestral 是 Mistral AI 首次为代码生成任务设计的代码模型。"

#: src/ollama_models.py:1319
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr "StarCoder 是一个经过 80 多种编程语言训练的代码生成模型。"

#: src/ollama_models.py:1351
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr "基于 Llama 和 Llama 2 的通用对话模型，上下文大小为 2K 至 16K。"

#: src/ollama_models.py:1388
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "IBM 代码智能开放式基础模型系列"

#: src/ollama_models.py:1410
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca 是一个 70 亿参数模型，利用 OpenOrca 数据集在 Mistral 7B 模型"
"的基础上进行了微调。"

#: src/ollama_models.py:1442
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 在一个新的高质量数据集上训练的一系列小型模型，参数分别为 1.35 亿、3.6 亿"
"和 17 亿。"

#: src/ollama_models.py:1474
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored 是一个 7B、13B 和 30B 参数模型，基于 Eric Hartford "
"的 Llama 2 Uncensored。"

#: src/ollama_models.py:1503
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr "基于 Llama 2 的模型进行了微调，以提高中文对话能力。"

#: src/ollama_models.py:1526
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr "BGE-M3 是 BAAI 推出的新型模型，具有多功能、多语言和多地域性的特点。"

#: src/ollama_models.py:1551
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr "功能丰富的，适合应用于 AI 辅助开发的模型，包括代码补全。"

#: src/ollama_models.py:1574
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"在各种数据上训练有素的开源模型系列，在各种基准测试中超越了 ChatGPT。已更新至 "
"3.5-0106 版。"

#: src/ollama_models.py:1602
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr "由 Cohere 发布的 Aya 23 是最先进的多语言模型新系列，支持 23 种语言。"

#: src/ollama_models.py:1625
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr "CodeQwen1.5 是一个基于大量代码数据预训练的大型语言模型。"

#: src/ollama_models.py:1653
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr "Nous Research 强大的模型系列，擅长科学讨论和编码任务。"

#: src/ollama_models.py:1675
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ 是一款功能强大、可扩展的大型语言模型，专为实际企业用例而设计。"

#: src/ollama_models.py:1698
msgid "State-of-the-art code generation model"
msgstr "最先进的代码生成模型"

#: src/ollama_models.py:1722
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B 是一种代码模型，其指令和代码完成变体可与 Code Llama 7B 等模型"
"相媲美，而后者的规模要大 2.5 倍。"

#: src/ollama_models.py:1744
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Eric Hartford 基于 TinyLlama 在新的 Dolphin 2.8 数据集上训练的 1.1B 参数实验"
"模型。"

#: src/ollama_models.py:1771
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 是 Teknium 在 Mistral 上使用完全开放的数据集微调的 7B 模型。"

#: src/ollama_models.py:1795
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 是 Mistral 的新的旗舰模型，在代码生成、数学运算和逻辑推理方面"
"具有显著优势，带有 128k 的上下文长度并支持多种语言。"

#: src/ollama_models.py:1828
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math 是建立在 Qwen2 LLMs 基础上的一系列专业数学语言模型，其数学能力大大"
"超过开源模型甚至闭源模型（如 GPT4o）。"

#: src/ollama_models.py:1852
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr "强大的多语言的通用模型，在性能上较 Llama 3 有竞争力。"

#: src/ollama_models.py:1886
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 是最先进的 1.6B 和 12B 参数语言模型，使用英语、西班牙语、德语、意"
"大利语、法语、葡萄牙语和荷兰语的多语言数据进行训练。"

#: src/ollama_models.py:1909
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr "BakLLaVA 是一个多模式模型，由 Mistral 7B 基本模型和 LLaVA 架构组成。"

#: src/ollama_models.py:1930
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"使用一种名为 “反思-调整 ”的新技术训练出的高性能模型，能教会 LLM 发现推理中的"
"错误并纠正方向。"

#: src/ollama_models.py:1961
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr "先进的语言模型包含 2 万亿个双语词库。"

#: src/ollama_models.py:1988
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr "该模型将 LLama-3 8B 的上下文长度从 8k 扩展到超过 1m 的标记。"

#: src/ollama_models.py:2021
msgid "Model focused on math and logic problems"
msgstr "侧重于数学和逻辑问题的模型"

#: src/ollama_models.py:2044
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr "moondream2 是一个小型视觉语言模型，被设计用于在边缘设备上高效运行。"

#: src/ollama_models.py:2066
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr "基于 Mistral 的微调模型对领域和语言都有很好的覆盖。"

#: src/ollama_models.py:2093
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"英伟达基于 Llama 3 的模型，擅长对话式问题解答（QA）和检索增强生成（RAG）。"

#: src/ollama_models.py:2120
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr "对话模型基于 Llama 2，在各种基准测试中表现优异。"

#: src/ollama_models.py:2148
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr "SQLCoder 是在 StarCoder 基础上微调的代码完成模型，用于 SQL 生成任务"

#: src/ollama_models.py:2175
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "基于 Llama 和 Llama 2 的 Nous Research 公司的通用模型。"

#: src/ollama_models.py:2198
msgid "Code generation model based on Code Llama."
msgstr "基于 Code Llama 的代码生成模型。"

#: src/ollama_models.py:2225
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Llama 2 的扩展，支持多达 128k 标记的上下文。"

#: src/ollama_models.py:2253
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr "基于 StarCoder2 的 Dolphin 模型系列的 7B 和 15B 无删节变体，擅长编码。"

#: src/ollama_models.py:2280
msgid "General use model based on Llama 2."
msgstr "基于 Llama 2 的通用模型。"

#: src/ollama_models.py:2309
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "强大、经济、高效的专家混合语言模型。"

#: src/ollama_models.py:2331
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling 是一个通过人工智能反馈强化学习训练出来的大型语言模型，专注于提高对话"
"机器人的帮助性。"

#: src/ollama_models.py:2353
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr "一名接受过哲学、心理学和人际关系培训的同伴助理。基于 Mistral。"

#: src/ollama_models.py:2391
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr "Hermes 3 是 Nous Research 旗舰产品 Hermes 系列 LLM 的最新版本"

#: src/ollama_models.py:2419
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder 是一系列开源代码语言模型，以不到 100 亿个参数提供最先进的编码性能。"

#: src/ollama_models.py:2450
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"技术创新研究所（TII）建立的大型语言模型，用于摘要、文本生成和聊天机器人。"

#: src/ollama_models.py:2487
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr "InternLM2.5 是为实际场景量身定制的 7B 参数模型，具有出色的推理能力。"

#: src/ollama_models.py:2509
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr "结构紧凑、功能强大的 10.7B 大语言机型，专为单匝通话而设计。"

#: src/ollama_models.py:2533
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 是一个 72B 参数模型，在代码完成、数学和日志提取任务方面表现出色。"

#: src/ollama_models.py:2556
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "新的从 Phi 3 Mini 微调而来的小型 LLaVA 模型。"

#: src/ollama_models.py:2584
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 由微软研究部门开发，是 Meta 的 Llama 2 模型的微调版。该模型在设计上尤"
"其擅长推理。"

#: src/ollama_models.py:2615
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr "为视觉语言理解设计的一系列多模态 LLM（MLLM）。"

#: src/ollama_models.py:2647
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"基于 Llama 2，在 Orca-style 数据集上进行了微调的基础模型。最初名为“Free "
"Willy”。"

#: src/ollama_models.py:2676
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr "Mistral Small 3 在低于70B参数的“小型”大语言模型类别中设立了新的基准。"

#: src/ollama_models.py:2698
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Eric Hartford 根据微软研究院的 Phi 语言模型制作的 2.7B 无审查 Dolphin 模型。"

#: src/ollama_models.py:2731
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 是一个紧凑型语言模型系列，有三种尺寸：135M、360M 和 1.7B 参数。"

#: src/ollama_models.py:2753
msgid "Uncensored version of Wizard LM model"
msgstr "未审查版 Wizard 大语言模型"

#: src/ollama_models.py:2776
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"英伟达公司推出的商业友好型小语言模型，针对角色扮演、RAG QA 和函数调用进行了优"
"化。"

#: src/ollama_models.py:2798
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr "Mistral 的扩展，支持 64K 或 128K 的上下文窗口。"

#: src/ollama_models.py:2826
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Llama 2 的扩展版，专门整合一般语言理解和特定领域知识，尤其是编程和数学知识。"

#: src/ollama_models.py:2848
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr "微调 Llama 2 模型，根据开源医疗数据集回答医疗问题。"

#: src/ollama_models.py:2875
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr "开源医疗大型语言模型，由 Llama 2 改编而来，适用于医疗领域。"

#: src/ollama_models.py:2903
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"来自 Groq 的一系列模型，代表了开源人工智能能力在工具使用/功能调用方面的重大进"
"步。"

#: src/ollama_models.py:2925
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct 是英伟达定制的大型语言模型，用于提高 LLM 生成"
"的对用户查询的回复的帮助性。"

#: src/ollama_models.py:2947
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr "Nexus Raven 是针对函数调用任务的 13B 指令调整模型。"

#: src/ollama_models.py:2968
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr "来自 Nous Research 的 Nous Hermes 2 模型，现在通过 Mixtral 进行训练。"

#: src/ollama_models.py:2991
msgid "Great code generation model based on Llama2."
msgstr "基于 Llama2 的优秀的代码生成模型。"

#: src/ollama_models.py:3013
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr "基于 Llama2 的无删减模型，支持 16K 上下文窗口。"

#: src/ollama_models.py:3054
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"IBM Granite 2B 和 8B 模型旨在支持基于工具的用例，支持检索增强生成（RAG），简"
"化代码生成、翻译和错误修复。"

#: src/ollama_models.py:3077
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder 是一个 7B 参数模型系列，使用 OSS-Instruct 在 75K 个合成指令数据"
"上进行训练，OSS-Instruct 是一种利用开源代码片段启发 LLM 的新方法。"

#: src/ollama_models.py:3099
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr "轻量级聊天模式无需高端硬件即可实现准确、灵敏的输出。"

#: src/ollama_models.py:3122
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr "通过合并两个现有的代码模型，创建了一个高性能代码指导模型。"

#: src/ollama_models.py:3145
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 是一个由 TII 构建的 11B 参数因果解码器模型，并通过 5T 标记进行了训"
"练。"

#: src/ollama_models.py:3167
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr "Wizard Vicuna 是一个 13B 参数模型，基于 MelodysDreamj 训练的 Llama 2。"

#: src/ollama_models.py:3189
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr "MistralLite 是基于 Mistral 的微调模型，具有更强的长语境处理能力。"

#: src/ollama_models.py:3212
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr "MathΣtral：Mistral AI 为数学推理和科学发现设计的 7B 模型。"

#: src/ollama_models.py:3234
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr "MotherDuck 和 Numbers Station 制作的 7B 参数文本到 SQL 模型。"

#: src/ollama_models.py:3255
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b 是 Dolphin-2.2-70b 的转换版本，通过将模型与自身交错创建"
"而成。"

#: src/ollama_models.py:3277
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro 预览版：先进的大型语言模型 (LLM)，拥有 220 亿个参数，专为适合单个 "
"GPU 而设计"

#: src/ollama_models.py:3304
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"一系列可将 HTML 内容转换为 Markdown 内容的模型，对内容转换任务非常有用。"

#: src/ollama_models.py:3325
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr "利用高质量数据对性能最佳的专家混合模型进行微调。"

#: src/ollama_models.py:3347
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr "以 Zephyr 为基础，利用高质量数据对 7B 聊天模型进行微调。"

#: src/ollama_models.py:3370
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"由 Open Orca OpenChat 模型和 Garage-bAInd Platypus 2 模型合并而成。专为聊天和"
"代码生成而设计。"

#: src/ollama_models.py:3387
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr "由两个经过微调的 Llama 2 70B 模型合并而成的语言模型。"

#: src/ollama_models.py:3428
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B 和 3B 模型是 IBM 首款专为低延迟使用而设计的混合专家（MoE）"
"Granite 模型。"

#: src/ollama_models.py:3450
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"在用于信息提取的私人高质量合成数据集上微调的 3.8B 模型，以 Phi-3 为基础。"

#: src/ollama_models.py:3501
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr "Cohere For AI 的语言模型经过训练，在 23 种不同语言中表现出色。"

#: src/ollama_models.py:3523
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX 是由 Databricks 创建的开放式通用 LLM。"

#: src/ollama_models.py:3545
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"阿里巴巴国际数字商业集团（AIDC-AI）为现实世界解决方案建立的开放式大型推理模"
"型。"

#: src/ollama_models.py:3568
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "来自 BAAI 的嵌入模型，将文本映射为矢量。"

#: src/ollama_models.py:3590
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr "基于 Llama 3 的开放式权重函数调用模型，与 GPT-4o 函数调用能力相媲美。"

#: src/ollama_models.py:3611
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr "一个强大的对话模型，设计用于聊天和指示用例。"

#: src/ollama_models.py:3633
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"DeekSeek-V2的升级版本，整合了DeepSeek-V2-Chat和DeepSeek-Coder-V2-Instruct的综"
"合能力和编码能力。"

#: src/ollama_models.py:3666
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma 是一套经过指令调整的模型，用于根据一组定义的安全策略评估文本提示"
"输入和文本输出响应的安全性。"

#: src/ollama_models.py:3688
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr "Bespoke Labs 开发的最先进的事实核查模型。"

#: src/ollama_models.py:3716
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 是一系列针对 LLM 输入和响应的内容安全分类进行微调的模型。"

#: src/ollama_models.py:3740
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr "可用于聚类或语义搜索等任务的句子转换器模型。"

#: src/ollama_models.py:3770
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder 是一个开放和可复制的代码 LLM 系列，包括 1.5B 和 8B 模型，支持中英文"
"对话。"

#: src/ollama_models.py:3799
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 是一个领先的指令跟随模型系列，由艾伦人工智能研究所提供完全开源的数据、"
"代码和配方。"

#: src/ollama_models.py:3827
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Snowflake 的前沿嵌入模型。Arctic Embed 2.0 在不牺牲英语性能或可扩展性的情况下"
"增加了多语言支持。"

#: src/ollama_models.py:3855
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr "IBM Granite Guardian 3.0 2B 和 8B 模型旨在检测提示和/或响应中的风险。"

#: src/ollama_models.py:3889
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 是一个经过指令调整的双语（英语和韩语）生成模型集合，参数从 2.4B "
"到 32B 不等，由 LG AI Research 开发并发布。"

#: src/ollama_models.py:3937
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr "Sailor2 是专为东南亚制作的多语种语言模型。有 1B、8B 和 20B 参数规格。"

#: src/ollama_models.py:3975
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"通过创新的训练技术，在科学、数学和编码方面性能优越的 10B 参数以下的高效人工智"
"能模型系列。"

#: src/ollama_models.py:4016
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"IBM Granite 2B 和 8B 模型是在超过 12 万亿个词组数据基础上训练的纯文本密集 "
"LLM，在 IBM 的初步测试中，其性能和速度都较前代产品有了显著提高。"

#: src/ollama_models.py:4057
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B 和 3B 模型是 IBM 为低延迟使用而设计的长上下文混合专家（MoE）"
"Granite 模型。"

#: src/ollama_models.py:4098
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"IBM Granite Embedding 30M 和 278M 模型是纯文本密集生物编码器嵌入模型，其中 "
"30M 仅提供英语版本，而 278M 则服务于多语言使用案例。"

#: src/ollama_models.py:4120
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr "Phi-4 是微软发布的14B参数的最新开源模型。"

#: src/ollama_models.py:4143
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr "一个新的小型推理模型，基于Qwen 2.5 3B指令模型微调而来。"

#: src/ollama_models.py:4167
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 是 Dolphin 系列指令微调模型的下一代，旨在成为终极"
"通用本地模型，能够支持编程、数学、代理行为、函数调用以及一般用途场景。"

#: src/ollama_models.py:4218
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"DeepSeek 的第一代推理模型，性能与 OpenAI-o1 相当，包括六个从基于 Llama 和 "
"Qwen 的 DeepSeek-R1 提炼而来的大纲模型。"

#: src/ollama_models.py:4239
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"一个强大的Mixture-of-Experts（MoE）语言模型，总参数量为671B，每个词令牌激活"
"37B参数。"

#: src/ollama_models.py:4266
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 是一个新的家族，包括7B和13B参数的模型，训练数据量高达5万亿个词令牌。这"
"些模型与同等规模的完全开源模型相当或更优，并且在英语学术基准测试中与像 Llama "
"3.1 这样的开放权重模型竞争激烈。"

#: src/ollama_models.py:4314
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"Cohere R 系列中的最小模型提供了顶级的速度、效率和质量，使得在普通GPU和边缘设"
"备上构建强大的AI应用变得可能。"

#: src/ollama_models.py:4342
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"一个完全开源的推理模型家族，使用了从 DeepSeek-R1 提炼出的数据集构建而成。"

#: src/ollama_models.py:4366
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"基于 DeepSeek-R1 提炼的 Qwen-1.5B 微调版本，在流行的数学评估中性能超越了 "
"OpenAI 的 o1-preview，仅使用1.5亿个参数。"

#: src/ollama_models.py:4396
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"经过 Perplexity 后微调的 DeepSeek-R1 模型版本，能够提供\"无偏见、准确且事实"
"\"的信息。"

#: src/ollama_models.py:4433
msgid "The current, most capable model that runs on a single GPU."
msgstr "这是当前单GPU环境下性能最优的模型。"

#: src/ollama_models.py:4480
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini 模型在多语言处理、推理能力及数学计算性能上均有显著提升，并新增了对"
"函数调用机制的支持。"

#: src/ollama_models.py:4504
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"一款紧凑高效的多模态视觉语言模型，专为视觉文档理解而设计，能够从表格、图表、"
"信息图、曲线图、示意图等多种视觉元素中自动提取内容。"

#: src/ollama_models.py:4544
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 是 IBM Granite 系列的长上下文 AI 模型，经过微调以增强思维推理能"
"力。"

#: src/ollama_models.py:4568
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"这是轻量级 Command R7B 模型的最新尖端版本，专为中东北非地区企业打造，在高级阿"
"拉伯语处理能力方面表现卓越。"

#: src/ollama_models.py:4614
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr "专为高要求企业优化的1110亿参数大模型，提供快速、安全且高质量的AI服务。"

#: src/ollama_models.py:4655
msgid ""
"Qwen3 is the latest generation of large language models in Qwen series, "
"offering a comprehensive suite of dense and mixture-of-experts (MoE) models."
msgstr ""
"Qwen3是通义千问系列大语言模型的最新版本，提供包含稠密型和专家混合（MoE）架构"
"在内的完整模型组合。"

#: src/ollama_models.py:4802
msgid "Devstral: the best open source model for coding agents"
msgstr "Devstral：专为代码智能体打造的最强开源模型"

#: src/ollama_models.py:4830
msgid "Meta's latest collection of multimodal models."
msgstr "Meta的最新多模态模型套件"

#: src/ollama_models.py:4878
msgid ""
"Flagship vision-language model of Qwen and also a significant leap from the "
"previous Qwen2-VL."
msgstr "Qwen系列旗舰级视觉语言模型，较前代Qwen2-VL实现重大突破"

#: src/ollama_models.py:4908
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""
"DeepCoder 是一个完全开源的 140 亿参数（14B）代码模型，性能达到 O3-mini 级别，"
"同时还提供 15 亿参数（1.5B）的轻量版本。"

#: src/ollama_models.py:4933
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""
"基于Mistral Small 3升级的Mistral Small 3.1（2503）新增了业界领先的视觉理解能"
"力以及将上下文处理长度扩展至12.8万词符的同时完整保留了原有文本处理性能。"

#: src/ollama_models.py:4973
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""
"由深度思考（Deep Cogito）研发的Cogito v1预览版系列混合推理模型，在多数标准基"
"准测试中表现卓越，性能超越同体量最优开源模型（包括LLaMA、深度求索[DeepSeek]及"
"通义千问[Qwen]等同类模型）。"

#: src/ollama_models.py:5002
msgid ""
"IBM Granite 2B and 8B models are 128K context length language models that "
"have been fine-tuned for improved reasoning and instruction-following "
"capabilities."
msgstr ""
"IBM Granite 2B与8B模型是支持128K上下文长度的大语言模型，经过专门优化以提升推"
"理能力和指令遵循性能。"

#: src/ollama_models.py:5040
msgid ""
"Phi 4 reasoning and reasoning plus are 14-billion parameter open-weight "
"reasoning models that rival much larger models on complex reasoning tasks."
msgstr ""
"Phi-4 Reasoning与Reasoning Plus是两款14B参数的开源推理模型，在复杂推理任务上"
"可媲美规模更大的模型。"

#: src/ollama_models.py:5073
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""
"LG人工智能研究院（LG AI Research）开发并发布的 EXAONE Deep 模型，在数学与编程"
"基准测试等多项推理任务中展现出卓越性能，其参数量级覆盖24亿至320亿"
"（2.4B-32B）。"

#: src/ollama_models.py:5100
msgid ""
"Phi 4 mini reasoning is a lightweight open model that balances efficiency "
"with advanced reasoning ability."
msgstr ""
"Phi-4 Mini Reasoning 是一款轻量级开源模型，在高效运行与先进推理能力之间实现了"
"出色平衡。"

#: src/window.py:156
msgid "Ollama Was Not Found"
msgstr "未找到 Ollama"

#: src/window.py:157
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""
"要添加一个托管的 Ollama 实例，您必须在您的设备上本地安装 Ollama。这是一个简单"
"的过程，应该不会超过 5 分钟。"

#: src/window.py:159
msgid "Open Tutorial in Web Browser"
msgstr "在网页浏览器中打开教程"

#: src/window.py:165 src/window.py:173 src/window.ui:496 src/window.ui:506
#: src/window.ui:528
msgid "Add Instance"
msgstr "添加实例"

#: src/window.py:174
msgid "Select a type of instance to add"
msgstr "选择要添加的实例类型"

#: src/window.py:387
msgid "No tools enabled."
msgstr "无已启用的工具。"

#: src/window.py:387
msgid "Open Tool Manager"
msgstr "打开工具管理器"

#: src/window.py:390
msgid "Please select a model before chatting"
msgstr "请在对话前先选择一个模型"

#: src/window.py:463 src/window.py:464 src/window.py:559 src/window.ui:355
msgid "Close"
msgstr "关闭"

#: src/window.py:466 src/window.py:467 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "下一页"

#: src/window.py:557 src/window.ui:992 src/window.ui:996
#: src/widgets/dialog.py:150 src/widgets/dialog.py:163
#: src/widgets/dialog.py:176 src/widgets/instance_manager.py:470
#: src/widgets/instance_manager.py:471 src/widgets/model_manager.py:644
#: src/widgets/blocks/code.py:136 src/widgets/blocks/text.py:111
#: src/widgets/tools/tools.py:132
msgid "Cancel"
msgstr "取消"

#: src/window.py:558
msgid "Hide"
msgstr "隐藏"

#: src/window.py:562
msgid "Close Alpaca?"
msgstr "关闭 Alpaca？"

#: src/window.py:563
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr "当前有一个任务正在进行中。你确定要关闭 Alpaca 吗？"

#: src/window.py:775 src/window.ui:163 src/window.ui:1232
#: src/widgets/chat.py:206 src/widgets/instance_manager.py:58
#: src/widgets/instance_manager.py:69 src/widgets/instance_manager.py:110
msgid "New Chat"
msgstr "新对话"

#: src/window.py:855
msgid "This video does not have any transcriptions"
msgstr "本视频没有任何转录内容"

#: src/window.py:863
msgid "Attach YouTube Video?"
msgstr "附加 YouTube 视频？"

#: src/window.py:864
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"请选择要附加的转录"

#: src/window.py:870
msgid "Error attaching video, please try again"
msgstr "附加视频出错，请重试"

#: src/window.py:892 src/window.py:1259
msgid "Attach Website? (Experimental)"
msgstr "附加网站？（试验性）"

#: src/window.py:893
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"您确定要附加\n"
"'{}'?"

#: src/window.py:912 src/window.py:1256
msgid "Image recognition is only available on specific models"
msgstr "图像识别功能仅适用于特定模型"

#: src/window.py:1038
msgid "Chat imported successfully"
msgstr "对话记录已成功导入"

#: src/window.py:1052
msgid "Attachment failed, screenshot might be too big"
msgstr "添加附件失败，截图可能太大了。"

#: src/window.py:1101
msgid "Any compatible Alpaca attachment"
msgstr "任何与 Alpaca 兼容的附件"

#: src/window.py:1227
msgid "Attach Screenshot"
msgstr "附加屏幕截图"

#: src/window.py:1260
msgid "Please enter a website URL"
msgstr "请输入一个网站地址"

#: src/window.py:1266
msgid "Attach YouTube Captions?"
msgstr "附加上 YouTube 字幕？"

#: src/window.py:1267
msgid "Please enter a YouTube video URL"
msgstr "请输入一个YouTube视频地址"

#: src/window.py:1275
msgid "Download Model?"
msgstr "下载模型？"

#: src/window.py:1276
msgid "Please enter the model name following this template: name:tag"
msgstr "请按照以下模板输入模型名称：name:tag"

#: src/window.py:1283
msgid "Delete All Chats?"
msgstr "要删除所有对话吗？"

#: src/window.py:1284
msgid "Are you sure you want to delete all chats?"
msgstr "你确定要删除所有对话吗？"

#: src/window.py:1286 src/widgets/attachments.py:211 src/widgets/chat.py:459
msgid "Delete"
msgstr "删除"

#: src/window.py:1313
msgid "Already Installed!"
msgstr "安装完成！"

#: src/window.ui:34
msgid "Welcome"
msgstr "欢迎！"

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "上一个"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "欢迎来到 Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr "助力您的潜力"

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""
"使用AI模型生成的代码执行导致的任何设备或软件损坏，Alpaca及其开发人员不承担任"
"何责任。请在运行代码前谨慎检查并仔细审核。\n"
"\n"
"Alpaca 按照 GPLv3.0 协议分发，本软件不提供任何形式的保障。"

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr "代码轻松执行"

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""
"Alpaca 可以直接从您的对话中运行Python、C++，甚至HTML（需要一个live服务器）。"
"试试看！"

#: src/window.ui:107
msgid "Private by Design"
msgstr "私密性设计"

#: src/window.ui:108
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""
"使用 Alpaca，您的对话将保存在您设备的本地，因此您可以确保您的数据始终安全且私"
"密。"

#: src/window.ui:114
msgid "Local AI"
msgstr "本地 AI"

#: src/window.ui:115
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""
"Alpaca 支持与 Gemini、ChatGPT 等 AI 服务商对接。若需在本地设备运行 AI 模型，"
"您只需在 Alpaca 中安装 Ollama 即可。我们已大幅简化安装流程，助您快速上手！"

#: src/window.ui:120 src/window.ui:121
msgid "Install Ollama"
msgstr "安装 Ollama"

#: src/window.ui:174
msgid "Menu"
msgstr "目录"

#: src/window.ui:181
msgid "Search Chats"
msgstr "搜索对话"

#: src/window.ui:190
msgid "Chat search bar"
msgstr "对话搜索栏"

#: src/window.ui:198 src/window.ui:200
msgid "Search chats"
msgstr "搜索对话"

#: src/window.ui:236
msgid "No Chats Found"
msgstr "未找到对话"

#: src/window.ui:237
msgid "Oh no! It looks like there are no chats found for your search."
msgstr "哎呀！似乎没有找到符合您搜索条件的聊天记录呢"

#: src/window.ui:254
msgid "Toggle Sidebar"
msgstr "切换侧边栏"

#: src/window.ui:261
msgid "Search Messages"
msgstr "搜索消息"

#: src/window.ui:278 src/window.ui:303 src/window.ui:1256
msgid "Manage Models"
msgstr "管理模型"

#: src/window.ui:299
msgid "Add Models"
msgstr "添加模型"

#: src/window.ui:316
msgid "Chat Menu"
msgstr "对话列表"

#: src/window.ui:329
msgid "Message search bar"
msgstr "消息搜索栏"

#: src/window.ui:338 src/window.ui:340
msgid "Search messages"
msgstr "搜索消息"

#: src/window.ui:356
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr "警告：省电模式已启用，消息生成速度将减慢"

#: src/window.ui:391 src/window.ui:1354
msgid "Attach File"
msgstr "附加文件"

#: src/window.ui:428
msgid "Send Message"
msgstr "发送消息"

#: src/window.ui:447
msgid "Stop Message"
msgstr "停止消息"

#: src/window.ui:477
msgid "Instance Manager"
msgstr "实例管理器"

#: src/window.ui:492
msgid "No Instances Found"
msgstr "未找到任何实例"

#: src/window.ui:493
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr "这里看起来有点空荡。试试添加一个实例开始使用吧！"

#: src/window.ui:522
msgid "Added Instances"
msgstr "已添加的实例"

#: src/window.ui:523
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr "管理您的 AI 实例，在生成响应时，对话和交流会在不同实例之间共享。"

#: src/window.ui:559
msgid "Tool Manager"
msgstr "工具管理器"

#: src/window.ui:570
msgid "Available Tools"
msgstr "可用工具"

#: src/window.ui:571
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""
"当您在发送按钮的目录菜单中选择\"使用工具\"时，AI模型可能调用的功能模块。"

#: src/window.ui:590
msgid "Model Manager"
msgstr "模型管理器"

#: src/window.ui:628
msgid "Search Model"
msgstr "搜索模型"

#: src/window.ui:642
msgid "Model Manager Menu"
msgstr "模型管理菜单"

#: src/window.ui:655
msgid "Model search bar"
msgstr "模型搜索框"

#: src/window.ui:667 src/window.ui:669
msgid "Search models"
msgstr "搜索模型"

#: src/window.ui:676
msgid "Filter Models"
msgstr "过滤器模型"

#: src/window.ui:692
msgid "Added"
msgstr "已添加"

#: src/window.ui:702 src/window.ui:763 src/window.ui:817
msgid "No Models Found"
msgstr "未找到模型"

#: src/window.ui:703
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr "这里看起来有点空荡。试试下载一些模型或更改您的 AI 实例开始使用吧！"

#: src/window.ui:706 src/window.ui:716 src/window.ui:1252
msgid "Manage Instances"
msgstr "管理实例"

#: src/window.ui:764 src/window.ui:818
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"看来没有找到符合条件的模型。您可以尝试调整关键词，或者探索一些新的内容！"

#: src/window.ui:776
msgid "Available"
msgstr "可获取"

#: src/window.ui:830
msgid "Creator"
msgstr "创建者"

#: src/window.ui:841
msgid "Model Creator"
msgstr "模型创建者"

#: src/window.ui:842
msgid "Select a method of importing a model to continue"
msgstr "请选择一种导入模型的方法继续："

#: src/window.ui:854
msgid "GGUF File"
msgstr "GGUF 文件"

#: src/window.ui:865
msgid "Existing Model"
msgstr "已存在的模型"

#: src/window.ui:883
msgid "Identity"
msgstr "识别信息"

#: src/window.ui:886
msgid "Base"
msgstr "基础模型"

#: src/window.ui:893
msgid "Profile Picture"
msgstr "简介图片"

#: src/window.ui:898
msgid "Open File"
msgstr "打开文件"

#: src/window.ui:909 src/widgets/instance_manager.py:278
msgid "Name"
msgstr "名称"

#: src/window.ui:914 src/widgets/model_manager.py:478
msgid "Tag"
msgstr "标签"

#: src/window.ui:921 src/widgets/model_manager.py:495
msgid "Context"
msgstr "上下文"

#: src/window.ui:922
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr "用模型的主要语言（通常是英语）描述您希望的模型的行为。"

#: src/window.ui:950
msgid "Behavior"
msgstr "行为"

#: src/window.ui:953
msgid "Imagination"
msgstr "想象力"

#: src/window.ui:954
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr "较高的数字会导致模型生成更多样化的回答。（top_k）"

#: src/window.ui:968
msgid "Focus"
msgstr "专注力"

#: src/window.ui:969
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "较高的数字会增加可能的答案范围。（top_p）"

#: src/window.ui:1002 src/window.ui:1010
msgid "Add Model"
msgstr "添加模型"

#: src/window.ui:1044 src/window.ui:1266
msgid "Preferences"
msgstr "首选项"

#: src/window.ui:1052
msgid "Run Alpaca In Background"
msgstr "在后台运行 Alpaca"

#: src/window.ui:1059
msgid "Show Power Saver Warning"
msgstr "显示省电警告"

#: src/window.ui:1060
msgid "When running a managed Ollama instance"
msgstr "运行托管的 Ollama 实例时"

#: src/window.ui:1067
msgid "Zoom"
msgstr "缩放"

#: src/window.ui:1084
msgid "Speech Recognition Model"
msgstr "语音识别模型\t"

#: src/window.ui:1085
msgid ""
"Models are downloaded upon first use, you can delete them from the model "
"manager"
msgstr "模型将在首次使用时自动下载，您可通过模型管理器随时删除。"

#: src/window.ui:1092
msgid "Speech Recognition Language"
msgstr "语音识别语言"

#: src/window.ui:1099
msgid "Auto Send Message After Talking"
msgstr "通话后自动发送消息"

#: src/window.ui:1110
msgid "Default Text to Speech Voice"
msgstr "默认文本转语音声线"

#: src/window.ui:1111
msgid ""
"Voices are downloaded upon first use, each weighing around 1 MB, and you can "
"delete them from the model manager"
msgstr ""
"语音模型将在首次使用时自动下载（每个约1MB大小），您可通过模型管理器随时删除。"

#: src/window.ui:1118
msgid "Dictate New Messages Automatically"
msgstr "自动听写新消息"

#: src/window.ui:1119
msgid "Dictate new messages once they have finished being generated"
msgstr "消息生成后自动听写"

#: src/window.ui:1132
msgid "Delete All Chats"
msgstr "删除所有对话"

#: src/window.ui:1144
msgid "Notice"
msgstr "通知"

#: src/window.ui:1164
msgid ""
"Hey Alpaca users! We're so excited to bring you a fresh update packed with "
"awesome new features to explore! Get ready to experience Alpaca in a whole "
"new way!"
msgstr ""
"亲爱的Alpaca用户们！我们怀着无比激动的心情为您带来全新升级版本！本次更新包含"
"一系列令人惊艳的新功能，等待您来探索！准备好以焕然一新的方式体验Alpaca吧！"

#: src/window.ui:1171
msgid "Smart Tools"
msgstr "智能工具"

#: src/window.ui:1172
msgid ""
"Supported AI models can use handy tools to grab information both locally and "
"online. Head over to the brand new \"Tool Manager\" to toggle them on or off."
msgstr ""
"已支持的 AI 模型可使用便捷工具获取本地及在线信息。前往全新推出的\"工具管理器"
"\"开启或关闭这些功能。"

#: src/window.ui:1179
msgid "Talk to Models"
msgstr "与模型对话"

#: src/window.ui:1180
msgid ""
"You can now dictate your messages using local speech recognition. It's super "
"convenient! You can even customize your language and other settings in the "
"Preferences dialog."
msgstr ""
"现在您可以使用本地语音识别口述消息，超级方便！您还可以在“偏好设置”对话框中自"
"定义语言和其他选项"

#: src/window.ui:1187
msgid "Find Models Faster"
msgstr "快速查找模型"

#: src/window.ui:1188
msgid ""
"Browsing through your Ollama models just got easier! We've added the ability "
"to filter models by their categories in the Model Manager. Now you can "
"quickly find exactly the model you're looking for."
msgstr ""
"浏览您的 Ollama 模型变得更简单了！我们新增了在模型管理器中按类别筛选的功能，"
"现在您可以快速找到所需模型"

#: src/window.ui:1195
msgid "Math Rendering"
msgstr "数学公式渲染"

#: src/window.ui:1196
msgid ""
"We've improved how LaTeX equations are rendered in messages, making them "
"look cleaner and more consistent. Your mathematical discussions will be "
"clearer than ever!"
msgstr ""
"我们优化了消息中LaTeX方程的渲染效果，使其更清晰、更统一。您的数学讨论将比以往"
"更加一目了然！"

#: src/window.ui:1203
msgid "More Instances"
msgstr "更多AI服务接入"

#: src/window.ui:1204
msgid ""
"Get ready to connect Alpaca to a whole universe of AI providers! We've added "
"support for over 5 new AI instance providers, including Anthropic, "
"OpenRouter, and Fireworks. The possibilities are endless!"
msgstr ""
"现在您可以将Alpaca连接到更多AI服务提供商了！我们新增支持Anthropic、"
"OpenRouter、Fireworks等5家以上AI服务，可能性无限扩展！"

#: src/window.ui:1211
msgid "Attachment Enhancement"
msgstr "文件附件功能升级"

#: src/window.ui:1212
msgid ""
"You can now attach and ask questions about even more file types, including ."
"docx, .pptx, and .xlsx! Plus, when you preview an attachment, you'll see it "
"with rich text styling, making it easier to understand the content before "
"you send it."
msgstr ""
"现已支持更多文件类型（包括.docx、.pptx和.xlsx）的附件上传与提问！此外，预览附"
"件时将显示富文本样式，让您在发送前更轻松理解内容。"

#: src/window.ui:1236 src/widgets/chat.py:20
msgid "New Notebook"
msgstr "新建笔记本"

#: src/window.ui:1244
msgid "Start Quick Ask"
msgstr "开始快速提问"

#: src/window.ui:1248
msgid "Import Chat"
msgstr "导入对话"

#: src/window.ui:1260
msgid "Manage Tools"
msgstr "管理工具"

#: src/window.ui:1270
msgid "Keyboard Shortcuts"
msgstr "快捷键"

#: src/window.ui:1274
msgid "About Alpaca"
msgstr "关于 Alpaca"

#: src/window.ui:1282 src/window.ui:1316
msgid "Rename Chat"
msgstr "重命名对话"

#: src/window.ui:1286 src/window.ui:1320
msgid "Duplicate Chat"
msgstr "复制对话"

#: src/window.ui:1290 src/window.ui:1324 src/widgets/chat.py:557
msgid "Export Chat"
msgstr "导出对话"

#: src/window.ui:1296 src/window.ui:1330
msgid "Delete Chat"
msgstr "删除对话"

#: src/window.ui:1304
msgid "Reload Added Models"
msgstr "重载已添加的模型"

#: src/window.ui:1308
msgid "Download Model From Name"
msgstr "根据名称下载模型"

#: src/window.ui:1338
msgid "Send as User"
msgstr "以用户身份发送"

#: src/window.ui:1342
msgid "Send as System"
msgstr "以系统身份发送"

#: src/window.ui:1346 src/gtk/help-overlay.ui:133
msgid "Use Tools"
msgstr "使用工具"

#: src/window.ui:1358
msgid "Attach Website"
msgstr "附加网站"

#: src/window.ui:1362
msgid "Attach YouTube Captions"
msgstr "附加 YouTube 字幕"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "通用"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "显示快捷方式"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "首选项"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr "快速提问"

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "模型管理器"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "实例管理器"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr "行为管理器"

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "切换侧边栏"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr "退出"

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "对话管理"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "创建对话"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "删除对话"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "清除对话"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "重命名对话"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr "切换搜索栏"

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "消息输入框"

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "复制"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "粘贴"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr "打开 Emoji 目录"

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "插入新行"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr "以系统身份发送消息"

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr "系统消息会被模型视为严格的指令"

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr "要求模型调用工具生成消息"

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr "以用户身份发送消息"

#: src/widgets/attachments.py:124
msgid "Remove Attachment"
msgstr "移除附件"

#: src/widgets/attachments.py:138
msgid "Replace Notebook Content"
msgstr "更换笔记本内容"

#: src/widgets/attachments.py:208
msgid "Delete Attachment?"
msgstr "删除附件吗？"

#: src/widgets/attachments.py:209 src/widgets/chat.py:457
msgid "Are you sure you want to delete '{}'?"
msgstr "你确定你想要删除 '{}' 吗？"

#: src/widgets/attachments.py:285
msgid "Image"
msgstr "图像"

#: src/widgets/attachments.py:296 src/widgets/attachments.py:308
msgid "Missing Image"
msgstr "无图像"

#: src/widgets/chat.py:86 src/widgets/instance_manager.py:96
msgid "Notebook"
msgstr "笔记"

#: src/widgets/chat.py:87
msgid "Start a notebook with a message"
msgstr "根据消息创建笔记本"

#: src/widgets/chat.py:95 src/widgets/chat.py:247
msgid "No Messages Found"
msgstr "未找到相关消息"

#: src/widgets/chat.py:96 src/widgets/chat.py:248
msgid "Uh oh! No messages found for your search."
msgstr "哎呀！没有找到符合搜索条件的消息"

#: src/widgets/chat.py:238
msgid "Try one of these prompts"
msgstr "试试这些提示"

#: src/widgets/chat.py:268
msgid "Send prompt: '{}'"
msgstr "发送提示： '{}'"

#: src/widgets/chat.py:274
msgid "Refresh Prompts"
msgstr "刷新提示词"

#: src/widgets/chat.py:435
msgid "Rename Chat?"
msgstr "重命名对话？"

#: src/widgets/chat.py:436
msgid "Renaming '{}'"
msgstr "重命名 '{}'"

#: src/widgets/chat.py:438
msgid "Chat name"
msgstr "对话命名"

#: src/widgets/chat.py:439
msgid "Rename"
msgstr "重命名"

#: src/widgets/chat.py:456
msgid "Delete Chat?"
msgstr "删除对话？"

#: src/widgets/chat.py:464
msgid "Copy of {}"
msgstr "{} 的副本"

#: src/widgets/chat.py:477
msgid "Chat exported successfully"
msgstr "聊天记录已成功导出"

#: src/widgets/chat.py:497
msgid "User"
msgstr "用户"

#: src/widgets/chat.py:501
msgid "System"
msgstr "系统"

#: src/widgets/chat.py:549
msgid "Importable (.db)"
msgstr "可导入 (.db)"

#: src/widgets/chat.py:550
msgid "Markdown"
msgstr "Markdown格式"

#: src/widgets/chat.py:551
msgid "Markdown (Obsidian Style)"
msgstr "Markdown格式 （Obsidian 风格）"

#: src/widgets/chat.py:552
msgid "JSON"
msgstr "JSON"

#: src/widgets/chat.py:553
msgid "JSON (Include Metadata)"
msgstr "JSON（包含元数据）"

#: src/widgets/chat.py:558
msgid "Select a method to export the chat"
msgstr "选择一个模型以导出对话"

#: src/widgets/dialog.py:148 src/widgets/dialog.py:161
#: src/widgets/dialog.py:174 src/widgets/tools/tools.py:136
msgid "Accept"
msgstr "接受"

#: src/widgets/instance_manager.py:30 src/widgets/instance_manager.py:430
msgid "Instance"
msgstr "实例"

#: src/widgets/instance_manager.py:88
msgid "Notebook Error"
msgstr "笔记本发生错误"

#: src/widgets/instance_manager.py:89 src/widgets/instance_manager.py:159
msgid "An error occurred while running tool"
msgstr "运行工具过程中发生错误"

#: src/widgets/instance_manager.py:116
msgid "Selecting tool to use..."
msgstr "正在选择使用工具…"

#: src/widgets/instance_manager.py:125
msgid "Using {}"
msgstr "正在使用 {}"

#: src/widgets/instance_manager.py:158
msgid "Tool Error"
msgstr "工具错误"

#: src/widgets/instance_manager.py:165
msgid "Generating message..."
msgstr "正在生成消息..."

#: src/widgets/instance_manager.py:219 src/widgets/instance_manager.py:529
#: src/widgets/instance_manager.py:543 src/widgets/instance_manager.py:693
#: src/widgets/instance_manager.py:775 src/widgets/instance_manager.py:822
#: src/widgets/instance_manager.py:856 src/widgets/instance_manager.py:903
#: src/widgets/instance_manager.py:928 src/widgets/instance_manager.py:954
msgid "Instance Error"
msgstr "实例错误"

#: src/widgets/instance_manager.py:220
msgid "Message generation failed"
msgstr "消息生成失败"

#: src/widgets/instance_manager.py:286
msgid "Port"
msgstr "端口"

#: src/widgets/instance_manager.py:287
msgid "Which network port will '{}' use"
msgstr "'{}' 将会使用那哪一个网络端口"

#: src/widgets/instance_manager.py:301
msgid "Instance URL"
msgstr "实例 URL"

#: src/widgets/instance_manager.py:304 src/widgets/instance_manager.py:314
#: src/widgets/instance_manager.py:317 src/widgets/instance_manager.py:319
msgid "API Key (Unchanged)"
msgstr "API密钥（未更改）"

#: src/widgets/instance_manager.py:304 src/widgets/instance_manager.py:314
msgid "API Key (Optional)"
msgstr "API密钥（可选）"

#: src/widgets/instance_manager.py:317 src/widgets/instance_manager.py:319
msgid "API Key"
msgstr "API密钥"

#: src/widgets/instance_manager.py:327
msgid "Max Tokens"
msgstr "最大tokens数"

#: src/widgets/instance_manager.py:328
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"定义了 AI 在响应中可以生成的最大 token 数（单词+空格）。更多的 token 允许更长"
"的回复，但可能需要更多的时间并产生更高的成本。"

#: src/widgets/instance_manager.py:343
msgid "Temperature"
msgstr "温度（随机性控制参数）"

#: src/widgets/instance_manager.py:344
msgid "Increasing the temperature will make the models answer more creatively."
msgstr "提高温度会使模型的回答更具创造性。"

#: src/widgets/instance_manager.py:359
msgid "Seed"
msgstr "种子值"

#: src/widgets/instance_manager.py:360
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr "将其设置为除0以外的具体数字可以确保在相同提示下模型生成相同的文本。"

#: src/widgets/instance_manager.py:375
msgid "Overrides"
msgstr "覆盖设置"

#: src/widgets/instance_manager.py:375
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr "这些条目是可选的，它们用于排查与 Ollama 相关的 GPU 问题。"

#: src/widgets/instance_manager.py:393
msgid "Model Directory"
msgstr "模型目录"

#: src/widgets/instance_manager.py:395
msgid "Select Directory"
msgstr "选择目录"

#: src/widgets/instance_manager.py:410
msgid "Default Model"
msgstr "默认模型"

#: src/widgets/instance_manager.py:410
msgid "Model to select when starting a new chat."
msgstr "启动新聊天时选择的模型。"

#: src/widgets/instance_manager.py:412
msgid "Title Model"
msgstr "标题模型"

#: src/widgets/instance_manager.py:412
msgid "Model to use when generating a chat title."
msgstr "生成聊天标题时使用的模型。"

#: src/widgets/instance_manager.py:477 src/widgets/instance_manager.py:478
#: src/widgets/blocks/code.py:145 src/widgets/blocks/text.py:120
msgid "Save"
msgstr "保存"

#: src/widgets/instance_manager.py:530 src/widgets/instance_manager.py:776
#: src/widgets/instance_manager.py:823 src/widgets/instance_manager.py:857
msgid "Could not retrieve added models"
msgstr "无法检索到已添加的模型"

#: src/widgets/instance_manager.py:544
msgid "Could not retrieve available models"
msgstr "无法检索到可用的模型"

#: src/widgets/instance_manager.py:613
msgid "Ollama (Managed)"
msgstr "Ollama（托管版）"

#: src/widgets/instance_manager.py:622
msgid "Local AI instance managed directly by Alpaca"
msgstr "由 Alpaca 托管的本地 AI 实例"

#: src/widgets/instance_manager.py:645
msgid "Alpaca Support"
msgstr "Alpaca 支持文档"

#: src/widgets/instance_manager.py:652
msgid "Model request too large for system"
msgstr "模型需求太大，超出系统处理能力"

#: src/widgets/instance_manager.py:655
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr "检测到 AMD GPU，但未安装支持扩展，Ollama 将使用 CPU。"

#: src/widgets/instance_manager.py:657
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "检测到 AMD GPU，但缺少 ROCm，Ollama 将使用 CPU。"

#: src/widgets/instance_manager.py:659
msgid "Using AMD GPU type '{}'"
msgstr "使用 AMD GPU 类型"

#: src/widgets/instance_manager.py:669
msgid "Integrated Ollama instance is not running"
msgstr "集成的 Ollama 实例未运行"

#: src/widgets/instance_manager.py:694
msgid "Managed Ollama instance failed to start"
msgstr "托管的 Ollama 实例启动失败"

#: src/widgets/instance_manager.py:699
msgid "Integrated Ollama instance is running"
msgstr "集成的 Ollama 实例正在运行"

#: src/widgets/instance_manager.py:704 src/widgets/instance_manager.py:707
msgid "Ollama Log"
msgstr "Ollama 日志"

#: src/widgets/instance_manager.py:724
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "本地或远程AI实例不由Alpaca管理"

#: src/widgets/instance_manager.py:904 src/widgets/instance_manager.py:929
#: src/widgets/instance_manager.py:955
msgid "Could not retrieve models"
msgstr "无法获取模型列表"

#: src/widgets/instance_manager.py:915
msgid "Fireworks AI inference platform"
msgstr "Fireworks AI 推理平台"

#: src/widgets/instance_manager.py:940
msgid "Lambda Labs cloud inference API"
msgstr "Lambda Labs 云端推理 API"

#: src/widgets/instance_manager.py:966
msgid "Cerebras AI cloud inference API"
msgstr "Cerebras AI 云端推理API"

#: src/widgets/instance_manager.py:972
msgid "Kluster AI cloud inference API"
msgstr "Kluster AI 云端推理API"

#: src/widgets/instance_manager.py:976
msgid "OpenAI Compatible Instance"
msgstr "兼容 OpenAI 的实例"

#: src/widgets/instance_manager.py:977
msgid "AI instance compatible with OpenAI library"
msgstr "兼容 OpenAI 库的 AI 实例"

#: src/widgets/instance_manager.py:987
msgid "Meta AI Llama API"
msgstr "Meta AI Llama API"

#: src/widgets/instance_manager.py:1008
msgid "Remove Instance?"
msgstr "移除实例？"

#: src/widgets/instance_manager.py:1009
msgid "Are you sure you want to remove this instance?"
msgstr "您确定要移除这个实例吗？"

#: src/widgets/instance_manager.py:1011 src/widgets/model_manager.py:114
#: src/widgets/model_manager.py:201 src/widgets/model_manager.py:645
#: src/widgets/model_manager.py:702
msgid "Remove"
msgstr "移除"

#: src/widgets/instance_manager.py:1029
msgid "Edit Instance"
msgstr "编辑实例"

#: src/widgets/message.py:33
msgid "Remove Message"
msgstr "移除消息"

#: src/widgets/message.py:43
msgid "Copy Message"
msgstr "复制消息"

#: src/widgets/message.py:53
msgid "Edit Message"
msgstr "编辑消息"

#: src/widgets/message.py:64
msgid "Regenerate Message"
msgstr "重新生成消息"

#: src/widgets/message.py:76
msgid "Dictate Message"
msgstr "语音输入消息"

#: src/widgets/message.py:95
msgid "Message copied to the clipboard"
msgstr "消息已复制到剪切板"

#: src/widgets/message.py:144
msgid "Text to Speech Error"
msgstr "文本转语音错误"

#: src/widgets/message.py:145
msgid "An error occurred while running text to speech model"
msgstr "运行文本转语音(TTS)模型时发生错误"

#: src/widgets/message.py:173
msgid "Message cannot be regenerated while receiving a response"
msgstr "当收到回复时无法重新生成信息"

#: src/widgets/model_manager.py:107 src/widgets/model_manager.py:194
#: src/widgets/model_manager.py:695
msgid "Remove Model"
msgstr "移除模型"

#: src/widgets/model_manager.py:111 src/widgets/model_manager.py:198
#: src/widgets/model_manager.py:699
msgid "Remove Model?"
msgstr "要移除该模型吗？"

#: src/widgets/model_manager.py:112 src/widgets/model_manager.py:199
#: src/widgets/model_manager.py:700
msgid "Are you sure you want to remove '{}'?"
msgstr "您确定要移除 '{}' 吗？"

#: src/widgets/model_manager.py:122
msgid "Local text to speech model provided by Kokoro."
msgstr "由Kokoro提供的本地文本转语音(TTS)模型"

#: src/widgets/model_manager.py:159 src/widgets/model_manager.py:293
msgid "Speech to Text"
msgstr "语言转文本"

#: src/widgets/model_manager.py:209
msgid "Local speech to text model provided by OpenAI Whisper."
msgstr "OpenAI Whisper 提供的本地语音转文本（STT）模型"

#: src/widgets/model_manager.py:238
msgid "Downloading…"
msgstr "下载中......"

#: src/widgets/model_manager.py:248 src/widgets/model_manager.py:250
msgid "Stop Download"
msgstr "停止下载"

#: src/widgets/model_manager.py:256
msgid "Stop Download?"
msgstr "停止下载？"

#: src/widgets/model_manager.py:257
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "你确定要停止拉取 '{}' 吗？"

#: src/widgets/model_manager.py:259
msgid "Stop"
msgstr "停止"

#: src/widgets/model_manager.py:341
msgid "Model Manager Error"
msgstr "模型管理错误"

#: src/widgets/model_manager.py:342
msgid "An error occurred whilst pulling '{}'"
msgstr "从远程获取 '{}' 时发生错误。"

#: src/widgets/model_manager.py:372
msgid "Download Completed"
msgstr "下载完成"

#: src/widgets/model_manager.py:373
msgid "Model '{}' downloaded successfully."
msgstr "模型 '{}' 下载成功。"

#: src/widgets/model_manager.py:437
msgid "Change Profile Picture"
msgstr "更改简介图片"

#: src/widgets/model_manager.py:454
msgid "Voice"
msgstr "语音"

#: src/widgets/model_manager.py:459
msgid "Default"
msgstr "默认"

#: src/widgets/model_manager.py:479
msgid "Family"
msgstr "系列"

#: src/widgets/model_manager.py:480
msgid "Parameter Size"
msgstr "参数大小"

#: src/widgets/model_manager.py:481
msgid "Quantization Level"
msgstr "量化级别"

#: src/widgets/model_manager.py:484
msgid "Parent Model"
msgstr "父模型"

#: src/widgets/model_manager.py:487 src/widgets/model_manager.py:489
msgid "Modified At"
msgstr "修改于"

#: src/widgets/model_manager.py:497
msgid "Description"
msgstr "描述"

#: src/widgets/model_manager.py:646
msgid "Change"
msgstr "更改"

#: src/widgets/model_manager.py:654
msgid "Model Profile Picture"
msgstr "模型简介图片"

#: src/widgets/model_manager.py:655
msgid "What do you want to do with the model's profile picture?"
msgstr "您想如何处理模型的简介照片？"

#: src/widgets/model_manager.py:687
msgid "Create Child"
msgstr "创建子模型"

#: src/widgets/model_manager.py:714
msgid "Multilingual"
msgstr "多语言"

#: src/widgets/model_manager.py:715
msgid "Code"
msgstr "代码"

#: src/widgets/model_manager.py:716
msgid "Math"
msgstr "数学"

#: src/widgets/model_manager.py:717
msgid "Vision"
msgstr "视觉"

#: src/widgets/model_manager.py:718
msgid "Embedding"
msgstr "嵌入"

#: src/widgets/model_manager.py:719
msgid "Tools"
msgstr "工具"

#: src/widgets/model_manager.py:720
msgid "Reasoning"
msgstr "推理"

#: src/widgets/model_manager.py:721
msgid "Small"
msgstr "小型"

#: src/widgets/model_manager.py:722
msgid "Medium"
msgstr "中型"

#: src/widgets/model_manager.py:723
msgid "Big"
msgstr "大型"

#: src/widgets/model_manager.py:724
msgid "Huge"
msgstr "巨型"

#: src/widgets/model_manager.py:814
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr "通过下载此模型，您将接受在该模型网站上提供的许可协议。"

#: src/widgets/model_manager.py:895
msgid "Languages"
msgstr "语言"

#: src/widgets/terminal.py:17
msgid "Setting up Python environment..."
msgstr "设置 Python 环境……"

#: src/widgets/terminal.py:29
msgid "Using Python HTTP server..."
msgstr "正在使用 Python HTTP 服务器..."

#: src/widgets/terminal.py:34
msgid "Using Flatpak contained shell..."
msgstr "正在使用 Flatpak 容器化的 Shell 环境..."

#: src/widgets/terminal.py:38
msgid "Using SSH to run command"
msgstr "使用 SSH 运行命令"

#: src/widgets/terminal.py:85
msgid "Terminal"
msgstr "终端"

#: src/widgets/terminal.py:97
msgid "Open Environment Directory"
msgstr "打开环境目录"

#: src/widgets/terminal.py:181
msgid "Script Exited"
msgstr "脚本已退出"

#: src/widgets/terminal.py:192
msgid "Alpaca Terminal is not compatible with Windows"
msgstr "Alpaca 终端与 Windows 系统不兼容"

#: src/widgets/blocks/code.py:84
msgid "Code Block"
msgstr "代码块"

#: src/widgets/blocks/code.py:111
msgid "Edit Script"
msgstr "编辑脚本"

#: src/widgets/blocks/code.py:119
msgid "Copy Script"
msgstr "复制脚本"

#: src/widgets/blocks/code.py:127
msgid "Run Script"
msgstr "运行脚本"

#: src/widgets/blocks/code.py:193
msgid "Changes saved successfully"
msgstr "修改已成功保存"

#: src/widgets/blocks/code.py:199
msgid "Code copied to the clipboard"
msgstr "代码已复制到剪切板"

#: src/widgets/blocks/latex.py:41
msgid "Copy Equation"
msgstr "复制公式"

#: src/widgets/blocks/latex.py:76
msgid "Equation copied to the clipboard"
msgstr "公式已复制到剪贴板。"

#: src/widgets/blocks/__init__.py:36
msgid "Thought"
msgstr "思考\t"

#: src/widgets/tools/notebook_tools.py:18
msgid "Read Notebook"
msgstr "阅读笔记本"

#: src/widgets/tools/notebook_tools.py:19
msgid "Reads the current notebook."
msgstr "阅读当前笔记本。"

#: src/widgets/tools/notebook_tools.py:38
msgid "Write Notebook"
msgstr "写入笔记本"

#: src/widgets/tools/notebook_tools.py:39
msgid "Overwrites the notebook with new text."
msgstr "使用新文本覆盖笔记本内容"

#: src/widgets/tools/notebook_tools.py:58
msgid "Append to Notebook"
msgstr "追加笔记本内容"

#: src/widgets/tools/notebook_tools.py:59
msgid "Appends text to the notebook."
msgstr "向笔记本追加文本"

#: src/widgets/tools/tools.py:67
msgid "AI Description"
msgstr "AI 描述说明"

#: src/widgets/tools/tools.py:68
msgid "The description the AI model will use to understand what the tool does."
msgstr "AI 模型用于理解工具功能的描述说明"

#: src/widgets/tools/tools.py:79
msgid "Arguments"
msgstr "参量"

#: src/widgets/tools/tools.py:80
msgid "Variables that are filled by the AI."
msgstr "由 AI 填充的变量"

#: src/widgets/tools/tools.py:93
msgid "Variables"
msgstr "变量"

#: src/widgets/tools/tools.py:94
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr "用户填写的值是用于工具工作，人工智能无法访问这些变量。"

#: src/widgets/tools/tools.py:182
msgid "Gets the current date and/or time."
msgstr "获取当前日期和（或）时间。"

#: src/widgets/tools/tools.py:215
msgid "Gets a recipe by the meal's name"
msgstr "根据餐点名称获取菜谱"

#: src/widgets/tools/tools.py:230 src/widgets/tools/tools.py:297
msgid "YouTube Video"
msgstr "YouTube 视频"

#: src/widgets/tools/tools.py:238 src/widgets/tools/tools.py:306
msgid "Source"
msgstr "来源"

#: src/widgets/tools/tools.py:276
msgid "Gets a list of food recipes by a specified category"
msgstr "按指定类别获取食物食谱列表"

#: src/widgets/tools/tools.py:333
msgid "Extracts an article from Wikipedia by it's title"
msgstr "根据标题从维基百科中提取文章"

#: src/widgets/tools/tools.py:375
msgid "Search for a term online using DuckDuckGo"
msgstr "使用 DuckDuckGo 在线搜索术语"

#: src/widgets/tools/tools.py:393
msgid "Abstract Source"
msgstr "摘要来源"

#: src/widgets/tools/tools.py:417
msgid "Official Website"
msgstr "官方网站"

#: src/widgets/tools/tools.py:468
msgid "Request to run a command using SSH to connect to the device"
msgstr "请求使用 SSH 运行命令连接设备"

#: src/widgets/tools/tools.py:471
msgid "IP Address"
msgstr "IP 地址"

#: src/widgets/tools/tools.py:476
msgid "Username"
msgstr "用户名"

#: src/widgets/tools/tools.py:481
msgid "Network Port"
msgstr "网络端口"

#: src/widgets/tools/tools.py:498
msgid "Model Requested to Run Command"
msgstr "要求运行命令的模型"

#: src/widgets/tools/tools.py:499
msgid "Command"
msgstr "命令"

#: src/widgets/tools/tools.py:501
msgid "Explanation"
msgstr "解释"

#: src/widgets/tools/tools.py:502
msgid "No explanation was provided"
msgstr "未提供解释"

#: src/widgets/tools/tools.py:503
msgid "Make sure you understand what the command does before running it."
msgstr "在运行该命令之前，请确保您了解它的作用。"

#~ msgid "Speech Recognition Error"
#~ msgstr "语音识别错误"

#~ msgid "An error occurred while pulling speech recognition model"
#~ msgstr "拉取语音识别模型时发生错误"

#~ msgid "An error occurred while using speech recognition"
#~ msgstr "使用语音识别时发生错误"

#~ msgid "Quick Ask"
#~ msgstr "快速提问"

#~ msgid "Use Speech Recognition"
#~ msgstr "使用语音识别"

#~ msgid "Quick ask dialog"
#~ msgstr "快速问答框"

#~ msgid "Save Conversation to Alpaca"
#~ msgstr "保存对话至 Alpace"

#~ msgid "'{}' does not support tools."
#~ msgstr "'{}' 不支持工具。"

#~ msgid "Open Model Manager"
#~ msgstr "打开模型管理器"

#~ msgid "Cannot open image"
#~ msgstr "无法打开图片"

#~ msgid "Remove Attachment?"
#~ msgstr "移除附件？"

#~ msgid "Are you sure you want to remove attachment?"
#~ msgstr "你确定你想要移除附件？"

#~ msgid "Text to Speech Voice"
#~ msgstr "文本转语音"

#~ msgid "Terminal dialog"
#~ msgstr "终端对话框"

#~ msgid "File preview dialog"
#~ msgstr "文件预览对话框"

#~ msgid "Open With Default App"
#~ msgstr "用默认应用打开"

#~ msgid "An error occurred while extracting text from the website"
#~ msgstr "从网站提取文本时发生错误"

#~ msgid "Regenerate Response"
#~ msgstr "重新生成回复"

#~ msgid "Save Message"
#~ msgstr "保存消息"

#~ msgid "Message edited successfully"
#~ msgstr "更改消息成功"

#~ msgid "Response message"
#~ msgstr "回复消息"

#~ msgid "System message"
#~ msgstr "系统消息"

#~ msgid "User message"
#~ msgstr "用户消息"

#~ msgid "{}Code Block"
#~ msgstr "{} 代码块"

#~ msgid "Edit Code Block"
#~ msgstr "编辑代码块"

#~ msgid ""
#~ "Make sure you understand what this script does before running it, Alpaca "
#~ "is not responsible for any damages to your device or data"
#~ msgstr ""
#~ "在运行该脚本之前，请确保您已了解其功能，Alpaca 不对设备或数据的任何损坏负"
#~ "责"

#~ msgid "Execute"
#~ msgstr "执行"

#~ msgid "Missing image"
#~ msgstr "无图像"

#~ msgid "Compiling C++ script..."
#~ msgstr "正在编译C++脚本..."

#~ msgid "Running local web server"
#~ msgstr "运行本地网页服务器"

#~ msgid "Using Flatpak contained shell"
#~ msgstr "使用 Flatpak 内置的 shell 环境"

#~ msgid "Speech recognition model is being downloaded ({})"
#~ msgstr "正在下载语音识别模型 ({})"
