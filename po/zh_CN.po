# Simplified Chinese Translation for Alpaca
# Copyright (C) 2024 Jeffser
# This file is distributed under the same license as the Alpaca package.
# Aleksana <me@aleksana.moe>, 2024.
# Yuehao Sui <8ar10der@amao.run>, 2024-2025.
#
msgid ""
msgstr ""
"Project-Id-Version: 5.1.0\n"
"Report-Msgid-Bugs-To: https://github.com/Jeffser/Alpaca/issues\n"
"POT-Creation-Date: 2025-03-06 18:23-0600\n"
"PO-Revision-Date: 2025-03-11 16:57+0100\n"
"Last-Translator: Yuehao Sui <8ar10der@amao.run>\n"
"Language-Team: Chinese (China)\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Gtranslator 47.1\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

# 建议不翻译
#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ai;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "与AI模型聊天"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "私人AI客户端"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1026
msgid "Features"
msgstr "功能特点"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
msgid "Built in Ollama instance"
msgstr "内置 Ollama 实例"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1028
msgid "Talk to multiple models in the same conversation"
msgstr "在同一对话中与多个模型交谈"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
#: data/com.jeffser.Alpaca.metainfo.xml.in:1029
msgid "Pull and delete models from the app"
msgstr "在应用中拉取或删除模型"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Have multiple conversations"
msgstr "进行多重对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Image recognition (Only available with compatible models)"
msgstr "图像识别（仅适用于兼容模型）"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Plain text documents recognition"
msgstr "纯文本文档识别"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Import and export chats"
msgstr "导入导出对话记录"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append YouTube transcripts to the prompt"
msgstr "将 Youtube 的转录文本添加到提示中"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "Append text from a website to the prompt"
msgstr "将来自网站的文本添加到提示中"

#: data/com.jeffser.Alpaca.metainfo.xml.in:22
msgid "PDF recognition"
msgstr "PDF 识别"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24 src/window.ui:90
msgid "Disclaimer"
msgstr "免责声明"

#: data/com.jeffser.Alpaca.metainfo.xml.in:25
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"本项目与 Ollama 没有任何关联，对于运行任何模型所提供的代码而对您的设备或软件"
"造成的任何损害，我概不负责。"

#: data/com.jeffser.Alpaca.metainfo.xml.in:28
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:54
msgid "A normal conversation with an AI Model"
msgstr "一段与 AI 模型的普通对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:58
msgid "A conversation involving image recognition"
msgstr "一段带有图像识别的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:62
msgid "A conversation involving a custom model"
msgstr "一段涉及自定义模型的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:66
msgid "A conversation showing code highlighting"
msgstr "一段展示代码高亮的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:70
msgid "A Python script running inside integrated terminal"
msgstr "一段在内置终端中运行的 Python 脚本"

#: data/com.jeffser.Alpaca.metainfo.xml.in:74
msgid "A conversation involving a YouTube video transcript"
msgstr "一段含有 YouTube 转录文本的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:78
msgid "Multiple models being downloaded"
msgstr "已下载的多个模型"

#: data/com.jeffser.Alpaca.metainfo.xml.in:82
msgid "Model creator screen"
msgstr "模型创建者界面"

#: data/com.jeffser.Alpaca.metainfo.xml.in:96
#: data/com.jeffser.Alpaca.metainfo.xml.in:146
#: data/com.jeffser.Alpaca.metainfo.xml.in:192
#: data/com.jeffser.Alpaca.metainfo.xml.in:223
#: data/com.jeffser.Alpaca.metainfo.xml.in:232
#: data/com.jeffser.Alpaca.metainfo.xml.in:295
#: data/com.jeffser.Alpaca.metainfo.xml.in:323
#: data/com.jeffser.Alpaca.metainfo.xml.in:337
#: data/com.jeffser.Alpaca.metainfo.xml.in:354
#: data/com.jeffser.Alpaca.metainfo.xml.in:365
#: data/com.jeffser.Alpaca.metainfo.xml.in:374
#: data/com.jeffser.Alpaca.metainfo.xml.in:391
#: data/com.jeffser.Alpaca.metainfo.xml.in:401
#: data/com.jeffser.Alpaca.metainfo.xml.in:418
#: data/com.jeffser.Alpaca.metainfo.xml.in:428
#: data/com.jeffser.Alpaca.metainfo.xml.in:475
#: data/com.jeffser.Alpaca.metainfo.xml.in:500
#: data/com.jeffser.Alpaca.metainfo.xml.in:525
#: data/com.jeffser.Alpaca.metainfo.xml.in:547
#: data/com.jeffser.Alpaca.metainfo.xml.in:565
#: data/com.jeffser.Alpaca.metainfo.xml.in:583
#: data/com.jeffser.Alpaca.metainfo.xml.in:595
#: data/com.jeffser.Alpaca.metainfo.xml.in:611
msgid "Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:98
msgid "Don't clear the building output of C++ scripts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
msgid "Better handling of attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:100
msgid "Handle remote Ollama instance's API Key better"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:101
msgid "Remove '\\n' characters in instance edit page"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:108
#: data/com.jeffser.Alpaca.metainfo.xml.in:118
#: data/com.jeffser.Alpaca.metainfo.xml.in:129
#: data/com.jeffser.Alpaca.metainfo.xml.in:156
#: data/com.jeffser.Alpaca.metainfo.xml.in:176
#: data/com.jeffser.Alpaca.metainfo.xml.in:202
#: data/com.jeffser.Alpaca.metainfo.xml.in:217
#: data/com.jeffser.Alpaca.metainfo.xml.in:242
#: data/com.jeffser.Alpaca.metainfo.xml.in:270
#: data/com.jeffser.Alpaca.metainfo.xml.in:280
#: data/com.jeffser.Alpaca.metainfo.xml.in:291
#: data/com.jeffser.Alpaca.metainfo.xml.in:305
#: data/com.jeffser.Alpaca.metainfo.xml.in:317
#: data/com.jeffser.Alpaca.metainfo.xml.in:333
#: data/com.jeffser.Alpaca.metainfo.xml.in:348
#: data/com.jeffser.Alpaca.metainfo.xml.in:383
#: data/com.jeffser.Alpaca.metainfo.xml.in:408
#: data/com.jeffser.Alpaca.metainfo.xml.in:439
#: data/com.jeffser.Alpaca.metainfo.xml.in:465
#: data/com.jeffser.Alpaca.metainfo.xml.in:487
#: data/com.jeffser.Alpaca.metainfo.xml.in:518
#: data/com.jeffser.Alpaca.metainfo.xml.in:540
#: data/com.jeffser.Alpaca.metainfo.xml.in:561
#: data/com.jeffser.Alpaca.metainfo.xml.in:576
#: data/com.jeffser.Alpaca.metainfo.xml.in:601
msgid "New"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:110
msgid "Dynamic chat loading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "Updated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:120
msgid "Tweaked appearance of models in model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:121
msgid "Updated Ollama instance to 0.5.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "Added new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:131
msgid "New instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:132
msgid "New welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "New Instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:136
msgid "OpenAI ChatGPT"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:137
msgid "Google Gemini"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:138
msgid "Together AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:139
msgid "Venice"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:148
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:149
msgid "Fixed attachment filters"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:158
msgid "New model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:159
msgid "Changed GtkSpinner to AdwSpinner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:160
msgid "Better handling of launch process"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:161
msgid "New loading screen at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:162
msgid "Better handling of file types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:163
msgid "Better regex expression for LaTeX equations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:164
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:165
msgid "Better handling of think tags in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:166
msgid "Default model is now in charge of generating titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:167
msgid "Message header is now shown whilst the message is being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:168
msgid "Better handling of model profile pictures"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:169
msgid "New models in 'available models' list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:178
msgid "Added option for attaching screenshots"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:179
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:180
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Added option to open the environment directory from the terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Added option to edit code blocks directly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:183
msgid "Complete keyboard shortcut list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:184
msgid "Images are now attached in 640p resolution"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:185
msgid "Website attachments now use extracted titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:186
msgid "Better chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:187
msgid "Added option to attach any plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:188
msgid "Added spellchecker to message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:189
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:190
msgid "Small appearance changes in text entries"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:194
msgid "Alpaca's launch process is more reliable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:195
msgid "Closing the terminal now kills the script subprocess"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:205
msgid "Changed appearance of messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:206
msgid "Added the option to add profile pictures to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:208
#: data/com.jeffser.Alpaca.metainfo.xml.in:680
#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:210
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:219
msgid "Added categories to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:220
msgid "Specified model's languages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:221
msgid "Added warning when downloading embedding models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:225
msgid "Replaced low ram warning with big model warning"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:234
msgid "Correctly escape markup before rendering message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:235
msgid "Fixed about dialog not working if log file was missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:244
msgid "System messages can now be sent directly from Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:245
msgid "New redesign for messages and smaller minimum size"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:246
msgid "New models included in 'available models list'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:247
msgid "Added symbolic icon when attaching code files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:248
msgid "When exporting a chat it now includes a markdown file"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:249
msgid "Refresh button in model manager when using a remote instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:250
msgid "Assistant messages are now editable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "Updated Ollama to v0.5.2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:252
msgid "New option to change model directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:253
msgid "File previewer now resizes dynamically to content"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:254
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:255
msgid "Compatibility added with ODT files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:258
msgid "Restored ROCm compatibility"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:259
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "Fixed edit button not saving changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Changed max temperature value to 2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "Made seed 0 actually random"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:263
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:272
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:273
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:282
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:283
msgid "Added integration as Gnome Search Provider"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:284
msgid "Updated Ollama to v0.4.2 with new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:293
msgid "User messages are now compacted into bubbles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:298
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:307
msgid "Details page for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:308
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:309
msgid "Added warning when model is too big for the device"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:310
msgid "Added AMD GPU indicator in preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:319
msgid "Better system for handling dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:320
msgid "Better system for handling instance switching"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:321
msgid "Remote connection dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:325
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:326
msgid "Better internal instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:335
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:339
msgid "Better handling of image recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
msgid "Remove unused files when canceling a model download"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
msgid "Better message blocks rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:350
msgid "Run bash and python scripts straight from chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:351
msgid "Updated Ollama to 0.3.12"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:352
msgid "New models!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid "Fixed and made faster the launch sequence"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:357
msgid "Better detection of code blocks in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:358
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:367
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:376
msgid "Fixed message generation sometimes failing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:385
msgid "Sidebar resizes with the window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:386
msgid "New welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:387
msgid "Message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:388
msgid "Updated Ollama to v0.3.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:389
msgid "A lot of new models provided by Ollama repository"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:393
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:394
msgid "Fixed image recognition on unsupported models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:403
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:404
msgid "Fixed image recognition with local images"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:405
msgid "Changed appearance of delete / stop model buttons"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:406
msgid "Fixed stop button crashing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:410
msgid "Made sidebar resize a little when the window is smaller"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:411
msgid "Instant launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:420
msgid "Fixed error on first run (welcome dialog)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:421
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:430
msgid "Fixed 'clear chat' option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:431
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:432
msgid "Fixed support for AMD GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:441
msgid "Model, message and chat systems have been rewritten"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:442
msgid "New models are available"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:443
msgid "Ollama updated to v0.3.9"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:444
msgid "Added support for multiple chat generations simultaneously"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:445
msgid "Added experimental AMD GPU support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:446
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:447
msgid "Added animations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:448
msgid "Changed model manager / model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:449
msgid "Changed message appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:450
msgid "Added markdown and code blocks to user messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:451
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:452
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:453
msgid "Added inactivity timer to integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:456
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:457
msgid "Better handling of focus on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:458
msgid "Better general performance on the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:467
msgid "New duplicate chat option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:468
msgid "Changed model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid "Message entry is focused on launch and chat change"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:470
msgid "Message is focused when it's being edited"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:471
msgid "Added loading spinner when regenerating a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:472
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:473
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:477
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:479
msgid "Fixed message generation not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:480
msgid "Fixed message edition not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:489
msgid "Model manager opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:490
msgid "Delete chat option in secondary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:491
msgid "New model selector popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:492
msgid "Standard shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:493
msgid "Model manager is navigable with keyboard"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:494
msgid "Changed sidebar collapsing behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:495
msgid "Focus indicators on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:497
msgid "Give message entry focus at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:498
msgid "Generally better code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:502
msgid "Better width for dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:503
msgid "Better compatibility with screen readers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:504
msgid "Fixed message regenerator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:505
msgid "Removed 'Featured models' from welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:506
msgid "Added default buttons to dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:507
msgid "Fixed import / export of chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:508
msgid "Changed Python2 title to Python on code blocks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:509
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:510
msgid "Show date on stopped messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:511
msgid "Fix clear chat error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:520
msgid "Changed shortcuts to standards"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:521
msgid "Moved 'Manage Models' button to primary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:522
#: data/com.jeffser.Alpaca.metainfo.xml.in:544
msgid "Stable support for GGUF model files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:523
#: data/com.jeffser.Alpaca.metainfo.xml.in:798
msgid "General optimizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:527
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:528
msgid "Removed sponsor dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:529
msgid "Added sponsor link in about dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:530
msgid "Changed window and elements dimensions"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:531
msgid "Selected model changes when entering model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:532
msgid "Better image tooltips"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:533
msgid "GGUF Support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:542
msgid "Regenerate any response, even if they are incomplete"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:543
msgid "Support for pulling models by name:tag"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Restored sidebar toggle button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "Reverted back to standard styles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Changed min width for model dropdown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:552
msgid "Changed message entry shadow"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:553
msgid "The last model used is now restored when the user changes chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:554
msgid "Better check for message finishing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:563
msgid "Added table rendering (Thanks Nokse)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:567
msgid "Made support dialog more common"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:568
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:569
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:578
msgid "Bearer Token entry on connection error dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:579
msgid "Small appearance changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:580
msgid "Compatibility with code blocks without explicit language"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:581
msgid "Rare, optional and dismissible support dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:585
msgid "Date format for Simplified Chinese translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:586
msgid "Bug with unsupported localizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:587
msgid "Min height being too large to be used on mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:588
msgid "Remote connection checker bug"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:597
msgid "Models with capital letters on their tag don't work"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Ollama fails to launch on some systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:603
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:614
msgid "Better connection check for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Features and fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Updated Ollama instance to 0.2.8"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "Better model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:627
msgid "Model manager redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:628
msgid "Better tag selector when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:629
msgid "Model search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:630
msgid "Added support for bearer tokens on remote instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:631
msgid "Preferences dialog redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:632
msgid "Added context menus to interact with a chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:633
msgid "Redesigned primary and secondary menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:634
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:635
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:636
msgid "Chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:637
msgid "Auto resizing of message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:638
msgid "Chat notifications"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:639
msgid "Added indicator when an image is missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:640
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:641
msgid "Redesigned file preview dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid "Credited new contributors"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "Better stability and optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Edit messages to change the context of a conversation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Added disclaimers when pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "Preview files before sending a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Better format for date and time on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:648
msgid "Error and debug logging on terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:649
msgid "Auto-hiding sidebar button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:650
msgid "Various UI tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:652
msgid "New Models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:654
msgid "Gemma2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:655
msgid "GLM4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:656
msgid "Codegeex4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:657
msgid "InternLM2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:658
msgid "Llama3-groq-tool-use"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:659
msgid "Mathstral"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:660
msgid "Mistral-nemo"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:661
msgid "Firefunction-v2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:662
msgid "Nuextract"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:664
msgid "Translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:665
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:667
msgid "Russian: Alex K"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:668
msgid "Spanish: Jeffser"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:669
msgid "Brazilian Portuguese: Daimar Stein"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:670
msgid "French: Louis Chauvet-Villaret"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Norwegian: CounterFlow64"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:672
msgid "Bengali: Aritra Saha"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:673
msgid "Simplified Chinese: Yuehao Sui"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:687
#: data/com.jeffser.Alpaca.metainfo.xml.in:717
#: data/com.jeffser.Alpaca.metainfo.xml.in:738
#: data/com.jeffser.Alpaca.metainfo.xml.in:943
#: data/com.jeffser.Alpaca.metainfo.xml.in:1000
msgid "Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:689
msgid "Added compatibility for PDF"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:690
msgid "Added compatibility for DOCX"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:691
msgid "Merged 'file attachment' menu into one button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:698
#: data/com.jeffser.Alpaca.metainfo.xml.in:891
msgid "Quick Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:699
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:705
#: data/com.jeffser.Alpaca.metainfo.xml.in:857
msgid "Huge Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:707
msgid "Added: Support for plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:708
msgid "Added: New backend system for storing messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:709
msgid "Added: Support for changing Ollama's overrides"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:710
msgid "General Optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:719
msgid "Added: Support for GGUF models (experimental)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:720
msgid "Added: Support for customization and creation of models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:722
msgid "Update Ollama to v0.1.39"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:731
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:741
msgid "Combined export / import chat buttons into a menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Fixed send / stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:744
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:753
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:755
msgid "New message entry design"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:756
msgid "Fixed: Can't rename the same chat multiple times"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "The fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:765
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:773
msgid "Quick tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:775
msgid "Added progress bar to models that are being pulled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:776
msgid "Added size to tags when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:777
msgid "General optimizations on the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:784
msgid "Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:786
msgid "Fixed: Scroll when message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:787
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:788
msgid "Added 'Featured Models' page on welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:795
msgid "Nice Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:797
msgid "UI tweaks (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:799
msgid "Metadata fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:806
msgid "Quick fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:808
msgid "Updated Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:809
msgid "Added compatibility for PNG"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:816
msgid "New Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:818
msgid "Updated model list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:819
msgid "Added image recognition to more models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:820
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:821
msgid "Refined the general UI (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Added 'delete message' feature"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:823
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:831
msgid "Bug Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid "Fixed: Minor spelling mistake"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:834
msgid "Added 'mobile' as a supported form factor"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid "Fixed: App might freeze randomly on startup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:837
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Cool Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Better design for chat window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "Better design for chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "Fixed remote connections"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:849
msgid "Fixed Ollama restarting in loop"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:850
msgid "Other cool backend stuff"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:859
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:860
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:861
msgid "Added option to import and export chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:862
msgid "Added option to run Alpaca with Ollama in the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:863
msgid "Added preferences dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:864
msgid "Changed the welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:866
#: data/com.jeffser.Alpaca.metainfo.xml.in:883
#: data/com.jeffser.Alpaca.metainfo.xml.in:895
#: data/com.jeffser.Alpaca.metainfo.xml.in:914
#: data/com.jeffser.Alpaca.metainfo.xml.in:935
#: data/com.jeffser.Alpaca.metainfo.xml.in:951
#: data/com.jeffser.Alpaca.metainfo.xml.in:967
#: data/com.jeffser.Alpaca.metainfo.xml.in:981
#: data/com.jeffser.Alpaca.metainfo.xml.in:991
#: data/com.jeffser.Alpaca.metainfo.xml.in:1009
#: data/com.jeffser.Alpaca.metainfo.xml.in:1031
msgid "Please report any errors to the issues page, thank you."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:874
msgid "Yet Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:876
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Added better UI for the chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:878
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "Added myself to the credits as the spanish translator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:880
msgid "Using XDG properly to get config folder"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:881
msgid "Update for translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:893
msgid "The last update had some mistakes in the description of the update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:903
msgid "Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:905
msgid "Added full Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:906
msgid "Added support for background pulling of multiple models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:907
msgid "Added interrupt button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:908
msgid "Added basic shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:909
msgid "Better translation support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:910
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:911
msgid "Better scalling for different window sizes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:912
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:922
msgid "Really Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "Added multiple chats support!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:925
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:927
msgid "Added support for multiple tags on a single model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Added better model management dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "Added loading spinner when sending message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:931
msgid "Added new symbolic icon"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:932
msgid "Added frame to message textview widget"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:933
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:945
msgid "Added code highlighting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:946
msgid "Added image recognition (llava model)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:947
msgid "Added multiline prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:948
msgid "Fixed some small bugs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:949
msgid "General optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
msgid "Fixes and features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:961
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:962
msgid "Fixed: Cannot close app on first setup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:963
msgid "Fixed: Brand colors for Flathub"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:964
msgid "Fixed: App description"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:965
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:975
msgid "0.2.2 Bug fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:977
msgid "Toast messages appearing behind dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:978
msgid "Local model list not updating when changing servers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:979
msgid "Closing the setup dialog closes the whole app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:989
msgid "0.2.1 Data saving fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:990
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid "0.2.0"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1001
msgid "New Features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1003
msgid "Restore chat after closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1004
msgid "A button to clear the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1005
msgid "Fixed multiple bugs involving how messages are shown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1006
msgid "Added welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1007
msgid "More stability"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1017
msgid "0.1.2 Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1018
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "0.1.1 Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1025
msgid "This is the first public version of Alpaca"
msgstr ""

#: src/window.py:175 src/window.py:182 src/window.ui:422 src/window.ui:432
#: src/window.ui:454
msgid "Add Instance"
msgstr ""

#: src/window.py:183
msgid "Select a type of instance to add"
msgstr ""

#: src/window.py:371 src/window.py:933
msgid "Please select a model before chatting"
msgstr "请在对话前先选择一个模型"

#: src/window.py:410 src/window.py:411 src/window.py:470 src/window.ui:276
msgid "Close"
msgstr "关闭"

#: src/window.py:413 src/window.py:414 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "下一页"

#: src/window.py:468 src/instance_manager.py:410 src/instance_manager.py:411
#: src/instance_manager.py:527 src/instance_manager.py:528
#: src/instance_manager.py:672 src/instance_manager.py:673 src/window.ui:873
#: src/window.ui:877 src/custom_widgets/message_widget.py:60
#: src/custom_widgets/message_widget.py:199
#: src/custom_widgets/model_manager_widget.py:395
#: src/custom_widgets/dialog_widget.py:149
#: src/custom_widgets/dialog_widget.py:161
#: src/custom_widgets/dialog_widget.py:173
msgid "Cancel"
msgstr "取消"

#: src/window.py:469
msgid "Hide"
msgstr "隐藏"

#: src/window.py:473
msgid "Close Alpaca?"
msgstr "关闭 Alpaca？"

#: src/window.py:474
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr "当前有一个任务正在进行中。你确定要关闭 Alpaca 吗？"

#: src/window.py:700
msgid "Cannot open image"
msgstr "无法打开图片"

#: src/window.py:806
msgid "Delete Chat?"
msgstr "删除对话？"

#: src/window.py:807
msgid "Are you sure you want to delete '{}'?"
msgstr "你确定你想要删除 '{}' 吗？"

#: src/window.py:809
msgid "Delete"
msgstr "删除"

#: src/window.py:816
msgid "Rename Chat?"
msgstr "重命名对话？"

#: src/window.py:817
msgid "Renaming '{}'"
msgstr "重命名 '{}'"

#: src/window.py:819
msgid "Chat name"
msgstr "对话命名"

#: src/window.py:820
msgid "Rename"
msgstr "重命名"

#: src/window.py:825
msgid "Importable (.db)"
msgstr "可导入 (.db)"

#: src/window.py:826
msgid "Markdown"
msgstr "Markdown格式"

#: src/window.py:827
msgid "Markdown (Obsidian Style)"
msgstr "Markdown格式 （Obsidian 风格）"

#: src/window.py:828
msgid "JSON"
msgstr "JSON"

#: src/window.py:829
msgid "JSON (Include Metadata)"
msgstr "JSON（包含元数据）"

#: src/window.py:832 src/window.ui:1176 src/window.ui:1214
msgid "Export Chat"
msgstr "导出对话"

#: src/window.py:833
msgid "Select a method to export the chat"
msgstr "选择一个模型以导出对话"

#: src/window.py:849
msgid "This video does not have any transcriptions"
msgstr "本视频没有任何转录内容"

#: src/window.py:856
msgid "Attach YouTube Video?"
msgstr "附加 YouTube 视频？"

#: src/window.py:857
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"请选择要附加的转录"

#: src/window.py:863
msgid "Error attaching video, please try again"
msgstr "附加视频出错，请重试"

#: src/window.py:884 src/window.py:1173
msgid "Attach Website? (Experimental)"
msgstr "附加网站？（试验性）"

#: src/window.py:885
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"您确定要附加\n"
"'{}'?"

#: src/window.py:903 src/window.py:915 src/window.py:1172
#: src/generic_actions.py:102
msgid "Image recognition is only available on specific models"
msgstr "图像识别功能仅适用于特定模型"

#: src/window.py:935 src/window.ui:1001
msgid "Quick Ask"
msgstr "快速提问"

#: src/window.py:1055
msgid "Attachment failed, screenshot might be too big"
msgstr "添加附件失败，截图可能太大了。"

#: src/window.py:1069
msgid "Any compatible Alpaca attachment"
msgstr "任何与 Alpaca 兼容的附件"

#: src/window.py:1147
msgid "Attach Screenshot"
msgstr "附加屏幕截图"

#: src/window.py:1157
msgid "Clear Chat?"
msgstr "清除对话记录？"

#: src/window.py:1157
msgid "Are you sure you want to clear the chat?"
msgstr "你确定你想要清除对话记录吗？"

#: src/window.py:1157
msgid "Clear"
msgstr "清除"

#: src/window.py:1173
msgid "Please enter a website URL"
msgstr "请输入一个网站地址"

#: src/window.py:1174
msgid "Attach YouTube Captions?"
msgstr "附加上 YouTube 字幕？"

#: src/window.py:1174
msgid "Please enter a YouTube video URL"
msgstr "请输入一个YouTube视频地址"

#: src/window.py:1177
msgid "Download Model?"
msgstr "下载模型？"

#: src/window.py:1177
msgid "Please enter the model name following this template: name:tag"
msgstr "请按照以下模板输入模型名称：name:tag"

#: src/window.py:1187
msgid "Remove Attachment?"
msgstr "移除附件？"

#: src/window.py:1187
msgid "Are you sure you want to remove attachment?"
msgstr "你确定你想要移除附件？"

#: src/window.py:1187 src/instance_manager.py:795
#: src/custom_widgets/model_manager_widget.py:396
#: src/custom_widgets/model_manager_widget.py:438
msgid "Remove"
msgstr "移除"

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"最新一代的70B参数模型。Llama 3.3 70B 与 Llama 3.1 405B 模型相比提供了相似的性"
"能。"

#: src/available_models_descriptions.py:3
msgid ""
"QwQ is an experimental research model focused on advancing AI reasoning "
"capabilities."
msgstr "QwQ 是一个实验研究模型，重点在于提高人工智能的推理能力。"

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision 是一套经过指令调整的图像推理生成模型，有 11B 和 90B 大小。"

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Meta 的 Llama 3.2 采用小型 1B 和 3B 模型。"

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr "Llama 3.1 是新的来自 Meta 的先进模型，提供 8B, 70B, 和 405B 参数量。"

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3：迄今能力最强的开源大模型"

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "Mistral AI 发布的 7B 模型，已更新至 0.3 版。"

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr "具有大型标记上下文窗口的高性能开放式嵌入模型。"

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr "Gemma 是由 Google DeepMind 构建的轻量级先进开放模型系列。更新至 1.1 版"

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr "Qwen 1.5 是阿里云推出的一系列大型语言模型，参数从 0.5B 到 110B 不等"

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 是阿里巴巴推出的新的大语言模型系列"

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 是微软公司推出的一系列轻型 3B（迷你）和 14B（中型）先进开源模型。"

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr "Llama 2 是一组基础语言模型，参数从 7B 到 70B 不等。"

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Qwen2.5 模型在阿里巴巴最新的大规模数据集上进行了预训练，该数据集包含多达 18 "
"万亿个token。该模型最大支持 128K token，并支持多种语言。"

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr "Google Gemma 2 是一款高性能、高效率的模型，有三种规格：2B、9B 和 27B。"

#: src/available_models_descriptions.py:17
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA 是一种新颖的端到端训练型大型多模态模型，它将视觉编码器和 Vicuna 结合"
"在一起，用于通用视觉和语言理解。已更新至 1.6 版。"

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr "大语言模型，可使用文本提示生成和讨论代码。"

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"最新系列的代码专用 Qwen 模型，在代码生成、代码推理和代码修复方面都有显著改"
"进。"

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr "一个具有 128k 上下文长度的先进模型，由 Mistral AI 与 NVIDIA 合作开发。"

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"TinyLlama 项目是一个开源的项目，旨在用 3 万亿标记训练一个 1.1B 的紧凑型 "
"Llama 模型。"

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "来自 mixedbread.ai 的最先进的大型嵌入模型"

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 是新一代透明训练的开放代码 LLM，有三种大小： 3B、7B 和 15B 参数。"

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Mistral AI 在 8x7b 和 8x22b 两种参数大小下建立的一套权重开放的专家混合模型"
"（MoE）。"

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"基于 Mixtral 混合专家模型的无审查、8x7b 和 8x22b 的微调模型，擅长编码任务。"
"由 Eric Hartford 创建。"

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma 是一系列功能强大的轻量级模型，可执行各种代码任务，如中间代码补全、"
"代码生成、自然语言理解、数学推理和指令跟踪。"

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"开源的 Mixture-of-Experts 代码语言模型在特定代码任务中的性能可与 GPT4-Turbo "
"相媲美。"

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr "Phi-2：微软研究院开发的 27 亿语言模型，具有出色的推理和语言理解能力。"

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "George Sung 和 Jarrad Hope 制作的无审查的 Llama 2 模型。"

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder 是一个基于两万亿个代码和自然语言标记训练而成的代码模型。"

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr "一套由 Snowflake 提供的文本嵌入模型，并对性能进行了优化。"

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"来自 Microsoft AI 的最先进的大型语言模型，在复杂的对话、多语言、推理和代理用"
"例中性能更佳。"

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr "基于 Mistral 的审查 Dolphin 模型，擅长代码任务。已更新至 2.8 版。"

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 是 Eric Hartford 在 Llama 3 的基础上开发的新模型，有 8B 和 70B 大"
"小，具有各种教学、会话和代码技能。"

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 是一个高性能的双语语言模型。"

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr "Command R 是一种大语言模型，针对对话交互和长语境任务进行了优化。"

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr "通用模型，参数范围从 30 亿到 700 亿，适合入门级硬件。"

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr "根据 Llama 3 进行微调的 LLaVA 模型在多个基准测试中取得了更好的成绩。"

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr 是一系列经过微调的 Mistral 和 Mixtral 模型，经过训练后可充当得力助手。"

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr "拥有 38 亿个参数的轻量人工智能模型，性能超越同类和更大规模的模型。"

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr "在超大型语句级数据集上嵌入模型。"

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr "Codestral 是 Mistral AI 首次为代码生成任务设计的代码模型。"

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr "StarCoder 是一个经过 80 多种编程语言训练的代码生成模型。"

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr "基于 Llama 和 Llama 2 的通用对话模型，上下文大小为 2K 至 16K。"

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "IBM 代码智能开放式基础模型系列"

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca 是一个 70 亿参数模型，利用 OpenOrca 数据集在 Mistral 7B 模型"
"的基础上进行了微调。"

#: src/available_models_descriptions.py:47
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 在一个新的高质量数据集上训练的一系列小型模型，参数分别为 1.35 亿、3.6 亿"
"和 17 亿。"

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored 是一个 7B、13B 和 30B 参数模型，基于 Eric Hartford "
"的 Llama 2 Uncensored。"

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr "基于 Llama 2 的模型进行了微调，以提高中文对话能力。"

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr "BGE-M3 是 BAAI 推出的新型模型，具有多功能、多语言和多地域性的特点。"

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr "功能丰富的，适合应用于 AI 辅助开发的模型，包括代码补全。"

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"在各种数据上训练有素的开源模型系列，在各种基准测试中超越了 ChatGPT。已更新至 "
"3.5-0106 版。"

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr "由 Cohere 发布的 Aya 23 是最先进的多语言模型新系列，支持 23 种语言。"

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr "CodeQwen1.5 是一个基于大量代码数据预训练的大型语言模型。"

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr "Nous Research 强大的模型系列，擅长科学讨论和编码任务。"

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ 是一款功能强大、可扩展的大型语言模型，专为实际企业用例而设计。"

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "最先进的代码生成模型"

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B 是一种代码模型，其指令和代码完成变体可与 Code Llama 7B 等模型"
"相媲美，而后者的规模要大 2.5 倍。"

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Eric Hartford 基于 TinyLlama 在新的 Dolphin 2.8 数据集上训练的 1.1B 参数实验"
"模型。"

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 是 Teknium 在 Mistral 上使用完全开放的数据集微调的 7B 模型。"

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 是 Mistral 的新的旗舰模型，在代码生成、数学运算和逻辑推理方面"
"具有显著优势，带有 128k 的上下文长度并支持多种语言。"

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math 是建立在 Qwen2 LLMs 基础上的一系列专业数学语言模型，其数学能力大大"
"超过开源模型甚至闭源模型（如 GPT4o）。"

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr "强大的多语言的通用模型，在性能上较 Llama 3 有竞争力。"

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 是最先进的 1.6B 和 12B 参数语言模型，使用英语、西班牙语、德语、意"
"大利语、法语、葡萄牙语和荷兰语的多语言数据进行训练。"

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr "BakLLaVA 是一个多模式模型，由 Mistral 7B 基本模型和 LLaVA 架构组成。"

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"使用一种名为 “反思-调整 ”的新技术训练出的高性能模型，能教会 LLM 发现推理中的"
"错误并纠正方向。"

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr "先进的语言模型包含 2 万亿个双语词库。"

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr "该模型将 LLama-3 8B 的上下文长度从 8k 扩展到超过 1m 的标记。"

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "侧重于数学和逻辑问题的模型"

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr "moondream2 是一个小型视觉语言模型，被设计用于在边缘设备上高效运行。"

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr "基于 Mistral 的微调模型对领域和语言都有很好的覆盖。"

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"英伟达基于 Llama 3 的模型，擅长对话式问题解答（QA）和检索增强生成（RAG）。"

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr "对话模型基于 Llama 2，在各种基准测试中表现优异。"

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr "SQLCoder 是在 StarCoder 基础上微调的代码完成模型，用于 SQL 生成任务"

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "基于 Llama 和 Llama 2 的 Nous Research 公司的通用模型。"

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "基于 Code Llama 的代码生成模型。"

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Llama 2 的扩展，支持多达 128k 标记的上下文。"

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr "基于 StarCoder2 的 Dolphin 模型系列的 7B 和 15B 无删节变体，擅长编码。"

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "基于 Llama 2 的通用模型。"

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "强大、经济、高效的专家混合语言模型。"

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling 是一个通过人工智能反馈强化学习训练出来的大型语言模型，专注于提高对话"
"机器人的帮助性。"

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr "一名接受过哲学、心理学和人际关系培训的同伴助理。基于 Mistral。"

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr "Hermes 3 是 Nous Research 旗舰产品 Hermes 系列 LLM 的最新版本"

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder 是一系列开源代码语言模型，以不到 100 亿个参数提供最先进的编码性能。"

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"技术创新研究所（TII）建立的大型语言模型，用于摘要、文本生成和聊天机器人。"

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr "InternLM2.5 是为实际场景量身定制的 7B 参数模型，具有出色的推理能力。"

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr "结构紧凑、功能强大的 10.7B 大语言机型，专为单匝通话而设计。"

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 是一个 72B 参数模型，在代码完成、数学和日志提取任务方面表现出色。"

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "新的从 Phi 3 Mini 微调而来的小型 LLaVA 模型。"

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 由微软研究部门开发，是 Meta 的 Llama 2 模型的微调版。该模型在设计上尤"
"其擅长推理。"

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr "为视觉语言理解设计的一系列多模态 LLM（MLLM）。"

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"基于 Llama 2，在 Orca-style 数据集上进行了微调的基础模型。最初名为“Free "
"Willy”。"

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr "Mistral Small 3 在低于70B参数的“小型”大语言模型类别中设立了新的基准。"

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Eric Hartford 根据微软研究院的 Phi 语言模型制作的 2.7B 无审查 Dolphin 模型。"

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 是一个紧凑型语言模型系列，有三种尺寸：135M、360M 和 1.7B 参数。"

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "未审查版 Wizard 大语言模型"

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"英伟达公司推出的商业友好型小语言模型，针对角色扮演、RAG QA 和函数调用进行了优"
"化。"

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr "Mistral 的扩展，支持 64K 或 128K 的上下文窗口。"

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Llama 2 的扩展版，专门整合一般语言理解和特定领域知识，尤其是编程和数学知识。"

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr "微调 Llama 2 模型，根据开源医疗数据集回答医疗问题。"

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr "开源医疗大型语言模型，由 Llama 2 改编而来，适用于医疗领域。"

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"来自 Groq 的一系列模型，代表了开源人工智能能力在工具使用/功能调用方面的重大进"
"步。"

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct 是英伟达定制的大型语言模型，用于提高 LLM 生成"
"的对用户查询的回复的帮助性。"

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr "Nexus Raven 是针对函数调用任务的 13B 指令调整模型。"

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr "来自 Nous Research 的 Nous Hermes 2 模型，现在通过 Mixtral 进行训练。"

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "基于 Llama2 的优秀的代码生成模型。"

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr "基于 Llama2 的无删减模型，支持 16K 上下文窗口。"

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"IBM Granite 2B 和 8B 模型旨在支持基于工具的用例，支持检索增强生成（RAG），简"
"化代码生成、翻译和错误修复。"

#: src/available_models_descriptions.py:109
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder 是一个 7B 参数模型系列，使用 OSS-Instruct 在 75K 个合成指令数据"
"上进行训练，OSS-Instruct 是一种利用开源代码片段启发 LLM 的新方法。"

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr "轻量级聊天模式无需高端硬件即可实现准确、灵敏的输出。"

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr "通过合并两个现有的代码模型，创建了一个高性能代码指导模型。"

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 是一个由 TII 构建的 11B 参数因果解码器模型，并通过 5T 标记进行了训"
"练。"

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr "Wizard Vicuna 是一个 13B 参数模型，基于 MelodysDreamj 训练的 Llama 2。"

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr "MistralLite 是基于 Mistral 的微调模型，具有更强的长语境处理能力。"

#: src/available_models_descriptions.py:115
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr "MathΣtral：Mistral AI 为数学推理和科学发现设计的 7B 模型。"

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr "MotherDuck 和 Numbers Station 制作的 7B 参数文本到 SQL 模型。"

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b 是 Dolphin-2.2-70b 的转换版本，通过将模型与自身交错创建"
"而成。"

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro 预览版：先进的大型语言模型 (LLM)，拥有 220 亿个参数，专为适合单个 "
"GPU 而设计"

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"一系列可将 HTML 内容转换为 Markdown 内容的模型，对内容转换任务非常有用。"

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr "利用高质量数据对性能最佳的专家混合模型进行微调。"

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr "以 Zephyr 为基础，利用高质量数据对 7B 聊天模型进行微调。"

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"由 Open Orca OpenChat 模型和 Garage-bAInd Platypus 2 模型合并而成。专为聊天和"
"代码生成而设计。"

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr "由两个经过微调的 Llama 2 70B 模型合并而成的语言模型。"

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B 和 3B 模型是 IBM 首款专为低延迟使用而设计的混合专家（MoE）"
"Granite 模型。"

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"在用于信息提取的私人高质量合成数据集上微调的 3.8B 模型，以 Phi-3 为基础。"

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr "Cohere For AI 的语言模型经过训练，在 23 种不同语言中表现出色。"

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX 是由 Databricks 创建的开放式通用 LLM。"

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"阿里巴巴国际数字商业集团（AIDC-AI）为现实世界解决方案建立的开放式大型推理模"
"型。"

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "来自 BAAI 的嵌入模型，将文本映射为矢量。"

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr "基于 Llama 3 的开放式权重函数调用模型，与 GPT-4o 函数调用能力相媲美。"

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr "一个强大的对话模型，设计用于聊天和指示用例。"

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"DeekSeek-V2的升级版本，整合了DeepSeek-V2-Chat和DeepSeek-Coder-V2-Instruct的综"
"合能力和编码能力。"

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma 是一套经过指令调整的模型，用于根据一组定义的安全策略评估文本提示"
"输入和文本输出响应的安全性。"

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr "Bespoke Labs 开发的最先进的事实核查模型。"

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 是一系列针对 LLM 输入和响应的内容安全分类进行微调的模型。"

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr "可用于聚类或语义搜索等任务的句子转换器模型。"

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder 是一个开放和可复制的代码 LLM 系列，包括 1.5B 和 8B 模型，支持中英文"
"对话。"

#: src/available_models_descriptions.py:138
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 是一个领先的指令跟随模型系列，由艾伦人工智能研究所提供完全开源的数据、"
"代码和配方。"

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Snowflake 的前沿嵌入模型。Arctic Embed 2.0 在不牺牲英语性能或可扩展性的情况下"
"增加了多语言支持。"

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr "IBM Granite Guardian 3.0 2B 和 8B 模型旨在检测提示和/或响应中的风险。"

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 是一个经过指令调整的双语（英语和韩语）生成模型集合，参数从 2.4B "
"到 32B 不等，由 LG AI Research 开发并发布。"

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr "Sailor2 是专为东南亚制作的多语种语言模型。有 1B、8B 和 20B 参数规格。"

#: src/available_models_descriptions.py:143
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"通过创新的训练技术，在科学、数学和编码方面性能优越的 10B 参数以下的高效人工智"
"能模型系列。"

#: src/available_models_descriptions.py:144
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"IBM Granite 2B 和 8B 模型是在超过 12 万亿个词组数据基础上训练的纯文本密集 "
"LLM，在 IBM 的初步测试中，其性能和速度都较前代产品有了显著提高。"

#: src/available_models_descriptions.py:145
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B 和 3B 模型是 IBM 为低延迟使用而设计的长上下文混合专家（MoE）"
"Granite 模型。"

#: src/available_models_descriptions.py:146
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"IBM Granite Embedding 30M 和 278M 模型是纯文本密集生物编码器嵌入模型，其中 "
"30M 仅提供英语版本，而 278M 则服务于多语言使用案例。"

#: src/available_models_descriptions.py:147
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr "Phi-4 是微软发布的14B参数的最新开源模型。"

#: src/available_models_descriptions.py:148
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr "一个新的小型推理模型，基于Qwen 2.5 3B指令模型微调而来。"

#: src/available_models_descriptions.py:149
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 是 Dolphin 系列指令微调模型的下一代，旨在成为终极"
"通用本地模型，能够支持编程、数学、代理行为、函数调用以及一般用途场景。"

#: src/available_models_descriptions.py:150
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"DeepSeek 的第一代推理模型，性能与 OpenAI-o1 相当，包括六个从基于 Llama 和 "
"Qwen 的 DeepSeek-R1 提炼而来的大纲模型。"

#: src/available_models_descriptions.py:151
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"一个强大的Mixture-of-Experts（MoE）语言模型，总参数量为671B，每个词令牌激活"
"37B参数。"

#: src/available_models_descriptions.py:152
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 是一个新的家族，包括7B和13B参数的模型，训练数据量高达5万亿个词令牌。这"
"些模型与同等规模的完全开源模型相当或更优，并且在英语学术基准测试中与像 Llama "
"3.1 这样的开放权重模型竞争激烈。"

#: src/available_models_descriptions.py:153
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"Cohere R 系列中的最小模型提供了顶级的速度、效率和质量，使得在普通GPU和边缘设"
"备上构建强大的AI应用变得可能。"

#: src/available_models_descriptions.py:154
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"一个完全开源的推理模型家族，使用了从 DeepSeek-R1 提炼出的数据集构建而成。"

#: src/available_models_descriptions.py:155
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"基于 DeepSeek-R1 提炼的 Qwen-1.5B 微调版本，在流行的数学评估中性能超越了 "
"OpenAI 的 o1-preview，仅使用1.5亿个参数。"

#: src/available_models_descriptions.py:156
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"经过 Perplexity 后微调的 DeepSeek-R1 模型版本，能够提供\"无偏见、准确且事实"
"\"的信息。"

#: src/instance_manager.py:30
msgid "Instance"
msgstr "实例"

#: src/instance_manager.py:60 src/window.ui:141
#: src/custom_widgets/chat_widget.py:396
msgid "New Chat"
msgstr "新对话"

#: src/instance_manager.py:84 src/instance_manager.py:171
#: src/instance_manager.py:181 src/instance_manager.py:324
#: src/instance_manager.py:593 src/instance_manager.py:734
#: src/instance_manager.py:762
msgid "Instance Error"
msgstr "实例错误"

#: src/instance_manager.py:84
msgid "Message generation failed"
msgstr "消息生成失败"

#: src/instance_manager.py:171 src/instance_manager.py:593
#: src/instance_manager.py:734 src/instance_manager.py:762
msgid "Could not retrieve added models"
msgstr "无法检索到已添加的模型"

#: src/instance_manager.py:181
msgid "Could not retrieve available models"
msgstr "无法检索到可用的模型"

#: src/instance_manager.py:249
msgid "Ollama (Managed)"
msgstr "Ollama（托管版）"

#: src/instance_manager.py:278
msgid "Alpaca Support"
msgstr "Alpaca 支持文档"

#: src/instance_manager.py:285
msgid "Model request too large for system"
msgstr "模型需求太大，超出系统处理能力"

#: src/instance_manager.py:288
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr "检测到 AMD GPU，但未安装支持扩展，Ollama 将使用 CPU。"

#: src/instance_manager.py:290
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "检测到 AMD GPU，但缺少 ROCm，Ollama 将使用 CPU。"

#: src/instance_manager.py:292
msgid "Using AMD GPU type '{}'"
msgstr "使用 AMD GPU 类型"

#: src/instance_manager.py:302
msgid "Integrated Ollama instance is not running"
msgstr "集成的 Ollama 实例未运行"

#: src/instance_manager.py:324
msgid "Managed Ollama instance failed to start"
msgstr "托管的 Ollama 实例启动失败"

#: src/instance_manager.py:327
msgid "Integrated Ollama instance is running"
msgstr "集成的 Ollama 实例正在运行"

#: src/instance_manager.py:331
msgid "Local AI instance managed directly by Alpaca"
msgstr "本地AI实例由 Alpaca 直接管理"

#: src/instance_manager.py:334 src/instance_manager.py:335
msgid "Ollama Log"
msgstr "Ollama 日志"

#: src/instance_manager.py:340 src/instance_manager.py:476
#: src/instance_manager.py:609 src/window.ui:790
msgid "Name"
msgstr "名称"

#: src/instance_manager.py:346
msgid "Port"
msgstr "端口"

#: src/instance_manager.py:346
msgid "Which network port will Ollama use"
msgstr "Ollama 将使用哪个网络端口？"

#: src/instance_manager.py:351 src/instance_manager.py:496
#: src/instance_manager.py:640
msgid "Temperature"
msgstr "温度（随机性控制参数）"

#: src/instance_manager.py:351 src/instance_manager.py:496
#: src/instance_manager.py:640
msgid "Increasing the temperature will make the models answer more creatively."
msgstr "提高温度会使模型的回答更具创造性。"

#: src/instance_manager.py:354 src/instance_manager.py:499
#: src/instance_manager.py:644
msgid "Seed"
msgstr "种子值"

#: src/instance_manager.py:354 src/instance_manager.py:499
#: src/instance_manager.py:644
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr "将其设置为除0以外的具体数字可以确保在相同提示下模型生成相同的文本。"

#: src/instance_manager.py:359
msgid "Model Directory"
msgstr "模型目录"

#: src/instance_manager.py:361
msgid "Select Directory"
msgstr "选择目录"

#: src/instance_manager.py:372 src/instance_manager.py:505
#: src/instance_manager.py:650
msgid "Default Model"
msgstr "默认模型"

#: src/instance_manager.py:372 src/instance_manager.py:505
#: src/instance_manager.py:650
msgid "Model to select when starting a new chat."
msgstr "启动新聊天时选择的模型。"

#: src/instance_manager.py:374 src/instance_manager.py:507
#: src/instance_manager.py:652
msgid "Title Model"
msgstr "标题模型"

#: src/instance_manager.py:374 src/instance_manager.py:507
#: src/instance_manager.py:652
msgid "Model to use when generating a chat title."
msgstr "生成聊天标题时使用的模型。"

#: src/instance_manager.py:390
msgid "Overrides"
msgstr "覆盖设置"

#: src/instance_manager.py:390
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr "这些条目是可选的，它们用于排查与 Ollama 相关的 GPU 问题。"

#: src/instance_manager.py:417 src/instance_manager.py:418
#: src/instance_manager.py:534 src/instance_manager.py:535
#: src/instance_manager.py:679 src/instance_manager.py:680
#: src/custom_widgets/message_widget.py:203
msgid "Save"
msgstr "保存"

#: src/instance_manager.py:473
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "本地或远程AI实例不由Alpaca管理"

#: src/instance_manager.py:479 src/instance_manager.py:612
msgid "Instance URL"
msgstr "实例 URL"

#: src/instance_manager.py:482
msgid "API Key (Optional)"
msgstr "API密钥（可选）"

#: src/instance_manager.py:614 src/instance_manager.py:616
msgid "API Key (Unchanged)"
msgstr "API密钥（未更改）"

#: src/instance_manager.py:614 src/instance_manager.py:616
msgid "API Key"
msgstr "API密钥"

#: src/instance_manager.py:622
msgid "Max Tokens"
msgstr "最大tokens数"

#: src/instance_manager.py:623
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"定义了 AI 在响应中可以生成的最大 token 数（单词+空格）。更多的 token 允许更长"
"的回复，但可能需要更多的时间并产生更高的成本。"

#: src/instance_manager.py:773
msgid "OpenAI Compatible Instance"
msgstr "兼容 OpenAI 的实例"

#: src/instance_manager.py:795
msgid "Remove Instance?"
msgstr "移除实例？"

#: src/instance_manager.py:795
msgid "Are you sure you want to remove this instance?"
msgstr "您确定要移除这个实例吗？"

#: src/instance_manager.py:810
msgid "Edit Instance"
msgstr "编辑实例"

#: src/window.ui:34
msgid "Welcome"
msgstr "欢迎！"

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "上一个"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "欢迎来到 Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr "助力您的潜力"

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""
"使用AI模型生成的代码执行导致的任何设备或软件损坏，Alpaca及其开发人员不承担任"
"何责任。请在运行代码前谨慎检查并仔细审核。\n"
"\n"
"Alpaca 按照 GPLv3.0 协议分发，本软件不提供任何形式的保障。"

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr "代码轻松执行"

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""
"Alpaca 可以直接从您的对话中运行Python、C++，甚至HTML（需要一个live服务器）。"
"试试看！"

#: src/window.ui:107
msgid "Your AI, Your Choice"
msgstr "你的 AI 你做主！"

#: src/window.ui:108
msgid ""
"Alpaca includes Ollama by default, giving you instant access to AI. "
"Customize your experience further by connecting to Google Gemini, OpenAI "
"ChatGPT, Together.AI, and more."
msgstr ""
"Alpaca 默认包含 Ollama，为您提供即时访问AI的功能。您可以进一步自定义体验，连"
"接到 Google Gemini、OpenAI ChatGPT、Together.AI 等更多服务。"

#: src/window.ui:114
msgid "Private by Design"
msgstr "私密性设计"

#: src/window.ui:115
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""
"使用 Alpaca，您的对话将保存在您设备的本地，因此您可以确保您的数据始终安全且私"
"密。"

#: src/window.ui:152
msgid "Menu"
msgstr "目录"

#: src/window.ui:174
msgid "Toggle Sidebar"
msgstr "切换侧边栏"

#: src/window.ui:181
msgid "Search Messages"
msgstr "搜索消息"

#: src/window.ui:198 src/window.ui:225 src/window.ui:1146
msgid "Manage Models"
msgstr "管理模型"

#: src/window.ui:237
msgid "Chat Menu"
msgstr "对话列表"

#: src/window.ui:250
msgid "Message search bar"
msgstr "消息搜索栏"

#: src/window.ui:259 src/window.ui:261
msgid "Search messages"
msgstr "搜索消息"

#: src/window.ui:277
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr "警告：省电模式已启用，消息生成速度将减慢"

#: src/window.ui:324 src/window.ui:1240
msgid "Attach File"
msgstr "附加文件"

#: src/window.ui:354
msgid "Send Message"
msgstr "发送消息"

#: src/window.ui:373
msgid "Stop Message"
msgstr "停止消息"

#: src/window.ui:403
msgid "Instance Manager"
msgstr "实例管理器"

#: src/window.ui:418
msgid "No Instances Found"
msgstr "未找到任何实例"

#: src/window.ui:419
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr "这里看起来有点空荡。试试添加一个实例开始使用吧！"

#: src/window.ui:448
msgid "Added Instances"
msgstr "已添加的实例"

#: src/window.ui:449
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr "管理您的 AI 实例，在生成响应时，对话和交流会在不同实例之间共享。"

#: src/window.ui:484
msgid "Model Manager"
msgstr "模型管理器"

#: src/window.ui:522
msgid "Search Model"
msgstr "搜索模型"

#: src/window.ui:536
msgid "Model Manager Menu"
msgstr "模型管理菜单"

#: src/window.ui:549
msgid "Model search bar"
msgstr "模型搜索框"

#: src/window.ui:558 src/window.ui:560
msgid "Search models"
msgstr "搜索模型"

#: src/window.ui:574
msgid "Added"
msgstr "已添加"

#: src/window.ui:584 src/window.ui:644 src/window.ui:698
msgid "No Models Found"
msgstr "未找到模型"

#: src/window.ui:585
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr "这里看起来有点空荡。试试下载一些模型或更改您的 AI 实例开始使用吧！"

#: src/window.ui:588 src/window.ui:598 src/window.ui:1142
msgid "Manage Instances"
msgstr "管理实例"

#: src/window.ui:645 src/window.ui:699
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"看来没有找到符合条件的模型。您可以尝试调整关键词，或者探索一些新的内容！"

#: src/window.ui:657
msgid "Available"
msgstr "可获取"

#: src/window.ui:711
msgid "Creator"
msgstr "创建者"

#: src/window.ui:722
msgid "Model Creator"
msgstr "模型创建者"

#: src/window.ui:723
msgid "Select a method of importing a model to continue"
msgstr "请选择一种导入模型的方法继续："

#: src/window.ui:735
msgid "GGUF File"
msgstr "GGUF 文件"

#: src/window.ui:746
msgid "Existing Model"
msgstr "已存在的模型"

#: src/window.ui:764
msgid "Identity"
msgstr "识别信息"

#: src/window.ui:767
msgid "Base"
msgstr "基础模型"

#: src/window.ui:774
msgid "Profile Picture"
msgstr "简介图片"

#: src/window.ui:779
msgid "Open File"
msgstr "打开文件"

#: src/window.ui:795 src/custom_widgets/model_manager_widget.py:216
msgid "Tag"
msgstr "标签"

#: src/window.ui:802
msgid "Context"
msgstr "上下文"

#: src/window.ui:803
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr "用模型的主要语言（通常是英语）描述您希望的模型的行为。"

#: src/window.ui:831
msgid "Behavior"
msgstr "行为"

#: src/window.ui:834
msgid "Imagination"
msgstr "想象力"

#: src/window.ui:835
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr "较高的数字会导致模型生成更多样化的回答。（top_k）"

#: src/window.ui:849
msgid "Focus"
msgstr "专注力"

#: src/window.ui:850
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "较高的数字会增加可能的答案范围。（top_p）"

#: src/window.ui:883 src/window.ui:891
msgid "Add Model"
msgstr "添加模型"

#: src/window.ui:925 src/window.ui:1152
msgid "Preferences"
msgstr "首选项"

#: src/window.ui:933
msgid "Run Alpaca In Background"
msgstr "在后台运行 Alpaca"

#: src/window.ui:939
msgid "Show Power Saver Warning"
msgstr "显示省电警告"

#: src/window.ui:945
msgid "Zoom"
msgstr "缩放"

#: src/window.ui:963
msgid "Notice"
msgstr "注意"

#: src/window.ui:974
msgid "Removal of Ollama"
msgstr "移除 Ollama"

#: src/window.ui:975
msgid ""
"Hey there! With Alpaca 5.1.0, we're making some changes. To keep using "
"Ollama directly within Alpaca, you'll just need to install our new Ollama "
"extension. Don't worry, your models remain untouched!"
msgstr ""
"你好！在 Alpaca 5.1.0 中，我们进行了一些更改。要继续直接在Alpaca中使用 "
"Ollama，您只需安装我们的新 Ollama 扩展即可。别担心，您的模型不会受到影响！"

#: src/window.ui:980 src/window.ui:981
msgid "Install Ollama"
msgstr "安装 Ollama"

#: src/window.ui:999
msgid "Quick ask dialog"
msgstr "快速问答框"

#: src/window.ui:1011
msgid "Save Conversation to Alpaca"
msgstr "保存对话至 Alpace"

#: src/window.ui:1026
msgid "Terminal dialog"
msgstr "终端对话框"

#: src/window.ui:1029
msgid "Terminal"
msgstr "终端"

#: src/window.ui:1041
msgid "Open Environment Directory"
msgstr "打开环境目录"

#: src/window.ui:1062
msgid "File preview dialog"
msgstr "文件预览对话框"

#: src/window.ui:1073
msgid "Open With Default App"
msgstr "用默认应用打开"

#: src/window.ui:1081
msgid "Remove Attachment"
msgstr "移除附件"

#: src/window.ui:1138
msgid "Import Chat"
msgstr "导入对话"

#: src/window.ui:1156
msgid "Keyboard Shortcuts"
msgstr "快捷键"

#: src/window.ui:1160
msgid "About Alpaca"
msgstr "关于 Alpaca"

#: src/window.ui:1168 src/window.ui:1206
msgid "Rename Chat"
msgstr "重命名对话"

#: src/window.ui:1172 src/window.ui:1210
msgid "Duplicate Chat"
msgstr "复制对话"

#: src/window.ui:1180
msgid "Clear Chat"
msgstr "清除对话"

#: src/window.ui:1186 src/window.ui:1220
msgid "Delete Chat"
msgstr "删除对话"

#: src/window.ui:1194
msgid "Reload Added Models"
msgstr "重载已添加的模型"

#: src/window.ui:1198
msgid "Download Model From Name"
msgstr "根据名称下载模型"

#: src/window.ui:1228
msgid "Send as User"
msgstr "以用户身份发送"

#: src/window.ui:1232
msgid "Send as System"
msgstr "以系统身份发送"

#: src/window.ui:1244
msgid "Attach Website"
msgstr "附加网站"

#: src/window.ui:1248
msgid "Attach YouTube Captions"
msgstr "附加 YouTube 字幕"

#: src/alpaca_search_provider.py.in:43
msgid "Open chat"
msgstr "打开对话"

#: src/alpaca_search_provider.py.in:44
msgid "Quick ask"
msgstr "快速问答"

#: src/generic_actions.py:79
msgid "An error occurred while extracting text from the website"
msgstr "从网站提取文本时发生错误"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "通用"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "显示快捷方式"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "首选项"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "模型管理器"

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "实例管理器"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "切换侧边栏"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Quit"
msgstr "退出"

#: src/gtk/help-overlay.ui:52
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "对话管理"

#: src/gtk/help-overlay.ui:55
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "创建对话"

#: src/gtk/help-overlay.ui:61
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "删除对话"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "清除对话"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "重命名对话"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr "切换搜索栏"

#: src/gtk/help-overlay.ui:87
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "消息输入框"

#: src/gtk/help-overlay.ui:90
msgid "Copy"
msgstr "复制"

#: src/gtk/help-overlay.ui:96
msgid "Paste"
msgstr "粘贴"

#: src/gtk/help-overlay.ui:102
msgid "Open Emoji Menu"
msgstr "打开 Emoji 目录"

#: src/gtk/help-overlay.ui:108
msgid "Insert new line"
msgstr "插入新行"

#: src/gtk/help-overlay.ui:114
msgid "Send Message as System"
msgstr "以系统身份发送消息"

#: src/gtk/help-overlay.ui:115
msgid "System messages are taken as literal instructions by models"
msgstr "系统消息会被模型视为严格的指令"

#: src/gtk/help-overlay.ui:121
msgid "Send Message as User"
msgstr "以用户身份发送消息"

#: src/custom_widgets/chat_widget.py:84
msgid "Send prompt: '{}'"
msgstr "发送提示： '{}'"

#: src/custom_widgets/chat_widget.py:90 src/custom_widgets/chat_widget.py:91
msgid "Open Model Manager"
msgstr "打开模型管理器"

#: src/custom_widgets/chat_widget.py:100
msgid "Try one of these prompts"
msgstr "试试这些提示"

#: src/custom_widgets/chat_widget.py:100
msgid ""
"It looks like you don't have any models downloaded yet. Download models to "
"get started!"
msgstr "看起来你还没有下载任何模型。快去下载一些模型开始吧！"

#: src/custom_widgets/chat_widget.py:153
msgid "Chat exported successfully"
msgstr "聊天记录已成功导出"

#: src/custom_widgets/chat_widget.py:173
msgid "User"
msgstr "用户"

#: src/custom_widgets/chat_widget.py:177
#: src/custom_widgets/message_widget.py:626
msgid "System"
msgstr "系统"

#: src/custom_widgets/chat_widget.py:265
msgid "Regenerate Response"
msgstr "重新生成回复"

#: src/custom_widgets/chat_widget.py:434
msgid "Copy of {}"
msgstr "{} 的副本"

#: src/custom_widgets/chat_widget.py:449
msgid "Chat imported successfully"
msgstr "对话记录已成功导入"

#: src/custom_widgets/message_widget.py:69
msgid "Save Message"
msgstr "保存消息"

#: src/custom_widgets/message_widget.py:110
#: src/custom_widgets/message_widget.py:238
msgid "Message edited successfully"
msgstr "更改消息成功"

#: src/custom_widgets/message_widget.py:136
msgid "Response message"
msgstr "回复消息"

#: src/custom_widgets/message_widget.py:138
msgid "System message"
msgstr "系统消息"

#: src/custom_widgets/message_widget.py:140
msgid "User message"
msgstr "用户消息"

#: src/custom_widgets/message_widget.py:188
msgid "{}Code Block"
msgstr "{} 代码块"

#: src/custom_widgets/message_widget.py:190
msgid "Code Block"
msgstr "代码块"

#: src/custom_widgets/message_widget.py:191
#: src/custom_widgets/message_widget.py:525
msgid "Copy Message"
msgstr "复制消息"

#: src/custom_widgets/message_widget.py:195
msgid "Edit Code Block"
msgstr "编辑代码块"

#: src/custom_widgets/message_widget.py:207
#: src/custom_widgets/message_widget.py:283
msgid "Run Script"
msgstr "运行脚本"

#: src/custom_widgets/message_widget.py:247
msgid "Code copied to the clipboard"
msgstr "代码已复制到剪切板"

#: src/custom_widgets/message_widget.py:284
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""
"在运行该脚本之前，请确保您已了解其功能，Alpaca 不对设备或数据的任何损坏负责"

#: src/custom_widgets/message_widget.py:286
msgid "Execute"
msgstr "执行"

#: src/custom_widgets/message_widget.py:361
#: src/custom_widgets/message_widget.py:363
msgid "Image"
msgstr "图像"

#: src/custom_widgets/message_widget.py:372
#: src/custom_widgets/message_widget.py:384
msgid "Missing Image"
msgstr "无图像"

#: src/custom_widgets/message_widget.py:386
msgid "Missing image"
msgstr "无图像"

#: src/custom_widgets/message_widget.py:419
msgid "Copy Equation"
msgstr "复制公式"

#: src/custom_widgets/message_widget.py:425
msgid "Regenerate Equation"
msgstr "重新生成公式"

#: src/custom_widgets/message_widget.py:446
msgid "Equation copied to the clipboard"
msgstr "公式已复制到剪贴板。"

#: src/custom_widgets/message_widget.py:450
msgid "LaTeX Equation"
msgstr "Latex 公式"

#: src/custom_widgets/message_widget.py:515
msgid "Remove Message"
msgstr "移除消息"

#: src/custom_widgets/message_widget.py:535
msgid "Edit Message"
msgstr "编辑消息"

#: src/custom_widgets/message_widget.py:546
msgid "Regenerate Message"
msgstr "重新生成消息"

#: src/custom_widgets/message_widget.py:565
msgid "Message copied to the clipboard"
msgstr "消息已复制到剪切板"

#: src/custom_widgets/message_widget.py:593
msgid "Message cannot be regenerated while receiving a response"
msgstr "当收到回复时无法重新生成信息"

#: src/custom_widgets/message_widget.py:879
msgid "Thought"
msgstr "思考\t"

#: src/custom_widgets/model_manager_widget.py:120
msgid "Model Manager Error"
msgstr "模型管理错误"

#: src/custom_widgets/model_manager_widget.py:120
msgid "An error occurred whilst pulling '{}'"
msgstr "从远程获取 '{}' 时发生错误。"

#: src/custom_widgets/model_manager_widget.py:145
msgid "Download Completed"
msgstr "下载完成"

#: src/custom_widgets/model_manager_widget.py:145
msgid "Model '{}' downloaded successfully."
msgstr "模型 '{}' 下载成功。"

#: src/custom_widgets/model_manager_widget.py:157
#: src/custom_widgets/model_manager_widget.py:159
msgid "Stop Download"
msgstr "停止下在"

#: src/custom_widgets/model_manager_widget.py:163
msgid "Stop Download?"
msgstr "停止下载？"

#: src/custom_widgets/model_manager_widget.py:164
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "你确定要停止拉取 '{}' 吗？"

#: src/custom_widgets/model_manager_widget.py:166
msgid "Stop"
msgstr "停止"

#: src/custom_widgets/model_manager_widget.py:196
msgid "Change Profile Picture"
msgstr "更改简介图片"

#: src/custom_widgets/model_manager_widget.py:217
msgid "Family"
msgstr "系列"

#: src/custom_widgets/model_manager_widget.py:218
msgid "Parameter Size"
msgstr "参数大小"

#: src/custom_widgets/model_manager_widget.py:219
msgid "Quantization Level"
msgstr "量化级别"

#: src/custom_widgets/model_manager_widget.py:222
msgid "Parent Model"
msgstr "父模型"

#: src/custom_widgets/model_manager_widget.py:225
#: src/custom_widgets/model_manager_widget.py:227
msgid "Modified At"
msgstr "修改于"

#: src/custom_widgets/model_manager_widget.py:397
msgid "Change"
msgstr "更改"

#: src/custom_widgets/model_manager_widget.py:400
msgid "Model Profile Picture"
msgstr "模型简介图片"

#: src/custom_widgets/model_manager_widget.py:400
msgid "What do you want to do with the model's profile picture?"
msgstr "您想如何处理模型的简介照片？"

#: src/custom_widgets/model_manager_widget.py:422
msgid "Create Child"
msgstr "创建子模型"

#: src/custom_widgets/model_manager_widget.py:431
msgid "Remove Model"
msgstr "移除模型"

#: src/custom_widgets/model_manager_widget.py:435
msgid "Remove Model?"
msgstr "要移除该模型吗？"

#: src/custom_widgets/model_manager_widget.py:436
msgid "Are you sure you want to remove '{}'?"
msgstr "您确定要移除 '{}' 吗？"

#: src/custom_widgets/model_manager_widget.py:450
msgid "Multilingual"
msgstr "多语言"

#: src/custom_widgets/model_manager_widget.py:451
msgid "Code"
msgstr "代码"

#: src/custom_widgets/model_manager_widget.py:452
msgid "Math"
msgstr "数学"

#: src/custom_widgets/model_manager_widget.py:453
msgid "Vision"
msgstr "视觉"

#: src/custom_widgets/model_manager_widget.py:454
msgid "Embedding"
msgstr "嵌入"

#: src/custom_widgets/model_manager_widget.py:455
msgid "Small"
msgstr "小型"

#: src/custom_widgets/model_manager_widget.py:456
msgid "Medium"
msgstr "中型"

#: src/custom_widgets/model_manager_widget.py:457
msgid "Big"
msgstr "大型"

#: src/custom_widgets/model_manager_widget.py:458
msgid "Huge"
msgstr "巨型"

#: src/custom_widgets/model_manager_widget.py:539
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr "通过下载此模型，您将接受在该模型网站上提供的许可协议。"

#: src/custom_widgets/model_manager_widget.py:597
msgid "Visit Website"
msgstr "访问网站"

#: src/custom_widgets/dialog_widget.py:147
#: src/custom_widgets/dialog_widget.py:159
#: src/custom_widgets/dialog_widget.py:171
msgid "Accept"
msgstr "接受"

#: src/custom_widgets/terminal_widget.py:80
msgid "Setting up Python environment..."
msgstr "设置 Python 环境……"

#: src/custom_widgets/terminal_widget.py:95
msgid "Compiling C++ script..."
msgstr "正在编译C++脚本..."

#: src/custom_widgets/terminal_widget.py:108
msgid "Running local web server"
msgstr "运行本地网页服务器"

#: src/custom_widgets/terminal_widget.py:133
msgid "Using Flatpak contained shell"
msgstr "使用 Flatpak 内置的 shell 环境"

#: src/custom_widgets/terminal_widget.py:139
msgid "Script Exited"
msgstr "脚本已退出"
