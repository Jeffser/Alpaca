# Simplified Chinese Translation for Alpaca
# Copyright (C) 2024 Jeffser
# This file is distributed under the same license as the Alpaca package.
# Aleksana <me@aleksana.moe>, 2024.
# Yuehao Sui <8ar10der@amao.run>, 2024-2025.
#
msgid ""
msgstr ""
"Project-Id-Version: 5.1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-12 11:09-0600\n"
"PO-Revision-Date: 2025-04-03 21:23+0200\n"
"Last-Translator: Yuehao Sui <8ar10der@amao.run>\n"
"Language-Team: Chinese (China)\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Generator: Gtranslator 48.0\n"

#: data/com.jeffser.Alpaca.desktop.in:2
#: data/com.jeffser.Alpaca.metainfo.xml.in:7
msgid "Alpaca"
msgstr "Alpaca"

# 建议不翻译
#: data/com.jeffser.Alpaca.desktop.in:8
msgid "ai;ollama;llm"
msgstr "ai;ollama;llm"

#: data/com.jeffser.Alpaca.metainfo.xml.in:8
msgid "Chat with AI models"
msgstr "与AI模型聊天"

#: data/com.jeffser.Alpaca.metainfo.xml.in:10
msgid "A private AI client"
msgstr "私人AI客户端"

#: data/com.jeffser.Alpaca.metainfo.xml.in:11
#: data/com.jeffser.Alpaca.metainfo.xml.in:1119
msgid "Features"
msgstr "功能特点"

#: data/com.jeffser.Alpaca.metainfo.xml.in:13
#: data/com.jeffser.Alpaca.metainfo.xml.in:1121
msgid "Talk to multiple models in the same conversation"
msgstr "在同一对话中与多个模型交谈"

#: data/com.jeffser.Alpaca.metainfo.xml.in:14
#: data/com.jeffser.Alpaca.metainfo.xml.in:1122
msgid "Pull and delete models from the app"
msgstr "在应用中拉取或删除模型"

#: data/com.jeffser.Alpaca.metainfo.xml.in:15
msgid "Have multiple conversations"
msgstr "进行多重对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:16
msgid "Image recognition (Only available with compatible models)"
msgstr "图像识别（仅适用于兼容模型）"

#: data/com.jeffser.Alpaca.metainfo.xml.in:17
msgid "Plain text documents recognition"
msgstr "纯文本文档识别"

#: data/com.jeffser.Alpaca.metainfo.xml.in:18
msgid "Import and export chats"
msgstr "导入导出对话记录"

#: data/com.jeffser.Alpaca.metainfo.xml.in:19
msgid "Append YouTube transcripts to the prompt"
msgstr "将 Youtube 的转录文本添加到提示中"

#: data/com.jeffser.Alpaca.metainfo.xml.in:20
msgid "Append text from a website to the prompt"
msgstr "将来自网站的文本添加到提示中"

#: data/com.jeffser.Alpaca.metainfo.xml.in:21
msgid "PDF recognition"
msgstr "PDF 识别"

#: data/com.jeffser.Alpaca.metainfo.xml.in:23 src/window.ui:90
msgid "Disclaimer"
msgstr "免责声明"

#: data/com.jeffser.Alpaca.metainfo.xml.in:24
msgid ""
"This project is not affiliated at all with Ollama, I'm not responsible for "
"any damages to your device or software caused by running code given by any "
"models."
msgstr ""
"本项目与 Ollama 没有任何关联，对于运行任何模型所提供的代码而对您的设备或软件"
"造成的任何损害，我概不负责。"

#: data/com.jeffser.Alpaca.metainfo.xml.in:27
msgid "Jeffry Samuel Eduarte Rojas"
msgstr "Jeffry Samuel Eduarte Rojas"

#: data/com.jeffser.Alpaca.metainfo.xml.in:53
msgid "A normal conversation with an AI Model"
msgstr "一段与 AI 模型的普通对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:57
msgid "A conversation involving image recognition"
msgstr "一段带有图像识别的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:61
msgid "A conversation involving a custom model"
msgstr "一段涉及自定义模型的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:65
msgid "A conversation showing code highlighting"
msgstr "一段展示代码高亮的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:69
msgid "A Python script running inside integrated terminal"
msgstr "一段在内置终端中运行的 Python 脚本"

#: data/com.jeffser.Alpaca.metainfo.xml.in:73
msgid "A conversation involving a YouTube video transcript"
msgstr "一段含有 YouTube 转录文本的对话"

#: data/com.jeffser.Alpaca.metainfo.xml.in:77
msgid "Multiple models being downloaded"
msgstr "已下载的多个模型"

#: data/com.jeffser.Alpaca.metainfo.xml.in:81
msgid "Model creator screen"
msgstr "模型创建者界面"

#: data/com.jeffser.Alpaca.metainfo.xml.in:95
#: data/com.jeffser.Alpaca.metainfo.xml.in:143
#: data/com.jeffser.Alpaca.metainfo.xml.in:161
#: data/com.jeffser.Alpaca.metainfo.xml.in:177
#: data/com.jeffser.Alpaca.metainfo.xml.in:189
#: data/com.jeffser.Alpaca.metainfo.xml.in:239
#: data/com.jeffser.Alpaca.metainfo.xml.in:285
#: data/com.jeffser.Alpaca.metainfo.xml.in:316
#: data/com.jeffser.Alpaca.metainfo.xml.in:325
#: data/com.jeffser.Alpaca.metainfo.xml.in:388
#: data/com.jeffser.Alpaca.metainfo.xml.in:416
#: data/com.jeffser.Alpaca.metainfo.xml.in:430
#: data/com.jeffser.Alpaca.metainfo.xml.in:447
#: data/com.jeffser.Alpaca.metainfo.xml.in:458
#: data/com.jeffser.Alpaca.metainfo.xml.in:467
#: data/com.jeffser.Alpaca.metainfo.xml.in:484
#: data/com.jeffser.Alpaca.metainfo.xml.in:494
#: data/com.jeffser.Alpaca.metainfo.xml.in:511
#: data/com.jeffser.Alpaca.metainfo.xml.in:521
#: data/com.jeffser.Alpaca.metainfo.xml.in:568
#: data/com.jeffser.Alpaca.metainfo.xml.in:593
#: data/com.jeffser.Alpaca.metainfo.xml.in:618
#: data/com.jeffser.Alpaca.metainfo.xml.in:640
#: data/com.jeffser.Alpaca.metainfo.xml.in:658
#: data/com.jeffser.Alpaca.metainfo.xml.in:676
#: data/com.jeffser.Alpaca.metainfo.xml.in:688
#: data/com.jeffser.Alpaca.metainfo.xml.in:704
msgid "Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:97
msgid "Instance manager now follows default model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:98
msgid "English text-to-speech voices not working"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:99
msgid "Instance manager sometimes not saving instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:100
msgid "Fixed Gorq and Deepseek instances not generating text"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:107
#: data/com.jeffser.Alpaca.metainfo.xml.in:154
#: data/com.jeffser.Alpaca.metainfo.xml.in:171
#: data/com.jeffser.Alpaca.metainfo.xml.in:201
#: data/com.jeffser.Alpaca.metainfo.xml.in:211
#: data/com.jeffser.Alpaca.metainfo.xml.in:222
#: data/com.jeffser.Alpaca.metainfo.xml.in:249
#: data/com.jeffser.Alpaca.metainfo.xml.in:269
#: data/com.jeffser.Alpaca.metainfo.xml.in:295
#: data/com.jeffser.Alpaca.metainfo.xml.in:310
#: data/com.jeffser.Alpaca.metainfo.xml.in:335
#: data/com.jeffser.Alpaca.metainfo.xml.in:363
#: data/com.jeffser.Alpaca.metainfo.xml.in:373
#: data/com.jeffser.Alpaca.metainfo.xml.in:384
#: data/com.jeffser.Alpaca.metainfo.xml.in:398
#: data/com.jeffser.Alpaca.metainfo.xml.in:410
#: data/com.jeffser.Alpaca.metainfo.xml.in:426
#: data/com.jeffser.Alpaca.metainfo.xml.in:441
#: data/com.jeffser.Alpaca.metainfo.xml.in:476
#: data/com.jeffser.Alpaca.metainfo.xml.in:501
#: data/com.jeffser.Alpaca.metainfo.xml.in:532
#: data/com.jeffser.Alpaca.metainfo.xml.in:558
#: data/com.jeffser.Alpaca.metainfo.xml.in:580
#: data/com.jeffser.Alpaca.metainfo.xml.in:611
#: data/com.jeffser.Alpaca.metainfo.xml.in:633
#: data/com.jeffser.Alpaca.metainfo.xml.in:654
#: data/com.jeffser.Alpaca.metainfo.xml.in:669
#: data/com.jeffser.Alpaca.metainfo.xml.in:694
msgid "New"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:109
msgid "Smart tools for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:110
msgid "Speech recognition (message dictation)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:111
msgid "Text to Speech"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:112
msgid "New Quick Chat system"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:113
msgid "Filter Ollama models by categories"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:114
msgid "Better math Latex rendering in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:115
msgid "Rich text rendering in attachment preview"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:116
msgid "Matplotlib is now included in Python code runner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:117
msgid "Styling for messages being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:119
#: data/com.jeffser.Alpaca.metainfo.xml.in:227
msgid "New Instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:121
msgid "Deepseek"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:122
msgid "OpenRouter AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:123
msgid "Anthropic"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:124
msgid "Groq Cloud"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:125
msgid "Fireworks AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:126
msgid "Lambda Labs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:128
msgid "New Attachment Types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:130
msgid "Microsoft Word Document (docx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:131
msgid "Microsoft PowerPoint Document (pptx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:132
msgid "Microsoft Excel Document (xlsx)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:134
msgid "New Tools"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:136 src/tool_manager.py:431
msgid "Run Command (Testing)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:137 src/tool_manager.py:348
msgid "Online Search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:138 src/tool_manager.py:306
msgid "Extract Wikipedia Article"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:139 src/tool_manager.py:210
msgid "Get Recipe by Name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:140 src/tool_manager.py:261
msgid "Get Recipes by Category"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:141 src/tool_manager.py:176
msgid "Get Current Datetime"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:145
msgid "Fixed welcome screen not showing sometimes when deleting a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:146
msgid "Fixed bold text not rendering correctly in tables"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:147
msgid "Fixed sample prompt buttons overflowing on small screens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:156
msgid "Updated runtime to Gnome 48"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:157
msgid "Added back 'category pills' to model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:158
msgid "Better appearance for model manager sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:159
#: data/com.jeffser.Alpaca.metainfo.xml.in:175
msgid "New models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:163
msgid "Fixed bad title generation with chain-of-thought models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:164
msgid ""
"Hide page switcher in model manager if there's only one page (online "
"instances)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:173
msgid "Option to delete all chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:174
msgid "Button to refresh sample prompts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:179
msgid "Fixed saving Ollama (Managed) instance might crash it"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:180
msgid "Fixed stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:181
msgid "Fixed model search not working if there are only pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:182
msgid "Fixed sample prompts sometimes not appearing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:191
msgid "Don't clear the building output of C++ scripts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:192
msgid "Better handling of attachments"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:193
msgid "Handle remote Ollama instance's API Key better"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:194
msgid "Remove '\\n' characters in instance edit page"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:203
msgid "Dynamic chat loading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:204
msgid "Updated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:213
msgid "Tweaked appearance of models in model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:214
msgid "Updated Ollama instance to 0.5.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:215
msgid "Added new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:224
msgid "New instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:225
msgid "New welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:229
msgid "OpenAI ChatGPT"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:230
msgid "Google Gemini"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:231
msgid "Together AI"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:232
msgid "Venice"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:241
msgid "Exporting chats with 'thoughts' attachment is fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:242
msgid "Fixed attachment filters"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:251
msgid "New model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:252
msgid "Changed GtkSpinner to AdwSpinner"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:253
msgid "Better handling of launch process"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:254
msgid "New loading screen at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:255
msgid "Better handling of file types"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:256
msgid "Better regex expression for LaTeX equations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:257
msgid "Confirmation dialog if user closes Alpaca whilst a model is downloading"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:258
msgid "Better handling of think tags in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:259
msgid "Default model is now in charge of generating titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:260
msgid "Message header is now shown whilst the message is being generated"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:261
msgid "Better handling of model profile pictures"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:262
msgid "New models in 'available models' list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:271
msgid "Added option for attaching screenshots"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:272
msgid "Basic LaTeX math equations are now rendered in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:273
msgid "HTML and C++ scripts can now be run inside Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:274
msgid "Added option to open the environment directory from the terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:275
msgid "Added option to edit code blocks directly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:276
msgid "Complete keyboard shortcut list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:277
msgid "Images are now attached in 640p resolution"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:278
msgid "Website attachments now use extracted titles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:279
msgid "Better chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:280
msgid "Added option to attach any plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:281
msgid "Added spellchecker to message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:282
msgid "Alpaca's parameters are now stored using SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:283
msgid "Small appearance changes in text entries"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:287
msgid "Alpaca's launch process is more reliable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:288
msgid "Closing the terminal now kills the script subprocess"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:297
msgid "Transitioned chat backend from JSON to SQLite3"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:298
msgid "Changed appearance of messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:299
msgid "Added the option to add profile pictures to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:301
#: data/com.jeffser.Alpaca.metainfo.xml.in:773
#: data/com.jeffser.Alpaca.metainfo.xml.in:822
msgid "Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:303
msgid "Changed override HIP_VISIBLE_DEVICES to ROCR_VISIBLE_DEVICES"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:312
msgid "Added categories to models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:313
msgid "Specified model's languages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:314
msgid "Added warning when downloading embedding models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:318
msgid "Replaced low ram warning with big model warning"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:327
msgid "Correctly escape markup before rendering message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:328
msgid "Fixed about dialog not working if log file was missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:337
msgid "System messages can now be sent directly from Alpaca"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:338
msgid "New redesign for messages and smaller minimum size"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:339
msgid "New models included in 'available models list'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:340
msgid "Added symbolic icon when attaching code files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:341
msgid "When exporting a chat it now includes a markdown file"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:342
msgid "Refresh button in model manager when using a remote instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:343
msgid "Assistant messages are now editable"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:344
msgid "Updated Ollama to v0.5.2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:345
msgid "New option to change model directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:346
msgid "File previewer now resizes dynamically to content"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:347
msgid "Adapted Alpaca to work without integrated Ollama instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:348
msgid "Compatibility added with ODT files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:351
msgid "Restored ROCm compatibility"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:352
msgid ""
"Added long press gesture to chat rows so actions can be done in touchscreens"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:353
msgid "Fixed edit button not saving changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:354
msgid "Changed max temperature value to 2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:355
msgid "Made seed 0 actually random"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:356
msgid ""
"Fixed Gnome search provider not working outside of Flatpak installations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:365
msgid "New option --ask MESSAGE, to open a new 'Quick Ask' window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:366
msgid "Gnome Search integration now works whilst the app is opened"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:375
msgid ""
"Added launch paramenters --ask MESSAGE, --new-chat CHAT, --select-chat CHAT, "
"--list-chats, --version"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:376
msgid "Added integration as Gnome Search Provider"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:377
msgid "Updated Ollama to v0.4.2 with new models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:386
msgid "User messages are now compacted into bubbles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:390
msgid ""
"Fixed re connection dialog not working when 'use local instance' is selected"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:391
msgid "Fixed model manager not adapting to large system fonts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:400
msgid "Details page for models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:401
msgid ""
"Model selector gets replaced with 'manage models' button when there are no "
"models downloaded"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:402
msgid "Added warning when model is too big for the device"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:403
msgid "Added AMD GPU indicator in preferences"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:412
msgid "Better system for handling dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:413
msgid "Better system for handling instance switching"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:414
msgid "Remote connection dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:418
msgid "Fixed: Models get duplicated when switching remote and local instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:419
msgid "Better internal instance manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:428
msgid "Added 'Cancel' and 'Save' buttons when editing a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:432
msgid "Better handling of image recognition"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:433
msgid "Remove unused files when canceling a model download"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:434
msgid "Better message blocks rendering"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:443
msgid "Run bash and python scripts straight from chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:444
msgid "Updated Ollama to 0.3.12"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:445
msgid "New models!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:449
msgid "Fixed and made faster the launch sequence"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:450
msgid "Better detection of code blocks in messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:451
msgid "Fixed app not loading in certain setups with Nvidia GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:460
msgid ""
"Fixed message notification sometimes crashing text rendering because of them "
"running on different threads"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:469
msgid "Fixed message generation sometimes failing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:478
msgid "Sidebar resizes with the window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:479
msgid "New welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:480
msgid "Message search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:481
msgid "Updated Ollama to v0.3.11"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:482
msgid "A lot of new models provided by Ollama repository"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:486
msgid ""
"Fixed text inside model manager when the accessibility option 'large text' "
"is on"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:487
msgid "Fixed image recognition on unsupported models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:496
msgid "Fixed spinner not hiding if the back end fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:497
msgid "Fixed image recognition with local images"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:498
msgid "Changed appearance of delete / stop model buttons"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:499
msgid "Fixed stop button crashing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:503
msgid "Made sidebar resize a little when the window is smaller"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:504
msgid "Instant launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:513
msgid "Fixed error on first run (welcome dialog)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:514
msgid "Fixed checker for Ollama instance (used on system packages)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:523
msgid "Fixed 'clear chat' option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:524
msgid "Fixed welcome dialog causing the local instance to not launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:525
msgid "Fixed support for AMD GPUs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:534
msgid "Model, message and chat systems have been rewritten"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:535
msgid "New models are available"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:536
msgid "Ollama updated to v0.3.9"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:537
msgid "Added support for multiple chat generations simultaneously"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:538
msgid "Added experimental AMD GPU support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:539
msgid "Added message loading spinner and new message indicator to chat tab"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:540
msgid "Added animations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:541
msgid "Changed model manager / model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:542
msgid "Changed message appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:543
msgid "Added markdown and code blocks to user messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:544
msgid "Added loading dialog at launch so the app opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:545
msgid "Added warning when device is on 'battery saver' mode"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:546
msgid "Added inactivity timer to integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:549
msgid "The chat is now scrolled to the bottom when it's changed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:550
msgid "Better handling of focus on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:551
msgid "Better general performance on the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:560
msgid "New duplicate chat option"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:561
msgid "Changed model selector appearance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:562
msgid "Message entry is focused on launch and chat change"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:563
msgid "Message is focused when it's being edited"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:564
msgid "Added loading spinner when regenerating a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:565
msgid "Added Ollama debugging to 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:566
msgid "Changed YouTube transcription dialog appearance and behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:570
msgid "CTRL+W and CTRL+Q stops local instance before closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:571
msgid "Changed appearance of 'Open Model Manager' button on welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:572
msgid "Fixed message generation not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:573
msgid "Fixed message edition not working consistently"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:582
msgid "Model manager opens faster"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:583
msgid "Delete chat option in secondary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:584
msgid "New model selector popup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:585
msgid "Standard shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:586
msgid "Model manager is navigable with keyboard"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:587
msgid "Changed sidebar collapsing behavior"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:588
msgid "Focus indicators on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:589
msgid "Welcome screen"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:590
msgid "Give message entry focus at launch"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:591
msgid "Generally better code"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:595
msgid "Better width for dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:596
msgid "Better compatibility with screen readers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:597
msgid "Fixed message regenerator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:598
msgid "Removed 'Featured models' from welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:599
msgid "Added default buttons to dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:600
msgid "Fixed import / export of chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:601
msgid "Changed Python2 title to Python on code blocks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:602
msgid ""
"Prevent regeneration of title when the user changed it to a custom title"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:603
msgid "Show date on stopped messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:604
msgid "Fix clear chat error"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:613
msgid "Changed shortcuts to standards"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:614
msgid "Moved 'Manage Models' button to primary menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:615
#: data/com.jeffser.Alpaca.metainfo.xml.in:637
msgid "Stable support for GGUF model files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:616
#: data/com.jeffser.Alpaca.metainfo.xml.in:891
msgid "General optimizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:620
msgid "Better handling of enter key (important for Japanese input)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:621
msgid "Removed sponsor dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:622
msgid "Added sponsor link in about dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:623
msgid "Changed window and elements dimensions"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:624
msgid "Selected model changes when entering model manager"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:625
msgid "Better image tooltips"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:626
msgid "GGUF Support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:635
msgid "Regenerate any response, even if they are incomplete"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:636
msgid "Support for pulling models by name:tag"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:638
msgid "Restored sidebar toggle button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:642
msgid "Reverted back to standard styles"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:643
msgid "Fixed generated titles having \"'S\" for some reason"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:644
msgid "Changed min width for model dropdown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:645
msgid "Changed message entry shadow"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:646
msgid "The last model used is now restored when the user changes chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:647
msgid "Better check for message finishing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:656
msgid "Added table rendering (Thanks Nokse)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:660
msgid "Made support dialog more common"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:661
msgid ""
"Dialog title on tag chooser when downloading models didn't display properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:662
msgid "Prevent chat generation from generating a title with multiple lines"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:671
msgid "Bearer Token entry on connection error dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:672
msgid "Small appearance changes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:673
msgid "Compatibility with code blocks without explicit language"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:674
msgid "Rare, optional and dismissible support dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:678
msgid "Date format for Simplified Chinese translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:679
msgid "Bug with unsupported localizations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:680
msgid "Min height being too large to be used on mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:681
msgid "Remote connection checker bug"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:690
msgid "Models with capital letters on their tag don't work"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:691
msgid "Ollama fails to launch on some systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:692
msgid "YouTube transcripts are not being saved in the right TMP directory"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:696
msgid "Debug messages are now shown on the 'About Alpaca' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:697
msgid "Updated Ollama to v0.3.0 (new models)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:706
msgid "Models with '-' in their names didn't work properly, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:707
msgid "Better connection check for Ollama"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:714
msgid "Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:715
msgid ""
"The new icon was made by Tobias Bernard over the Gnome Gitlab, thanks for "
"the great icon!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:716
msgid "Features and fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:718
msgid "Updated Ollama instance to 0.2.8"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:719
msgid "Better model selector"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:720
msgid "Model manager redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:721
msgid "Better tag selector when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:722
msgid "Model search"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:723
msgid "Added support for bearer tokens on remote instances"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:724
msgid "Preferences dialog redesign"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:725
msgid "Added context menus to interact with a chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:726
msgid "Redesigned primary and secondary menus"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:727
msgid ""
"YouTube integration: Paste the URL of a video with a transcript and it will "
"be added to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:728
msgid ""
"Website integration (Experimental): Extract the text from the body of a "
"website by adding it's URL to the prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:729
msgid "Chat title generation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:730
msgid "Auto resizing of message entry"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:731
msgid "Chat notifications"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:732
msgid "Added indicator when an image is missing"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:733
msgid "Auto rearrange the order of chats when a message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:734
msgid "Redesigned file preview dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:735
msgid "Credited new contributors"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:736
msgid "Better stability and optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:737
msgid "Edit messages to change the context of a conversation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:738
msgid "Added disclaimers when pulling models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:739
msgid "Preview files before sending a message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:740
msgid "Better format for date and time on messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:741
msgid "Error and debug logging on terminal"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:742
msgid "Auto-hiding sidebar button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:743
msgid "Various UI tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:745
msgid "New Models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:747
msgid "Gemma2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:748
msgid "GLM4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:749
msgid "Codegeex4"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:750
msgid "InternLM2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:751
msgid "Llama3-groq-tool-use"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:752
msgid "Mathstral"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:753
msgid "Mistral-nemo"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:754
msgid "Firefunction-v2"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:755
msgid "Nuextract"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:757
msgid "Translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:758
msgid ""
"These are all the available translations on 1.0.0, thanks to all the "
"contributors!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:760
msgid "Russian: Alex K"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:761
msgid "Spanish: Jeffser"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:762
msgid "Brazilian Portuguese: Daimar Stein"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:763
msgid "French: Louis Chauvet-Villaret"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:764
msgid "Norwegian: CounterFlow64"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:765
msgid "Bengali: Aritra Saha"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:766
msgid "Simplified Chinese: Yuehao Sui"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:774
msgid ""
"Removed DOCX compatibility temporally due to error with python-lxml "
"dependency"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:780
#: data/com.jeffser.Alpaca.metainfo.xml.in:810
#: data/com.jeffser.Alpaca.metainfo.xml.in:831
#: data/com.jeffser.Alpaca.metainfo.xml.in:1036
#: data/com.jeffser.Alpaca.metainfo.xml.in:1093
msgid "Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:782
msgid "Added compatibility for PDF"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:783
msgid "Added compatibility for DOCX"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:784
msgid "Merged 'file attachment' menu into one button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:791
#: data/com.jeffser.Alpaca.metainfo.xml.in:984
msgid "Quick Fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:792
msgid ""
"There were some errors when transitioning from the old version of chats to "
"the new version. I apologize if this caused any corruption in your chat "
"history. This should be the only time such a transition is needed."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:798
#: data/com.jeffser.Alpaca.metainfo.xml.in:950
msgid "Huge Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:800
msgid "Added: Support for plain text files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:801
msgid "Added: New backend system for storing messages"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:802
msgid "Added: Support for changing Ollama's overrides"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:803
msgid "General Optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:812
msgid "Added: Support for GGUF models (experimental)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:813
msgid "Added: Support for customization and creation of models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:814
msgid "Fixed: Icons don't appear on non Gnome systems"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:815
msgid "Update Ollama to v0.1.39"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:824
msgid ""
"Fixed: app didn't open if models tweaks wasn't present in the config files"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:833
msgid "Changed multiple icons (paper airplane for the send button)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:834
msgid "Combined export / import chat buttons into a menu"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:835
msgid "Added 'model tweaks' (temperature, seed, keep_alive)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:836
msgid "Fixed send / stop button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:837
msgid "Fixed app not checking if remote connection works when starting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:844
msgid "Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:846
msgid "Added text ellipsis to chat name so it doesn't change the button width"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:847
msgid "New shortcut for creating a chat (CTRL+N)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:848
msgid "New message entry design"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:849
msgid "Fixed: Can't rename the same chat multiple times"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:856
msgid "The fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:858
msgid ""
"Fixed: Ollama instance keeps running on the background even when it is "
"disabled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:859
msgid "Fixed: Can't pull models on the integrated instance"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:866
msgid "Quick tweaks"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:868
msgid "Added progress bar to models that are being pulled"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:869
msgid "Added size to tags when pulling a model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:870
msgid "General optimizations on the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:877
msgid "Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:879
msgid "Fixed: Scroll when message is received"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:880
msgid "Fixed: Content doesn't change when creating a new chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:881
msgid "Added 'Featured Models' page on welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:888
msgid "Nice Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:890
msgid "UI tweaks (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:892
msgid "Metadata fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:899
msgid "Quick fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:901
msgid "Updated Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:902
msgid "Added compatibility for PNG"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:909
msgid "New Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:911
msgid "Updated model list"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:912
msgid "Added image recognition to more models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:913
msgid "Added Brazilian Portuguese translation (Thanks Daimaar Stein)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:914
msgid "Refined the general UI (Thanks Nokse22)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:915
msgid "Added 'delete message' feature"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:916
msgid ""
"Added metadata so that software distributors know that the app is compatible "
"with mobile"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:917
msgid ""
"Changed 'send' shortcut to just the return/enter key (to add a new line use "
"shift+return)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:924
msgid "Bug Fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:926
msgid "Fixed: Minor spelling mistake"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:927
msgid "Added 'mobile' as a supported form factor"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:928
msgid "Fixed: 'Connection Error' dialog not working properly"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:929
msgid "Fixed: App might freeze randomly on startup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:930
msgid "Changed 'chats' label on sidebar for 'Alpaca'"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:937
msgid "Cool Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:939
msgid "Better design for chat window"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:940
msgid "Better design for chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:941
msgid "Fixed remote connections"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:942
msgid "Fixed Ollama restarting in loop"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:943
msgid "Other cool backend stuff"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:952
msgid "Added Ollama as part of Alpaca, Ollama will run in a sandbox"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:953
msgid "Added option to connect to remote instances (how it worked before)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:954
msgid "Added option to import and export chats"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:955
msgid "Added option to run Alpaca with Ollama in the background"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:956
msgid "Added preferences dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:957
msgid "Changed the welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:959
#: data/com.jeffser.Alpaca.metainfo.xml.in:976
#: data/com.jeffser.Alpaca.metainfo.xml.in:988
#: data/com.jeffser.Alpaca.metainfo.xml.in:1007
#: data/com.jeffser.Alpaca.metainfo.xml.in:1028
#: data/com.jeffser.Alpaca.metainfo.xml.in:1044
#: data/com.jeffser.Alpaca.metainfo.xml.in:1060
#: data/com.jeffser.Alpaca.metainfo.xml.in:1074
#: data/com.jeffser.Alpaca.metainfo.xml.in:1084
#: data/com.jeffser.Alpaca.metainfo.xml.in:1102
#: data/com.jeffser.Alpaca.metainfo.xml.in:1124
msgid "Please report any errors to the issues page, thank you."
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:967
msgid "Yet Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:969
msgid "Added better UI for 'Manage Models' dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:970
msgid "Added better UI for the chat sidebar"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:971
msgid ""
"Replaced model description with a button to open Ollama's website for the "
"model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:972
msgid "Added myself to the credits as the spanish translator"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:973
msgid "Using XDG properly to get config folder"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:974
msgid "Update for translations"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:986
msgid "The last update had some mistakes in the description of the update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:996
msgid "Another Daily Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:998
msgid "Added full Spanish translation"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:999
msgid "Added support for background pulling of multiple models"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1000
msgid "Added interrupt button"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1001
msgid "Added basic shortcuts"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1002
msgid "Better translation support"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1003
msgid ""
"User can now leave chat name empty when creating a new one, it will add a "
"placeholder name"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1004
msgid "Better scalling for different window sizes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1005
msgid "Fixed: Can't close app if first time setup fails"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1015
msgid "Really Big Update"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1017
msgid "Added multiple chats support!"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1018
msgid "Added Pango Markup support (bold, list, title, subtitle, monospace)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1019
msgid "Added autoscroll if the user is at the bottom of the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1020
msgid "Added support for multiple tags on a single model"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1021
msgid "Added better model management dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1022
msgid "Added loading spinner when sending message"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1023
msgid "Added notifications if app is not active and a model pull finishes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1024
msgid "Added new symbolic icon"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1025
msgid "Added frame to message textview widget"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1026
msgid "Fixed \"code blocks shouldn't be editable\""
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1038
msgid "Added code highlighting"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1039
msgid "Added image recognition (llava model)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1040
msgid "Added multiline prompt"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1041
msgid "Fixed some small bugs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1042
msgid "General optimization"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1052
msgid "Fixes and features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1054
msgid "Russian translation (thanks github/alexkdeveloper)"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1055
msgid "Fixed: Cannot close app on first setup"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1056
msgid "Fixed: Brand colors for Flathub"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1057
msgid "Fixed: App description"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1058
msgid "Fixed: Only show 'save changes dialog' when you actually change the url"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1068
msgid "0.2.2 Bug fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1070
msgid "Toast messages appearing behind dialogs"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1071
msgid "Local model list not updating when changing servers"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1072
msgid "Closing the setup dialog closes the whole app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1082
msgid "0.2.1 Data saving fix"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1083
msgid ""
"The app didn't save the config files and chat history to the right "
"directory, this is now fixed"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1092
msgid "0.2.0"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1094
msgid "New Features"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1096
msgid "Restore chat after closing the app"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1097
msgid "A button to clear the chat"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1098
msgid "Fixed multiple bugs involving how messages are shown"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1099
msgid "Added welcome dialog"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1100
msgid "More stability"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1110
msgid "0.1.2 Quick fixes"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1111
msgid ""
"This release fixes some metadata needed to have a proper Flatpak application"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1117
msgid "0.1.1 Stable Release"
msgstr ""

#: data/com.jeffser.Alpaca.metainfo.xml.in:1118
msgid "This is the first public version of Alpaca"
msgstr ""

#: src/main.py:193
msgid "Documentation"
msgstr ""

#: src/main.py:194
msgid "Become a Sponsor"
msgstr ""

#: src/main.py:195
msgid "Discussions"
msgstr ""

#: src/window.py:185
msgid "Speech recognition model is being downloaded ({})"
msgstr ""

#: src/window.py:210 src/window.py:240
msgid "Speech Recognition Error"
msgstr ""

#: src/window.py:210
msgid "An error occurred while pulling speech recognition model"
msgstr ""

#: src/window.py:240
msgid "An error occurred while using speech recognition"
msgstr ""

#: src/window.py:275
msgid "Ollama Was Not Found"
msgstr ""

#: src/window.py:276
msgid ""
"To add a managed Ollama instance, you must have Ollama installed locally in "
"your device, this is a simple process and should not take more than 5 "
"minutes."
msgstr ""

#: src/window.py:278
msgid "Open Tutorial in Web Browser"
msgstr ""

#: src/window.py:284 src/window.py:291 src/window.ui:472 src/window.ui:482
#: src/window.ui:504
msgid "Add Instance"
msgstr ""

#: src/window.py:292
msgid "Select a type of instance to add"
msgstr ""

#: src/window.py:527
msgid "No tools enabled."
msgstr ""

#: src/window.py:527
msgid "Open Tool Manager"
msgstr ""

#: src/window.py:530
msgid "'{}' does not support tools."
msgstr ""

#: src/window.py:530
msgid "Open Model Manager"
msgstr "打开模型管理器"

#: src/window.py:533 src/window.py:1122
msgid "Please select a model before chatting"
msgstr "请在对话前先选择一个模型"

#: src/window.py:581 src/window.py:582 src/window.py:651 src/window.ui:288
msgid "Close"
msgstr "关闭"

#: src/window.py:584 src/window.py:585 src/window.ui:62 src/window.ui:63
msgid "Next"
msgstr "下一页"

#: src/window.py:649 src/instance_manager.py:405 src/instance_manager.py:406
#: src/tool_manager.py:136 src/window.ui:968 src/window.ui:972
#: src/custom_widgets/message_widget.py:79
#: src/custom_widgets/message_widget.py:229
#: src/custom_widgets/model_manager_widget.py:422
#: src/custom_widgets/dialog_widget.py:148
#: src/custom_widgets/dialog_widget.py:160
#: src/custom_widgets/dialog_widget.py:172
msgid "Cancel"
msgstr "取消"

#: src/window.py:650
msgid "Hide"
msgstr "隐藏"

#: src/window.py:654
msgid "Close Alpaca?"
msgstr "关闭 Alpaca？"

#: src/window.py:655
msgid "A task is currently in progress. Are you sure you want to close Alpaca?"
msgstr "当前有一个任务正在进行中。你确定要关闭 Alpaca 吗？"

#: src/window.py:899
msgid "Cannot open image"
msgstr "无法打开图片"

#: src/window.py:978
msgid "Delete Chat?"
msgstr "删除对话？"

#: src/window.py:979
msgid "Are you sure you want to delete '{}'?"
msgstr "你确定你想要删除 '{}' 吗？"

#: src/window.py:981 src/window.py:1450
msgid "Delete"
msgstr "删除"

#: src/window.py:988
msgid "Rename Chat?"
msgstr "重命名对话？"

#: src/window.py:989
msgid "Renaming '{}'"
msgstr "重命名 '{}'"

#: src/window.py:991
msgid "Chat name"
msgstr "对话命名"

#: src/window.py:992
msgid "Rename"
msgstr "重命名"

#: src/window.py:997
msgid "Importable (.db)"
msgstr "可导入 (.db)"

#: src/window.py:998
msgid "Markdown"
msgstr "Markdown格式"

#: src/window.py:999
msgid "Markdown (Obsidian Style)"
msgstr "Markdown格式 （Obsidian 风格）"

#: src/window.py:1000
msgid "JSON"
msgstr "JSON"

#: src/window.py:1001
msgid "JSON (Include Metadata)"
msgstr "JSON（包含元数据）"

#: src/window.py:1004 src/window.ui:1405 src/window.ui:1439
msgid "Export Chat"
msgstr "导出对话"

#: src/window.py:1005
msgid "Select a method to export the chat"
msgstr "选择一个模型以导出对话"

#: src/window.py:1021
msgid "This video does not have any transcriptions"
msgstr "本视频没有任何转录内容"

#: src/window.py:1028
msgid "Attach YouTube Video?"
msgstr "附加 YouTube 视频？"

#: src/window.py:1029
msgid ""
"{}\n"
"\n"
"Please select a transcript to include"
msgstr ""
"{}\n"
"\n"
"请选择要附加的转录"

#: src/window.py:1035
msgid "Error attaching video, please try again"
msgstr "附加视频出错，请重试"

#: src/window.py:1056 src/window.py:1444
msgid "Attach Website? (Experimental)"
msgstr "附加网站？（试验性）"

#: src/window.py:1057
msgid ""
"Are you sure you want to attach\n"
"'{}'?"
msgstr ""
"您确定要附加\n"
"'{}'?"

#: src/window.py:1075 src/window.py:1087 src/window.py:1443
#: src/generic_actions.py:105
msgid "Image recognition is only available on specific models"
msgstr "图像识别功能仅适用于特定模型"

#: src/window.py:1106 src/window.ui:1189
msgid "Quick Ask"
msgstr "快速提问"

#: src/window.py:1276
msgid "Attachment failed, screenshot might be too big"
msgstr "添加附件失败，截图可能太大了。"

#: src/window.py:1290
msgid "Any compatible Alpaca attachment"
msgstr "任何与 Alpaca 兼容的附件"

#: src/window.py:1419
msgid "Attach Screenshot"
msgstr "附加屏幕截图"

#: src/window.py:1444
msgid "Please enter a website URL"
msgstr "请输入一个网站地址"

#: src/window.py:1445
msgid "Attach YouTube Captions?"
msgstr "附加上 YouTube 字幕？"

#: src/window.py:1445
msgid "Please enter a YouTube video URL"
msgstr "请输入一个YouTube视频地址"

#: src/window.py:1448
msgid "Download Model?"
msgstr "下载模型？"

#: src/window.py:1448
msgid "Please enter the model name following this template: name:tag"
msgstr "请按照以下模板输入模型名称：name:tag"

#: src/window.py:1450
msgid "Delete All Chats?"
msgstr "要删除所有对话吗？"

#: src/window.py:1450
msgid "Are you sure you want to delete all chats?"
msgstr "你确定要删除所有对话吗？"

#: src/window.py:1461
msgid "Remove Attachment?"
msgstr "移除附件？"

#: src/window.py:1461
msgid "Are you sure you want to remove attachment?"
msgstr "你确定你想要移除附件？"

#: src/window.py:1461 src/instance_manager.py:885
#: src/custom_widgets/model_manager_widget.py:423
#: src/custom_widgets/model_manager_widget.py:463
msgid "Remove"
msgstr "移除"

#: src/window.py:1476
msgid "Already Installed!"
msgstr "安装完成！"

#: src/available_models_descriptions.py:2
msgid ""
"New state of the art 70B model. Llama 3.3 70B offers similar performance "
"compared to the Llama 3.1 405B model."
msgstr ""
"最新一代的70B参数模型。Llama 3.3 70B 与 Llama 3.1 405B 模型相比提供了相似的性"
"能。"

#: src/available_models_descriptions.py:3
msgid "QwQ is the reasoning model of the Qwen series."
msgstr "QwQ 是Qwen系列模型的推理模型。"

#: src/available_models_descriptions.py:4
msgid ""
"Llama 3.2 Vision is a collection of instruction-tuned image reasoning "
"generative models in 11B and 90B sizes."
msgstr ""
"Llama 3.2 Vision 是一套经过指令调整的图像推理生成模型，有 11B 和 90B 大小。"

#: src/available_models_descriptions.py:5
msgid "Meta's Llama 3.2 goes small with 1B and 3B models."
msgstr "Meta 的 Llama 3.2 采用小型 1B 和 3B 模型。"

#: src/available_models_descriptions.py:6
msgid ""
"Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and "
"405B parameter sizes."
msgstr "Llama 3.1 是新的来自 Meta 的先进模型，提供 8B, 70B, 和 405B 参数量。"

#: src/available_models_descriptions.py:7
msgid "Meta Llama 3: The most capable openly available LLM to date"
msgstr "Meta Llama 3：迄今能力最强的开源大模型"

#: src/available_models_descriptions.py:8
msgid "The 7B model released by Mistral AI, updated to version 0.3."
msgstr "Mistral AI 发布的 7B 模型，已更新至 0.3 版。"

#: src/available_models_descriptions.py:9
msgid ""
"A high-performing open embedding model with a large token context window."
msgstr "具有大型标记上下文窗口的高性能开放式嵌入模型。"

#: src/available_models_descriptions.py:10
msgid ""
"Gemma is a family of lightweight, state-of-the-art open models built by "
"Google DeepMind. Updated to version 1.1"
msgstr "Gemma 是由 Google DeepMind 构建的轻量级先进开放模型系列。更新至 1.1 版"

#: src/available_models_descriptions.py:11
msgid ""
"Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from "
"0.5B to 110B parameters"
msgstr "Qwen 1.5 是阿里云推出的一系列大型语言模型，参数从 0.5B 到 110B 不等"

#: src/available_models_descriptions.py:12
msgid "Qwen2 is a new series of large language models from Alibaba group"
msgstr "Qwen2 是阿里巴巴推出的新的大语言模型系列"

#: src/available_models_descriptions.py:13
msgid ""
"Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art "
"open models by Microsoft."
msgstr ""
"Phi-3 是微软公司推出的一系列轻型 3B（迷你）和 14B（中型）先进开源模型。"

#: src/available_models_descriptions.py:14
msgid ""
"Llama 2 is a collection of foundation language models ranging from 7B to 70B "
"parameters."
msgstr "Llama 2 是一组基础语言模型，参数从 7B 到 70B 不等。"

#: src/available_models_descriptions.py:15
msgid ""
"Qwen2.5 models are pretrained on Alibaba's latest large-scale dataset, "
"encompassing up to 18 trillion tokens. The model supports up to 128K tokens "
"and has multilingual support."
msgstr ""
"Qwen2.5 模型在阿里巴巴最新的大规模数据集上进行了预训练，该数据集包含多达 18 "
"万亿个token。该模型最大支持 128K token，并支持多种语言。"

#: src/available_models_descriptions.py:16
msgid ""
"Google Gemma 2 is a high-performing and efficient model available in three "
"sizes: 2B, 9B, and 27B."
msgstr "Google Gemma 2 是一款高性能、高效率的模型，有三种规格：2B、9B 和 27B。"

#: src/available_models_descriptions.py:17
msgid ""
"🌋 LLaVA is a novel end-to-end trained large multimodal model that combines "
"a vision encoder and Vicuna for general-purpose visual and language "
"understanding. Updated to version 1.6."
msgstr ""
"🌋 LLaVA 是一种新颖的端到端训练型大型多模态模型，它将视觉编码器和 Vicuna 结合"
"在一起，用于通用视觉和语言理解。已更新至 1.6 版。"

#: src/available_models_descriptions.py:18
msgid ""
"A large language model that can use text prompts to generate and discuss "
"code."
msgstr "大语言模型，可使用文本提示生成和讨论代码。"

#: src/available_models_descriptions.py:19
msgid ""
"The latest series of Code-Specific Qwen models, with significant "
"improvements in code generation, code reasoning, and code fixing."
msgstr ""
"最新系列的代码专用 Qwen 模型，在代码生成、代码推理和代码修复方面都有显著改"
"进。"

#: src/available_models_descriptions.py:20
msgid ""
"A state-of-the-art 12B model with 128k context length, built by Mistral AI "
"in collaboration with NVIDIA."
msgstr "一个具有 128k 上下文长度的先进模型，由 Mistral AI 与 NVIDIA 合作开发。"

#: src/available_models_descriptions.py:21
msgid ""
"The TinyLlama project is an open endeavor to train a compact 1.1B Llama "
"model on 3 trillion tokens."
msgstr ""
"TinyLlama 项目是一个开源的项目，旨在用 3 万亿标记训练一个 1.1B 的紧凑型 "
"Llama 模型。"

#: src/available_models_descriptions.py:22
msgid "State-of-the-art large embedding model from mixedbread.ai"
msgstr "来自 mixedbread.ai 的最先进的大型嵌入模型"

#: src/available_models_descriptions.py:23
msgid ""
"StarCoder2 is the next generation of transparently trained open code LLMs "
"that comes in three sizes: 3B, 7B and 15B parameters."
msgstr ""
"StarCoder2 是新一代透明训练的开放代码 LLM，有三种大小： 3B、7B 和 15B 参数。"

#: src/available_models_descriptions.py:24
msgid ""
"A set of Mixture of Experts (MoE) model with open weights by Mistral AI in "
"8x7b and 8x22b parameter sizes."
msgstr ""
"Mistral AI 在 8x7b 和 8x22b 两种参数大小下建立的一套权重开放的专家混合模型"
"（MoE）。"

#: src/available_models_descriptions.py:25
msgid ""
"Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of "
"experts models that excels at coding tasks. Created by Eric Hartford."
msgstr ""
"基于 Mixtral 混合专家模型的无审查、8x7b 和 8x22b 的微调模型，擅长编码任务。"
"由 Eric Hartford 创建。"

#: src/available_models_descriptions.py:26
msgid ""
"CodeGemma is a collection of powerful, lightweight models that can perform a "
"variety of coding tasks like fill-in-the-middle code completion, code "
"generation, natural language understanding, mathematical reasoning, and "
"instruction following."
msgstr ""
"CodeGemma 是一系列功能强大的轻量级模型，可执行各种代码任务，如中间代码补全、"
"代码生成、自然语言理解、数学推理和指令跟踪。"

#: src/available_models_descriptions.py:27
msgid ""
"An open-source Mixture-of-Experts code language model that achieves "
"performance comparable to GPT4-Turbo in code-specific tasks."
msgstr ""
"开源的 Mixture-of-Experts 代码语言模型在特定代码任务中的性能可与 GPT4-Turbo "
"相媲美。"

#: src/available_models_descriptions.py:28
msgid ""
"Phi-2: a 2.7B language model by Microsoft Research that demonstrates "
"outstanding reasoning and language understanding capabilities."
msgstr "Phi-2：微软研究院开发的 27 亿语言模型，具有出色的推理和语言理解能力。"

#: src/available_models_descriptions.py:29
msgid "Uncensored Llama 2 model by George Sung and Jarrad Hope."
msgstr "George Sung 和 Jarrad Hope 制作的无审查的 Llama 2 模型。"

#: src/available_models_descriptions.py:30
msgid ""
"DeepSeek Coder is a capable coding model trained on two trillion code and "
"natural language tokens."
msgstr ""
"DeepSeek Coder 是一个基于两万亿个代码和自然语言标记训练而成的代码模型。"

#: src/available_models_descriptions.py:31
msgid ""
"A suite of text embedding models by Snowflake, optimized for performance."
msgstr "一套由 Snowflake 提供的文本嵌入模型，并对性能进行了优化。"

#: src/available_models_descriptions.py:32
msgid ""
"State of the art large language model from Microsoft AI with improved "
"performance on complex chat, multilingual, reasoning and agent use cases."
msgstr ""
"来自 Microsoft AI 的最先进的大型语言模型，在复杂的对话、多语言、推理和代理用"
"例中性能更佳。"

#: src/available_models_descriptions.py:33
msgid ""
"The uncensored Dolphin model based on Mistral that excels at coding tasks. "
"Updated to version 2.8."
msgstr "基于 Mistral 的审查 Dolphin 模型，擅长代码任务。已更新至 2.8 版。"

#: src/available_models_descriptions.py:34
msgid ""
"Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on "
"Llama 3 that has a variety of instruction, conversational, and coding skills."
msgstr ""
"Dolphin 2.9 是 Eric Hartford 在 Llama 3 的基础上开发的新模型，有 8B 和 70B 大"
"小，具有各种教学、会话和代码技能。"

#: src/available_models_descriptions.py:35
msgid "Yi 1.5 is a high-performing, bilingual language model."
msgstr "Yi 1.5 是一个高性能的双语语言模型。"

#: src/available_models_descriptions.py:36
msgid ""
"Command R is a Large Language Model optimized for conversational interaction "
"and long context tasks."
msgstr "Command R 是一种大语言模型，针对对话交互和长语境任务进行了优化。"

#: src/available_models_descriptions.py:37
msgid ""
"A general-purpose model ranging from 3 billion parameters to 70 billion, "
"suitable for entry-level hardware."
msgstr "通用模型，参数范围从 30 亿到 700 亿，适合入门级硬件。"

#: src/available_models_descriptions.py:38
msgid ""
"A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several "
"benchmarks."
msgstr "根据 Llama 3 进行微调的 LLaVA 模型在多个基准测试中取得了更好的成绩。"

#: src/available_models_descriptions.py:39
msgid ""
"Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models "
"that are trained to act as helpful assistants."
msgstr ""
"Zephyr 是一系列经过微调的 Mistral 和 Mixtral 模型，经过训练后可充当得力助手。"

#: src/available_models_descriptions.py:40
msgid ""
"A lightweight AI model with 3.8 billion parameters with performance "
"overtaking similarly and larger sized models."
msgstr "拥有 38 亿个参数的轻量人工智能模型，性能超越同类和更大规模的模型。"

#: src/available_models_descriptions.py:41
msgid "Embedding models on very large sentence level datasets."
msgstr "在超大型语句级数据集上嵌入模型。"

#: src/available_models_descriptions.py:42
msgid ""
"Codestral is Mistral AI’s first-ever code model designed for code generation "
"tasks."
msgstr "Codestral 是 Mistral AI 首次为代码生成任务设计的代码模型。"

#: src/available_models_descriptions.py:43
msgid ""
"StarCoder is a code generation model trained on 80+ programming languages."
msgstr "StarCoder 是一个经过 80 多种编程语言训练的代码生成模型。"

#: src/available_models_descriptions.py:44
msgid ""
"General use chat model based on Llama and Llama 2 with 2K to 16K context "
"sizes."
msgstr "基于 Llama 和 Llama 2 的通用对话模型，上下文大小为 2K 至 16K。"

#: src/available_models_descriptions.py:45
msgid "A family of open foundation models by IBM for Code Intelligence"
msgstr "IBM 代码智能开放式基础模型系列"

#: src/available_models_descriptions.py:46
msgid ""
"Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the "
"Mistral 7B model using the OpenOrca dataset."
msgstr ""
"Mistral OpenOrca 是一个 70 亿参数模型，利用 OpenOrca 数据集在 Mistral 7B 模型"
"的基础上进行了微调。"

#: src/available_models_descriptions.py:47
msgid ""
"🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on "
"a new high-quality dataset."
msgstr ""
"🪐 在一个新的高质量数据集上训练的一系列小型模型，参数分别为 1.35 亿、3.6 亿"
"和 17 亿。"

#: src/available_models_descriptions.py:48
msgid ""
"Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on "
"Llama 2 uncensored by Eric Hartford."
msgstr ""
"Wizard Vicuna Uncensored 是一个 7B、13B 和 30B 参数模型，基于 Eric Hartford "
"的 Llama 2 Uncensored。"

#: src/available_models_descriptions.py:49
msgid "Llama 2 based model fine tuned to improve Chinese dialogue ability."
msgstr "基于 Llama 2 的模型进行了微调，以提高中文对话能力。"

#: src/available_models_descriptions.py:50
msgid ""
"BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-"
"Functionality, Multi-Linguality, and Multi-Granularity."
msgstr "BGE-M3 是 BAAI 推出的新型模型，具有多功能、多语言和多地域性的特点。"

#: src/available_models_descriptions.py:51
msgid ""
"A versatile model for AI software development scenarios, including code "
"completion."
msgstr "功能丰富的，适合应用于 AI 辅助开发的模型，包括代码补全。"

#: src/available_models_descriptions.py:52
msgid ""
"A family of open-source models trained on a wide variety of data, surpassing "
"ChatGPT on various benchmarks. Updated to version 3.5-0106."
msgstr ""
"在各种数据上训练有素的开源模型系列，在各种基准测试中超越了 ChatGPT。已更新至 "
"3.5-0106 版。"

#: src/available_models_descriptions.py:53
msgid ""
"Aya 23, released by Cohere, is a new family of state-of-the-art, "
"multilingual models that support 23 languages."
msgstr "由 Cohere 发布的 Aya 23 是最先进的多语言模型新系列，支持 23 种语言。"

#: src/available_models_descriptions.py:54
msgid ""
"CodeQwen1.5 is a large language model pretrained on a large amount of code "
"data."
msgstr "CodeQwen1.5 是一个基于大量代码数据预训练的大型语言模型。"

#: src/available_models_descriptions.py:55
msgid ""
"The powerful family of models by Nous Research that excels at scientific "
"discussion and coding tasks."
msgstr "Nous Research 强大的模型系列，擅长科学讨论和编码任务。"

#: src/available_models_descriptions.py:56
msgid ""
"Command R+ is a powerful, scalable large language model purpose-built to "
"excel at real-world enterprise use cases."
msgstr ""
"Command R+ 是一款功能强大、可扩展的大型语言模型，专为实际企业用例而设计。"

#: src/available_models_descriptions.py:57
msgid "State-of-the-art code generation model"
msgstr "最先进的代码生成模型"

#: src/available_models_descriptions.py:58
msgid ""
"Stable Code 3B is a coding model with instruct and code completion variants "
"on par with models such as Code Llama 7B that are 2.5x larger."
msgstr ""
"Stable Code 3B 是一种代码模型，其指令和代码完成变体可与 Code Llama 7B 等模型"
"相媲美，而后者的规模要大 2.5 倍。"

#: src/available_models_descriptions.py:59
msgid ""
"An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset "
"by Eric Hartford and based on TinyLlama."
msgstr ""
"Eric Hartford 基于 TinyLlama 在新的 Dolphin 2.8 数据集上训练的 1.1B 参数实验"
"模型。"

#: src/available_models_descriptions.py:60
msgid ""
"OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully "
"open datasets."
msgstr ""
"OpenHermes 2.5 是 Teknium 在 Mistral 上使用完全开放的数据集微调的 7B 模型。"

#: src/available_models_descriptions.py:61
msgid ""
"Mistral Large 2 is Mistral's new flagship model that is significantly more "
"capable in code generation, mathematics, and reasoning with 128k context "
"window and support for dozens of languages."
msgstr ""
"Mistral Large 2 是 Mistral 的新的旗舰模型，在代码生成、数学运算和逻辑推理方面"
"具有显著优势，带有 128k 的上下文长度并支持多种语言。"

#: src/available_models_descriptions.py:62
msgid ""
"Qwen2 Math is a series of specialized math language models built upon the "
"Qwen2 LLMs, which significantly outperforms the mathematical capabilities of "
"open-source models and even closed-source models (e.g., GPT4o)."
msgstr ""
"Qwen2 Math 是建立在 Qwen2 LLMs 基础上的一系列专业数学语言模型，其数学能力大大"
"超过开源模型甚至闭源模型（如 GPT4o）。"

#: src/available_models_descriptions.py:63
msgid ""
"A strong multi-lingual general language model with competitive performance "
"to Llama 3."
msgstr "强大的多语言的通用模型，在性能上较 Llama 3 有竞争力。"

#: src/available_models_descriptions.py:64
msgid ""
"Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model "
"trained on multilingual data in English, Spanish, German, Italian, French, "
"Portuguese, and Dutch."
msgstr ""
"Stable LM 2 是最先进的 1.6B 和 12B 参数语言模型，使用英语、西班牙语、德语、意"
"大利语、法语、葡萄牙语和荷兰语的多语言数据进行训练。"

#: src/available_models_descriptions.py:65
msgid ""
"BakLLaVA is a multimodal model consisting of the Mistral 7B base model "
"augmented with the LLaVA architecture."
msgstr "BakLLaVA 是一个多模式模型，由 Mistral 7B 基本模型和 LLaVA 架构组成。"

#: src/available_models_descriptions.py:66
msgid ""
"A high-performing model trained with a new technique called Reflection-"
"tuning that teaches a LLM to detect mistakes in its reasoning and correct "
"course."
msgstr ""
"使用一种名为 “反思-调整 ”的新技术训练出的高性能模型，能教会 LLM 发现推理中的"
"错误并纠正方向。"

#: src/available_models_descriptions.py:67
msgid "An advanced language model crafted with 2 trillion bilingual tokens."
msgstr "先进的语言模型包含 2 万亿个双语词库。"

#: src/available_models_descriptions.py:68
msgid ""
"This model extends LLama-3 8B's context length from 8k to over 1m tokens."
msgstr "该模型将 LLama-3 8B 的上下文长度从 8k 扩展到超过 1m 的标记。"

#: src/available_models_descriptions.py:69
msgid "Model focused on math and logic problems"
msgstr "侧重于数学和逻辑问题的模型"

#: src/available_models_descriptions.py:70
msgid ""
"moondream2 is a small vision language model designed to run efficiently on "
"edge devices."
msgstr "moondream2 是一个小型视觉语言模型，被设计用于在边缘设备上高效运行。"

#: src/available_models_descriptions.py:71
msgid ""
"A fine-tuned model based on Mistral with good coverage of domain and "
"language."
msgstr "基于 Mistral 的微调模型对领域和语言都有很好的覆盖。"

#: src/available_models_descriptions.py:72
msgid ""
"A model from NVIDIA based on Llama 3 that excels at conversational question "
"answering (QA) and retrieval-augmented generation (RAG)."
msgstr ""
"英伟达基于 Llama 3 的模型，擅长对话式问题解答（QA）和检索增强生成（RAG）。"

#: src/available_models_descriptions.py:73
msgid ""
"Conversational model based on Llama 2 that performs competitively on various "
"benchmarks."
msgstr "对话模型基于 Llama 2，在各种基准测试中表现优异。"

#: src/available_models_descriptions.py:74
msgid ""
"SQLCoder is a code completion model fined-tuned on StarCoder for SQL "
"generation tasks"
msgstr "SQLCoder 是在 StarCoder 基础上微调的代码完成模型，用于 SQL 生成任务"

#: src/available_models_descriptions.py:75
msgid "General use models based on Llama and Llama 2 from Nous Research."
msgstr "基于 Llama 和 Llama 2 的 Nous Research 公司的通用模型。"

#: src/available_models_descriptions.py:76
msgid "Code generation model based on Code Llama."
msgstr "基于 Code Llama 的代码生成模型。"

#: src/available_models_descriptions.py:77
msgid "An extension of Llama 2 that supports a context of up to 128k tokens."
msgstr "Llama 2 的扩展，支持多达 128k 标记的上下文。"

#: src/available_models_descriptions.py:78
msgid ""
"A 7B and 15B uncensored variant of the Dolphin model family that excels at "
"coding, based on StarCoder2."
msgstr "基于 StarCoder2 的 Dolphin 模型系列的 7B 和 15B 无删节变体，擅长编码。"

#: src/available_models_descriptions.py:79
msgid "General use model based on Llama 2."
msgstr "基于 Llama 2 的通用模型。"

#: src/available_models_descriptions.py:80
msgid "A strong, economical, and efficient Mixture-of-Experts language model."
msgstr "强大、经济、高效的专家混合语言模型。"

#: src/available_models_descriptions.py:81
msgid ""
"Starling is a large language model trained by reinforcement learning from AI "
"feedback focused on improving chatbot helpfulness."
msgstr ""
"Starling 是一个通过人工智能反馈强化学习训练出来的大型语言模型，专注于提高对话"
"机器人的帮助性。"

#: src/available_models_descriptions.py:82
msgid ""
"A companion assistant trained in philosophy, psychology, and personal "
"relationships. Based on Mistral."
msgstr "一名接受过哲学、心理学和人际关系培训的同伴助理。基于 Mistral。"

#: src/available_models_descriptions.py:83
msgid ""
"Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous "
"Research"
msgstr "Hermes 3 是 Nous Research 旗舰产品 Hermes 系列 LLM 的最新版本"

#: src/available_models_descriptions.py:84
msgid ""
"Yi-Coder is a series of open-source code language models that delivers state-"
"of-the-art coding performance with fewer than 10 billion parameters."
msgstr ""
"Yi-Coder 是一系列开源代码语言模型，以不到 100 亿个参数提供最先进的编码性能。"

#: src/available_models_descriptions.py:85
msgid ""
"A large language model built by the Technology Innovation Institute (TII) "
"for use in summarization, text generation, and chat bots."
msgstr ""
"技术创新研究所（TII）建立的大型语言模型，用于摘要、文本生成和聊天机器人。"

#: src/available_models_descriptions.py:86
msgid ""
"InternLM2.5 is a 7B parameter model tailored for practical scenarios with "
"outstanding reasoning capability."
msgstr "InternLM2.5 是为实际场景量身定制的 7B 参数模型，具有出色的推理能力。"

#: src/available_models_descriptions.py:87
msgid ""
"A compact, yet powerful 10.7B large language model designed for single-turn "
"conversation."
msgstr "结构紧凑、功能强大的 10.7B 大语言机型，专为单匝通话而设计。"

#: src/available_models_descriptions.py:88
msgid ""
"Athene-V2 is a 72B parameter model which excels at code completion, "
"mathematics, and log extraction tasks."
msgstr ""
"Athene-V2 是一个 72B 参数模型，在代码完成、数学和日志提取任务方面表现出色。"

#: src/available_models_descriptions.py:89
msgid "A new small LLaVA model fine-tuned from Phi 3 Mini."
msgstr "新的从 Phi 3 Mini 微调而来的小型 LLaVA 模型。"

#: src/available_models_descriptions.py:90
msgid ""
"Orca 2 is built by Microsoft research, and are a fine-tuned version of "
"Meta's Llama 2 models. The model is designed to excel particularly in "
"reasoning."
msgstr ""
"Orca 2 由微软研究部门开发，是 Meta 的 Llama 2 模型的微调版。该模型在设计上尤"
"其擅长推理。"

#: src/available_models_descriptions.py:91
msgid ""
"A series of multimodal LLMs (MLLMs) designed for vision-language "
"understanding."
msgstr "为视觉语言理解设计的一系列多模态 LLM（MLLM）。"

#: src/available_models_descriptions.py:92
msgid ""
"Llama 2 based model fine tuned on an Orca-style dataset. Originally called "
"Free Willy."
msgstr ""
"基于 Llama 2，在 Orca-style 数据集上进行了微调的基础模型。最初名为“Free "
"Willy”。"

#: src/available_models_descriptions.py:93
msgid ""
"Mistral Small 3 sets a new benchmark in the “small” Large Language Models "
"category below 70B."
msgstr "Mistral Small 3 在低于70B参数的“小型”大语言模型类别中设立了新的基准。"

#: src/available_models_descriptions.py:94
msgid ""
"2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language "
"model by Microsoft Research."
msgstr ""
"Eric Hartford 根据微软研究院的 Phi 语言模型制作的 2.7B 无审查 Dolphin 模型。"

#: src/available_models_descriptions.py:95
msgid ""
"SmolLM2 is a family of compact language models available in three size: "
"135M, 360M, and 1.7B parameters."
msgstr ""
"SmolLM2 是一个紧凑型语言模型系列，有三种尺寸：135M、360M 和 1.7B 参数。"

#: src/available_models_descriptions.py:96
msgid "Uncensored version of Wizard LM model"
msgstr "未审查版 Wizard 大语言模型"

#: src/available_models_descriptions.py:97
msgid ""
"A commercial-friendly small language model by NVIDIA optimized for roleplay, "
"RAG QA, and function calling."
msgstr ""
"英伟达公司推出的商业友好型小语言模型，针对角色扮演、RAG QA 和函数调用进行了优"
"化。"

#: src/available_models_descriptions.py:98
msgid "An extension of Mistral to support context windows of 64K or 128K."
msgstr "Mistral 的扩展，支持 64K 或 128K 的上下文窗口。"

#: src/available_models_descriptions.py:99
msgid ""
"An expansion of Llama 2 that specializes in integrating both general "
"language understanding and domain-specific knowledge, particularly in "
"programming and mathematics."
msgstr ""
"Llama 2 的扩展版，专门整合一般语言理解和特定领域知识，尤其是编程和数学知识。"

#: src/available_models_descriptions.py:100
msgid ""
"Fine-tuned Llama 2 model to answer medical questions based on an open source "
"medical dataset."
msgstr "微调 Llama 2 模型，根据开源医疗数据集回答医疗问题。"

#: src/available_models_descriptions.py:101
msgid ""
"Open-source medical large language model adapted from Llama 2 to the medical "
"domain."
msgstr "开源医疗大型语言模型，由 Llama 2 改编而来，适用于医疗领域。"

#: src/available_models_descriptions.py:102
msgid ""
"A series of models from Groq that represent a significant advancement in "
"open-source AI capabilities for tool use/function calling."
msgstr ""
"来自 Groq 的一系列模型，代表了开源人工智能能力在工具使用/功能调用方面的重大进"
"步。"

#: src/available_models_descriptions.py:103
msgid ""
"Llama-3.1-Nemotron-70B-Instruct is a large language model customized by "
"NVIDIA to improve the helpfulness of LLM generated responses to user queries."
msgstr ""
"Llama-3.1-Nemotron-70B-Instruct 是英伟达定制的大型语言模型，用于提高 LLM 生成"
"的对用户查询的回复的帮助性。"

#: src/available_models_descriptions.py:104
msgid ""
"Nexus Raven is a 13B instruction tuned model for function calling tasks."
msgstr "Nexus Raven 是针对函数调用任务的 13B 指令调整模型。"

#: src/available_models_descriptions.py:105
msgid "The Nous Hermes 2 model from Nous Research, now trained over Mixtral."
msgstr "来自 Nous Research 的 Nous Hermes 2 模型，现在通过 Mixtral 进行训练。"

#: src/available_models_descriptions.py:106
msgid "Great code generation model based on Llama2."
msgstr "基于 Llama2 的优秀的代码生成模型。"

#: src/available_models_descriptions.py:107
msgid "Uncensored Llama2 based model with support for a 16K context window."
msgstr "基于 Llama2 的无删减模型，支持 16K 上下文窗口。"

#: src/available_models_descriptions.py:108
msgid ""
"The IBM Granite 2B and 8B models are designed to support tool-based use "
"cases and support for retrieval augmented generation (RAG), streamlining "
"code generation, translation and bug fixing."
msgstr ""
"IBM Granite 2B 和 8B 模型旨在支持基于工具的用例，支持检索增强生成（RAG），简"
"化代码生成、翻译和错误修复。"

#: src/available_models_descriptions.py:109
msgid ""
"🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic "
"instruction data using OSS-Instruct, a novel approach to enlightening LLMs "
"with open-source code snippets."
msgstr ""
"🎩 Magicoder 是一个 7B 参数模型系列，使用 OSS-Instruct 在 75K 个合成指令数据"
"上进行训练，OSS-Instruct 是一种利用开源代码片段启发 LLM 的新方法。"

#: src/available_models_descriptions.py:110
msgid ""
"A lightweight chat model allowing accurate, and responsive output without "
"requiring high-end hardware."
msgstr "轻量级聊天模式无需高端硬件即可实现准确、灵敏的输出。"

#: src/available_models_descriptions.py:111
msgid ""
"A high-performing code instruct model created by merging two existing code "
"models."
msgstr "通过合并两个现有的代码模型，创建了一个高性能代码指导模型。"

#: src/available_models_descriptions.py:112
msgid ""
"Falcon2 is an 11B parameters causal decoder-only model built by TII and "
"trained over 5T tokens."
msgstr ""
"Falcon2 是一个由 TII 构建的 11B 参数因果解码器模型，并通过 5T 标记进行了训"
"练。"

#: src/available_models_descriptions.py:113
msgid ""
"Wizard Vicuna is a 13B parameter model based on Llama 2 trained by "
"MelodysDreamj."
msgstr "Wizard Vicuna 是一个 13B 参数模型，基于 MelodysDreamj 训练的 Llama 2。"

#: src/available_models_descriptions.py:114
msgid ""
"MistralLite is a fine-tuned model based on Mistral with enhanced "
"capabilities of processing long contexts."
msgstr "MistralLite 是基于 Mistral 的微调模型，具有更强的长语境处理能力。"

#: src/available_models_descriptions.py:115
msgid ""
"MathΣtral: a 7B model designed for math reasoning and scientific discovery "
"by Mistral AI."
msgstr "MathΣtral：Mistral AI 为数学推理和科学发现设计的 7B 模型。"

#: src/available_models_descriptions.py:116
msgid "7B parameter text-to-SQL model made by MotherDuck and Numbers Station."
msgstr "MotherDuck 和 Numbers Station 制作的 7B 参数文本到 SQL 模型。"

#: src/available_models_descriptions.py:117
msgid ""
"MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by "
"interleaving the model with itself."
msgstr ""
"MegaDolphin-2.2-120b 是 Dolphin-2.2-70b 的转换版本，通过将模型与自身交错创建"
"而成。"

#: src/available_models_descriptions.py:118
msgid ""
"Solar Pro Preview: an advanced large language model (LLM) with 22 billion "
"parameters designed to fit into a single GPU"
msgstr ""
"Solar Pro 预览版：先进的大型语言模型 (LLM)，拥有 220 亿个参数，专为适合单个 "
"GPU 而设计"

#: src/available_models_descriptions.py:119
msgid ""
"A series of models that convert HTML content to Markdown content, which is "
"useful for content conversion tasks."
msgstr ""
"一系列可将 HTML 内容转换为 Markdown 内容的模型，对内容转换任务非常有用。"

#: src/available_models_descriptions.py:120
msgid ""
"A top-performing mixture of experts model, fine-tuned with high-quality data."
msgstr "利用高质量数据对性能最佳的专家混合模型进行微调。"

#: src/available_models_descriptions.py:121
msgid "A 7B chat model fine-tuned with high-quality data and based on Zephyr."
msgstr "以 Zephyr 为基础，利用高质量数据对 7B 聊天模型进行微调。"

#: src/available_models_descriptions.py:122
msgid ""
"Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. "
"Designed for chat and code generation."
msgstr ""
"由 Open Orca OpenChat 模型和 Garage-bAInd Platypus 2 模型合并而成。专为聊天和"
"代码生成而设计。"

#: src/available_models_descriptions.py:123
msgid ""
"A language model created by combining two fine-tuned Llama 2 70B models into "
"one."
msgstr "由两个经过微调的 Llama 2 70B 模型合并而成的语言模型。"

#: src/available_models_descriptions.py:124
msgid ""
"The IBM Granite 1B and 3B models are the first mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B 和 3B 模型是 IBM 首款专为低延迟使用而设计的混合专家（MoE）"
"Granite 模型。"

#: src/available_models_descriptions.py:125
msgid ""
"A 3.8B model fine-tuned on a private high-quality synthetic dataset for "
"information extraction, based on Phi-3."
msgstr ""
"在用于信息提取的私人高质量合成数据集上微调的 3.8B 模型，以 Phi-3 为基础。"

#: src/available_models_descriptions.py:126
msgid ""
"Cohere For AI's language models trained to perform well across 23 different "
"languages."
msgstr "Cohere For AI 的语言模型经过训练，在 23 种不同语言中表现出色。"

#: src/available_models_descriptions.py:127
msgid "DBRX is an open, general-purpose LLM created by Databricks."
msgstr "DBRX 是由 Databricks 创建的开放式通用 LLM。"

#: src/available_models_descriptions.py:128
msgid ""
"An open large reasoning model for real-world solutions by the Alibaba "
"International Digital Commerce Group (AIDC-AI)."
msgstr ""
"阿里巴巴国际数字商业集团（AIDC-AI）为现实世界解决方案建立的开放式大型推理模"
"型。"

#: src/available_models_descriptions.py:129
msgid "Embedding model from BAAI mapping texts to vectors."
msgstr "来自 BAAI 的嵌入模型，将文本映射为矢量。"

#: src/available_models_descriptions.py:130
msgid ""
"An open weights function calling model based on Llama 3, competitive with "
"GPT-4o function calling capabilities."
msgstr "基于 Llama 3 的开放式权重函数调用模型，与 GPT-4o 函数调用能力相媲美。"

#: src/available_models_descriptions.py:131
msgid ""
"A robust conversational model designed to be used for both chat and instruct "
"use cases."
msgstr "一个强大的对话模型，设计用于聊天和指示用例。"

#: src/available_models_descriptions.py:132
msgid ""
"An upgraded version of DeekSeek-V2 that integrates the general and coding "
"abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct."
msgstr ""
"DeekSeek-V2的升级版本，整合了DeepSeek-V2-Chat和DeepSeek-Coder-V2-Instruct的综"
"合能力和编码能力。"

#: src/available_models_descriptions.py:133
msgid ""
"ShieldGemma is set of instruction tuned models for evaluating the safety of "
"text prompt input and text output responses against a set of defined safety "
"policies."
msgstr ""
"ShieldGemma 是一套经过指令调整的模型，用于根据一组定义的安全策略评估文本提示"
"输入和文本输出响应的安全性。"

#: src/available_models_descriptions.py:134
msgid "A state-of-the-art fact-checking model developed by Bespoke Labs."
msgstr "Bespoke Labs 开发的最先进的事实核查模型。"

#: src/available_models_descriptions.py:135
msgid ""
"Llama Guard 3 is a series of models fine-tuned for content safety "
"classification of LLM inputs and responses."
msgstr ""
"Llama Guard 3 是一系列针对 LLM 输入和响应的内容安全分类进行微调的模型。"

#: src/available_models_descriptions.py:136
msgid ""
"Sentence-transformers model that can be used for tasks like clustering or "
"semantic search."
msgstr "可用于聚类或语义搜索等任务的句子转换器模型。"

#: src/available_models_descriptions.py:137
msgid ""
"OpenCoder is an open and reproducible code LLM family which includes 1.5B "
"and 8B models, supporting chat in English and Chinese languages."
msgstr ""
"OpenCoder 是一个开放和可复制的代码 LLM 系列，包括 1.5B 和 8B 模型，支持中英文"
"对话。"

#: src/available_models_descriptions.py:138
msgid ""
"Tülu 3 is a leading instruction following model family, offering fully open-"
"source data, code, and recipes by the The Allen Institute for AI."
msgstr ""
"Tülu 3 是一个领先的指令跟随模型系列，由艾伦人工智能研究所提供完全开源的数据、"
"代码和配方。"

#: src/available_models_descriptions.py:139
msgid ""
"Snowflake's frontier embedding model. Arctic Embed 2.0 adds multilingual "
"support without sacrificing English performance or scalability."
msgstr ""
"Snowflake 的前沿嵌入模型。Arctic Embed 2.0 在不牺牲英语性能或可扩展性的情况下"
"增加了多语言支持。"

#: src/available_models_descriptions.py:140
msgid ""
"The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks "
"in prompts and/or responses."
msgstr "IBM Granite Guardian 3.0 2B 和 8B 模型旨在检测提示和/或响应中的风险。"

#: src/available_models_descriptions.py:141
msgid ""
"EXAONE 3.5 is a collection of instruction-tuned bilingual (English and "
"Korean) generative models ranging from 2.4B to 32B parameters, developed and "
"released by LG AI Research."
msgstr ""
"EXAONE 3.5 是一个经过指令调整的双语（英语和韩语）生成模型集合，参数从 2.4B "
"到 32B 不等，由 LG AI Research 开发并发布。"

#: src/available_models_descriptions.py:142
msgid ""
"Sailor2 are multilingual language models made for South-East Asia. Available "
"in 1B, 8B, and 20B parameter sizes."
msgstr "Sailor2 是专为东南亚制作的多语种语言模型。有 1B、8B 和 20B 参数规格。"

#: src/available_models_descriptions.py:143
msgid ""
"A family of efficient AI models under 10B parameters performant in science, "
"math, and coding through innovative training techniques."
msgstr ""
"通过创新的训练技术，在科学、数学和编码方面性能优越的 10B 参数以下的高效人工智"
"能模型系列。"

#: src/available_models_descriptions.py:144
msgid ""
"The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 "
"trillion tokens of data, demonstrated significant improvements over their "
"predecessors in performance and speed in IBM’s initial testing."
msgstr ""
"IBM Granite 2B 和 8B 模型是在超过 12 万亿个词组数据基础上训练的纯文本密集 "
"LLM，在 IBM 的初步测试中，其性能和速度都较前代产品有了显著提高。"

#: src/available_models_descriptions.py:145
msgid ""
"The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) "
"Granite models from IBM designed for low latency usage."
msgstr ""
"IBM Granite 1B 和 3B 模型是 IBM 为低延迟使用而设计的长上下文混合专家（MoE）"
"Granite 模型。"

#: src/available_models_descriptions.py:146
msgid ""
"The IBM Granite Embedding 30M and 278M models models are text-only dense "
"biencoder embedding models, with 30M available in English only and 278M "
"serving multilingual use cases."
msgstr ""
"IBM Granite Embedding 30M 和 278M 模型是纯文本密集生物编码器嵌入模型，其中 "
"30M 仅提供英语版本，而 278M 则服务于多语言使用案例。"

#: src/available_models_descriptions.py:147
msgid "Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft."
msgstr "Phi-4 是微软发布的14B参数的最新开源模型。"

#: src/available_models_descriptions.py:148
msgid ""
"A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model."
msgstr "一个新的小型推理模型，基于Qwen 2.5 3B指令模型微调而来。"

#: src/available_models_descriptions.py:149
msgid ""
"Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of "
"instruct-tuned models designed to be the ultimate general purpose local "
"model, enabling coding, math, agentic, function calling, and general use "
"cases."
msgstr ""
"Dolphin 3.0 Llama 3.1 8B 🐬 是 Dolphin 系列指令微调模型的下一代，旨在成为终极"
"通用本地模型，能够支持编程、数学、代理行为、函数调用以及一般用途场景。"

#: src/available_models_descriptions.py:150
msgid ""
"DeepSeek's first-generation of reasoning models with comparable performance "
"to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on "
"Llama and Qwen."
msgstr ""
"DeepSeek 的第一代推理模型，性能与 OpenAI-o1 相当，包括六个从基于 Llama 和 "
"Qwen 的 DeepSeek-R1 提炼而来的大纲模型。"

#: src/available_models_descriptions.py:151
msgid ""
"A strong Mixture-of-Experts (MoE) language model with 671B total parameters "
"with 37B activated for each token."
msgstr ""
"一个强大的Mixture-of-Experts（MoE）语言模型，总参数量为671B，每个词令牌激活"
"37B参数。"

#: src/available_models_descriptions.py:152
msgid ""
"OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. "
"These models are on par with or better than equivalently sized fully open "
"models, and competitive with open-weight models such as Llama 3.1 on English "
"academic benchmarks."
msgstr ""
"OLMo 2 是一个新的家族，包括7B和13B参数的模型，训练数据量高达5万亿个词令牌。这"
"些模型与同等规模的完全开源模型相当或更优，并且在英语学术基准测试中与像 Llama "
"3.1 这样的开放权重模型竞争激烈。"

#: src/available_models_descriptions.py:153
msgid ""
"The smallest model in Cohere's R series delivers top-tier speed, efficiency, "
"and quality to build powerful AI applications on commodity GPUs and edge "
"devices."
msgstr ""
"Cohere R 系列中的最小模型提供了顶级的速度、效率和质量，使得在普通GPU和边缘设"
"备上构建强大的AI应用变得可能。"

#: src/available_models_descriptions.py:154
msgid ""
"A fully open-source family of reasoning models built using a dataset derived "
"by distilling DeepSeek-R1."
msgstr ""
"一个完全开源的推理模型家族，使用了从 DeepSeek-R1 提炼出的数据集构建而成。"

#: src/available_models_descriptions.py:155
msgid ""
"A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the "
"performance of OpenAI’s o1-preview with just 1.5B parameters on popular math "
"evaluations."
msgstr ""
"基于 DeepSeek-R1 提炼的 Qwen-1.5B 微调版本，在流行的数学评估中性能超越了 "
"OpenAI 的 o1-preview，仅使用1.5亿个参数。"

#: src/available_models_descriptions.py:156
msgid ""
"A version of the DeepSeek-R1 model that has been post trained to provide "
"unbiased, accurate, and factual information by Perplexity."
msgstr ""
"经过 Perplexity 后微调的 DeepSeek-R1 模型版本，能够提供\"无偏见、准确且事实"
"\"的信息。"

#: src/available_models_descriptions.py:157
msgid "The current, most capable model that runs on a single GPU."
msgstr "这是当前单GPU环境下性能最优的模型。"

#: src/available_models_descriptions.py:158
msgid ""
"Phi-4-mini brings significant enhancements in multilingual support, "
"reasoning, and mathematics, and now, the long-awaited function calling "
"feature is finally supported."
msgstr ""
"Phi-4-mini 模型在多语言处理、推理能力及数学计算性能上均有显著提升，并新增了对"
"函数调用机制的支持。"

#: src/available_models_descriptions.py:159
msgid ""
"A compact and efficient vision-language model, specifically designed for "
"visual document understanding, enabling automated content extraction from "
"tables, charts, infographics, plots, diagrams, and more."
msgstr ""
"一款紧凑高效的多模态视觉语言模型，专为视觉文档理解而设计，能够从表格、图表、"
"信息图、曲线图、示意图等多种视觉元素中自动提取内容。"

#: src/available_models_descriptions.py:160
msgid ""
"Granite-3.2 is a family of long-context AI models from IBM Granite fine-"
"tuned for thinking capabilities."
msgstr ""
"Granite-3.2 是 IBM Granite 系列的长上下文 AI 模型，经过微调以增强思维推理能"
"力。"

#: src/available_models_descriptions.py:161
msgid ""
"A new state-of-the-art version of the lightweight Command R7B model that "
"excels in advanced Arabic language capabilities for enterprises in the "
"Middle East and Northern Africa."
msgstr ""
"这是轻量级 Command R7B 模型的最新尖端版本，专为中东北非地区企业打造，在高级阿"
"拉伯语处理能力方面表现卓越。"

#: src/available_models_descriptions.py:162
msgid ""
"111 billion parameter model optimized for demanding enterprises that require "
"fast, secure, and high-quality AI"
msgstr "专为高要求企业优化的1110亿参数大模型，提供快速、安全且高质量的AI服务。"

#: src/available_models_descriptions.py:163
msgid ""
"EXAONE Deep exhibits superior capabilities in various reasoning tasks "
"including math and coding benchmarks, ranging from 2.4B to 32B parameters "
"developed and released by LG AI Research."
msgstr ""

#: src/available_models_descriptions.py:164
msgid ""
"Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-"
"art vision understanding and enhances long context capabilities up to 128k "
"tokens without compromising text performance."
msgstr ""

#: src/available_models_descriptions.py:165
msgid ""
"Cogito v1 Preview is a family of hybrid reasoning models by Deep Cogito that "
"outperform the best available open models of the same size, including "
"counterparts from LLaMA, DeepSeek, and Qwen across most standard benchmarks."
msgstr ""

#: src/available_models_descriptions.py:166
msgid ""
"DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a "
"1.5B version also available."
msgstr ""

#: src/instance_manager.py:30 src/instance_manager.py:366
msgid "Instance"
msgstr "实例"

#: src/instance_manager.py:60 src/instance_manager.py:69 src/window.ui:154
#: src/custom_widgets/chat_widget.py:423
msgid "New Chat"
msgstr "新对话"

#: src/instance_manager.py:76
msgid "Selecting tool to use..."
msgstr "正在选择使用工具…"

#: src/instance_manager.py:85
msgid "Using {}"
msgstr "正在使用 {}"

#: src/instance_manager.py:111
msgid "Tool Error"
msgstr "工具错误"

#: src/instance_manager.py:111
msgid "An error occurred while running tool"
msgstr "运行工具过程中发生错误"

#: src/instance_manager.py:114
msgid "Generating message..."
msgstr "正在生成消息..."

#: src/instance_manager.py:162 src/instance_manager.py:462
#: src/instance_manager.py:472 src/instance_manager.py:616
#: src/instance_manager.py:688 src/instance_manager.py:730
#: src/instance_manager.py:759 src/instance_manager.py:802
#: src/instance_manager.py:822 src/instance_manager.py:843
msgid "Instance Error"
msgstr "实例错误"

#: src/instance_manager.py:162
msgid "Message generation failed"
msgstr "消息生成失败"

#: src/instance_manager.py:218 src/window.ui:885
msgid "Name"
msgstr "名称"

#: src/instance_manager.py:226
msgid "Port"
msgstr "端口"

#: src/instance_manager.py:227
msgid "Which network port will '{}' use"
msgstr "'{}' 将会使用那哪一个网络端口"

#: src/instance_manager.py:241
msgid "Instance URL"
msgstr "实例 URL"

#: src/instance_manager.py:244 src/instance_manager.py:254
#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key (Unchanged)"
msgstr "API密钥（未更改）"

#: src/instance_manager.py:244 src/instance_manager.py:254
msgid "API Key (Optional)"
msgstr "API密钥（可选）"

#: src/instance_manager.py:257 src/instance_manager.py:259
msgid "API Key"
msgstr "API密钥"

#: src/instance_manager.py:267
msgid "Max Tokens"
msgstr "最大tokens数"

#: src/instance_manager.py:268
msgid ""
"Defines the maximum number of tokens (words + spaces) the AI can generate in "
"a response. More tokens allow longer replies but may take more time and cost "
"more."
msgstr ""
"定义了 AI 在响应中可以生成的最大 token 数（单词+空格）。更多的 token 允许更长"
"的回复，但可能需要更多的时间并产生更高的成本。"

#: src/instance_manager.py:283
msgid "Temperature"
msgstr "温度（随机性控制参数）"

#: src/instance_manager.py:284
msgid "Increasing the temperature will make the models answer more creatively."
msgstr "提高温度会使模型的回答更具创造性。"

#: src/instance_manager.py:299
msgid "Seed"
msgstr "种子值"

#: src/instance_manager.py:300
msgid ""
"Setting this to a specific number other than 0 will make the model generate "
"the same text for the same prompt."
msgstr "将其设置为除0以外的具体数字可以确保在相同提示下模型生成相同的文本。"

#: src/instance_manager.py:315
msgid "Overrides"
msgstr "覆盖设置"

#: src/instance_manager.py:315
msgid ""
"These entries are optional, they are used to troubleshoot GPU related "
"problems with Ollama."
msgstr "这些条目是可选的，它们用于排查与 Ollama 相关的 GPU 问题。"

#: src/instance_manager.py:333
msgid "Model Directory"
msgstr "模型目录"

#: src/instance_manager.py:335
msgid "Select Directory"
msgstr "选择目录"

#: src/instance_manager.py:346
msgid "Default Model"
msgstr "默认模型"

#: src/instance_manager.py:346
msgid "Model to select when starting a new chat."
msgstr "启动新聊天时选择的模型。"

#: src/instance_manager.py:348
msgid "Title Model"
msgstr "标题模型"

#: src/instance_manager.py:348
msgid "Model to use when generating a chat title."
msgstr "生成聊天标题时使用的模型。"

#: src/instance_manager.py:412 src/instance_manager.py:413
#: src/custom_widgets/message_widget.py:233
msgid "Save"
msgstr "保存"

#: src/instance_manager.py:462 src/instance_manager.py:688
#: src/instance_manager.py:730 src/instance_manager.py:759
msgid "Could not retrieve added models"
msgstr "无法检索到已添加的模型"

#: src/instance_manager.py:472
msgid "Could not retrieve available models"
msgstr "无法检索到可用的模型"

#: src/instance_manager.py:539
msgid "Ollama (Managed)"
msgstr "Ollama（托管版）"

#: src/instance_manager.py:547
msgid "Local AI instance managed directly by Alpaca"
msgstr "本地AI实例由 Alpaca 直接管理"

#: src/instance_manager.py:570
msgid "Alpaca Support"
msgstr "Alpaca 支持文档"

#: src/instance_manager.py:577
msgid "Model request too large for system"
msgstr "模型需求太大，超出系统处理能力"

#: src/instance_manager.py:580
msgid "AMD GPU detected but the extension is missing, Ollama will use CPU."
msgstr "检测到 AMD GPU，但未安装支持扩展，Ollama 将使用 CPU。"

#: src/instance_manager.py:582
msgid "AMD GPU detected but ROCm is missing, Ollama will use CPU."
msgstr "检测到 AMD GPU，但缺少 ROCm，Ollama 将使用 CPU。"

#: src/instance_manager.py:584
msgid "Using AMD GPU type '{}'"
msgstr "使用 AMD GPU 类型"

#: src/instance_manager.py:594
msgid "Integrated Ollama instance is not running"
msgstr "集成的 Ollama 实例未运行"

#: src/instance_manager.py:616
msgid "Managed Ollama instance failed to start"
msgstr "托管的 Ollama 实例启动失败"

#: src/instance_manager.py:619
msgid "Integrated Ollama instance is running"
msgstr "集成的 Ollama 实例正在运行"

#: src/instance_manager.py:624 src/instance_manager.py:625
msgid "Ollama Log"
msgstr "Ollama 日志"

#: src/instance_manager.py:637
msgid "Local or remote AI instance not managed by Alpaca"
msgstr "本地或远程AI实例不由Alpaca管理"

#: src/instance_manager.py:802 src/instance_manager.py:822
#: src/instance_manager.py:843
msgid "Could not retrieve models"
msgstr "无法获取模型列表"

#: src/instance_manager.py:811
msgid "Fireworks AI inference platform"
msgstr ""

#: src/instance_manager.py:831
msgid "Lambda Labs cloud inference API"
msgstr ""

#: src/instance_manager.py:852
msgid "Cerebras AI cloud inference API"
msgstr ""

#: src/instance_manager.py:858
msgid "Kluster AI cloud inference API"
msgstr ""

#: src/instance_manager.py:862
msgid "OpenAI Compatible Instance"
msgstr "兼容 OpenAI 的实例"

#: src/instance_manager.py:863
msgid "AI instance compatible with OpenAI library"
msgstr ""

#: src/instance_manager.py:885
msgid "Remove Instance?"
msgstr "移除实例？"

#: src/instance_manager.py:885
msgid "Are you sure you want to remove this instance?"
msgstr "您确定要移除这个实例吗？"

#: src/instance_manager.py:900
msgid "Edit Instance"
msgstr "编辑实例"

#: src/tool_manager.py:71
msgid "AI Description"
msgstr ""

#: src/tool_manager.py:72
msgid "The description the AI model will use to understand what the tool does."
msgstr ""

#: src/tool_manager.py:83
msgid "Arguments"
msgstr ""

#: src/tool_manager.py:84
msgid "Variables that are filled by the AI."
msgstr ""

#: src/tool_manager.py:97
msgid "Variables"
msgstr ""

#: src/tool_manager.py:98
msgid ""
"User filled values that the tool uses to work, the AI does not have access "
"to these variables at all."
msgstr ""

#: src/tool_manager.py:140 src/custom_widgets/dialog_widget.py:146
#: src/custom_widgets/dialog_widget.py:158
#: src/custom_widgets/dialog_widget.py:170
msgid "Accept"
msgstr "接受"

#: src/tool_manager.py:177
msgid "Gets the current date and/or time."
msgstr ""

#: src/tool_manager.py:211
msgid "Gets a recipe by the meal's name"
msgstr ""

#: src/tool_manager.py:224 src/tool_manager.py:281
msgid "YouTube Video"
msgstr ""

#: src/tool_manager.py:227 src/tool_manager.py:284
msgid "Source"
msgstr ""

#: src/tool_manager.py:262
msgid "Gets a list of food recipes by a specified category"
msgstr ""

#: src/tool_manager.py:307
msgid "Extracts an article from Wikipedia by it's title"
msgstr ""

#: src/tool_manager.py:349
msgid "Search for a term online using DuckDuckGo"
msgstr ""

#: src/tool_manager.py:365
msgid "Abstract Source"
msgstr ""

#: src/tool_manager.py:384
msgid "Official Website"
msgstr ""

#: src/tool_manager.py:432
msgid "Request to run a command using SSH to connect to the device"
msgstr ""

#: src/tool_manager.py:435
msgid "IP Address"
msgstr ""

#: src/tool_manager.py:440
msgid "Username"
msgstr ""

#: src/tool_manager.py:445
msgid "Network Port"
msgstr ""

#: src/tool_manager.py:462
msgid "Model Requested to Run Command"
msgstr ""

#: src/tool_manager.py:463
msgid "Command"
msgstr ""

#: src/tool_manager.py:465
msgid "Explanation"
msgstr ""

#: src/tool_manager.py:466
msgid "No explanation was provided"
msgstr ""

#: src/tool_manager.py:467
msgid "Make sure you understand what the command does before running it."
msgstr ""

#: src/window.ui:34
msgid "Welcome"
msgstr "欢迎！"

#: src/window.ui:46 src/window.ui:47
msgid "Previous"
msgstr "上一个"

#: src/window.ui:82
msgid "Welcome to Alpaca"
msgstr "欢迎来到 Alpaca"

#: src/window.ui:83
msgid "Powering your potential"
msgstr "助力您的潜力"

#: src/window.ui:91
msgid ""
"Alpaca and its developers are not liable for any damages to devices or "
"software resulting from the execution of code generated by an AI model. "
"Please exercise caution and review the code carefully before running it.\n"
"\n"
"Alpaca is distributed under GPL v3.0, this software comes with no warranty."
msgstr ""
"使用AI模型生成的代码执行导致的任何设备或软件损坏，Alpaca及其开发人员不承担任"
"何责任。请在运行代码前谨慎检查并仔细审核。\n"
"\n"
"Alpaca 按照 GPLv3.0 协议分发，本软件不提供任何形式的保障。"

#: src/window.ui:100
msgid "Effortless Code Execution"
msgstr "代码轻松执行"

#: src/window.ui:101
msgid ""
"Alpaca can run Python, C++, and even HTML (with a live server) right from "
"your conversations. Give it a try!"
msgstr ""
"Alpaca 可以直接从您的对话中运行Python、C++，甚至HTML（需要一个live服务器）。"
"试试看！"

#: src/window.ui:107
msgid "Private by Design"
msgstr "私密性设计"

#: src/window.ui:108
msgid ""
"With Alpaca, your conversations are saved locally on your device, so you can "
"be confident that your data is always secure and private."
msgstr ""
"使用 Alpaca，您的对话将保存在您设备的本地，因此您可以确保您的数据始终安全且私"
"密。"

#: src/window.ui:114
msgid "Local AI"
msgstr "本地 AI"

#: src/window.ui:115
msgid ""
"Alpaca works with AI providers such as Gemini and ChatGPT.  To run AI models "
"locally on your machine, you'll need to install Ollama within Alpaca. We've "
"made it super easy to do, so you can get started quickly!"
msgstr ""
"Alpaca 支持与 Gemini、ChatGPT 等 AI 服务商对接。若需在本地设备运行 AI 模型，"
"您只需在 Alpaca 中安装 Ollama 即可。我们已大幅简化安装流程，助您快速上手！"

#: src/window.ui:120 src/window.ui:121
msgid "Install Ollama"
msgstr "安装 Ollama"

#: src/window.ui:165
msgid "Menu"
msgstr "目录"

#: src/window.ui:187
msgid "Toggle Sidebar"
msgstr "切换侧边栏"

#: src/window.ui:194
msgid "Search Messages"
msgstr "搜索消息"

#: src/window.ui:211 src/window.ui:236 src/window.ui:1371
msgid "Manage Models"
msgstr "管理模型"

#: src/window.ui:232
msgid "Add Models"
msgstr "添加模型"

#: src/window.ui:249
msgid "Chat Menu"
msgstr "对话列表"

#: src/window.ui:262
msgid "Message search bar"
msgstr "消息搜索栏"

#: src/window.ui:271 src/window.ui:273
msgid "Search messages"
msgstr "搜索消息"

#: src/window.ui:289
msgid ""
"Warning: Power saver mode is enabled, this will slow down message generation"
msgstr "警告：省电模式已启用，消息生成速度将减慢"

#: src/window.ui:336 src/window.ui:1469
msgid "Attach File"
msgstr "附加文件"

#: src/window.ui:369 src/window.ui:1238
msgid "Use Speech Recognition"
msgstr ""

#: src/window.ui:404
msgid "Send Message"
msgstr "发送消息"

#: src/window.ui:423
msgid "Stop Message"
msgstr "停止消息"

#: src/window.ui:453
msgid "Instance Manager"
msgstr "实例管理器"

#: src/window.ui:468
msgid "No Instances Found"
msgstr "未找到任何实例"

#: src/window.ui:469
msgid "It looks a bit empty in here. Try adding an instance get started!"
msgstr "这里看起来有点空荡。试试添加一个实例开始使用吧！"

#: src/window.ui:498
msgid "Added Instances"
msgstr "已添加的实例"

#: src/window.ui:499
msgid ""
"Manage your AI instances, chats and messages are shared between instances "
"when generating responses."
msgstr "管理您的 AI 实例，在生成响应时，对话和交流会在不同实例之间共享。"

#: src/window.ui:535
msgid "Tool Manager"
msgstr "工具管理器"

#: src/window.ui:546
msgid "Available Tools"
msgstr "可用工具"

#: src/window.ui:547
msgid ""
"Functions that AI models might use when sending a message by selecting \"Use "
"Tools\" in the send button context menu."
msgstr ""
"当您在发送按钮的目录菜单中选择\"使用工具\"时，AI模型可能调用的功能模块。"

#: src/window.ui:566
msgid "Model Manager"
msgstr "模型管理器"

#: src/window.ui:604
msgid "Search Model"
msgstr "搜索模型"

#: src/window.ui:618
msgid "Model Manager Menu"
msgstr "模型管理菜单"

#: src/window.ui:631
msgid "Model search bar"
msgstr "模型搜索框"

#: src/window.ui:643 src/window.ui:645
msgid "Search models"
msgstr "搜索模型"

#: src/window.ui:652
msgid "Filter Models"
msgstr ""

#: src/window.ui:668
msgid "Added"
msgstr "已添加"

#: src/window.ui:678 src/window.ui:739 src/window.ui:793
msgid "No Models Found"
msgstr "未找到模型"

#: src/window.ui:679
msgid ""
"It looks a bit empty in here. Try downloading some models or change your AI "
"instance to get started!"
msgstr "这里看起来有点空荡。试试下载一些模型或更改您的 AI 实例开始使用吧！"

#: src/window.ui:682 src/window.ui:692 src/window.ui:1367
msgid "Manage Instances"
msgstr "管理实例"

#: src/window.ui:740 src/window.ui:794
msgid ""
"Looks like we’re fresh out of models for that search. Try tweaking your "
"keywords, or maybe explore something new!"
msgstr ""
"看来没有找到符合条件的模型。您可以尝试调整关键词，或者探索一些新的内容！"

#: src/window.ui:752
msgid "Available"
msgstr "可获取"

#: src/window.ui:806
msgid "Creator"
msgstr "创建者"

#: src/window.ui:817
msgid "Model Creator"
msgstr "模型创建者"

#: src/window.ui:818
msgid "Select a method of importing a model to continue"
msgstr "请选择一种导入模型的方法继续："

#: src/window.ui:830
msgid "GGUF File"
msgstr "GGUF 文件"

#: src/window.ui:841
msgid "Existing Model"
msgstr "已存在的模型"

#: src/window.ui:859
msgid "Identity"
msgstr "识别信息"

#: src/window.ui:862
msgid "Base"
msgstr "基础模型"

#: src/window.ui:869
msgid "Profile Picture"
msgstr "简介图片"

#: src/window.ui:874
msgid "Open File"
msgstr "打开文件"

#: src/window.ui:890 src/custom_widgets/model_manager_widget.py:257
msgid "Tag"
msgstr "标签"

#: src/window.ui:897 src/custom_widgets/model_manager_widget.py:274
msgid "Context"
msgstr "上下文"

#: src/window.ui:898
msgid ""
"Describe the desired behavior of the model in its primary language "
"(typically English)."
msgstr "用模型的主要语言（通常是英语）描述您希望的模型的行为。"

#: src/window.ui:926
msgid "Behavior"
msgstr "行为"

#: src/window.ui:929
msgid "Imagination"
msgstr "想象力"

#: src/window.ui:930
msgid "A higher number results in more diverse answers from the model. (top_k)"
msgstr "较高的数字会导致模型生成更多样化的回答。（top_k）"

#: src/window.ui:944
msgid "Focus"
msgstr "专注力"

#: src/window.ui:945
msgid "A higher number widens the amount of possible answers. (top_p)"
msgstr "较高的数字会增加可能的答案范围。（top_p）"

#: src/window.ui:978 src/window.ui:986
msgid "Add Model"
msgstr "添加模型"

#: src/window.ui:1020 src/window.ui:1381
msgid "Preferences"
msgstr "首选项"

#: src/window.ui:1028
msgid "Run Alpaca In Background"
msgstr "在后台运行 Alpaca"

#: src/window.ui:1034
msgid "Show Power Saver Warning"
msgstr "显示省电警告"

#: src/window.ui:1035
msgid "When running a managed Ollama instance"
msgstr ""

#: src/window.ui:1041
msgid "Zoom"
msgstr "缩放"

#: src/window.ui:1058
msgid "Auto Send Message After Talking"
msgstr ""

#: src/window.ui:1064
msgid "Speech Recognition Language"
msgstr ""

#: src/window.ui:1074
msgid "Text to Speech Voice"
msgstr ""

#: src/window.ui:1086
msgid "Delete All Chats"
msgstr "删除所有对话"

#: src/window.ui:1098
msgid "Notice"
msgstr "注意"

#: src/window.ui:1118
msgid ""
"Hey Alpaca users! We're so excited to bring you a fresh update packed with "
"awesome new features to explore! Get ready to experience Alpaca in a whole "
"new way!"
msgstr ""

#: src/window.ui:1125
msgid "Smart Tools"
msgstr ""

#: src/window.ui:1126
msgid ""
"Supported AI models can use handy tools to grab information both locally and "
"online. Head over to the brand new \"Tool Manager\" to toggle them on or off."
msgstr ""

#: src/window.ui:1133
msgid "Talk to Models"
msgstr ""

#: src/window.ui:1134
msgid ""
"You can now dictate your messages using local speech recognition. It's super "
"convenient! You can even customize your language and other settings in the "
"Preferences dialog."
msgstr ""

#: src/window.ui:1141
msgid "Find Models Faster"
msgstr ""

#: src/window.ui:1142
msgid ""
"Browsing through your Ollama models just got easier! We've added the ability "
"to filter models by their categories in the Model Manager. Now you can "
"quickly find exactly the model you're looking for."
msgstr ""

#: src/window.ui:1149
msgid "Math Rendering"
msgstr ""

#: src/window.ui:1150
msgid ""
"We've improved how LaTeX equations are rendered in messages, making them "
"look cleaner and more consistent. Your mathematical discussions will be "
"clearer than ever!"
msgstr ""

#: src/window.ui:1157
msgid "More Instances"
msgstr ""

#: src/window.ui:1158
msgid ""
"Get ready to connect Alpaca to a whole universe of AI providers! We've added "
"support for over 5 new AI instance providers, including Anthropic, "
"OpenRouter, and Fireworks. The possibilities are endless!"
msgstr ""

#: src/window.ui:1165
msgid "Attachment Enhancement"
msgstr ""

#: src/window.ui:1166
msgid ""
"You can now attach and ask questions about even more file types, "
"including .docx, .pptx, and .xlsx! Plus, when you preview an attachment, "
"you'll see it with rich text styling, making it easier to understand the "
"content before you send it."
msgstr ""

#: src/window.ui:1187
msgid "Quick ask dialog"
msgstr "快速问答框"

#: src/window.ui:1199
msgid "Save Conversation to Alpaca"
msgstr "保存对话至 Alpace"

#: src/window.ui:1268
msgid "Terminal dialog"
msgstr "终端对话框"

#: src/window.ui:1271
msgid "Terminal"
msgstr "终端"

#: src/window.ui:1285
msgid "Open Environment Directory"
msgstr "打开环境目录"

#: src/window.ui:1306
msgid "File preview dialog"
msgstr "文件预览对话框"

#: src/window.ui:1317
msgid "Open With Default App"
msgstr "用默认应用打开"

#: src/window.ui:1325
msgid "Remove Attachment"
msgstr "移除附件"

#: src/window.ui:1359
msgid "Start Quick Ask"
msgstr ""

#: src/window.ui:1363
msgid "Import Chat"
msgstr "导入对话"

#: src/window.ui:1375
msgid "Manage Tools"
msgstr ""

#: src/window.ui:1385
msgid "Keyboard Shortcuts"
msgstr "快捷键"

#: src/window.ui:1389
msgid "About Alpaca"
msgstr "关于 Alpaca"

#: src/window.ui:1397 src/window.ui:1431
msgid "Rename Chat"
msgstr "重命名对话"

#: src/window.ui:1401 src/window.ui:1435
msgid "Duplicate Chat"
msgstr "复制对话"

#: src/window.ui:1411 src/window.ui:1445
msgid "Delete Chat"
msgstr "删除对话"

#: src/window.ui:1419
msgid "Reload Added Models"
msgstr "重载已添加的模型"

#: src/window.ui:1423
msgid "Download Model From Name"
msgstr "根据名称下载模型"

#: src/window.ui:1453
msgid "Send as User"
msgstr "以用户身份发送"

#: src/window.ui:1457
msgid "Send as System"
msgstr "以系统身份发送"

#: src/window.ui:1461 src/gtk/help-overlay.ui:133
msgid "Use Tools"
msgstr ""

#: src/window.ui:1473
msgid "Attach Website"
msgstr "附加网站"

#: src/window.ui:1477
msgid "Attach YouTube Captions"
msgstr "附加 YouTube 字幕"

#: src/alpaca_search_provider.py.in:43
msgid "Open chat"
msgstr "打开对话"

#: src/alpaca_search_provider.py.in:44
msgid "Quick ask"
msgstr "快速问答"

#: src/generic_actions.py:79
msgid "An error occurred while extracting text from the website"
msgstr "从网站提取文本时发生错误"

#: src/gtk/help-overlay.ui:11
msgctxt "shortcut window"
msgid "General"
msgstr "通用"

#: src/gtk/help-overlay.ui:14
msgctxt "shortcut window"
msgid "Show Shortcuts"
msgstr "显示快捷方式"

#: src/gtk/help-overlay.ui:20
msgctxt "shortcut window"
msgid "Preferences"
msgstr "首选项"

#: src/gtk/help-overlay.ui:26
msgctxt "shortcut window"
msgid "Quick Ask"
msgstr ""

#: src/gtk/help-overlay.ui:32
msgctxt "shortcut window"
msgid "Model Manager"
msgstr "模型管理器"

#: src/gtk/help-overlay.ui:38
msgctxt "shortcut window"
msgid "Instance Manager"
msgstr "实例管理器"

#: src/gtk/help-overlay.ui:44
msgctxt "shortcut window"
msgid "Action Manager"
msgstr "行为管理器"

#: src/gtk/help-overlay.ui:50
msgctxt "shortcut window"
msgid "Toggle Sidebar"
msgstr "切换侧边栏"

#: src/gtk/help-overlay.ui:56
msgctxt "shortcut window"
msgid "Quit"
msgstr "退出"

#: src/gtk/help-overlay.ui:64
msgctxt "shortcut window"
msgid "Chat Management"
msgstr "对话管理"

#: src/gtk/help-overlay.ui:67
msgctxt "shortcut window"
msgid "Create Chat"
msgstr "创建对话"

#: src/gtk/help-overlay.ui:73
msgctxt "shortcut window"
msgid "Delete Chat"
msgstr "删除对话"

#: src/gtk/help-overlay.ui:79
msgctxt "shortcut window"
msgid "Clear Chat"
msgstr "清除对话"

#: src/gtk/help-overlay.ui:85
msgctxt "shortcut window"
msgid "Rename Chat"
msgstr "重命名对话"

#: src/gtk/help-overlay.ui:91
msgctxt "shortcut window"
msgid "Toggle Searchbars"
msgstr "切换搜索栏"

#: src/gtk/help-overlay.ui:99
msgctxt "shortcut window"
msgid "Message Entry"
msgstr "消息输入框"

#: src/gtk/help-overlay.ui:102
msgid "Copy"
msgstr "复制"

#: src/gtk/help-overlay.ui:108
msgid "Paste"
msgstr "粘贴"

#: src/gtk/help-overlay.ui:114
msgid "Open Emoji Menu"
msgstr "打开 Emoji 目录"

#: src/gtk/help-overlay.ui:120
msgid "Insert new line"
msgstr "插入新行"

#: src/gtk/help-overlay.ui:126
msgid "Send Message as System"
msgstr "以系统身份发送消息"

#: src/gtk/help-overlay.ui:127
msgid "System messages are taken as literal instructions by models"
msgstr "系统消息会被模型视为严格的指令"

#: src/gtk/help-overlay.ui:134
msgid "Ask model to use tools to generate a message"
msgstr ""

#: src/gtk/help-overlay.ui:140
msgid "Send Message as User"
msgstr "以用户身份发送消息"

#: src/custom_widgets/chat_widget.py:92
msgid "Try one of these prompts"
msgstr "试试这些提示"

#: src/custom_widgets/chat_widget.py:121
msgid "Send prompt: '{}'"
msgstr "发送提示： '{}'"

#: src/custom_widgets/chat_widget.py:127
msgid "Refresh Prompts"
msgstr "刷新提示词"

#: src/custom_widgets/chat_widget.py:185
msgid "Chat exported successfully"
msgstr "聊天记录已成功导出"

#: src/custom_widgets/chat_widget.py:205
msgid "User"
msgstr "用户"

#: src/custom_widgets/chat_widget.py:209
#: src/custom_widgets/message_widget.py:680
msgid "System"
msgstr "系统"

#: src/custom_widgets/chat_widget.py:297
msgid "Regenerate Response"
msgstr "重新生成回复"

#: src/custom_widgets/chat_widget.py:461
msgid "Copy of {}"
msgstr "{} 的副本"

#: src/custom_widgets/chat_widget.py:474
msgid "Chat imported successfully"
msgstr "对话记录已成功导入"

#: src/custom_widgets/message_widget.py:88
msgid "Save Message"
msgstr "保存消息"

#: src/custom_widgets/message_widget.py:129
#: src/custom_widgets/message_widget.py:268
msgid "Message edited successfully"
msgstr "更改消息成功"

#: src/custom_widgets/message_widget.py:155
msgid "Response message"
msgstr "回复消息"

#: src/custom_widgets/message_widget.py:157
msgid "System message"
msgstr "系统消息"

#: src/custom_widgets/message_widget.py:159
msgid "User message"
msgstr "用户消息"

#: src/custom_widgets/message_widget.py:218
msgid "{}Code Block"
msgstr "{} 代码块"

#: src/custom_widgets/message_widget.py:220
msgid "Code Block"
msgstr "代码块"

#: src/custom_widgets/message_widget.py:221
#: src/custom_widgets/message_widget.py:530
msgid "Copy Message"
msgstr "复制消息"

#: src/custom_widgets/message_widget.py:225
msgid "Edit Code Block"
msgstr "编辑代码块"

#: src/custom_widgets/message_widget.py:237
#: src/custom_widgets/message_widget.py:313
msgid "Run Script"
msgstr "运行脚本"

#: src/custom_widgets/message_widget.py:277
msgid "Code copied to the clipboard"
msgstr "代码已复制到剪切板"

#: src/custom_widgets/message_widget.py:314
msgid ""
"Make sure you understand what this script does before running it, Alpaca is "
"not responsible for any damages to your device or data"
msgstr ""
"在运行该脚本之前，请确保您已了解其功能，Alpaca 不对设备或数据的任何损坏负责"

#: src/custom_widgets/message_widget.py:316
msgid "Execute"
msgstr "执行"

#: src/custom_widgets/message_widget.py:395
#: src/custom_widgets/message_widget.py:397
msgid "Image"
msgstr "图像"

#: src/custom_widgets/message_widget.py:406
#: src/custom_widgets/message_widget.py:418
msgid "Missing Image"
msgstr "无图像"

#: src/custom_widgets/message_widget.py:420
msgid "Missing image"
msgstr "无图像"

#: src/custom_widgets/message_widget.py:493
msgid "Copy Equation"
msgstr "复制公式"

#: src/custom_widgets/message_widget.py:500
msgid "Equation copied to the clipboard"
msgstr "公式已复制到剪贴板。"

#: src/custom_widgets/message_widget.py:520
msgid "Remove Message"
msgstr "移除消息"

#: src/custom_widgets/message_widget.py:540
msgid "Edit Message"
msgstr "编辑消息"

#: src/custom_widgets/message_widget.py:551
msgid "Regenerate Message"
msgstr "重新生成消息"

#: src/custom_widgets/message_widget.py:563
msgid "Dictate Message"
msgstr ""

#: src/custom_widgets/message_widget.py:583
msgid "Message copied to the clipboard"
msgstr "消息已复制到剪切板"

#: src/custom_widgets/message_widget.py:648
msgid "Message cannot be regenerated while receiving a response"
msgstr "当收到回复时无法重新生成信息"

#: src/custom_widgets/message_widget.py:957
msgid "Thought"
msgstr "思考\t"

#: src/custom_widgets/model_manager_widget.py:67
#: src/custom_widgets/model_manager_widget.py:69
msgid "Stop Download"
msgstr "停止下在"

#: src/custom_widgets/model_manager_widget.py:74
msgid "Stop Download?"
msgstr "停止下载？"

#: src/custom_widgets/model_manager_widget.py:75
msgid "Are you sure you want to stop pulling '{}'?"
msgstr "你确定要停止拉取 '{}' 吗？"

#: src/custom_widgets/model_manager_widget.py:77
msgid "Stop"
msgstr "停止"

#: src/custom_widgets/model_manager_widget.py:147
msgid "Model Manager Error"
msgstr "模型管理错误"

#: src/custom_widgets/model_manager_widget.py:147
msgid "An error occurred whilst pulling '{}'"
msgstr "从远程获取 '{}' 时发生错误。"

#: src/custom_widgets/model_manager_widget.py:172
msgid "Download Completed"
msgstr "下载完成"

#: src/custom_widgets/model_manager_widget.py:172
msgid "Model '{}' downloaded successfully."
msgstr "模型 '{}' 下载成功。"

#: src/custom_widgets/model_manager_widget.py:235
msgid "Change Profile Picture"
msgstr "更改简介图片"

#: src/custom_widgets/model_manager_widget.py:258
msgid "Family"
msgstr "系列"

#: src/custom_widgets/model_manager_widget.py:259
msgid "Parameter Size"
msgstr "参数大小"

#: src/custom_widgets/model_manager_widget.py:260
msgid "Quantization Level"
msgstr "量化级别"

#: src/custom_widgets/model_manager_widget.py:263
msgid "Parent Model"
msgstr "父模型"

#: src/custom_widgets/model_manager_widget.py:266
#: src/custom_widgets/model_manager_widget.py:268
msgid "Modified At"
msgstr "修改于"

#: src/custom_widgets/model_manager_widget.py:276
msgid "Description"
msgstr "描述"

#: src/custom_widgets/model_manager_widget.py:424
msgid "Change"
msgstr "更改"

#: src/custom_widgets/model_manager_widget.py:427
msgid "Model Profile Picture"
msgstr "模型简介图片"

#: src/custom_widgets/model_manager_widget.py:427
msgid "What do you want to do with the model's profile picture?"
msgstr "您想如何处理模型的简介照片？"

#: src/custom_widgets/model_manager_widget.py:449
msgid "Create Child"
msgstr "创建子模型"

#: src/custom_widgets/model_manager_widget.py:457
msgid "Remove Model"
msgstr "移除模型"

#: src/custom_widgets/model_manager_widget.py:460
msgid "Remove Model?"
msgstr "要移除该模型吗？"

#: src/custom_widgets/model_manager_widget.py:461
msgid "Are you sure you want to remove '{}'?"
msgstr "您确定要移除 '{}' 吗？"

#: src/custom_widgets/model_manager_widget.py:475
msgid "Multilingual"
msgstr "多语言"

#: src/custom_widgets/model_manager_widget.py:476
msgid "Code"
msgstr "代码"

#: src/custom_widgets/model_manager_widget.py:477
msgid "Math"
msgstr "数学"

#: src/custom_widgets/model_manager_widget.py:478
msgid "Vision"
msgstr "视觉"

#: src/custom_widgets/model_manager_widget.py:479
msgid "Embedding"
msgstr "嵌入"

#: src/custom_widgets/model_manager_widget.py:480
msgid "Tools"
msgstr ""

#: src/custom_widgets/model_manager_widget.py:481
msgid "Small"
msgstr "小型"

#: src/custom_widgets/model_manager_widget.py:482
msgid "Medium"
msgstr "中型"

#: src/custom_widgets/model_manager_widget.py:483
msgid "Big"
msgstr "大型"

#: src/custom_widgets/model_manager_widget.py:484
msgid "Huge"
msgstr "巨型"

#: src/custom_widgets/model_manager_widget.py:573
msgid ""
"By downloading this model you accept the license agreement available on the "
"model's website"
msgstr "通过下载此模型，您将接受在该模型网站上提供的许可协议。"

#: src/custom_widgets/terminal_widget.py:80
msgid "Setting up Python environment..."
msgstr "设置 Python 环境……"

#: src/custom_widgets/terminal_widget.py:98
msgid "Compiling C++ script..."
msgstr "正在编译C++脚本..."

#: src/custom_widgets/terminal_widget.py:111
msgid "Running local web server"
msgstr "运行本地网页服务器"

#: src/custom_widgets/terminal_widget.py:136
msgid "Using Flatpak contained shell"
msgstr "使用 Flatpak 内置的 shell 环境"

#: src/custom_widgets/terminal_widget.py:136
msgid "Using SSH to run command"
msgstr ""

#: src/custom_widgets/terminal_widget.py:142
msgid "Script Exited"
msgstr "脚本已退出"

#~ msgid "Clear Chat?"
#~ msgstr "清除对话记录？"

#~ msgid "Are you sure you want to clear the chat?"
#~ msgstr "你确定你想要清除对话记录吗？"

#~ msgid "Clear"
#~ msgstr "清除"

#~ msgid "Clear Chat"
#~ msgstr "清除对话"

#~ msgid "Removal of Ollama"
#~ msgstr "移除 Ollama"

#~ msgid ""
#~ "Hey there! With Alpaca 5.1.0, we're making some changes. To keep using "
#~ "Ollama directly within Alpaca, you'll just need to install our new Ollama "
#~ "extension. Don't worry, your models remain untouched!"
#~ msgstr ""
#~ "你好！在 Alpaca 5.1.0 中，我们进行了一些更改。要继续直接在Alpaca中使用 "
#~ "Ollama，您只需安装我们的新 Ollama 扩展即可。别担心，您的模型不会受到影响！"

#~ msgid "Regenerate Equation"
#~ msgstr "重新生成公式"

#~ msgid "LaTeX Equation"
#~ msgstr "Latex 公式"

#~ msgid "Actions"
#~ msgstr "行为"

#~ msgid "Which network port will Ollama use"
#~ msgstr "Ollama 将使用哪个网络端口？"

#~ msgid "Built in Ollama instance"
#~ msgstr "内置 Ollama 实例"

#~ msgid "Visit Website"
#~ msgstr "访问网站"

#~ msgid ""
#~ "QwQ is an experimental research model focused on advancing AI reasoning "
#~ "capabilities."
#~ msgstr "QwQ 是一个实验研究模型，重点在于提高人工智能的推理能力。"

#~ msgid "Your AI, Your Choice"
#~ msgstr "你的 AI 你做主！"

#~ msgid ""
#~ "Alpaca includes Ollama by default, giving you instant access to AI. "
#~ "Customize your experience further by connecting to Google Gemini, OpenAI "
#~ "ChatGPT, Together.AI, and more."
#~ msgstr ""
#~ "Alpaca 默认包含 Ollama，为您提供即时访问AI的功能。您可以进一步自定义体验，"
#~ "连接到 Google Gemini、OpenAI ChatGPT、Together.AI 等更多服务。"

#~ msgid ""
#~ "It looks like you don't have any models downloaded yet. Download models "
#~ "to get started!"
#~ msgstr "看起来你还没有下载任何模型。快去下载一些模型开始吧！"
